/*! For license information please see lib-tfjs-core.c9ae1b3f71e1ac910e99.js.LICENSE.txt */
(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{103:function(e,t,a){"use strict";(function(e){a(20),a(28),a(25),a(8),a(69),a(38),a(5);var n=a(0);a.d(t,"a",(function(){return n.lh}));var s=a(2);a(7);function r(e){return new Promise((e=>setTimeout(e))).then(e)}class c{constructor(e){if(!Object(n.Bf)().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(c.URL_SCHEME)&&(e=e.slice(c.URL_SCHEME.length)),null!=e&&0!==e.length||(e="model"),this.modelTopologyFileName=e+".json",this.weightDataFileName=e+".weights.bin"}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=window.URL.createObjectURL(new Blob([e.weightData],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const a=[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}],s={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:a};null!=e.signature&&(s.signature=e.signature),null!=e.userDefinedMetadata&&(s.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(s.modelInitializer=e.modelInitializer);const c=window.URL.createObjectURL(new Blob([JSON.stringify(s)],{type:"application/json"})),i=null==this.jsonAnchor?document.createElement("a"):this.jsonAnchor;if(i.download=this.modelTopologyFileName,i.href=c,await r((()=>i.dispatchEvent(new MouseEvent("click")))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=t,await r((()=>e.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:Object(n.Gc)(e)}}}}c.URL_SCHEME="downloads://";class i{constructor(e){if(null==e||e.length<1)throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);this.files=e}async load(){const e=this.files[0],t=this.files.slice(1);return new Promise(((a,s)=>{const r=new FileReader;r.onload=r=>{const c=JSON.parse(r.target.result),i=c.modelTopology;if(null==i)return void s(new Error(`modelTopology field is missing from file ${e.name}`));0===t.length&&a({modelTopology:i});const o=c.weightsManifest;if(null==o)return void s(new Error(`weightManifest field is missing from file ${e.name}`));let l;try{this.checkManifestAndWeightFiles(o,t)}catch(e){return void s(e)}const b=[],h=[],u=[];o.forEach((e=>{e.paths.forEach((e=>{h.push(e),u.push(null)})),b.push(...e.weights)})),o.forEach((e=>{e.paths.forEach((e=>{const t=new FileReader;t.onload=t=>{const s=t.target.result,r=h.indexOf(e);if(u[r]=s,-1===u.indexOf(null)){const e={modelTopology:i,weightSpecs:b,weightData:Object(n.Hc)(u),format:c.format,generatedBy:c.generatedBy,convertedBy:c.convertedBy};null!=c.signature&&(e.signature=c.signature),null!=c.userDefinedMetadata&&(e.userDefinedMetadata=c.userDefinedMetadata),null!=c.modelInitializer&&(e.modelInitializer=c.modelInitializer),a(e)}},t.onerror=t=>s(`Failed to weights data from file of path '${e}'.`),t.readAsArrayBuffer(l[e])}))}))},r.onerror=t=>s(`Failed to read model topology and weights manifest JSON from file '${e.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),r.readAsText(e)}))}checkManifestAndWeightFiles(e,t){const a=[],s=t.map((e=>Object(n.Xg)(e.name))),r={};for(const c of e)c.paths.forEach((e=>{const c=Object(n.Xg)(e);if(-1!==a.indexOf(c))throw new Error(`Duplicate file basename found in weights manifest: '${c}'`);if(a.push(c),-1===s.indexOf(c))throw new Error(`Weight file with basename '${c}' is not provided.`);r[e]=t[s.indexOf(c)]}));if(a.length!==t.length)throw new Error(`Mismatch in the number of files in weights manifest (${a.length}) and the number of weight files provided (${t.length}).`);return r}}n.Fc.registerSaveRouter((e=>Object(n.Bf)().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(c.URL_SCHEME)?function(e="model"){return new c(e)}(e.slice(c.URL_SCHEME.length)):null));class o{constructor(e){this.modelArtifacts=e}async load(){return this.modelArtifacts}}class l{constructor(e){this.saveHandler=e}async save(e){return this.saveHandler(e)}}s.E,n.Hc,n.Yb,n.Yg,n.Xb,n.Gc,n.Zb,s.b,s.c,s.d,n.Zg,n.ah,s.e,n.bh,n.ch,n.dh,n.eh;Object(n.Mc)({confusionMatrix_:function(e,t,a){const s=Object(n.Lc)(e,"labels","confusionMatrix"),r=Object(n.Lc)(t,"predictions","confusionMatrix");Object(n.F)(null==a||a>0&&Number.isInteger(a),(()=>`If provided, numClasses must be a positive integer, but got ${a}`)),Object(n.F)(1===s.rank,(()=>`Expected the rank of labels to be 1, but got ${s.rank}`)),Object(n.F)(1===r.rank,(()=>`Expected the rank of predictions to be 1, but got ${r.rank}`)),Object(n.F)(s.shape[0]===r.shape[0],(()=>`Mismatch in the number of examples: ${s.shape[0]} vs. ${r.shape[0]}. Labels and predictions should have the same number of elements.`)),Object(n.F)(a>0&&Number.isInteger(a),(()=>`numClasses is required to be a positive integer, but got ${a}`));const c=Object(n.Bb)(Object(n.Cb)(s,"int32"),a),i=Object(n.Bb)(Object(n.Cb)(r,"int32"),a),o=Object(n.O)(c),l=Object(n.P)(o,i);return Object(n.Cb)(l,"int32")}});class b{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class h{constructor(){this.classNameMap={}}static getMap(){return null==h.instance&&(h.instance=new h),h.instance}static register(e){h.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function u(e){Object(n.F)(null!=e.className,(()=>"Class being registered does not have the static className property defined.")),Object(n.F)("string"==typeof e.className,(()=>"className is required to be a string, but got type "+typeof e.className)),Object(n.F)(e.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),h.register(e)}Object(n.Mc)({basicLSTMCell_:function(e,t,a,s,r,c){const i=Object(n.Lc)(e,"forgetBias","basicLSTMCell"),o=Object(n.Lc)(t,"lstmKernel","basicLSTMCell"),l=Object(n.Lc)(a,"lstmBias","basicLSTMCell"),b=Object(n.Lc)(s,"data","basicLSTMCell"),h=Object(n.Lc)(r,"c","basicLSTMCell"),u=Object(n.Lc)(c,"h","basicLSTMCell"),m=Object(n.K)([b,u],1),d=Object(n.P)(m,o),O=Object(n.oh)(d,l),j=O.shape[0],g=O.shape[1]/4,p=[j,g],f=Object(n.pb)(O,[0,0],p),v=Object(n.pb)(O,[0,g],p),k=Object(n.pb)(O,[0,2*g],p),M=Object(n.pb)(O,[0,3*g],p),y=Object(n.oh)(Object(n.mh)(Object(n.d)(f),Object(n.Ah)(v)),Object(n.mh)(h,Object(n.d)(Object(n.oh)(i,k))));return[y,Object(n.mh)(Object(n.Ah)(y),Object(n.d)(M))]}});Object(n.Mc)({batchNorm2d_:function(e,t,a,s,r,c){const i=Object(n.Lc)(e,"x","batchNorm"),o=Object(n.Lc)(t,"mean","batchNorm"),l=Object(n.Lc)(a,"variance","batchNorm");let b,h;return null!=r&&(b=Object(n.Lc)(r,"scale","batchNorm")),null!=s&&(h=Object(n.Lc)(s,"offset","batchNorm")),Object(n.F)(2===i.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),Object(n.F)(2===o.rank||1===o.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),Object(n.F)(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=b&&Object(n.F)(2===b.rank||1===b.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${b.rank}.`)),null!=h&&Object(n.F)(2===h.rank||1===h.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${h.rank}.`)),Object(n.T)(i,o,l,h,b,c)}});Object(n.Mc)({batchNorm3d_:function(e,t,a,s,r,c){const i=Object(n.Lc)(e,"x","batchNorm"),o=Object(n.Lc)(t,"mean","batchNorm"),l=Object(n.Lc)(a,"variance","batchNorm");let b,h;return null!=r&&(b=Object(n.Lc)(r,"scale","batchNorm")),null!=s&&(h=Object(n.Lc)(s,"offset","batchNorm")),Object(n.F)(3===i.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),Object(n.F)(3===o.rank||1===o.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),Object(n.F)(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=b&&Object(n.F)(3===b.rank||1===b.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${b.rank}.`)),null!=h&&Object(n.F)(3===h.rank||1===h.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${h.rank}.`)),Object(n.T)(i,o,l,h,b,c)}});Object(n.Mc)({batchNorm4d_:function(e,t,a,s,r,c){const i=Object(n.Lc)(e,"x","batchNorm"),o=Object(n.Lc)(t,"mean","batchNorm"),l=Object(n.Lc)(a,"variance","batchNorm");let b,h;return null!=r&&(b=Object(n.Lc)(r,"scale","batchNorm")),null!=s&&(h=Object(n.Lc)(s,"offset","batchNorm")),Object(n.F)(4===i.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),Object(n.F)(4===o.rank||1===o.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),Object(n.F)(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=b&&Object(n.F)(4===b.rank||1===b.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${b.rank}.`)),null!=h&&Object(n.F)(4===h.rank||1===h.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${h.rank}.`)),Object(n.T)(i,o,l,h,b,c)}});Object(n.Mc)({concat1d_:function(e){return Object(n.K)(e,0)}});Object(n.Mc)({concat3d_:function(e,t){return Object(n.K)(e,t)}});Object(n.Mc)({concat4d_:function(e,t){return Object(n.K)(e,t)}});Object(n.Mc)({conv3dTranspose_:function(e,t,a,s,r){const c=Object(n.Lc)(e,"x","conv3dTranspose"),i=Object(n.Lc)(t,"filter","conv3dTranspose");return Object(n.gh)(a,c,i,s,r)}});Object(n.Mc)({diag_:function(e){const t={x:Object(n.Lc)(e,"x","diag")};return n.Oc.runKernel(n.He,t)}});Object(n.Mc)({moments_:function(e,t=null,a=!1){e=Object(n.Lc)(e,"x","moments");const s=Object(n.ke)(t,e.shape),r=Object(n.bb)(e,s,a);let c=r.shape;a||(c=Object(n.Pd)(r.shape,s));const i=Object(n.Bh)(Object(n.Pb)(Object(n.Cb)(e,"float32"),Object(n.N)(r,c)));return{mean:r,variance:Object(n.bb)(i,s,a)}}});Object(n.Mc)({multiRNNCell_:function(e,t,a,s){const r=Object(n.Lc)(t,"data","multiRNNCell"),c=Object(n.hh)(a,"c","multiRNNCell"),i=Object(n.hh)(s,"h","multiRNNCell");let o=r;const l=[];for(let t=0;t<e.length;t++){const a=e[t](o,c[t],i[t]);l.push(a[0]),l.push(a[1]),o=a[1]}const b=[],h=[];for(let e=0;e<l.length;e+=2)b.push(l[e]),h.push(l[e+1]);return[b,h]}});Object(n.Mc)({outerProduct_:function(e,t){const a=Object(n.Lc)(e,"v1","outerProduct"),s=Object(n.Lc)(t,"v2","outerProduct");Object(n.F)(1===a.rank&&1===s.rank,(()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${a.rank} and ${s.rank}.`));const r=Object(n.N)(a,[-1,1]),c=Object(n.N)(s,[1,-1]);return Object(n.P)(r,c)}});Object(n.Mc)({pad1d_:function(e,t,a=0){return Object(n.F)(2===t.length,(()=>"Invalid number of paddings. Must be length of 2.")),Object(n.Tb)(e,[t],a)}});Object(n.Mc)({pad2d_:function(e,t,a=0){return Object(n.F)(2===t.length&&2===t[0].length&&2===t[1].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Object(n.Tb)(e,t,a)}});Object(n.Mc)({pad3d_:function(e,t,a=0){return Object(n.F)(3===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Object(n.Tb)(e,t,a)}});Object(n.Mc)({pad4d_:function(e,t,a=0){return Object(n.F)(4===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length&&2===t[3].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),Object(n.Tb)(e,t,a)}});Object(n.Mc)({rand_:function(e,t,a){const s=Object(n.Ec)(e);let r=null;if(null==a||"float32"===a)r=new Float32Array(s);else if("int32"===a)r=new Int32Array(s);else{if("bool"!==a)throw new Error(`Unknown data type ${a}`);r=new Uint8Array(s)}for(let e=0;e<s;e++)r[e]=t();return n.Oc.makeTensor(r,e,a)}});Object(n.Mc)({randomGamma_:function(e,t,a=1,r="float32",c){if(null==a&&(a=1),null==r&&(r="float32"),"float32"!==r&&"int32"!==r)throw new Error(`Unsupported data type ${r}`);const i=new s.g(t,a,r,c),o=Object(n.Yc)(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=i.nextValue();return o.toTensor()}});Object(n.Mc)({randomNormal_:function(e,t=0,a=1,r,c){if(null!=r&&"bool"===r)throw new Error(`Unsupported data type ${r}`);const i=new s.f(t,a,r,!1,c),o=Object(n.Yc)(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=i.nextValue();return o.toTensor()}});Object(n.Mc)({reverse1d_:function(e){const t=Object(n.Lc)(e,"x","reverse");return Object(n.F)(1===t.rank,(()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`)),Object(n.ib)(t,0)}});Object(n.Mc)({reverse2d_:function(e,t){const a=Object(n.Lc)(e,"x","reverse");return Object(n.F)(2===a.rank,(()=>`Error in reverse2D: x must be rank 2 but got rank ${a.rank}.`)),Object(n.ib)(a,t)}});Object(n.Mc)({reverse3d_:function(e,t){const a=Object(n.Lc)(e,"x","reverse");return Object(n.F)(3===a.rank,(()=>`Error in reverse3D: x must be rank 3 but got rank ${a.rank}.`)),Object(n.ib)(a,t)}});Object(n.Mc)({reverse4d_:function(e,t){const a=Object(n.Lc)(e,"x","reverse");return Object(n.F)(4===a.rank,(()=>`Error in reverse4D: x must be rank 4 but got rank ${a.rank}.`)),Object(n.ib)(a,t)}});Object(n.Mc)({slice1d_:function(e,t,a){const s=Object(n.Lc)(e,"x","slice1d");return Object(n.F)(1===s.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),Object(n.pb)(s,[t],[a])}});Object(n.Mc)({slice2d_:function(e,t,a){const s=Object(n.Lc)(e,"x","slice2d");return Object(n.F)(2===s.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),Object(n.pb)(s,t,a)}});Object(n.Mc)({slice3d_:function(e,t,a){const s=Object(n.Lc)(e,"x","slice3d");return Object(n.F)(3===s.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),Object(n.pb)(s,t,a)}});Object(n.Mc)({slice4d_:function(e,t,a){const s=Object(n.Lc)(e,"x","slice4d");return Object(n.F)(4===s.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),Object(n.pb)(s,t,a)}});Object(n.Mc)({movingAverage_:function(e,t,a,s,r=!0){const c=Object(n.Lc)(e,"v","movingAverage"),i=Object(n.Lc)(t,"x","movingAverage"),o=Object(n.Lc)(a,"decay","movingAverage");Object(n.ih)(c,i),Object(n.F)(Object(n.gb)(c.shape,i.shape),(()=>"Shape mismatch in v and x"));const l=Object(n.G)(1),b=Object(n.Pb)(l,o);let h=Object(n.mh)(Object(n.Pb)(i,c),b);if(r){Object(n.F)(null!=s,(()=>"When using zeroDebias: true, step is required."));const e=Object(n.Lc)(s,"step","movingAverage");h=Object(n.kh)(h,Object(n.Pb)(l,Object(n.uh)(o,e)))}return Object(n.oh)(c,h)}});Object(n.Mc)({dropout_:function(e,t,a,r){const c=Object(n.Lc)(e,"x","dropout");if(Object(n.F)("float32"===c.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${c.dtype} tensor instead.`)),Object(n.F)(t>=0&&t<1,(()=>`rate must be a float in the range [0, 1), but got ${t}.`)),0===t)return e instanceof n.ac?c.clone():c;const i=function(e,t){if(null==t)return e.shape.slice();if(Object(n.gb)(e.shape,t))return t;if(e.shape.length===t.length){const a=[];for(let n=0;n<e.shape.length;n++)null==t[n]&&null!=e.shape[n]?a.push(e.shape[n]):a.push(t[n]);return a}return t}(c,a),o=1-t,l=Object(n.kh)(Object(n.n)(Object(n.oh)(Object(s.n)(i,0,1,"float32",r),o)),o);return Object(n.mh)(c,l)}});s.m,s.l,s.u;class m extends b{minimize(e,t=!1,a){const{value:s,grads:r}=this.computeGradients(e,a);if(null!=a){const e=a.map((e=>({name:e.name,tensor:r[e.name]})));this.applyGradients(e)}else this.applyGradients(r);return Object(n.ld)(r),t?s:(s.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return Object(n.jh)(e,t)}dispose(){null!=this.iterations_&&Object(n.ld)(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:Object(n.G)(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(m,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class d extends m{constructor(e,t,a=null){super(),this.learningRate=e,this.rho=t,this.epsilon=a,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==a&&(this.epsilon=n.Oc.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,a)=>{const s=n.Oc.registeredVariables[t];null==this.accumulatedGrads[a]&&(this.accumulatedGrads[a]={originalName:`${t}/accum_grad`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(false)))}),null==this.accumulatedUpdates[a]&&(this.accumulatedUpdates[a]={originalName:`${t}/accum_var`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(false)))});const r=Array.isArray(e)?e[a].tensor:e[t];if(null==r)return;const c=this.accumulatedGrads[a].variable,i=this.accumulatedUpdates[a].variable;Object(n.M)((()=>{const e=Object(n.oh)(Object(n.mh)(c,this.rho),Object(n.mh)(Object(n.Bh)(r),1-this.rho)),t=Object(n.mh)(Object(n.kh)(Object(n.Ch)(Object(n.oh)(i,this.epsilon)),Object(n.Ch)(Object(n.oh)(c,this.epsilon))),r),a=Object(n.oh)(Object(n.mh)(i,this.rho),Object(n.mh)(Object(n.Bh)(t),1-this.rho));c.assign(e),i.assign(a);const o=Object(n.oh)(Object(n.mh)(t,-this.learningRate),s);s.assign(o)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(Object(n.ld)(this.accumulatedGrads.map((e=>e.variable))),Object(n.ld)(this.accumulatedUpdates.map((e=>e.variable))))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2;this.accumulatedGrads=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(false)}))),this.accumulatedUpdates=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(false)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}d.className="Adadelta",u(d);class O extends m{constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,a)=>{const r=n.Oc.registeredVariables[t];if(null==this.accumulatedGrads[a]){const e=!1;this.accumulatedGrads[a]={originalName:`${t}/accumulator`,variable:Object(n.M)((()=>Object(s.p)(r.shape,this.initialAccumulatorValue).variable(e)))}}const c=Array.isArray(e)?e[a].tensor:e[t];if(null==c)return;const i=this.accumulatedGrads[a].variable;Object(n.M)((()=>{const e=Object(n.oh)(i,Object(n.Bh)(c));i.assign(e);const t=Object(n.oh)(Object(n.mh)(Object(n.kh)(c,Object(n.Ch)(Object(n.oh)(e,n.Oc.backend.epsilon()))),-this.learningRate),r);r.assign(t)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&Object(n.ld)(this.accumulatedGrads.map((e=>e.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);this.accumulatedGrads=e.map((e=>({originalName:e.name,variable:e.tensor.variable(false)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}O.className="Adagrad",u(O);class j extends m{constructor(e,t,a,s=null){super(),this.learningRate=e,this.beta1=t,this.beta2=a,this.epsilon=s,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],Object(n.M)((()=>{this.accBeta1=Object(n.G)(t).variable(),this.accBeta2=Object(n.G)(a).variable()})),null==s&&(this.epsilon=n.Oc.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);Object(n.M)((()=>{const a=Object(n.Pb)(1,this.accBeta1),s=Object(n.Pb)(1,this.accBeta2);t.forEach(((t,r)=>{const c=n.Oc.registeredVariables[t];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${t}/m`,variable:Object(n.M)((()=>Object(n.xb)(c).variable(false)))}),null==this.accumulatedSecondMoment[r]&&(this.accumulatedSecondMoment[r]={originalName:`${t}/v`,variable:Object(n.M)((()=>Object(n.xb)(c).variable(false)))});const i=Array.isArray(e)?e[r].tensor:e[t];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedSecondMoment[r].variable,b=Object(n.oh)(Object(n.mh)(o,this.beta1),Object(n.mh)(i,1-this.beta1)),h=Object(n.oh)(Object(n.mh)(l,this.beta2),Object(n.mh)(Object(n.Bh)(i),1-this.beta2)),u=Object(n.kh)(b,a),m=Object(n.kh)(h,s);o.assign(b),l.assign(h);const d=Object(n.oh)(Object(n.mh)(Object(n.kh)(u,Object(n.oh)(Object(n.Ch)(m),this.epsilon)),-this.learningRate),c);c.assign(d)})),this.accBeta1.assign(Object(n.mh)(this.accBeta1,this.beta1)),this.accBeta2.assign(Object(n.mh)(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&Object(n.ld)(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedSecondMoment&&Object(n.ld)(this.accumulatedSecondMoment.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),Object(n.M)((()=>{this.accBeta1.assign(Object(n.uh)(this.beta1,this.iterations_+1)),this.accBeta2.assign(Object(n.uh)(this.beta2,this.iterations_+1))}));const t=e.length/2;this.accumulatedFirstMoment=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(false)}))),this.accumulatedSecondMoment=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(false)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}j.className="Adam",u(j);class g extends m{constructor(e,t,a,s=null,r=0){super(),this.learningRate=e,this.beta1=t,this.beta2=a,this.epsilon=s,this.decay=r,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],Object(n.M)((()=>{this.iteration=Object(n.G)(0).variable(),this.accBeta1=Object(n.G)(t).variable()})),null==s&&(this.epsilon=n.Oc.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);Object(n.M)((()=>{const a=Object(n.Pb)(1,this.accBeta1),s=Object(n.kh)(-this.learningRate,Object(n.oh)(Object(n.mh)(this.iteration,this.decay),1));t.forEach(((t,r)=>{const c=n.Oc.registeredVariables[t];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${t}/m`,variable:Object(n.xb)(c).variable(false)}),null==this.accumulatedWeightedInfNorm[r]&&(this.accumulatedWeightedInfNorm[r]={originalName:`${t}/v`,variable:Object(n.xb)(c).variable(false)});const i=Array.isArray(e)?e[r].tensor:e[t];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedWeightedInfNorm[r].variable,b=Object(n.oh)(Object(n.mh)(o,this.beta1),Object(n.mh)(i,1-this.beta1)),h=Object(n.mh)(l,this.beta2),u=Object(n.E)(i),m=Object(n.rh)(h,u);o.assign(b),l.assign(m);const d=Object(n.oh)(Object(n.mh)(Object(n.kh)(s,a),Object(n.kh)(b,Object(n.oh)(m,this.epsilon))),c);c.assign(d)})),this.iteration.assign(Object(n.oh)(this.iteration,1)),this.accBeta1.assign(Object(n.mh)(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&Object(n.ld)(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedWeightedInfNorm&&Object(n.ld)(this.accumulatedWeightedInfNorm.map((e=>e.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}g.className="Adamax",u(g);class p extends m{constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,a)=>{const s=Array.isArray(e)?e[a].tensor:e[t];if(null==s)return;const r=n.Oc.registeredVariables[t];Object(n.M)((()=>{const e=Object(n.oh)(Object(n.mh)(this.c,s),r);r.assign(e)}))})),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=Object(n.H)(Object(n.G)(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}p.className="SGD",u(p);class f extends p{constructor(e,t,a=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=a,this.accumulations=[],this.m=Object(n.G)(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,a)=>{const s=n.Oc.registeredVariables[t];if(null==this.accumulations[a]){const e=!1;this.accumulations[a]={originalName:`${t}/momentum`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(e)))}}const r=this.accumulations[a].variable,c=Array.isArray(e)?e[a].tensor:e[t];null!=c&&Object(n.M)((()=>{let e;const t=Object(n.oh)(Object(n.mh)(this.m,r),c);e=this.useNesterov?Object(n.oh)(Object(n.mh)(this.c,Object(n.oh)(c,Object(n.mh)(t,this.m))),s):Object(n.oh)(Object(n.mh)(this.c,t),s),r.assign(t),s.assign(e)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&Object(n.ld)(this.accumulations.map((e=>e.variable)))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);this.accumulations=e.map((e=>({originalName:e.name,variable:e.tensor.variable(false)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}f.className="Momentum",u(f);class v extends m{constructor(e,t=.9,a=0,s=null,r=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=a,this.epsilon=s,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=r,null==s&&(this.epsilon=n.Oc.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,a)=>{const s=n.Oc.registeredVariables[t],r=!1;null==this.accumulatedMeanSquares[a]&&(this.accumulatedMeanSquares[a]={originalName:`${t}/rms`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(r)))}),null==this.accumulatedMoments[a]&&(this.accumulatedMoments[a]={originalName:`${t}/momentum`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(r)))}),null==this.accumulatedMeanGrads[a]&&this.centered&&(this.accumulatedMeanGrads[a]={originalName:`${t}/mg`,variable:Object(n.M)((()=>Object(n.xb)(s).variable(r)))});const c=Array.isArray(e)?e[a].tensor:e[t];if(null==c)return;const i=this.accumulatedMeanSquares[a].variable,o=this.accumulatedMoments[a].variable;Object(n.M)((()=>{const e=Object(n.oh)(Object(n.mh)(i,this.decay),Object(n.mh)(Object(n.Bh)(c),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[a].variable,r=Object(n.oh)(Object(n.mh)(t,this.decay),Object(n.mh)(c,1-this.decay)),l=Object(n.kh)(Object(n.mh)(c,this.learningRate),Object(n.Ch)(Object(n.Pb)(e,Object(n.oh)(Object(n.Bh)(r),this.epsilon)))),b=Object(n.oh)(Object(n.mh)(o,this.momentum),l);i.assign(e),t.assign(r),o.assign(b);const h=Object(n.Pb)(s,b);s.assign(h)}else{const e=Object(n.oh)(Object(n.mh)(i,this.decay),Object(n.mh)(Object(n.Bh)(c),1-this.decay)),t=Object(n.oh)(Object(n.mh)(o,this.momentum),Object(n.kh)(Object(n.mh)(c,this.learningRate),Object(n.Ch)(Object(n.oh)(e,this.epsilon))));i.assign(e),o.assign(t);const a=Object(n.Pb)(s,t);s.assign(a)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&Object(n.ld)(this.accumulatedMeanSquares.map((e=>e.variable))),null!=this.accumulatedMeanGrads&&this.centered&&Object(n.ld)(this.accumulatedMeanGrads.map((e=>e.variable))),null!=this.accumulatedMoments&&Object(n.ld)(this.accumulatedMoments.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,a=!1;this.accumulatedMeanSquares=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(a)}))),this.accumulatedMoments=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(a)}))),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map((e=>({originalName:e.name,variable:e.tensor.variable(a)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}v.className="RMSProp",u(v);"undefined"!=typeof requestAnimationFrame&&requestAnimationFrame;n.fd,n.jd,n.hd,n.fc}).call(this,a(100).setImmediate)}}]);