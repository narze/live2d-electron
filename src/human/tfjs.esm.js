/* TFJS custom ESM bundle in ES2018 */
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __markAsModule = (target) => __defProp(target, "__esModule", { value: true });
var __require = (x) => {
  if (typeof require !== "undefined")
    return require(x);
  throw new Error('Dynamic require of "' + x + '" is not supported');
};
var __commonJS = (cb, mod5) => function __require2() {
  return mod5 || (0, cb[Object.keys(cb)[0]])((mod5 = { exports: {} }).exports, mod5), mod5.exports;
};
var __export = (target, all6) => {
  __markAsModule(target);
  for (var name in all6)
    __defProp(target, name, { get: all6[name], enumerable: true });
};
var __reExport = (target, module, desc) => {
  if (module && typeof module === "object" || typeof module === "function") {
    for (let key of __getOwnPropNames(module))
      if (!__hasOwnProp.call(target, key) && key !== "default")
        __defProp(target, key, { get: () => module[key], enumerable: !(desc = __getOwnPropDesc(module, key)) || desc.enumerable });
  }
  return target;
};
var __toModule = (module) => {
  return __reExport(__markAsModule(__defProp(module != null ? __create(__getProtoOf(module)) : {}, "default", module && module.__esModule && "default" in module ? { get: () => module.default, enumerable: true } : { value: module, enumerable: true })), module);
};

// node_modules/.pnpm/long@4.0.0/node_modules/long/src/long.js
var require_long = __commonJS({
  "node_modules/.pnpm/long@4.0.0/node_modules/long/src/long.js"(exports, module) {
    module.exports = Long3;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long3(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long3.prototype.__isLong__;
    Object.defineProperty(Long3.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long3.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long3.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long3.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long3(lowBits, highBits, unsigned);
    }
    Long3.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p2;
      if ((p2 = str.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p2 === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long3.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long3.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long3.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long3.UZERO = UZERO;
    var ONE = fromInt(1);
    Long3.ONE = ONE;
    var UONE = fromInt(1, true);
    Long3.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long3.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long3.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long3.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long3.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long3.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div4 = this.div(radixLong), rem1 = div4.mul(radixLong).sub(this);
          return div4.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven2() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(other);
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(other) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(other) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(other) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(other) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add8(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply5(multiplier) {
      if (this.isZero())
        return ZERO;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log22 = Math.ceil(Math.log(approx) / Math.LN2), delta = log22 <= 48 ? 1 : pow_dbl(2, log22 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long3.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long3.fromBytesLE(bytes, unsigned) : Long3.fromBytesBE(bytes, unsigned);
    };
    Long3.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long3(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long3.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long3(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
  }
});

// (disabled):node_modules/.pnpm/node-fetch@2.6.1/node_modules/node-fetch/browser.js
var require_browser = __commonJS({
  "(disabled):node_modules/.pnpm/node-fetch@2.6.1/node_modules/node-fetch/browser.js"() {
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/alea.js
var require_alea = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/alea.js"(exports, module) {
    (function(global2, module2, define2) {
      function Alea(seed) {
        var me = this, mash = Mash();
        me.next = function() {
          var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
          me.s0 = me.s1;
          me.s1 = me.s2;
          return me.s2 = t - (me.c = t | 0);
        };
        me.c = 1;
        me.s0 = mash(" ");
        me.s1 = mash(" ");
        me.s2 = mash(" ");
        me.s0 -= mash(seed);
        if (me.s0 < 0) {
          me.s0 += 1;
        }
        me.s1 -= mash(seed);
        if (me.s1 < 0) {
          me.s1 += 1;
        }
        me.s2 -= mash(seed);
        if (me.s2 < 0) {
          me.s2 += 1;
        }
        mash = null;
      }
      function copy(f, t) {
        t.c = f.c;
        t.s0 = f.s0;
        t.s1 = f.s1;
        t.s2 = f.s2;
        return t;
      }
      function impl(seed, opts) {
        var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
        prng.int32 = function() {
          return xg.next() * 4294967296 | 0;
        };
        prng.double = function() {
          return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
        };
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      function Mash() {
        var n = 4022871197;
        var mash = function(data) {
          data = data.toString();
          for (var i = 0; i < data.length; i++) {
            n += data.charCodeAt(i);
            var h = 0.02519603282416938 * n;
            n = h >>> 0;
            h -= n;
            h *= n;
            n = h >>> 0;
            h -= n;
            n += h * 4294967296;
          }
          return (n >>> 0) * 23283064365386963e-26;
        };
        return mash;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.alea = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xor128.js
var require_xor128 = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xor128.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.next = function() {
          var t = me.x ^ me.x << 11;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
        };
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor128 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xorwow.js
var require_xorwow = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xorwow.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var t = me.x ^ me.x >>> 2;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          me.w = me.v;
          return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
        };
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.v = 0;
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          if (k == strseed.length) {
            me.d = me.x << 10 ^ me.x >>> 4;
          }
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        t.v = f.v;
        t.d = f.d;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorwow = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xorshift7.js
var require_xorshift7 = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var X = me.x, i = me.i, t, v, w;
          t = X[i];
          t ^= t >>> 7;
          v = t ^ t << 24;
          t = X[i + 1 & 7];
          v ^= t ^ t >>> 10;
          t = X[i + 3 & 7];
          v ^= t ^ t >>> 3;
          t = X[i + 4 & 7];
          v ^= t ^ t << 7;
          t = X[i + 7 & 7];
          t = t ^ t << 13;
          v ^= t ^ t << 9;
          X[i] = v;
          me.i = i + 1 & 7;
          return v;
        };
        function init2(me2, seed2) {
          var j, w, X = [];
          if (seed2 === (seed2 | 0)) {
            w = X[0] = seed2;
          } else {
            seed2 = "" + seed2;
            for (j = 0; j < seed2.length; ++j) {
              X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
            }
          }
          while (X.length < 8)
            X.push(0);
          for (j = 0; j < 8 && X[j] === 0; ++j)
            ;
          if (j == 8)
            w = X[7] = -1;
          else
            w = X[j];
          me2.x = X;
          me2.i = 0;
          for (j = 256; j > 0; --j) {
            me2.next();
          }
        }
        init2(me, seed);
      }
      function copy(f, t) {
        t.x = f.x.slice();
        t.i = f.i;
        return t;
      }
      function impl(seed, opts) {
        if (seed == null)
          seed = +new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.x)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorshift7 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xor4096.js
var require_xor4096 = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/xor4096.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var w = me.w, X = me.X, i = me.i, t, v;
          me.w = w = w + 1640531527 | 0;
          v = X[i + 34 & 127];
          t = X[i = i + 1 & 127];
          v ^= v << 13;
          t ^= t << 17;
          v ^= v >>> 15;
          t ^= t >>> 12;
          v = X[i] = v ^ t;
          me.i = i;
          return v + (w ^ w >>> 16) | 0;
        };
        function init2(me2, seed2) {
          var t, v, i, j, w, X = [], limit = 128;
          if (seed2 === (seed2 | 0)) {
            v = seed2;
            seed2 = null;
          } else {
            seed2 = seed2 + "\0";
            v = 0;
            limit = Math.max(limit, seed2.length);
          }
          for (i = 0, j = -32; j < limit; ++j) {
            if (seed2)
              v ^= seed2.charCodeAt((j + 32) % seed2.length);
            if (j === 0)
              w = v;
            v ^= v << 10;
            v ^= v >>> 15;
            v ^= v << 4;
            v ^= v >>> 13;
            if (j >= 0) {
              w = w + 1640531527 | 0;
              t = X[j & 127] ^= v + w;
              i = t == 0 ? i + 1 : 0;
            }
          }
          if (i >= 128) {
            X[(seed2 && seed2.length || 0) & 127] = -1;
          }
          i = 127;
          for (j = 4 * 128; j > 0; --j) {
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            X[i] = v ^ t;
          }
          me2.w = w;
          me2.X = X;
          me2.i = i;
        }
        init2(me, seed);
      }
      function copy(f, t) {
        t.i = f.i;
        t.w = f.w;
        t.X = f.X.slice();
        return t;
      }
      ;
      function impl(seed, opts) {
        if (seed == null)
          seed = +new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.X)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor4096 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/tychei.js
var require_tychei = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/lib/tychei.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var b = me.b, c = me.c, d = me.d, a = me.a;
          b = b << 25 ^ b >>> 7 ^ c;
          c = c - d | 0;
          d = d << 24 ^ d >>> 8 ^ a;
          a = a - b | 0;
          me.b = b = b << 20 ^ b >>> 12 ^ c;
          me.c = c = c - d | 0;
          me.d = d << 16 ^ c >>> 16 ^ a;
          return me.a = a - b | 0;
        };
        me.a = 0;
        me.b = 0;
        me.c = 2654435769 | 0;
        me.d = 1367130551;
        if (seed === Math.floor(seed)) {
          me.a = seed / 4294967296 | 0;
          me.b = seed | 0;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 20; k++) {
          me.b ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.a = f.a;
        t.b = f.b;
        t.c = f.c;
        t.d = f.d;
        return t;
      }
      ;
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.tychei = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// (disabled):crypto
var require_crypto = __commonJS({
  "(disabled):crypto"() {
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/seedrandom.js
var require_seedrandom = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/seedrandom.js"(exports, module) {
    (function(pool4, math) {
      var global2 = this, width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
      function seedrandom6(seed, options, callback) {
        var key = [];
        options = options == true ? { entropy: true } : options || {};
        var shortseed = mixkey(flatten5(options.entropy ? [seed, tostring(pool4)] : seed == null ? autoseed() : seed, 3), key);
        var arc4 = new ARC4(key);
        var prng = function() {
          var n = arc4.g(chunks), d = startdenom, x = 0;
          while (n < significance) {
            n = (n + x) * width;
            d *= width;
            x = arc4.g(1);
          }
          while (n >= overflow) {
            n /= 2;
            d /= 2;
            x >>>= 1;
          }
          return (n + x) / d;
        };
        prng.int32 = function() {
          return arc4.g(4) | 0;
        };
        prng.quick = function() {
          return arc4.g(4) / 4294967296;
        };
        prng.double = prng;
        mixkey(tostring(arc4.S), pool4);
        return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
          if (state) {
            if (state.S) {
              copy(state, arc4);
            }
            prng2.state = function() {
              return copy(arc4, {});
            };
          }
          if (is_math_call) {
            math[rngname] = prng2;
            return seed2;
          } else
            return prng2;
        })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
      }
      math["seed" + rngname] = seedrandom6;
      function ARC4(key) {
        var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
        if (!keylen) {
          key = [keylen++];
        }
        while (i < width) {
          s[i] = i++;
        }
        for (i = 0; i < width; i++) {
          s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
          s[j] = t;
        }
        (me.g = function(count2) {
          var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
          while (count2--) {
            t2 = s2[i2 = mask & i2 + 1];
            r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
          }
          me.i = i2;
          me.j = j2;
          return r;
        })(width);
      }
      function copy(f, t) {
        t.i = f.i;
        t.j = f.j;
        t.S = f.S.slice();
        return t;
      }
      ;
      function flatten5(obj, depth) {
        var result = [], typ = typeof obj, prop;
        if (depth && typ == "object") {
          for (prop in obj) {
            try {
              result.push(flatten5(obj[prop], depth - 1));
            } catch (e) {
            }
          }
        }
        return result.length ? result : typ == "string" ? obj : obj + "\0";
      }
      function mixkey(seed, key) {
        var stringseed = seed + "", smear, j = 0;
        while (j < stringseed.length) {
          key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
        }
        return tostring(key);
      }
      function autoseed() {
        try {
          var out;
          if (nodecrypto && (out = nodecrypto.randomBytes)) {
            out = out(width);
          } else {
            out = new Uint8Array(width);
            (global2.crypto || global2.msCrypto).getRandomValues(out);
          }
          return tostring(out);
        } catch (e) {
          var browser = global2.navigator, plugins = browser && browser.plugins;
          return [+new Date(), global2, plugins, global2.screen, tostring(pool4)];
        }
      }
      function tostring(a) {
        return String.fromCharCode.apply(0, a);
      }
      mixkey(math.random(), pool4);
      if (typeof module == "object" && module.exports) {
        module.exports = seedrandom6;
        try {
          nodecrypto = require_crypto();
        } catch (ex) {
        }
      } else if (typeof define == "function" && define.amd) {
        define(function() {
          return seedrandom6;
        });
      }
    })([], Math);
  }
});

// node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/index.js
var require_seedrandom2 = __commonJS({
  "node_modules/.pnpm/seedrandom@2.4.3/node_modules/seedrandom/index.js"(exports, module) {
    var alea6 = require_alea();
    var xor128 = require_xor128();
    var xorwow = require_xorwow();
    var xorshift7 = require_xorshift7();
    var xor4096 = require_xor4096();
    var tychei = require_tychei();
    var sr = require_seedrandom();
    sr.alea = alea6;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    module.exports = sr;
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/alea.js
var require_alea2 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/alea.js"(exports, module) {
    (function(global2, module2, define2) {
      function Alea(seed) {
        var me = this, mash = Mash();
        me.next = function() {
          var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
          me.s0 = me.s1;
          me.s1 = me.s2;
          return me.s2 = t - (me.c = t | 0);
        };
        me.c = 1;
        me.s0 = mash(" ");
        me.s1 = mash(" ");
        me.s2 = mash(" ");
        me.s0 -= mash(seed);
        if (me.s0 < 0) {
          me.s0 += 1;
        }
        me.s1 -= mash(seed);
        if (me.s1 < 0) {
          me.s1 += 1;
        }
        me.s2 -= mash(seed);
        if (me.s2 < 0) {
          me.s2 += 1;
        }
        mash = null;
      }
      function copy(f, t) {
        t.c = f.c;
        t.s0 = f.s0;
        t.s1 = f.s1;
        t.s2 = f.s2;
        return t;
      }
      function impl(seed, opts) {
        var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
        prng.int32 = function() {
          return xg.next() * 4294967296 | 0;
        };
        prng.double = function() {
          return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
        };
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      function Mash() {
        var n = 4022871197;
        var mash = function(data) {
          data = String(data);
          for (var i = 0; i < data.length; i++) {
            n += data.charCodeAt(i);
            var h = 0.02519603282416938 * n;
            n = h >>> 0;
            h -= n;
            h *= n;
            n = h >>> 0;
            h -= n;
            n += h * 4294967296;
          }
          return (n >>> 0) * 23283064365386963e-26;
        };
        return mash;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.alea = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xor128.js
var require_xor1282 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xor128.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.next = function() {
          var t = me.x ^ me.x << 11;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
        };
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor128 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xorwow.js
var require_xorwow2 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xorwow.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var t = me.x ^ me.x >>> 2;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          me.w = me.v;
          return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
        };
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.v = 0;
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          if (k == strseed.length) {
            me.d = me.x << 10 ^ me.x >>> 4;
          }
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        t.v = f.v;
        t.d = f.d;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorwow = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xorshift7.js
var require_xorshift72 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var X = me.x, i = me.i, t, v, w;
          t = X[i];
          t ^= t >>> 7;
          v = t ^ t << 24;
          t = X[i + 1 & 7];
          v ^= t ^ t >>> 10;
          t = X[i + 3 & 7];
          v ^= t ^ t >>> 3;
          t = X[i + 4 & 7];
          v ^= t ^ t << 7;
          t = X[i + 7 & 7];
          t = t ^ t << 13;
          v ^= t ^ t << 9;
          X[i] = v;
          me.i = i + 1 & 7;
          return v;
        };
        function init2(me2, seed2) {
          var j, w, X = [];
          if (seed2 === (seed2 | 0)) {
            w = X[0] = seed2;
          } else {
            seed2 = "" + seed2;
            for (j = 0; j < seed2.length; ++j) {
              X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
            }
          }
          while (X.length < 8)
            X.push(0);
          for (j = 0; j < 8 && X[j] === 0; ++j)
            ;
          if (j == 8)
            w = X[7] = -1;
          else
            w = X[j];
          me2.x = X;
          me2.i = 0;
          for (j = 256; j > 0; --j) {
            me2.next();
          }
        }
        init2(me, seed);
      }
      function copy(f, t) {
        t.x = f.x.slice();
        t.i = f.i;
        return t;
      }
      function impl(seed, opts) {
        if (seed == null)
          seed = +new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.x)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorshift7 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xor4096.js
var require_xor40962 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/xor4096.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var w = me.w, X = me.X, i = me.i, t, v;
          me.w = w = w + 1640531527 | 0;
          v = X[i + 34 & 127];
          t = X[i = i + 1 & 127];
          v ^= v << 13;
          t ^= t << 17;
          v ^= v >>> 15;
          t ^= t >>> 12;
          v = X[i] = v ^ t;
          me.i = i;
          return v + (w ^ w >>> 16) | 0;
        };
        function init2(me2, seed2) {
          var t, v, i, j, w, X = [], limit = 128;
          if (seed2 === (seed2 | 0)) {
            v = seed2;
            seed2 = null;
          } else {
            seed2 = seed2 + "\0";
            v = 0;
            limit = Math.max(limit, seed2.length);
          }
          for (i = 0, j = -32; j < limit; ++j) {
            if (seed2)
              v ^= seed2.charCodeAt((j + 32) % seed2.length);
            if (j === 0)
              w = v;
            v ^= v << 10;
            v ^= v >>> 15;
            v ^= v << 4;
            v ^= v >>> 13;
            if (j >= 0) {
              w = w + 1640531527 | 0;
              t = X[j & 127] ^= v + w;
              i = t == 0 ? i + 1 : 0;
            }
          }
          if (i >= 128) {
            X[(seed2 && seed2.length || 0) & 127] = -1;
          }
          i = 127;
          for (j = 4 * 128; j > 0; --j) {
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            X[i] = v ^ t;
          }
          me2.w = w;
          me2.X = X;
          me2.i = i;
        }
        init2(me, seed);
      }
      function copy(f, t) {
        t.i = f.i;
        t.w = f.w;
        t.X = f.X.slice();
        return t;
      }
      ;
      function impl(seed, opts) {
        if (seed == null)
          seed = +new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.X)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor4096 = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/tychei.js
var require_tychei2 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/lib/tychei.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var b = me.b, c = me.c, d = me.d, a = me.a;
          b = b << 25 ^ b >>> 7 ^ c;
          c = c - d | 0;
          d = d << 24 ^ d >>> 8 ^ a;
          a = a - b | 0;
          me.b = b = b << 20 ^ b >>> 12 ^ c;
          me.c = c = c - d | 0;
          me.d = d << 16 ^ c >>> 16 ^ a;
          return me.a = a - b | 0;
        };
        me.a = 0;
        me.b = 0;
        me.c = 2654435769 | 0;
        me.d = 1367130551;
        if (seed === Math.floor(seed)) {
          me.a = seed / 4294967296 | 0;
          me.b = seed | 0;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 20; k++) {
          me.b ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.a = f.a;
        t.b = f.b;
        t.c = f.c;
        t.d = f.d;
        return t;
      }
      ;
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.tychei = impl;
      }
    })(exports, typeof module == "object" && module, typeof define == "function" && define);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/seedrandom.js
var require_seedrandom3 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/seedrandom.js"(exports, module) {
    (function(global2, pool4, math) {
      var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
      function seedrandom6(seed, options, callback) {
        var key = [];
        options = options == true ? { entropy: true } : options || {};
        var shortseed = mixkey(flatten5(options.entropy ? [seed, tostring(pool4)] : seed == null ? autoseed() : seed, 3), key);
        var arc4 = new ARC4(key);
        var prng = function() {
          var n = arc4.g(chunks), d = startdenom, x = 0;
          while (n < significance) {
            n = (n + x) * width;
            d *= width;
            x = arc4.g(1);
          }
          while (n >= overflow) {
            n /= 2;
            d /= 2;
            x >>>= 1;
          }
          return (n + x) / d;
        };
        prng.int32 = function() {
          return arc4.g(4) | 0;
        };
        prng.quick = function() {
          return arc4.g(4) / 4294967296;
        };
        prng.double = prng;
        mixkey(tostring(arc4.S), pool4);
        return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
          if (state) {
            if (state.S) {
              copy(state, arc4);
            }
            prng2.state = function() {
              return copy(arc4, {});
            };
          }
          if (is_math_call) {
            math[rngname] = prng2;
            return seed2;
          } else
            return prng2;
        })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
      }
      function ARC4(key) {
        var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
        if (!keylen) {
          key = [keylen++];
        }
        while (i < width) {
          s[i] = i++;
        }
        for (i = 0; i < width; i++) {
          s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
          s[j] = t;
        }
        (me.g = function(count2) {
          var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
          while (count2--) {
            t2 = s2[i2 = mask & i2 + 1];
            r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
          }
          me.i = i2;
          me.j = j2;
          return r;
        })(width);
      }
      function copy(f, t) {
        t.i = f.i;
        t.j = f.j;
        t.S = f.S.slice();
        return t;
      }
      ;
      function flatten5(obj, depth) {
        var result = [], typ = typeof obj, prop;
        if (depth && typ == "object") {
          for (prop in obj) {
            try {
              result.push(flatten5(obj[prop], depth - 1));
            } catch (e) {
            }
          }
        }
        return result.length ? result : typ == "string" ? obj : obj + "\0";
      }
      function mixkey(seed, key) {
        var stringseed = seed + "", smear, j = 0;
        while (j < stringseed.length) {
          key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
        }
        return tostring(key);
      }
      function autoseed() {
        try {
          var out;
          if (nodecrypto && (out = nodecrypto.randomBytes)) {
            out = out(width);
          } else {
            out = new Uint8Array(width);
            (global2.crypto || global2.msCrypto).getRandomValues(out);
          }
          return tostring(out);
        } catch (e) {
          var browser = global2.navigator, plugins = browser && browser.plugins;
          return [+new Date(), global2, plugins, global2.screen, tostring(pool4)];
        }
      }
      function tostring(a) {
        return String.fromCharCode.apply(0, a);
      }
      mixkey(math.random(), pool4);
      if (typeof module == "object" && module.exports) {
        module.exports = seedrandom6;
        try {
          nodecrypto = require_crypto();
        } catch (ex) {
        }
      } else if (typeof define == "function" && define.amd) {
        define(function() {
          return seedrandom6;
        });
      } else {
        math["seed" + rngname] = seedrandom6;
      }
    })(typeof self !== "undefined" ? self : exports, [], Math);
  }
});

// node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/index.js
var require_seedrandom4 = __commonJS({
  "node_modules/.pnpm/seedrandom@3.0.5/node_modules/seedrandom/index.js"(exports, module) {
    var alea6 = require_alea2();
    var xor128 = require_xor1282();
    var xorwow = require_xorwow2();
    var xorshift7 = require_xorshift72();
    var xor4096 = require_xor40962();
    var tychei = require_tychei2();
    var sr = require_seedrandom3();
    sr.alea = alea6;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    module.exports = sr;
  }
});

// (disabled):node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js
var require_string_decoder = __commonJS({
  "(disabled):node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js"() {
  }
});

// (disabled):path
var require_path = __commonJS({
  "(disabled):path"() {
  }
});

// (disabled):worker_threads
var require_worker_threads = __commonJS({
  "(disabled):worker_threads"() {
  }
});

// (disabled):perf_hooks
var require_perf_hooks = __commonJS({
  "(disabled):perf_hooks"() {
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/wasm-out/tfjs-backend-wasm-threaded-simd.js
var require_tfjs_backend_wasm_threaded_simd = __commonJS({
  "node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/wasm-out/tfjs-backend-wasm-threaded-simd.js"(exports, module) {
    var WasmBackendModuleThreadedSimd = function() {
      var _scriptDir = typeof document !== "undefined" && document.currentScript ? document.currentScript.src : void 0;
      if (typeof __filename !== "undefined")
        _scriptDir = _scriptDir || __filename;
      return function(WasmBackendModuleThreadedSimd2) {
        WasmBackendModuleThreadedSimd2 = WasmBackendModuleThreadedSimd2 || {};
        function GROWABLE_HEAP_I8() {
          if (wasmMemory.buffer != buffer3) {
            updateGlobalBufferAndViews(wasmMemory.buffer);
          }
          return HEAP8;
        }
        function GROWABLE_HEAP_U8() {
          if (wasmMemory.buffer != buffer3) {
            updateGlobalBufferAndViews(wasmMemory.buffer);
          }
          return HEAPU8;
        }
        function GROWABLE_HEAP_I32() {
          if (wasmMemory.buffer != buffer3) {
            updateGlobalBufferAndViews(wasmMemory.buffer);
          }
          return HEAP32;
        }
        function GROWABLE_HEAP_U32() {
          if (wasmMemory.buffer != buffer3) {
            updateGlobalBufferAndViews(wasmMemory.buffer);
          }
          return HEAPU32;
        }
        function GROWABLE_HEAP_F64() {
          if (wasmMemory.buffer != buffer3) {
            updateGlobalBufferAndViews(wasmMemory.buffer);
          }
          return HEAPF64;
        }
        var Module = typeof WasmBackendModuleThreadedSimd2 !== "undefined" ? WasmBackendModuleThreadedSimd2 : {};
        var readyPromiseResolve, readyPromiseReject;
        Module["ready"] = new Promise(function(resolve, reject) {
          readyPromiseResolve = resolve;
          readyPromiseReject = reject;
        });
        var moduleOverrides = {};
        var key;
        for (key in Module) {
          if (Module.hasOwnProperty(key)) {
            moduleOverrides[key] = Module[key];
          }
        }
        var arguments_ = [];
        var thisProgram = "./this.program";
        var quit_ = function(status, toThrow) {
          throw toThrow;
        };
        var ENVIRONMENT_IS_WEB = false;
        var ENVIRONMENT_IS_WORKER = false;
        var ENVIRONMENT_IS_NODE = false;
        var ENVIRONMENT_IS_SHELL = false;
        ENVIRONMENT_IS_WEB = typeof window === "object";
        ENVIRONMENT_IS_WORKER = typeof importScripts === "function";
        ENVIRONMENT_IS_NODE = typeof process === "object" && typeof process.versions === "object" && typeof process.versions.node === "string";
        ENVIRONMENT_IS_SHELL = !ENVIRONMENT_IS_WEB && !ENVIRONMENT_IS_NODE && !ENVIRONMENT_IS_WORKER;
        var ENVIRONMENT_IS_PTHREAD = Module["ENVIRONMENT_IS_PTHREAD"] || false;
        if (ENVIRONMENT_IS_PTHREAD) {
          buffer3 = Module["buffer"];
        }
        var scriptDirectory = "";
        function locateFile(path) {
          if (Module["locateFile"]) {
            return Module["locateFile"](path, scriptDirectory);
          }
          return scriptDirectory + path;
        }
        var read_, readAsync, readBinary, setWindowTitle;
        var nodeFS;
        var nodePath;
        if (ENVIRONMENT_IS_NODE) {
          if (ENVIRONMENT_IS_WORKER) {
            scriptDirectory = require_path().dirname(scriptDirectory) + "/";
          } else {
            scriptDirectory = __dirname + "/";
          }
          read_ = function shell_read(filename, binary) {
            if (!nodeFS)
              nodeFS = __require("fs");
            if (!nodePath)
              nodePath = require_path();
            filename = nodePath["normalize"](filename);
            return nodeFS["readFileSync"](filename, binary ? null : "utf8");
          };
          readBinary = function readBinary2(filename) {
            var ret = read_(filename, true);
            if (!ret.buffer) {
              ret = new Uint8Array(ret);
            }
            assert4(ret.buffer);
            return ret;
          };
          if (process["argv"].length > 1) {
            thisProgram = process["argv"][1].replace(/\\/g, "/");
          }
          arguments_ = process["argv"].slice(2);
          process["on"]("uncaughtException", function(ex) {
            if (!(ex instanceof ExitStatus)) {
              throw ex;
            }
          });
          process["on"]("unhandledRejection", abort);
          quit_ = function(status) {
            process["exit"](status);
          };
          Module["inspect"] = function() {
            return "[Emscripten Module object]";
          };
          var nodeWorkerThreads;
          try {
            nodeWorkerThreads = require_worker_threads();
          } catch (e) {
            console.error('The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?');
            throw e;
          }
          global.Worker = nodeWorkerThreads.Worker;
        } else if (ENVIRONMENT_IS_SHELL) {
          if (typeof read != "undefined") {
            read_ = function shell_read(f) {
              return read(f);
            };
          }
          readBinary = function readBinary2(f) {
            var data;
            if (typeof readbuffer === "function") {
              return new Uint8Array(readbuffer(f));
            }
            data = read(f, "binary");
            assert4(typeof data === "object");
            return data;
          };
          if (typeof scriptArgs != "undefined") {
            arguments_ = scriptArgs;
          } else if (typeof arguments != "undefined") {
            arguments_ = arguments;
          }
          if (typeof quit === "function") {
            quit_ = function(status) {
              quit(status);
            };
          }
          if (typeof print !== "undefined") {
            if (typeof console === "undefined")
              console = {};
            console.log = print;
            console.warn = console.error = typeof printErr !== "undefined" ? printErr : print;
          }
        } else if (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER) {
          if (ENVIRONMENT_IS_WORKER) {
            scriptDirectory = self.location.href;
          } else if (typeof document !== "undefined" && document.currentScript) {
            scriptDirectory = document.currentScript.src;
          }
          if (typeof _scriptDir !== "undefined" && _scriptDir) {
            scriptDirectory = _scriptDir;
          }
          if (scriptDirectory.indexOf("blob:") !== 0) {
            scriptDirectory = scriptDirectory.substr(0, scriptDirectory.lastIndexOf("/") + 1);
          } else {
            scriptDirectory = "";
          }
          if (ENVIRONMENT_IS_NODE) {
            read_ = function shell_read(filename, binary) {
              if (!nodeFS)
                nodeFS = __require("fs");
              if (!nodePath)
                nodePath = require_path();
              filename = nodePath["normalize"](filename);
              return nodeFS["readFileSync"](filename, binary ? null : "utf8");
            };
            readBinary = function readBinary2(filename) {
              var ret = read_(filename, true);
              if (!ret.buffer) {
                ret = new Uint8Array(ret);
              }
              assert4(ret.buffer);
              return ret;
            };
          } else {
            read_ = function(url) {
              var xhr = new XMLHttpRequest();
              xhr.open("GET", url, false);
              xhr.send(null);
              return xhr.responseText;
            };
            if (ENVIRONMENT_IS_WORKER) {
              readBinary = function(url) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, false);
                xhr.responseType = "arraybuffer";
                xhr.send(null);
                return new Uint8Array(xhr.response);
              };
            }
            readAsync = function(url, onload, onerror) {
              var xhr = new XMLHttpRequest();
              xhr.open("GET", url, true);
              xhr.responseType = "arraybuffer";
              xhr.onload = function() {
                if (xhr.status == 200 || xhr.status == 0 && xhr.response) {
                  onload(xhr.response);
                  return;
                }
                onerror();
              };
              xhr.onerror = onerror;
              xhr.send(null);
            };
          }
          setWindowTitle = function(title) {
            document.title = title;
          };
        } else {
        }
        if (ENVIRONMENT_IS_NODE) {
          if (typeof performance === "undefined") {
            global.performance = require_perf_hooks().performance;
          }
        }
        var out = Module["print"] || console.log.bind(console);
        var err = Module["printErr"] || console.warn.bind(console);
        for (key in moduleOverrides) {
          if (moduleOverrides.hasOwnProperty(key)) {
            Module[key] = moduleOverrides[key];
          }
        }
        moduleOverrides = null;
        if (Module["arguments"])
          arguments_ = Module["arguments"];
        if (Module["thisProgram"])
          thisProgram = Module["thisProgram"];
        if (Module["quit"])
          quit_ = Module["quit"];
        var Atomics_load = Atomics.load;
        var Atomics_store = Atomics.store;
        var Atomics_compareExchange = Atomics.compareExchange;
        var wasmBinary;
        if (Module["wasmBinary"])
          wasmBinary = Module["wasmBinary"];
        var noExitRuntime = Module["noExitRuntime"] || true;
        if (typeof WebAssembly !== "object") {
          abort("no native wasm support detected");
        }
        var wasmMemory;
        var wasmModule;
        var ABORT = false;
        var EXITSTATUS;
        function assert4(condition, text) {
          if (!condition) {
            abort("Assertion failed: " + text);
          }
        }
        function getCFunc(ident) {
          var func2 = Module["_" + ident];
          assert4(func2, "Cannot call unknown function " + ident + ", make sure it is exported");
          return func2;
        }
        function ccall(ident, returnType, argTypes, args, opts) {
          var toC = { "string": function(str) {
            var ret2 = 0;
            if (str !== null && str !== void 0 && str !== 0) {
              var len = (str.length << 2) + 1;
              ret2 = stackAlloc(len);
              stringToUTF8(str, ret2, len);
            }
            return ret2;
          }, "array": function(arr) {
            var ret2 = stackAlloc(arr.length);
            writeArrayToMemory(arr, ret2);
            return ret2;
          } };
          function convertReturnValue(ret2) {
            if (returnType === "string")
              return UTF8ToString(ret2);
            if (returnType === "boolean")
              return Boolean(ret2);
            return ret2;
          }
          var func2 = getCFunc(ident);
          var cArgs = [];
          var stack3 = 0;
          if (args) {
            for (var i = 0; i < args.length; i++) {
              var converter = toC[argTypes[i]];
              if (converter) {
                if (stack3 === 0)
                  stack3 = stackSave();
                cArgs[i] = converter(args[i]);
              } else {
                cArgs[i] = args[i];
              }
            }
          }
          var ret = func2.apply(null, cArgs);
          ret = convertReturnValue(ret);
          if (stack3 !== 0)
            stackRestore(stack3);
          return ret;
        }
        function cwrap(ident, returnType, argTypes, opts) {
          argTypes = argTypes || [];
          var numericArgs = argTypes.every(function(type) {
            return type === "number";
          });
          var numericRet = returnType !== "string";
          if (numericRet && numericArgs && !opts) {
            return getCFunc(ident);
          }
          return function() {
            return ccall(ident, returnType, argTypes, arguments, opts);
          };
        }
        function UTF8ArrayToString(heap, idx, maxBytesToRead) {
          var endIdx = idx + maxBytesToRead;
          var str = "";
          while (!(idx >= endIdx)) {
            var u0 = heap[idx++];
            if (!u0)
              return str;
            if (!(u0 & 128)) {
              str += String.fromCharCode(u0);
              continue;
            }
            var u1 = heap[idx++] & 63;
            if ((u0 & 224) == 192) {
              str += String.fromCharCode((u0 & 31) << 6 | u1);
              continue;
            }
            var u2 = heap[idx++] & 63;
            if ((u0 & 240) == 224) {
              u0 = (u0 & 15) << 12 | u1 << 6 | u2;
            } else {
              u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heap[idx++] & 63;
            }
            if (u0 < 65536) {
              str += String.fromCharCode(u0);
            } else {
              var ch = u0 - 65536;
              str += String.fromCharCode(55296 | ch >> 10, 56320 | ch & 1023);
            }
          }
          return str;
        }
        function UTF8ToString(ptr, maxBytesToRead) {
          return ptr ? UTF8ArrayToString(GROWABLE_HEAP_U8(), ptr, maxBytesToRead) : "";
        }
        function stringToUTF8Array(str, heap, outIdx, maxBytesToWrite) {
          if (!(maxBytesToWrite > 0))
            return 0;
          var startIdx = outIdx;
          var endIdx = outIdx + maxBytesToWrite - 1;
          for (var i = 0; i < str.length; ++i) {
            var u = str.charCodeAt(i);
            if (u >= 55296 && u <= 57343) {
              var u1 = str.charCodeAt(++i);
              u = 65536 + ((u & 1023) << 10) | u1 & 1023;
            }
            if (u <= 127) {
              if (outIdx >= endIdx)
                break;
              heap[outIdx++] = u;
            } else if (u <= 2047) {
              if (outIdx + 1 >= endIdx)
                break;
              heap[outIdx++] = 192 | u >> 6;
              heap[outIdx++] = 128 | u & 63;
            } else if (u <= 65535) {
              if (outIdx + 2 >= endIdx)
                break;
              heap[outIdx++] = 224 | u >> 12;
              heap[outIdx++] = 128 | u >> 6 & 63;
              heap[outIdx++] = 128 | u & 63;
            } else {
              if (outIdx + 3 >= endIdx)
                break;
              heap[outIdx++] = 240 | u >> 18;
              heap[outIdx++] = 128 | u >> 12 & 63;
              heap[outIdx++] = 128 | u >> 6 & 63;
              heap[outIdx++] = 128 | u & 63;
            }
          }
          heap[outIdx] = 0;
          return outIdx - startIdx;
        }
        function stringToUTF8(str, outPtr, maxBytesToWrite) {
          return stringToUTF8Array(str, GROWABLE_HEAP_U8(), outPtr, maxBytesToWrite);
        }
        function lengthBytesUTF8(str) {
          var len = 0;
          for (var i = 0; i < str.length; ++i) {
            var u = str.charCodeAt(i);
            if (u >= 55296 && u <= 57343)
              u = 65536 + ((u & 1023) << 10) | str.charCodeAt(++i) & 1023;
            if (u <= 127)
              ++len;
            else if (u <= 2047)
              len += 2;
            else if (u <= 65535)
              len += 3;
            else
              len += 4;
          }
          return len;
        }
        function writeArrayToMemory(array2, buffer4) {
          GROWABLE_HEAP_I8().set(array2, buffer4);
        }
        function alignUp(x, multiple) {
          if (x % multiple > 0) {
            x += multiple - x % multiple;
          }
          return x;
        }
        var buffer3, HEAP8, HEAPU8, HEAP16, HEAPU16, HEAP32, HEAPU32, HEAPF32, HEAPF64;
        function updateGlobalBufferAndViews(buf) {
          buffer3 = buf;
          Module["HEAP8"] = HEAP8 = new Int8Array(buf);
          Module["HEAP16"] = HEAP16 = new Int16Array(buf);
          Module["HEAP32"] = HEAP32 = new Int32Array(buf);
          Module["HEAPU8"] = HEAPU8 = new Uint8Array(buf);
          Module["HEAPU16"] = HEAPU16 = new Uint16Array(buf);
          Module["HEAPU32"] = HEAPU32 = new Uint32Array(buf);
          Module["HEAPF32"] = HEAPF32 = new Float32Array(buf);
          Module["HEAPF64"] = HEAPF64 = new Float64Array(buf);
        }
        var INITIAL_MEMORY = Module["INITIAL_MEMORY"] || 16777216;
        if (ENVIRONMENT_IS_PTHREAD) {
          wasmMemory = Module["wasmMemory"];
          buffer3 = Module["buffer"];
        } else {
          if (Module["wasmMemory"]) {
            wasmMemory = Module["wasmMemory"];
          } else {
            wasmMemory = new WebAssembly.Memory({ "initial": INITIAL_MEMORY / 65536, "maximum": 2147483648 / 65536, "shared": true });
            if (!(wasmMemory.buffer instanceof SharedArrayBuffer)) {
              err("requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag");
              if (ENVIRONMENT_IS_NODE) {
                console.log("(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and also use a recent version)");
              }
              throw Error("bad memory");
            }
          }
        }
        if (wasmMemory) {
          buffer3 = wasmMemory.buffer;
        }
        INITIAL_MEMORY = buffer3.byteLength;
        updateGlobalBufferAndViews(buffer3);
        var wasmTable;
        var __ATPRERUN__ = [];
        var __ATINIT__ = [];
        var __ATMAIN__ = [];
        var __ATEXIT__ = [];
        var __ATPOSTRUN__ = [];
        var runtimeInitialized = false;
        var runtimeExited = false;
        if (!ENVIRONMENT_IS_PTHREAD)
          __ATINIT__.push({ func: function() {
            ___wasm_call_ctors();
          } });
        function preRun() {
          if (ENVIRONMENT_IS_PTHREAD)
            return;
          if (Module["preRun"]) {
            if (typeof Module["preRun"] == "function")
              Module["preRun"] = [Module["preRun"]];
            while (Module["preRun"].length) {
              addOnPreRun(Module["preRun"].shift());
            }
          }
          callRuntimeCallbacks(__ATPRERUN__);
        }
        function initRuntime() {
          runtimeInitialized = true;
          if (ENVIRONMENT_IS_PTHREAD)
            return;
          callRuntimeCallbacks(__ATINIT__);
        }
        function preMain() {
          if (ENVIRONMENT_IS_PTHREAD)
            return;
          callRuntimeCallbacks(__ATMAIN__);
        }
        function exitRuntime() {
          if (ENVIRONMENT_IS_PTHREAD)
            return;
          runtimeExited = true;
        }
        function postRun() {
          if (ENVIRONMENT_IS_PTHREAD)
            return;
          if (Module["postRun"]) {
            if (typeof Module["postRun"] == "function")
              Module["postRun"] = [Module["postRun"]];
            while (Module["postRun"].length) {
              addOnPostRun(Module["postRun"].shift());
            }
          }
          callRuntimeCallbacks(__ATPOSTRUN__);
        }
        function addOnPreRun(cb) {
          __ATPRERUN__.unshift(cb);
        }
        function addOnPostRun(cb) {
          __ATPOSTRUN__.unshift(cb);
        }
        var runDependencies = 0;
        var runDependencyWatcher = null;
        var dependenciesFulfilled = null;
        function addRunDependency(id) {
          assert4(!ENVIRONMENT_IS_PTHREAD, "addRunDependency cannot be used in a pthread worker");
          runDependencies++;
          if (Module["monitorRunDependencies"]) {
            Module["monitorRunDependencies"](runDependencies);
          }
        }
        function removeRunDependency(id) {
          runDependencies--;
          if (Module["monitorRunDependencies"]) {
            Module["monitorRunDependencies"](runDependencies);
          }
          if (runDependencies == 0) {
            if (runDependencyWatcher !== null) {
              clearInterval(runDependencyWatcher);
              runDependencyWatcher = null;
            }
            if (dependenciesFulfilled) {
              var callback = dependenciesFulfilled;
              dependenciesFulfilled = null;
              callback();
            }
          }
        }
        Module["preloadedImages"] = {};
        Module["preloadedAudios"] = {};
        function abort(what) {
          if (Module["onAbort"]) {
            Module["onAbort"](what);
          }
          if (ENVIRONMENT_IS_PTHREAD)
            console.error("Pthread aborting at " + new Error().stack);
          what += "";
          err(what);
          ABORT = true;
          EXITSTATUS = 1;
          what = "abort(" + what + "). Build with -s ASSERTIONS=1 for more info.";
          var e = new WebAssembly.RuntimeError(what);
          readyPromiseReject(e);
          throw e;
        }
        function hasPrefix(str, prefix) {
          return String.prototype.startsWith ? str.startsWith(prefix) : str.indexOf(prefix) === 0;
        }
        var dataURIPrefix = "data:application/octet-stream;base64,";
        function isDataURI(filename) {
          return hasPrefix(filename, dataURIPrefix);
        }
        var fileURIPrefix = "file://";
        function isFileURI(filename) {
          return hasPrefix(filename, fileURIPrefix);
        }
        var wasmBinaryFile = "tfjs-backend-wasm-threaded-simd.wasm";
        if (!isDataURI(wasmBinaryFile)) {
          wasmBinaryFile = locateFile(wasmBinaryFile);
        }
        function getBinary(file) {
          try {
            if (file == wasmBinaryFile && wasmBinary) {
              return new Uint8Array(wasmBinary);
            }
            if (readBinary) {
              return readBinary(file);
            } else {
              throw "both async and sync fetching of the wasm failed";
            }
          } catch (err2) {
            abort(err2);
          }
        }
        function getBinaryPromise() {
          if (!wasmBinary && (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER)) {
            if (typeof fetch === "function" && !isFileURI(wasmBinaryFile)) {
              return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                if (!response["ok"]) {
                  throw "failed to load wasm binary file at '" + wasmBinaryFile + "'";
                }
                return response["arrayBuffer"]();
              }).catch(function() {
                return getBinary(wasmBinaryFile);
              });
            } else {
              if (readAsync) {
                return new Promise(function(resolve, reject) {
                  readAsync(wasmBinaryFile, function(response) {
                    resolve(new Uint8Array(response));
                  }, reject);
                });
              }
            }
          }
          return Promise.resolve().then(function() {
            return getBinary(wasmBinaryFile);
          });
        }
        function createWasm() {
          var info = { "a": asmLibraryArg };
          function receiveInstance(instance, module2) {
            var exports3 = instance.exports;
            Module["asm"] = exports3;
            wasmTable = Module["asm"]["F"];
            wasmModule = module2;
            if (!ENVIRONMENT_IS_PTHREAD) {
              var numWorkersToLoad = PThread.unusedWorkers.length;
              PThread.unusedWorkers.forEach(function(w) {
                PThread.loadWasmModuleToWorker(w, function() {
                  if (!--numWorkersToLoad)
                    removeRunDependency("wasm-instantiate");
                });
              });
            }
          }
          if (!ENVIRONMENT_IS_PTHREAD) {
            addRunDependency("wasm-instantiate");
          }
          function receiveInstantiatedSource(output) {
            receiveInstance(output["instance"], output["module"]);
          }
          function instantiateArrayBuffer(receiver) {
            return getBinaryPromise().then(function(binary) {
              return WebAssembly.instantiate(binary, info);
            }).then(receiver, function(reason) {
              err("failed to asynchronously prepare wasm: " + reason);
              abort(reason);
            });
          }
          function instantiateAsync() {
            if (!wasmBinary && typeof WebAssembly.instantiateStreaming === "function" && !isDataURI(wasmBinaryFile) && !isFileURI(wasmBinaryFile) && typeof fetch === "function") {
              return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                var result = WebAssembly.instantiateStreaming(response, info);
                return result.then(receiveInstantiatedSource, function(reason) {
                  err("wasm streaming compile failed: " + reason);
                  err("falling back to ArrayBuffer instantiation");
                  return instantiateArrayBuffer(receiveInstantiatedSource);
                });
              });
            } else {
              return instantiateArrayBuffer(receiveInstantiatedSource);
            }
          }
          if (Module["instantiateWasm"]) {
            try {
              var exports2 = Module["instantiateWasm"](info, receiveInstance);
              return exports2;
            } catch (e) {
              err("Module.instantiateWasm callback failed with error: " + e);
              return false;
            }
          }
          instantiateAsync().catch(readyPromiseReject);
          return {};
        }
        var ASM_CONSTS = { 9816: function() {
          throw "Canceled!";
        }, 9834: function($0, $1) {
          setTimeout(function() {
            __emscripten_do_dispatch_to_thread($0, $1);
          }, 0);
        } };
        function initPthreadsJS() {
          PThread.initRuntime();
        }
        function callRuntimeCallbacks(callbacks2) {
          while (callbacks2.length > 0) {
            var callback = callbacks2.shift();
            if (typeof callback == "function") {
              callback(Module);
              continue;
            }
            var func2 = callback.func;
            if (typeof func2 === "number") {
              if (callback.arg === void 0) {
                wasmTable.get(func2)();
              } else {
                wasmTable.get(func2)(callback.arg);
              }
            } else {
              func2(callback.arg === void 0 ? null : callback.arg);
            }
          }
        }
        function _emscripten_futex_wake(addr, count2) {
          if (addr <= 0 || addr > GROWABLE_HEAP_I8().length || addr & true || count2 < 0)
            return -28;
          if (count2 == 0)
            return 0;
          if (count2 >= 2147483647)
            count2 = Infinity;
          var mainThreadWaitAddress = Atomics.load(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2);
          var mainThreadWoken = 0;
          if (mainThreadWaitAddress == addr) {
            var loadedAddr = Atomics.compareExchange(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2, mainThreadWaitAddress, 0);
            if (loadedAddr == mainThreadWaitAddress) {
              --count2;
              mainThreadWoken = 1;
              if (count2 <= 0)
                return 1;
            }
          }
          var ret = Atomics.notify(GROWABLE_HEAP_I32(), addr >> 2, count2);
          if (ret >= 0)
            return ret + mainThreadWoken;
          throw "Atomics.notify returned an unexpected value " + ret;
        }
        Module["_emscripten_futex_wake"] = _emscripten_futex_wake;
        function killThread(pthread_ptr) {
          if (ENVIRONMENT_IS_PTHREAD)
            throw "Internal Error! killThread() can only ever be called from main application thread!";
          if (!pthread_ptr)
            throw "Internal Error! Null pthread_ptr in killThread!";
          GROWABLE_HEAP_I32()[pthread_ptr + 12 >> 2] = 0;
          var pthread = PThread.pthreads[pthread_ptr];
          pthread.worker.terminate();
          PThread.freeThreadData(pthread);
          PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(pthread.worker), 1);
          pthread.worker.pthread = void 0;
        }
        function cancelThread(pthread_ptr) {
          if (ENVIRONMENT_IS_PTHREAD)
            throw "Internal Error! cancelThread() can only ever be called from main application thread!";
          if (!pthread_ptr)
            throw "Internal Error! Null pthread_ptr in cancelThread!";
          var pthread = PThread.pthreads[pthread_ptr];
          pthread.worker.postMessage({ "cmd": "cancel" });
        }
        function cleanupThread(pthread_ptr) {
          if (ENVIRONMENT_IS_PTHREAD)
            throw "Internal Error! cleanupThread() can only ever be called from main application thread!";
          if (!pthread_ptr)
            throw "Internal Error! Null pthread_ptr in cleanupThread!";
          var pthread = PThread.pthreads[pthread_ptr];
          if (pthread) {
            GROWABLE_HEAP_I32()[pthread_ptr + 12 >> 2] = 0;
            var worker = pthread.worker;
            PThread.returnWorkerToPool(worker);
          }
        }
        var PThread = { unusedWorkers: [], runningWorkers: [], initMainThreadBlock: function() {
          var pthreadPoolSize = Math.min(4, Math.max(1, (navigator.hardwareConcurrency || 1) / 2));
          for (var i = 0; i < pthreadPoolSize; ++i) {
            PThread.allocateUnusedWorker();
          }
        }, initRuntime: function() {
          var tb = _malloc(228);
          for (var i = 0; i < 228 / 4; ++i)
            GROWABLE_HEAP_U32()[tb / 4 + i] = 0;
          GROWABLE_HEAP_I32()[tb + 12 >> 2] = tb;
          var headPtr = tb + 152;
          GROWABLE_HEAP_I32()[headPtr >> 2] = headPtr;
          var tlsMemory = _malloc(512);
          for (var i = 0; i < 128; ++i)
            GROWABLE_HEAP_U32()[tlsMemory / 4 + i] = 0;
          Atomics.store(GROWABLE_HEAP_U32(), tb + 100 >> 2, tlsMemory);
          Atomics.store(GROWABLE_HEAP_U32(), tb + 40 >> 2, tb);
          __emscripten_thread_init(tb, !ENVIRONMENT_IS_WORKER, 1);
          _emscripten_register_main_browser_thread_id(tb);
        }, initWorker: function() {
        }, pthreads: {}, threadExitHandlers: [], setThreadStatus: function() {
        }, runExitHandlers: function() {
          while (PThread.threadExitHandlers.length > 0) {
            PThread.threadExitHandlers.pop()();
          }
          if (ENVIRONMENT_IS_PTHREAD && _pthread_self())
            ___pthread_tsd_run_dtors();
        }, runExitHandlersAndDeinitThread: function(tb, exitCode) {
          Atomics.store(GROWABLE_HEAP_U32(), tb + 56 >> 2, 1);
          Atomics.store(GROWABLE_HEAP_U32(), tb + 60 >> 2, 0);
          PThread.runExitHandlers();
          Atomics.store(GROWABLE_HEAP_U32(), tb + 4 >> 2, exitCode);
          Atomics.store(GROWABLE_HEAP_U32(), tb + 0 >> 2, 1);
          _emscripten_futex_wake(tb + 0, 2147483647);
          __emscripten_thread_init(0, 0, 0);
        }, threadExit: function(exitCode) {
          var tb = _pthread_self();
          if (tb) {
            PThread.runExitHandlersAndDeinitThread(tb, exitCode);
            if (ENVIRONMENT_IS_PTHREAD) {
              postMessage({ "cmd": "exit" });
            }
          }
        }, threadCancel: function() {
          PThread.runExitHandlersAndDeinitThread(_pthread_self(), -1);
          postMessage({ "cmd": "cancelDone" });
        }, terminateAllThreads: function() {
          for (var t in PThread.pthreads) {
            var pthread = PThread.pthreads[t];
            if (pthread && pthread.worker) {
              PThread.returnWorkerToPool(pthread.worker);
            }
          }
          PThread.pthreads = {};
          for (var i = 0; i < PThread.unusedWorkers.length; ++i) {
            var worker = PThread.unusedWorkers[i];
            worker.terminate();
          }
          PThread.unusedWorkers = [];
          for (var i = 0; i < PThread.runningWorkers.length; ++i) {
            var worker = PThread.runningWorkers[i];
            var pthread = worker.pthread;
            PThread.freeThreadData(pthread);
            worker.terminate();
          }
          PThread.runningWorkers = [];
        }, freeThreadData: function(pthread) {
          if (!pthread)
            return;
          if (pthread.threadInfoStruct) {
            var tlsMemory = GROWABLE_HEAP_I32()[pthread.threadInfoStruct + 100 >> 2];
            GROWABLE_HEAP_I32()[pthread.threadInfoStruct + 100 >> 2] = 0;
            _free(tlsMemory);
            _free(pthread.threadInfoStruct);
          }
          pthread.threadInfoStruct = 0;
          if (pthread.allocatedOwnStack && pthread.stackBase)
            _free(pthread.stackBase);
          pthread.stackBase = 0;
          if (pthread.worker)
            pthread.worker.pthread = null;
        }, returnWorkerToPool: function(worker) {
          PThread.runWithoutMainThreadQueuedCalls(function() {
            delete PThread.pthreads[worker.pthread.threadInfoStruct];
            PThread.unusedWorkers.push(worker);
            PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker), 1);
            PThread.freeThreadData(worker.pthread);
            worker.pthread = void 0;
          });
        }, runWithoutMainThreadQueuedCalls: function(func2) {
          GROWABLE_HEAP_I32()[__emscripten_allow_main_runtime_queued_calls >> 2] = 0;
          try {
            func2();
          } finally {
            GROWABLE_HEAP_I32()[__emscripten_allow_main_runtime_queued_calls >> 2] = 1;
          }
        }, receiveObjectTransfer: function(data) {
        }, loadWasmModuleToWorker: function(worker, onFinishedLoading) {
          worker.onmessage = function(e) {
            var d = e["data"];
            var cmd = d["cmd"];
            if (worker.pthread)
              PThread.currentProxiedOperationCallerThread = worker.pthread.threadInfoStruct;
            if (d["targetThread"] && d["targetThread"] != _pthread_self()) {
              var thread = PThread.pthreads[d.targetThread];
              if (thread) {
                thread.worker.postMessage(e.data, d["transferList"]);
              } else {
                console.error('Internal error! Worker sent a message "' + cmd + '" to target pthread ' + d["targetThread"] + ", but that thread no longer exists!");
              }
              PThread.currentProxiedOperationCallerThread = void 0;
              return;
            }
            if (cmd === "processQueuedMainThreadWork") {
              _emscripten_main_thread_process_queued_calls();
            } else if (cmd === "spawnThread") {
              spawnThread(e.data);
            } else if (cmd === "cleanupThread") {
              cleanupThread(d["thread"]);
            } else if (cmd === "killThread") {
              killThread(d["thread"]);
            } else if (cmd === "cancelThread") {
              cancelThread(d["thread"]);
            } else if (cmd === "loaded") {
              worker.loaded = true;
              if (onFinishedLoading)
                onFinishedLoading(worker);
              if (worker.runPthread) {
                worker.runPthread();
                delete worker.runPthread;
              }
            } else if (cmd === "print") {
              out("Thread " + d["threadId"] + ": " + d["text"]);
            } else if (cmd === "printErr") {
              err("Thread " + d["threadId"] + ": " + d["text"]);
            } else if (cmd === "alert") {
              alert("Thread " + d["threadId"] + ": " + d["text"]);
            } else if (cmd === "exit") {
              var detached = worker.pthread && Atomics.load(GROWABLE_HEAP_U32(), worker.pthread.threadInfoStruct + 64 >> 2);
              if (detached) {
                PThread.returnWorkerToPool(worker);
              }
            } else if (cmd === "exitProcess") {
              try {
                exit(d["returnCode"]);
              } catch (e2) {
                if (e2 instanceof ExitStatus)
                  return;
                throw e2;
              }
            } else if (cmd === "cancelDone") {
              PThread.returnWorkerToPool(worker);
            } else if (cmd === "objectTransfer") {
              PThread.receiveObjectTransfer(e.data);
            } else if (e.data.target === "setimmediate") {
              worker.postMessage(e.data);
            } else {
              err("worker sent an unknown command " + cmd);
            }
            PThread.currentProxiedOperationCallerThread = void 0;
          };
          worker.onerror = function(e) {
            err("pthread sent an error! " + e.filename + ":" + e.lineno + ": " + e.message);
          };
          if (ENVIRONMENT_IS_NODE) {
            worker.on("message", function(data) {
              worker.onmessage({ data });
            });
            worker.on("error", function(data) {
              worker.onerror(data);
            });
            worker.on("exit", function(data) {
            });
          }
          worker.postMessage({ "cmd": "load", "urlOrBlob": Module["mainScriptUrlOrBlob"] || _scriptDir, "wasmMemory": wasmMemory, "wasmModule": wasmModule });
        }, allocateUnusedWorker: function() {
          var pthreadMainJs = locateFile("tfjs-backend-wasm-threaded-simd.worker.js");
          PThread.unusedWorkers.push(new Worker(pthreadMainJs));
        }, getNewWorker: function() {
          if (PThread.unusedWorkers.length == 0) {
            PThread.allocateUnusedWorker();
            PThread.loadWasmModuleToWorker(PThread.unusedWorkers[0]);
          }
          if (PThread.unusedWorkers.length > 0)
            return PThread.unusedWorkers.pop();
          else
            return null;
        }, busySpinWait: function(msecs) {
          var t = performance.now() + msecs;
          while (performance.now() < t) {
          }
        } };
        function establishStackSpace(stackTop, stackMax) {
          _emscripten_stack_set_limits(stackTop, stackMax);
          stackRestore(stackTop);
        }
        Module["establishStackSpace"] = establishStackSpace;
        function getNoExitRuntime() {
          return noExitRuntime;
        }
        Module["getNoExitRuntime"] = getNoExitRuntime;
        function invokeEntryPoint(ptr, arg) {
          return wasmTable.get(ptr)(arg);
        }
        Module["invokeEntryPoint"] = invokeEntryPoint;
        function ___assert_fail(condition, filename, line, func2) {
          abort("Assertion failed: " + UTF8ToString(condition) + ", at: " + [filename ? UTF8ToString(filename) : "unknown filename", line, func2 ? UTF8ToString(func2) : "unknown function"]);
        }
        function ___call_main(argc, argv) {
          var returnCode = _main(argc, argv);
        }
        var _emscripten_get_now;
        if (ENVIRONMENT_IS_NODE) {
          _emscripten_get_now = function() {
            var t = process["hrtime"]();
            return t[0] * 1e3 + t[1] / 1e6;
          };
        } else if (ENVIRONMENT_IS_PTHREAD) {
          _emscripten_get_now = function() {
            return performance.now() - Module["__performance_now_clock_drift"];
          };
        } else if (typeof dateNow !== "undefined") {
          _emscripten_get_now = dateNow;
        } else
          _emscripten_get_now = function() {
            return performance.now();
          };
        function setErrNo(value) {
          GROWABLE_HEAP_I32()[___errno_location() >> 2] = value;
          return value;
        }
        function _atexit(func2, arg) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(1, 1, func2, arg);
        }
        function __emscripten_notify_thread_queue(targetThreadId, mainThreadId) {
          if (targetThreadId == mainThreadId) {
            postMessage({ "cmd": "processQueuedMainThreadWork" });
          } else if (ENVIRONMENT_IS_PTHREAD) {
            postMessage({ "targetThread": targetThreadId, "cmd": "processThreadQueue" });
          } else {
            var pthread = PThread.pthreads[targetThreadId];
            var worker = pthread && pthread.worker;
            if (!worker) {
              return;
            }
            worker.postMessage({ "cmd": "processThreadQueue" });
          }
          return 1;
        }
        function _abort() {
          abort();
        }
        function _emscripten_asm_const_int(code, sigPtr, argbuf) {
          var args = readAsmConstArgs(sigPtr, argbuf);
          return ASM_CONSTS[code].apply(null, args);
        }
        function _emscripten_conditional_set_current_thread_status(expectedStatus, newStatus) {
        }
        function _emscripten_futex_wait(addr, val, timeout) {
          if (addr <= 0 || addr > GROWABLE_HEAP_I8().length || addr & true)
            return -28;
          if (!ENVIRONMENT_IS_WEB) {
            var ret = Atomics.wait(GROWABLE_HEAP_I32(), addr >> 2, val, timeout);
            if (ret === "timed-out")
              return -73;
            if (ret === "not-equal")
              return -6;
            if (ret === "ok")
              return 0;
            throw "Atomics.wait returned an unexpected value " + ret;
          } else {
            if (Atomics.load(GROWABLE_HEAP_I32(), addr >> 2) != val) {
              return -6;
            }
            var tNow = performance.now();
            var tEnd = tNow + timeout;
            var lastAddr = Atomics.exchange(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2, addr);
            while (1) {
              tNow = performance.now();
              if (tNow > tEnd) {
                lastAddr = Atomics.exchange(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2, 0);
                return -73;
              }
              lastAddr = Atomics.exchange(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2, 0);
              if (lastAddr == 0) {
                break;
              }
              _emscripten_main_thread_process_queued_calls();
              if (Atomics.load(GROWABLE_HEAP_I32(), addr >> 2) != val) {
                return -6;
              }
              lastAddr = Atomics.exchange(GROWABLE_HEAP_I32(), __emscripten_main_thread_futex >> 2, addr);
            }
            return 0;
          }
        }
        function _emscripten_memcpy_big(dest, src, num) {
          GROWABLE_HEAP_U8().copyWithin(dest, src, src + num);
        }
        function _emscripten_num_logical_cores() {
          if (ENVIRONMENT_IS_NODE)
            return __require("os").cpus().length;
          return navigator["hardwareConcurrency"];
        }
        function _emscripten_proxy_to_main_thread_js(index, sync) {
          var numCallArgs = arguments.length - 2;
          var stack3 = stackSave();
          var serializedNumCallArgs = numCallArgs;
          var args = stackAlloc(serializedNumCallArgs * 8);
          var b = args >> 3;
          for (var i = 0; i < numCallArgs; i++) {
            var arg = arguments[2 + i];
            GROWABLE_HEAP_F64()[b + i] = arg;
          }
          var ret = _emscripten_run_in_main_runtime_thread_js(index, serializedNumCallArgs, args, sync);
          stackRestore(stack3);
          return ret;
        }
        var _emscripten_receive_on_main_thread_js_callArgs = [];
        var readAsmConstArgsArray = [];
        function readAsmConstArgs(sigPtr, buf) {
          readAsmConstArgsArray.length = 0;
          var ch;
          buf >>= 2;
          while (ch = GROWABLE_HEAP_U8()[sigPtr++]) {
            var double = ch < 105;
            if (double && buf & 1)
              buf++;
            readAsmConstArgsArray.push(double ? GROWABLE_HEAP_F64()[buf++ >> 1] : GROWABLE_HEAP_I32()[buf]);
            ++buf;
          }
          return readAsmConstArgsArray;
        }
        function _emscripten_receive_on_main_thread_js(index, numCallArgs, args) {
          _emscripten_receive_on_main_thread_js_callArgs.length = numCallArgs;
          var b = args >> 3;
          for (var i = 0; i < numCallArgs; i++) {
            _emscripten_receive_on_main_thread_js_callArgs[i] = GROWABLE_HEAP_F64()[b + i];
          }
          var isEmAsmConst = index < 0;
          var func2 = !isEmAsmConst ? proxiedFunctionTable[index] : ASM_CONSTS[-index - 1];
          return func2.apply(null, _emscripten_receive_on_main_thread_js_callArgs);
        }
        function _emscripten_get_heap_size() {
          return GROWABLE_HEAP_U8().length;
        }
        function emscripten_realloc_buffer(size) {
          try {
            wasmMemory.grow(size - buffer3.byteLength + 65535 >>> 16);
            updateGlobalBufferAndViews(wasmMemory.buffer);
            return 1;
          } catch (e) {
          }
        }
        function _emscripten_resize_heap(requestedSize) {
          var oldSize = _emscripten_get_heap_size();
          if (requestedSize <= oldSize) {
            return false;
          }
          var maxHeapSize = 2147483648;
          if (requestedSize > maxHeapSize) {
            return false;
          }
          for (var cutDown = 1; cutDown <= 4; cutDown *= 2) {
            var overGrownHeapSize = oldSize * (1 + 0.2 / cutDown);
            overGrownHeapSize = Math.min(overGrownHeapSize, requestedSize + 100663296);
            var newSize = Math.min(maxHeapSize, alignUp(Math.max(requestedSize, overGrownHeapSize), 65536));
            var replacement = emscripten_realloc_buffer(newSize);
            if (replacement) {
              return true;
            }
          }
          return false;
        }
        var JSEvents = { inEventHandler: 0, removeAllEventListeners: function() {
          for (var i = JSEvents.eventHandlers.length - 1; i >= 0; --i) {
            JSEvents._removeHandler(i);
          }
          JSEvents.eventHandlers = [];
          JSEvents.deferredCalls = [];
        }, registerRemoveEventListeners: function() {
          if (!JSEvents.removeEventListenersRegistered) {
            __ATEXIT__.push(JSEvents.removeAllEventListeners);
            JSEvents.removeEventListenersRegistered = true;
          }
        }, deferredCalls: [], deferCall: function(targetFunction, precedence, argsList) {
          function arraysHaveEqualContent(arrA, arrB) {
            if (arrA.length != arrB.length)
              return false;
            for (var i2 in arrA) {
              if (arrA[i2] != arrB[i2])
                return false;
            }
            return true;
          }
          for (var i in JSEvents.deferredCalls) {
            var call = JSEvents.deferredCalls[i];
            if (call.targetFunction == targetFunction && arraysHaveEqualContent(call.argsList, argsList)) {
              return;
            }
          }
          JSEvents.deferredCalls.push({ targetFunction, precedence, argsList });
          JSEvents.deferredCalls.sort(function(x, y) {
            return x.precedence < y.precedence;
          });
        }, removeDeferredCalls: function(targetFunction) {
          for (var i = 0; i < JSEvents.deferredCalls.length; ++i) {
            if (JSEvents.deferredCalls[i].targetFunction == targetFunction) {
              JSEvents.deferredCalls.splice(i, 1);
              --i;
            }
          }
        }, canPerformEventHandlerRequests: function() {
          return JSEvents.inEventHandler && JSEvents.currentEventHandler.allowsDeferredCalls;
        }, runDeferredCalls: function() {
          if (!JSEvents.canPerformEventHandlerRequests()) {
            return;
          }
          for (var i = 0; i < JSEvents.deferredCalls.length; ++i) {
            var call = JSEvents.deferredCalls[i];
            JSEvents.deferredCalls.splice(i, 1);
            --i;
            call.targetFunction.apply(null, call.argsList);
          }
        }, eventHandlers: [], removeAllHandlersOnTarget: function(target, eventTypeString) {
          for (var i = 0; i < JSEvents.eventHandlers.length; ++i) {
            if (JSEvents.eventHandlers[i].target == target && (!eventTypeString || eventTypeString == JSEvents.eventHandlers[i].eventTypeString)) {
              JSEvents._removeHandler(i--);
            }
          }
        }, _removeHandler: function(i) {
          var h = JSEvents.eventHandlers[i];
          h.target.removeEventListener(h.eventTypeString, h.eventListenerFunc, h.useCapture);
          JSEvents.eventHandlers.splice(i, 1);
        }, registerOrRemoveHandler: function(eventHandler) {
          var jsEventHandler = function jsEventHandler2(event) {
            ++JSEvents.inEventHandler;
            JSEvents.currentEventHandler = eventHandler;
            JSEvents.runDeferredCalls();
            eventHandler.handlerFunc(event);
            JSEvents.runDeferredCalls();
            --JSEvents.inEventHandler;
          };
          if (eventHandler.callbackfunc) {
            eventHandler.eventListenerFunc = jsEventHandler;
            eventHandler.target.addEventListener(eventHandler.eventTypeString, jsEventHandler, eventHandler.useCapture);
            JSEvents.eventHandlers.push(eventHandler);
            JSEvents.registerRemoveEventListeners();
          } else {
            for (var i = 0; i < JSEvents.eventHandlers.length; ++i) {
              if (JSEvents.eventHandlers[i].target == eventHandler.target && JSEvents.eventHandlers[i].eventTypeString == eventHandler.eventTypeString) {
                JSEvents._removeHandler(i--);
              }
            }
          }
        }, queueEventHandlerOnThread_iiii: function(targetThread, eventHandlerFunc, eventTypeId, eventData, userData) {
          var stackTop = stackSave();
          var varargs = stackAlloc(12);
          GROWABLE_HEAP_I32()[varargs >> 2] = eventTypeId;
          GROWABLE_HEAP_I32()[varargs + 4 >> 2] = eventData;
          GROWABLE_HEAP_I32()[varargs + 8 >> 2] = userData;
          __emscripten_call_on_thread(0, targetThread, 637534208, eventHandlerFunc, eventData, varargs);
          stackRestore(stackTop);
        }, getTargetThreadForEventCallback: function(targetThread) {
          switch (targetThread) {
            case 1:
              return 0;
            case 2:
              return PThread.currentProxiedOperationCallerThread;
            default:
              return targetThread;
          }
        }, getNodeNameForTarget: function(target) {
          if (!target)
            return "";
          if (target == window)
            return "#window";
          if (target == screen)
            return "#screen";
          return target && target.nodeName ? target.nodeName : "";
        }, fullscreenEnabled: function() {
          return document.fullscreenEnabled || document.webkitFullscreenEnabled;
        } };
        function stringToNewUTF8(jsString) {
          var length = lengthBytesUTF8(jsString) + 1;
          var cString = _malloc(length);
          stringToUTF8(jsString, cString, length);
          return cString;
        }
        function _emscripten_set_offscreencanvas_size_on_target_thread_js(targetThread, targetCanvas, width, height) {
          var stackTop = stackSave();
          var varargs = stackAlloc(12);
          var targetCanvasPtr = 0;
          if (targetCanvas) {
            targetCanvasPtr = stringToNewUTF8(targetCanvas);
          }
          GROWABLE_HEAP_I32()[varargs >> 2] = targetCanvasPtr;
          GROWABLE_HEAP_I32()[varargs + 4 >> 2] = width;
          GROWABLE_HEAP_I32()[varargs + 8 >> 2] = height;
          __emscripten_call_on_thread(0, targetThread, 657457152, 0, targetCanvasPtr, varargs);
          stackRestore(stackTop);
        }
        function _emscripten_set_offscreencanvas_size_on_target_thread(targetThread, targetCanvas, width, height) {
          targetCanvas = targetCanvas ? UTF8ToString(targetCanvas) : "";
          _emscripten_set_offscreencanvas_size_on_target_thread_js(targetThread, targetCanvas, width, height);
        }
        function maybeCStringToJsString(cString) {
          return cString > 2 ? UTF8ToString(cString) : cString;
        }
        var specialHTMLTargets = [0, typeof document !== "undefined" ? document : 0, typeof window !== "undefined" ? window : 0];
        function findEventTarget(target) {
          target = maybeCStringToJsString(target);
          var domElement = specialHTMLTargets[target] || (typeof document !== "undefined" ? document.querySelector(target) : void 0);
          return domElement;
        }
        function findCanvasEventTarget(target) {
          return findEventTarget(target);
        }
        function _emscripten_set_canvas_element_size_calling_thread(target, width, height) {
          var canvas = findCanvasEventTarget(target);
          if (!canvas)
            return -4;
          if (canvas.canvasSharedPtr) {
            GROWABLE_HEAP_I32()[canvas.canvasSharedPtr >> 2] = width;
            GROWABLE_HEAP_I32()[canvas.canvasSharedPtr + 4 >> 2] = height;
          }
          if (canvas.offscreenCanvas || !canvas.controlTransferredOffscreen) {
            if (canvas.offscreenCanvas)
              canvas = canvas.offscreenCanvas;
            var autoResizeViewport = false;
            if (canvas.GLctxObject && canvas.GLctxObject.GLctx) {
              var prevViewport = canvas.GLctxObject.GLctx.getParameter(2978);
              autoResizeViewport = prevViewport[0] === 0 && prevViewport[1] === 0 && prevViewport[2] === canvas.width && prevViewport[3] === canvas.height;
            }
            canvas.width = width;
            canvas.height = height;
            if (autoResizeViewport) {
              canvas.GLctxObject.GLctx.viewport(0, 0, width, height);
            }
          } else if (canvas.canvasSharedPtr) {
            var targetThread = GROWABLE_HEAP_I32()[canvas.canvasSharedPtr + 8 >> 2];
            _emscripten_set_offscreencanvas_size_on_target_thread(targetThread, target, width, height);
            return 1;
          } else {
            return -4;
          }
          return 0;
        }
        function _emscripten_set_canvas_element_size_main_thread(target, width, height) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(2, 1, target, width, height);
          return _emscripten_set_canvas_element_size_calling_thread(target, width, height);
        }
        function _emscripten_set_canvas_element_size(target, width, height) {
          var canvas = findCanvasEventTarget(target);
          if (canvas) {
            return _emscripten_set_canvas_element_size_calling_thread(target, width, height);
          } else {
            return _emscripten_set_canvas_element_size_main_thread(target, width, height);
          }
        }
        function _emscripten_set_current_thread_status(newStatus) {
        }
        function _emscripten_set_thread_name(threadId, name) {
        }
        function __webgl_enable_ANGLE_instanced_arrays(ctx) {
          var ext = ctx.getExtension("ANGLE_instanced_arrays");
          if (ext) {
            ctx["vertexAttribDivisor"] = function(index, divisor) {
              ext["vertexAttribDivisorANGLE"](index, divisor);
            };
            ctx["drawArraysInstanced"] = function(mode, first, count2, primcount) {
              ext["drawArraysInstancedANGLE"](mode, first, count2, primcount);
            };
            ctx["drawElementsInstanced"] = function(mode, count2, type, indices, primcount) {
              ext["drawElementsInstancedANGLE"](mode, count2, type, indices, primcount);
            };
            return 1;
          }
        }
        function __webgl_enable_OES_vertex_array_object(ctx) {
          var ext = ctx.getExtension("OES_vertex_array_object");
          if (ext) {
            ctx["createVertexArray"] = function() {
              return ext["createVertexArrayOES"]();
            };
            ctx["deleteVertexArray"] = function(vao) {
              ext["deleteVertexArrayOES"](vao);
            };
            ctx["bindVertexArray"] = function(vao) {
              ext["bindVertexArrayOES"](vao);
            };
            ctx["isVertexArray"] = function(vao) {
              return ext["isVertexArrayOES"](vao);
            };
            return 1;
          }
        }
        function __webgl_enable_WEBGL_draw_buffers(ctx) {
          var ext = ctx.getExtension("WEBGL_draw_buffers");
          if (ext) {
            ctx["drawBuffers"] = function(n, bufs) {
              ext["drawBuffersWEBGL"](n, bufs);
            };
            return 1;
          }
        }
        function __webgl_enable_WEBGL_multi_draw(ctx) {
          return !!(ctx.multiDrawWebgl = ctx.getExtension("WEBGL_multi_draw"));
        }
        var GL = { counter: 1, buffers: [], programs: [], framebuffers: [], renderbuffers: [], textures: [], uniforms: [], shaders: [], vaos: [], contexts: {}, offscreenCanvases: {}, timerQueriesEXT: [], programInfos: {}, stringCache: {}, unpackAlignment: 4, recordError: function recordError(errorCode) {
          if (!GL.lastError) {
            GL.lastError = errorCode;
          }
        }, getNewId: function(table) {
          var ret = GL.counter++;
          for (var i = table.length; i < ret; i++) {
            table[i] = null;
          }
          return ret;
        }, getSource: function(shader, count2, string4, length) {
          var source = "";
          for (var i = 0; i < count2; ++i) {
            var len = length ? GROWABLE_HEAP_I32()[length + i * 4 >> 2] : -1;
            source += UTF8ToString(GROWABLE_HEAP_I32()[string4 + i * 4 >> 2], len < 0 ? void 0 : len);
          }
          return source;
        }, createContext: function(canvas, webGLContextAttributes) {
          var ctx = canvas.getContext("webgl", webGLContextAttributes);
          if (!ctx)
            return 0;
          var handle = GL.registerContext(ctx, webGLContextAttributes);
          return handle;
        }, registerContext: function(ctx, webGLContextAttributes) {
          var handle = _malloc(8);
          GROWABLE_HEAP_I32()[handle + 4 >> 2] = _pthread_self();
          var context = { handle, attributes: webGLContextAttributes, version: webGLContextAttributes.majorVersion, GLctx: ctx };
          if (ctx.canvas)
            ctx.canvas.GLctxObject = context;
          GL.contexts[handle] = context;
          if (typeof webGLContextAttributes.enableExtensionsByDefault === "undefined" || webGLContextAttributes.enableExtensionsByDefault) {
            GL.initExtensions(context);
          }
          return handle;
        }, makeContextCurrent: function(contextHandle) {
          GL.currentContext = GL.contexts[contextHandle];
          Module.ctx = GLctx = GL.currentContext && GL.currentContext.GLctx;
          return !(contextHandle && !GLctx);
        }, getContext: function(contextHandle) {
          return GL.contexts[contextHandle];
        }, deleteContext: function(contextHandle) {
          if (GL.currentContext === GL.contexts[contextHandle])
            GL.currentContext = null;
          if (typeof JSEvents === "object")
            JSEvents.removeAllHandlersOnTarget(GL.contexts[contextHandle].GLctx.canvas);
          if (GL.contexts[contextHandle] && GL.contexts[contextHandle].GLctx.canvas)
            GL.contexts[contextHandle].GLctx.canvas.GLctxObject = void 0;
          _free(GL.contexts[contextHandle].handle);
          GL.contexts[contextHandle] = null;
        }, initExtensions: function(context) {
          if (!context)
            context = GL.currentContext;
          if (context.initExtensionsDone)
            return;
          context.initExtensionsDone = true;
          var GLctx2 = context.GLctx;
          __webgl_enable_ANGLE_instanced_arrays(GLctx2);
          __webgl_enable_OES_vertex_array_object(GLctx2);
          __webgl_enable_WEBGL_draw_buffers(GLctx2);
          GLctx2.disjointTimerQueryExt = GLctx2.getExtension("EXT_disjoint_timer_query");
          __webgl_enable_WEBGL_multi_draw(GLctx2);
          var exts = GLctx2.getSupportedExtensions() || [];
          exts.forEach(function(ext) {
            if (ext.indexOf("lose_context") < 0 && ext.indexOf("debug") < 0) {
              GLctx2.getExtension(ext);
            }
          });
        }, populateUniformTable: function(program) {
          var p2 = GL.programs[program];
          var ptable = GL.programInfos[program] = { uniforms: {}, maxUniformLength: 0, maxAttributeLength: -1, maxUniformBlockNameLength: -1 };
          var utable = ptable.uniforms;
          var numUniforms = GLctx.getProgramParameter(p2, 35718);
          for (var i = 0; i < numUniforms; ++i) {
            var u = GLctx.getActiveUniform(p2, i);
            var name = u.name;
            ptable.maxUniformLength = Math.max(ptable.maxUniformLength, name.length + 1);
            if (name.slice(-1) == "]") {
              name = name.slice(0, name.lastIndexOf("["));
            }
            var loc = GLctx.getUniformLocation(p2, name);
            if (loc) {
              var id = GL.getNewId(GL.uniforms);
              utable[name] = [u.size, id];
              GL.uniforms[id] = loc;
              for (var j = 1; j < u.size; ++j) {
                var n = name + "[" + j + "]";
                loc = GLctx.getUniformLocation(p2, n);
                id = GL.getNewId(GL.uniforms);
                GL.uniforms[id] = loc;
              }
            }
          }
        } };
        var __emscripten_webgl_power_preferences = ["default", "low-power", "high-performance"];
        function _emscripten_webgl_do_create_context(target, attributes) {
          var a = attributes >> 2;
          var powerPreference = GROWABLE_HEAP_I32()[a + (24 >> 2)];
          var contextAttributes = { "alpha": !!GROWABLE_HEAP_I32()[a + (0 >> 2)], "depth": !!GROWABLE_HEAP_I32()[a + (4 >> 2)], "stencil": !!GROWABLE_HEAP_I32()[a + (8 >> 2)], "antialias": !!GROWABLE_HEAP_I32()[a + (12 >> 2)], "premultipliedAlpha": !!GROWABLE_HEAP_I32()[a + (16 >> 2)], "preserveDrawingBuffer": !!GROWABLE_HEAP_I32()[a + (20 >> 2)], "powerPreference": __emscripten_webgl_power_preferences[powerPreference], "failIfMajorPerformanceCaveat": !!GROWABLE_HEAP_I32()[a + (28 >> 2)], majorVersion: GROWABLE_HEAP_I32()[a + (32 >> 2)], minorVersion: GROWABLE_HEAP_I32()[a + (36 >> 2)], enableExtensionsByDefault: GROWABLE_HEAP_I32()[a + (40 >> 2)], explicitSwapControl: GROWABLE_HEAP_I32()[a + (44 >> 2)], proxyContextToMainThread: GROWABLE_HEAP_I32()[a + (48 >> 2)], renderViaOffscreenBackBuffer: GROWABLE_HEAP_I32()[a + (52 >> 2)] };
          var canvas = findCanvasEventTarget(target);
          if (!canvas) {
            return 0;
          }
          if (contextAttributes.explicitSwapControl) {
            return 0;
          }
          var contextHandle = GL.createContext(canvas, contextAttributes);
          return contextHandle;
        }
        function _emscripten_webgl_create_context(a0, a12) {
          return _emscripten_webgl_do_create_context(a0, a12);
        }
        var SYSCALLS = { mappings: {}, buffers: [null, [], []], printChar: function(stream, curr) {
          var buffer4 = SYSCALLS.buffers[stream];
          if (curr === 0 || curr === 10) {
            (stream === 1 ? out : err)(UTF8ArrayToString(buffer4, 0));
            buffer4.length = 0;
          } else {
            buffer4.push(curr);
          }
        }, varargs: void 0, get: function() {
          SYSCALLS.varargs += 4;
          var ret = GROWABLE_HEAP_I32()[SYSCALLS.varargs - 4 >> 2];
          return ret;
        }, getStr: function(ptr) {
          var ret = UTF8ToString(ptr);
          return ret;
        }, get64: function(low, high) {
          return low;
        } };
        function _fd_close(fd) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(3, 1, fd);
          return 0;
        }
        function _fd_seek(fd, offset_low, offset_high, whence, newOffset) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(4, 1, fd, offset_low, offset_high, whence, newOffset);
        }
        function _fd_write(fd, iov, iovcnt, pnum) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(5, 1, fd, iov, iovcnt, pnum);
          var num = 0;
          for (var i = 0; i < iovcnt; i++) {
            var ptr = GROWABLE_HEAP_I32()[iov + i * 8 >> 2];
            var len = GROWABLE_HEAP_I32()[iov + (i * 8 + 4) >> 2];
            for (var j = 0; j < len; j++) {
              SYSCALLS.printChar(fd, GROWABLE_HEAP_U8()[ptr + j]);
            }
            num += len;
          }
          GROWABLE_HEAP_I32()[pnum >> 2] = num;
          return 0;
        }
        function _pthread_cleanup_pop(execute2) {
          var routine = PThread.threadExitHandlers.pop();
          if (execute2)
            routine();
        }
        function _pthread_cleanup_push(routine, arg) {
          PThread.threadExitHandlers.push(function() {
            wasmTable.get(routine)(arg);
          });
        }
        function spawnThread(threadParams) {
          if (ENVIRONMENT_IS_PTHREAD)
            throw "Internal Error! spawnThread() can only ever be called from main application thread!";
          var worker = PThread.getNewWorker();
          if (worker.pthread !== void 0)
            throw "Internal error!";
          if (!threadParams.pthread_ptr)
            throw "Internal error, no pthread ptr!";
          PThread.runningWorkers.push(worker);
          var tlsMemory = _malloc(128 * 4);
          for (var i = 0; i < 128; ++i) {
            GROWABLE_HEAP_I32()[tlsMemory + i * 4 >> 2] = 0;
          }
          var stackHigh = threadParams.stackBase + threadParams.stackSize;
          var pthread = PThread.pthreads[threadParams.pthread_ptr] = { worker, stackBase: threadParams.stackBase, stackSize: threadParams.stackSize, allocatedOwnStack: threadParams.allocatedOwnStack, threadInfoStruct: threadParams.pthread_ptr };
          var tis = pthread.threadInfoStruct >> 2;
          Atomics.store(GROWABLE_HEAP_U32(), tis + (64 >> 2), threadParams.detached);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (100 >> 2), tlsMemory);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (40 >> 2), pthread.threadInfoStruct);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (80 >> 2), threadParams.stackSize);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (76 >> 2), stackHigh);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (104 >> 2), threadParams.stackSize);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (104 + 8 >> 2), stackHigh);
          Atomics.store(GROWABLE_HEAP_U32(), tis + (104 + 12 >> 2), threadParams.detached);
          var global_libc = _emscripten_get_global_libc();
          var global_locale = global_libc + 40;
          Atomics.store(GROWABLE_HEAP_U32(), tis + (172 >> 2), global_locale);
          worker.pthread = pthread;
          var msg = { "cmd": "run", "start_routine": threadParams.startRoutine, "arg": threadParams.arg, "threadInfoStruct": threadParams.pthread_ptr, "stackBase": threadParams.stackBase, "stackSize": threadParams.stackSize };
          worker.runPthread = function() {
            msg.time = performance.now();
            worker.postMessage(msg, threadParams.transferList);
          };
          if (worker.loaded) {
            worker.runPthread();
            delete worker.runPthread;
          }
        }
        function _pthread_create(pthread_ptr, attr, start_routine, arg) {
          if (typeof SharedArrayBuffer === "undefined") {
            err("Current environment does not support SharedArrayBuffer, pthreads are not available!");
            return 6;
          }
          if (!pthread_ptr) {
            err("pthread_create called with a null thread pointer!");
            return 28;
          }
          var transferList = [];
          var error = 0;
          if (ENVIRONMENT_IS_PTHREAD && (transferList.length === 0 || error)) {
            return _emscripten_sync_run_in_main_thread_4(687865856, pthread_ptr, attr, start_routine, arg);
          }
          if (error)
            return error;
          var stackSize = 0;
          var stackBase = 0;
          var detached = 0;
          if (attr && attr != -1) {
            stackSize = GROWABLE_HEAP_I32()[attr >> 2];
            stackSize += 81920;
            stackBase = GROWABLE_HEAP_I32()[attr + 8 >> 2];
            detached = GROWABLE_HEAP_I32()[attr + 12 >> 2] !== 0;
          } else {
            stackSize = 2097152;
          }
          var allocatedOwnStack = stackBase == 0;
          if (allocatedOwnStack) {
            stackBase = _memalign(16, stackSize);
          } else {
            stackBase -= stackSize;
            assert4(stackBase > 0);
          }
          var threadInfoStruct = _malloc(228);
          for (var i = 0; i < 228 >> 2; ++i)
            GROWABLE_HEAP_U32()[(threadInfoStruct >> 2) + i] = 0;
          GROWABLE_HEAP_I32()[pthread_ptr >> 2] = threadInfoStruct;
          GROWABLE_HEAP_I32()[threadInfoStruct + 12 >> 2] = threadInfoStruct;
          var headPtr = threadInfoStruct + 152;
          GROWABLE_HEAP_I32()[headPtr >> 2] = headPtr;
          var threadParams = { stackBase, stackSize, allocatedOwnStack, detached, startRoutine: start_routine, pthread_ptr: threadInfoStruct, arg, transferList };
          if (ENVIRONMENT_IS_PTHREAD) {
            threadParams.cmd = "spawnThread";
            postMessage(threadParams, transferList);
          } else {
            spawnThread(threadParams);
          }
          return 0;
        }
        function _sysconf(name) {
          if (ENVIRONMENT_IS_PTHREAD)
            return _emscripten_proxy_to_main_thread_js(6, 1, name);
          switch (name) {
            case 30:
              return 16384;
            case 85:
              var maxHeapSize = 2147483648;
              return maxHeapSize / 16384;
            case 132:
            case 133:
            case 12:
            case 137:
            case 138:
            case 15:
            case 235:
            case 16:
            case 17:
            case 18:
            case 19:
            case 20:
            case 149:
            case 13:
            case 10:
            case 236:
            case 153:
            case 9:
            case 21:
            case 22:
            case 159:
            case 154:
            case 14:
            case 77:
            case 78:
            case 139:
            case 82:
            case 68:
            case 67:
            case 164:
            case 11:
            case 29:
            case 47:
            case 48:
            case 95:
            case 52:
            case 51:
            case 46:
              return 200809;
            case 27:
            case 246:
            case 127:
            case 128:
            case 23:
            case 24:
            case 160:
            case 161:
            case 181:
            case 182:
            case 242:
            case 183:
            case 184:
            case 243:
            case 244:
            case 245:
            case 165:
            case 178:
            case 179:
            case 49:
            case 50:
            case 168:
            case 169:
            case 175:
            case 170:
            case 171:
            case 172:
            case 97:
            case 76:
            case 32:
            case 173:
            case 35:
            case 80:
            case 81:
            case 79:
              return -1;
            case 176:
            case 177:
            case 7:
            case 155:
            case 8:
            case 157:
            case 125:
            case 126:
            case 92:
            case 93:
            case 129:
            case 130:
            case 131:
            case 94:
            case 91:
              return 1;
            case 74:
            case 60:
            case 69:
            case 70:
            case 4:
              return 1024;
            case 31:
            case 42:
            case 72:
              return 32;
            case 87:
            case 26:
            case 33:
              return 2147483647;
            case 34:
            case 1:
              return 47839;
            case 38:
            case 36:
              return 99;
            case 43:
            case 37:
              return 2048;
            case 0:
              return 2097152;
            case 3:
              return 65536;
            case 28:
              return 32768;
            case 44:
              return 32767;
            case 75:
              return 16384;
            case 39:
              return 1e3;
            case 89:
              return 700;
            case 71:
              return 256;
            case 40:
              return 255;
            case 2:
              return 100;
            case 180:
              return 64;
            case 25:
              return 20;
            case 5:
              return 16;
            case 6:
              return 6;
            case 73:
              return 4;
            case 84: {
              if (typeof navigator === "object")
                return navigator["hardwareConcurrency"] || 1;
              return 1;
            }
          }
          setErrNo(28);
          return -1;
        }
        if (!ENVIRONMENT_IS_PTHREAD)
          PThread.initMainThreadBlock();
        var GLctx;
        var proxiedFunctionTable = [null, _atexit, _emscripten_set_canvas_element_size_main_thread, _fd_close, _fd_seek, _fd_write, _sysconf];
        var asmLibraryArg = { "e": ___assert_fail, "r": ___call_main, "x": __emscripten_notify_thread_queue, "b": _abort, "y": _emscripten_asm_const_int, "j": _emscripten_conditional_set_current_thread_status, "c": _emscripten_futex_wait, "d": _emscripten_futex_wake, "f": _emscripten_get_now, "p": _emscripten_memcpy_big, "z": _emscripten_num_logical_cores, "u": _emscripten_receive_on_main_thread_js, "q": _emscripten_resize_heap, "v": _emscripten_set_canvas_element_size, "i": _emscripten_set_current_thread_status, "t": _emscripten_set_thread_name, "w": _emscripten_webgl_create_context, "m": _fd_close, "n": _fd_seek, "g": _fd_write, "o": initPthreadsJS, "a": wasmMemory || Module["wasmMemory"], "k": _pthread_cleanup_pop, "l": _pthread_cleanup_push, "h": _pthread_create, "s": _sysconf };
        var asm = createWasm();
        var ___wasm_call_ctors = Module["___wasm_call_ctors"] = function() {
          return (___wasm_call_ctors = Module["___wasm_call_ctors"] = Module["asm"]["A"]).apply(null, arguments);
        };
        var _init = Module["_init"] = function() {
          return (_init = Module["_init"] = Module["asm"]["B"]).apply(null, arguments);
        };
        var _register_tensor = Module["_register_tensor"] = function() {
          return (_register_tensor = Module["_register_tensor"] = Module["asm"]["C"]).apply(null, arguments);
        };
        var _dispose_data = Module["_dispose_data"] = function() {
          return (_dispose_data = Module["_dispose_data"] = Module["asm"]["D"]).apply(null, arguments);
        };
        var _dispose = Module["_dispose"] = function() {
          return (_dispose = Module["_dispose"] = Module["asm"]["E"]).apply(null, arguments);
        };
        var _Abs = Module["_Abs"] = function() {
          return (_Abs = Module["_Abs"] = Module["asm"]["G"]).apply(null, arguments);
        };
        var _Add = Module["_Add"] = function() {
          return (_Add = Module["_Add"] = Module["asm"]["H"]).apply(null, arguments);
        };
        var _AddN = Module["_AddN"] = function() {
          return (_AddN = Module["_AddN"] = Module["asm"]["I"]).apply(null, arguments);
        };
        var _All = Module["_All"] = function() {
          return (_All = Module["_All"] = Module["asm"]["J"]).apply(null, arguments);
        };
        var _Any = Module["_Any"] = function() {
          return (_Any = Module["_Any"] = Module["asm"]["K"]).apply(null, arguments);
        };
        var _ArgMax = Module["_ArgMax"] = function() {
          return (_ArgMax = Module["_ArgMax"] = Module["asm"]["L"]).apply(null, arguments);
        };
        var _AvgPool = Module["_AvgPool"] = function() {
          return (_AvgPool = Module["_AvgPool"] = Module["asm"]["M"]).apply(null, arguments);
        };
        var _BatchMatMul = Module["_BatchMatMul"] = function() {
          return (_BatchMatMul = Module["_BatchMatMul"] = Module["asm"]["N"]).apply(null, arguments);
        };
        var _Ceil = Module["_Ceil"] = function() {
          return (_Ceil = Module["_Ceil"] = Module["asm"]["O"]).apply(null, arguments);
        };
        var _ClipByValue = Module["_ClipByValue"] = function() {
          return (_ClipByValue = Module["_ClipByValue"] = Module["asm"]["P"]).apply(null, arguments);
        };
        var _Conv2D2 = Module["_Conv2D"] = function() {
          return (_Conv2D2 = Module["_Conv2D"] = Module["asm"]["Q"]).apply(null, arguments);
        };
        var _Conv2DBackpropInput = Module["_Conv2DBackpropInput"] = function() {
          return (_Conv2DBackpropInput = Module["_Conv2DBackpropInput"] = Module["asm"]["R"]).apply(null, arguments);
        };
        var _Cos = Module["_Cos"] = function() {
          return (_Cos = Module["_Cos"] = Module["asm"]["S"]).apply(null, arguments);
        };
        var _CropAndResize = Module["_CropAndResize"] = function() {
          return (_CropAndResize = Module["_CropAndResize"] = Module["asm"]["T"]).apply(null, arguments);
        };
        var _Cumsum = Module["_Cumsum"] = function() {
          return (_Cumsum = Module["_Cumsum"] = Module["asm"]["U"]).apply(null, arguments);
        };
        var _DepthToSpace = Module["_DepthToSpace"] = function() {
          return (_DepthToSpace = Module["_DepthToSpace"] = Module["asm"]["V"]).apply(null, arguments);
        };
        var _DepthwiseConv2dNative = Module["_DepthwiseConv2dNative"] = function() {
          return (_DepthwiseConv2dNative = Module["_DepthwiseConv2dNative"] = Module["asm"]["W"]).apply(null, arguments);
        };
        var _Equal = Module["_Equal"] = function() {
          return (_Equal = Module["_Equal"] = Module["asm"]["X"]).apply(null, arguments);
        };
        var _Exp = Module["_Exp"] = function() {
          return (_Exp = Module["_Exp"] = Module["asm"]["Y"]).apply(null, arguments);
        };
        var _FlipLeftRight = Module["_FlipLeftRight"] = function() {
          return (_FlipLeftRight = Module["_FlipLeftRight"] = Module["asm"]["Z"]).apply(null, arguments);
        };
        var _Floor = Module["_Floor"] = function() {
          return (_Floor = Module["_Floor"] = Module["asm"]["_"]).apply(null, arguments);
        };
        var _FloorDiv = Module["_FloorDiv"] = function() {
          return (_FloorDiv = Module["_FloorDiv"] = Module["asm"]["$"]).apply(null, arguments);
        };
        var _FusedBatchNorm = Module["_FusedBatchNorm"] = function() {
          return (_FusedBatchNorm = Module["_FusedBatchNorm"] = Module["asm"]["aa"]).apply(null, arguments);
        };
        var _FusedConv2D = Module["_FusedConv2D"] = function() {
          return (_FusedConv2D = Module["_FusedConv2D"] = Module["asm"]["ba"]).apply(null, arguments);
        };
        var _FusedDepthwiseConv2D = Module["_FusedDepthwiseConv2D"] = function() {
          return (_FusedDepthwiseConv2D = Module["_FusedDepthwiseConv2D"] = Module["asm"]["ca"]).apply(null, arguments);
        };
        var _Gather = Module["_Gather"] = function() {
          return (_Gather = Module["_Gather"] = Module["asm"]["da"]).apply(null, arguments);
        };
        var _GatherNd = Module["_GatherNd"] = function() {
          return (_GatherNd = Module["_GatherNd"] = Module["asm"]["ea"]).apply(null, arguments);
        };
        var _Greater = Module["_Greater"] = function() {
          return (_Greater = Module["_Greater"] = Module["asm"]["fa"]).apply(null, arguments);
        };
        var _GreaterEqual = Module["_GreaterEqual"] = function() {
          return (_GreaterEqual = Module["_GreaterEqual"] = Module["asm"]["ga"]).apply(null, arguments);
        };
        var _LeakyRelu = Module["_LeakyRelu"] = function() {
          return (_LeakyRelu = Module["_LeakyRelu"] = Module["asm"]["ha"]).apply(null, arguments);
        };
        var _Less = Module["_Less"] = function() {
          return (_Less = Module["_Less"] = Module["asm"]["ia"]).apply(null, arguments);
        };
        var _LessEqual = Module["_LessEqual"] = function() {
          return (_LessEqual = Module["_LessEqual"] = Module["asm"]["ja"]).apply(null, arguments);
        };
        var _Log = Module["_Log"] = function() {
          return (_Log = Module["_Log"] = Module["asm"]["ka"]).apply(null, arguments);
        };
        var _LogicalAnd = Module["_LogicalAnd"] = function() {
          return (_LogicalAnd = Module["_LogicalAnd"] = Module["asm"]["la"]).apply(null, arguments);
        };
        var _Max = Module["_Max"] = function() {
          return (_Max = Module["_Max"] = Module["asm"]["ma"]).apply(null, arguments);
        };
        var _MaxPool = Module["_MaxPool"] = function() {
          return (_MaxPool = Module["_MaxPool"] = Module["asm"]["na"]).apply(null, arguments);
        };
        var _Maximum = Module["_Maximum"] = function() {
          return (_Maximum = Module["_Maximum"] = Module["asm"]["oa"]).apply(null, arguments);
        };
        var _Mean = Module["_Mean"] = function() {
          return (_Mean = Module["_Mean"] = Module["asm"]["pa"]).apply(null, arguments);
        };
        var _Min = Module["_Min"] = function() {
          return (_Min = Module["_Min"] = Module["asm"]["qa"]).apply(null, arguments);
        };
        var _Minimum = Module["_Minimum"] = function() {
          return (_Minimum = Module["_Minimum"] = Module["asm"]["ra"]).apply(null, arguments);
        };
        var _MirrorPad = Module["_MirrorPad"] = function() {
          return (_MirrorPad = Module["_MirrorPad"] = Module["asm"]["sa"]).apply(null, arguments);
        };
        var _Multiply = Module["_Multiply"] = function() {
          return (_Multiply = Module["_Multiply"] = Module["asm"]["ta"]).apply(null, arguments);
        };
        var _Neg = Module["_Neg"] = function() {
          return (_Neg = Module["_Neg"] = Module["asm"]["ua"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV3 = Module["_NonMaxSuppressionV3"] = function() {
          return (_NonMaxSuppressionV3 = Module["_NonMaxSuppressionV3"] = Module["asm"]["va"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV4 = Module["_NonMaxSuppressionV4"] = function() {
          return (_NonMaxSuppressionV4 = Module["_NonMaxSuppressionV4"] = Module["asm"]["wa"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV5 = Module["_NonMaxSuppressionV5"] = function() {
          return (_NonMaxSuppressionV5 = Module["_NonMaxSuppressionV5"] = Module["asm"]["xa"]).apply(null, arguments);
        };
        var _NotEqual = Module["_NotEqual"] = function() {
          return (_NotEqual = Module["_NotEqual"] = Module["asm"]["ya"]).apply(null, arguments);
        };
        var _OneHot = Module["_OneHot"] = function() {
          return (_OneHot = Module["_OneHot"] = Module["asm"]["za"]).apply(null, arguments);
        };
        var _PadV2 = Module["_PadV2"] = function() {
          return (_PadV2 = Module["_PadV2"] = Module["asm"]["Aa"]).apply(null, arguments);
        };
        var _Pow = Module["_Pow"] = function() {
          return (_Pow = Module["_Pow"] = Module["asm"]["Ba"]).apply(null, arguments);
        };
        var _Prelu = Module["_Prelu"] = function() {
          return (_Prelu = Module["_Prelu"] = Module["asm"]["Ca"]).apply(null, arguments);
        };
        var _Prod = Module["_Prod"] = function() {
          return (_Prod = Module["_Prod"] = Module["asm"]["Da"]).apply(null, arguments);
        };
        var _RealDiv = Module["_RealDiv"] = function() {
          return (_RealDiv = Module["_RealDiv"] = Module["asm"]["Ea"]).apply(null, arguments);
        };
        var _Relu = Module["_Relu"] = function() {
          return (_Relu = Module["_Relu"] = Module["asm"]["Fa"]).apply(null, arguments);
        };
        var _Relu6 = Module["_Relu6"] = function() {
          return (_Relu6 = Module["_Relu6"] = Module["asm"]["Ga"]).apply(null, arguments);
        };
        var _ResizeBilinear = Module["_ResizeBilinear"] = function() {
          return (_ResizeBilinear = Module["_ResizeBilinear"] = Module["asm"]["Ha"]).apply(null, arguments);
        };
        var _Reverse = Module["_Reverse"] = function() {
          return (_Reverse = Module["_Reverse"] = Module["asm"]["Ia"]).apply(null, arguments);
        };
        var _RotateWithOffset = Module["_RotateWithOffset"] = function() {
          return (_RotateWithOffset = Module["_RotateWithOffset"] = Module["asm"]["Ja"]).apply(null, arguments);
        };
        var _Round = Module["_Round"] = function() {
          return (_Round = Module["_Round"] = Module["asm"]["Ka"]).apply(null, arguments);
        };
        var _Rsqrt = Module["_Rsqrt"] = function() {
          return (_Rsqrt = Module["_Rsqrt"] = Module["asm"]["La"]).apply(null, arguments);
        };
        var _ScatterNd = Module["_ScatterNd"] = function() {
          return (_ScatterNd = Module["_ScatterNd"] = Module["asm"]["Ma"]).apply(null, arguments);
        };
        var _SelectV2 = Module["_SelectV2"] = function() {
          return (_SelectV2 = Module["_SelectV2"] = Module["asm"]["Na"]).apply(null, arguments);
        };
        var _Sigmoid = Module["_Sigmoid"] = function() {
          return (_Sigmoid = Module["_Sigmoid"] = Module["asm"]["Oa"]).apply(null, arguments);
        };
        var _Sin = Module["_Sin"] = function() {
          return (_Sin = Module["_Sin"] = Module["asm"]["Pa"]).apply(null, arguments);
        };
        var _Softmax = Module["_Softmax"] = function() {
          return (_Softmax = Module["_Softmax"] = Module["asm"]["Qa"]).apply(null, arguments);
        };
        var _Sqrt = Module["_Sqrt"] = function() {
          return (_Sqrt = Module["_Sqrt"] = Module["asm"]["Ra"]).apply(null, arguments);
        };
        var _Square = Module["_Square"] = function() {
          return (_Square = Module["_Square"] = Module["asm"]["Sa"]).apply(null, arguments);
        };
        var _SquaredDifference = Module["_SquaredDifference"] = function() {
          return (_SquaredDifference = Module["_SquaredDifference"] = Module["asm"]["Ta"]).apply(null, arguments);
        };
        var _Step = Module["_Step"] = function() {
          return (_Step = Module["_Step"] = Module["asm"]["Ua"]).apply(null, arguments);
        };
        var _StridedSlice = Module["_StridedSlice"] = function() {
          return (_StridedSlice = Module["_StridedSlice"] = Module["asm"]["Va"]).apply(null, arguments);
        };
        var _Sub = Module["_Sub"] = function() {
          return (_Sub = Module["_Sub"] = Module["asm"]["Wa"]).apply(null, arguments);
        };
        var _Sum = Module["_Sum"] = function() {
          return (_Sum = Module["_Sum"] = Module["asm"]["Xa"]).apply(null, arguments);
        };
        var _Tan = Module["_Tan"] = function() {
          return (_Tan = Module["_Tan"] = Module["asm"]["Ya"]).apply(null, arguments);
        };
        var _Tanh = Module["_Tanh"] = function() {
          return (_Tanh = Module["_Tanh"] = Module["asm"]["Za"]).apply(null, arguments);
        };
        var _Tile = Module["_Tile"] = function() {
          return (_Tile = Module["_Tile"] = Module["asm"]["_a"]).apply(null, arguments);
        };
        var _TopK = Module["_TopK"] = function() {
          return (_TopK = Module["_TopK"] = Module["asm"]["$a"]).apply(null, arguments);
        };
        var _Transform = Module["_Transform"] = function() {
          return (_Transform = Module["_Transform"] = Module["asm"]["ab"]).apply(null, arguments);
        };
        var _Transpose = Module["_Transpose"] = function() {
          return (_Transpose = Module["_Transpose"] = Module["asm"]["bb"]).apply(null, arguments);
        };
        var __FusedMatMul = Module["__FusedMatMul"] = function() {
          return (__FusedMatMul = Module["__FusedMatMul"] = Module["asm"]["cb"]).apply(null, arguments);
        };
        var _malloc = Module["_malloc"] = function() {
          return (_malloc = Module["_malloc"] = Module["asm"]["db"]).apply(null, arguments);
        };
        var _free = Module["_free"] = function() {
          return (_free = Module["_free"] = Module["asm"]["eb"]).apply(null, arguments);
        };
        var ___errno_location = Module["___errno_location"] = function() {
          return (___errno_location = Module["___errno_location"] = Module["asm"]["fb"]).apply(null, arguments);
        };
        var _emscripten_get_global_libc = Module["_emscripten_get_global_libc"] = function() {
          return (_emscripten_get_global_libc = Module["_emscripten_get_global_libc"] = Module["asm"]["gb"]).apply(null, arguments);
        };
        var _pthread_self = Module["_pthread_self"] = function() {
          return (_pthread_self = Module["_pthread_self"] = Module["asm"]["hb"]).apply(null, arguments);
        };
        var ___pthread_tsd_run_dtors = Module["___pthread_tsd_run_dtors"] = function() {
          return (___pthread_tsd_run_dtors = Module["___pthread_tsd_run_dtors"] = Module["asm"]["ib"]).apply(null, arguments);
        };
        var _emscripten_main_thread_process_queued_calls = Module["_emscripten_main_thread_process_queued_calls"] = function() {
          return (_emscripten_main_thread_process_queued_calls = Module["_emscripten_main_thread_process_queued_calls"] = Module["asm"]["jb"]).apply(null, arguments);
        };
        var _emscripten_current_thread_process_queued_calls = Module["_emscripten_current_thread_process_queued_calls"] = function() {
          return (_emscripten_current_thread_process_queued_calls = Module["_emscripten_current_thread_process_queued_calls"] = Module["asm"]["kb"]).apply(null, arguments);
        };
        var _emscripten_register_main_browser_thread_id = Module["_emscripten_register_main_browser_thread_id"] = function() {
          return (_emscripten_register_main_browser_thread_id = Module["_emscripten_register_main_browser_thread_id"] = Module["asm"]["lb"]).apply(null, arguments);
        };
        var __emscripten_do_dispatch_to_thread = Module["__emscripten_do_dispatch_to_thread"] = function() {
          return (__emscripten_do_dispatch_to_thread = Module["__emscripten_do_dispatch_to_thread"] = Module["asm"]["mb"]).apply(null, arguments);
        };
        var _emscripten_sync_run_in_main_thread_4 = Module["_emscripten_sync_run_in_main_thread_4"] = function() {
          return (_emscripten_sync_run_in_main_thread_4 = Module["_emscripten_sync_run_in_main_thread_4"] = Module["asm"]["nb"]).apply(null, arguments);
        };
        var _emscripten_run_in_main_runtime_thread_js = Module["_emscripten_run_in_main_runtime_thread_js"] = function() {
          return (_emscripten_run_in_main_runtime_thread_js = Module["_emscripten_run_in_main_runtime_thread_js"] = Module["asm"]["ob"]).apply(null, arguments);
        };
        var __emscripten_call_on_thread = Module["__emscripten_call_on_thread"] = function() {
          return (__emscripten_call_on_thread = Module["__emscripten_call_on_thread"] = Module["asm"]["pb"]).apply(null, arguments);
        };
        var _emscripten_tls_init = Module["_emscripten_tls_init"] = function() {
          return (_emscripten_tls_init = Module["_emscripten_tls_init"] = Module["asm"]["qb"]).apply(null, arguments);
        };
        var __emscripten_thread_init = Module["__emscripten_thread_init"] = function() {
          return (__emscripten_thread_init = Module["__emscripten_thread_init"] = Module["asm"]["rb"]).apply(null, arguments);
        };
        var stackSave = Module["stackSave"] = function() {
          return (stackSave = Module["stackSave"] = Module["asm"]["sb"]).apply(null, arguments);
        };
        var stackRestore = Module["stackRestore"] = function() {
          return (stackRestore = Module["stackRestore"] = Module["asm"]["tb"]).apply(null, arguments);
        };
        var stackAlloc = Module["stackAlloc"] = function() {
          return (stackAlloc = Module["stackAlloc"] = Module["asm"]["ub"]).apply(null, arguments);
        };
        var _emscripten_stack_set_limits = Module["_emscripten_stack_set_limits"] = function() {
          return (_emscripten_stack_set_limits = Module["_emscripten_stack_set_limits"] = Module["asm"]["vb"]).apply(null, arguments);
        };
        var _memalign = Module["_memalign"] = function() {
          return (_memalign = Module["_memalign"] = Module["asm"]["wb"]).apply(null, arguments);
        };
        var __emscripten_allow_main_runtime_queued_calls = Module["__emscripten_allow_main_runtime_queued_calls"] = 9808;
        var __emscripten_main_thread_futex = Module["__emscripten_main_thread_futex"] = 11432;
        Module["cwrap"] = cwrap;
        Module["PThread"] = PThread;
        Module["PThread"] = PThread;
        Module["wasmMemory"] = wasmMemory;
        Module["ExitStatus"] = ExitStatus;
        var calledRun;
        function ExitStatus(status) {
          this.name = "ExitStatus";
          this.message = "Program terminated with exit(" + status + ")";
          this.status = status;
        }
        dependenciesFulfilled = function runCaller() {
          if (!calledRun)
            run();
          if (!calledRun)
            dependenciesFulfilled = runCaller;
        };
        function run(args) {
          args = args || arguments_;
          if (runDependencies > 0) {
            return;
          }
          if (ENVIRONMENT_IS_PTHREAD) {
            readyPromiseResolve(Module);
            initRuntime();
            postMessage({ "cmd": "loaded" });
            return;
          }
          preRun();
          if (runDependencies > 0) {
            return;
          }
          function doRun() {
            if (calledRun)
              return;
            calledRun = true;
            Module["calledRun"] = true;
            if (ABORT)
              return;
            initRuntime();
            preMain();
            readyPromiseResolve(Module);
            if (Module["onRuntimeInitialized"])
              Module["onRuntimeInitialized"]();
            postRun();
          }
          if (Module["setStatus"]) {
            Module["setStatus"]("Running...");
            setTimeout(function() {
              setTimeout(function() {
                Module["setStatus"]("");
              }, 1);
              doRun();
            }, 1);
          } else {
            doRun();
          }
        }
        Module["run"] = run;
        function exit(status, implicit) {
          if (implicit && noExitRuntime && status === 0) {
            return;
          }
          if (!implicit) {
            if (ENVIRONMENT_IS_PTHREAD) {
              postMessage({ "cmd": "exitProcess", "returnCode": status });
              throw new ExitStatus(status);
            } else {
            }
          }
          if (noExitRuntime) {
          } else {
            PThread.terminateAllThreads();
            EXITSTATUS = status;
            exitRuntime();
            if (Module["onExit"])
              Module["onExit"](status);
            ABORT = true;
          }
          quit_(status, new ExitStatus(status));
        }
        if (Module["preInit"]) {
          if (typeof Module["preInit"] == "function")
            Module["preInit"] = [Module["preInit"]];
          while (Module["preInit"].length > 0) {
            Module["preInit"].pop()();
          }
        }
        if (ENVIRONMENT_IS_PTHREAD) {
          noExitRuntime = false;
          PThread.initWorker();
        }
        run();
        return WasmBackendModuleThreadedSimd2.ready;
      };
    }();
    if (typeof exports === "object" && typeof module === "object")
      module.exports = WasmBackendModuleThreadedSimd;
    else if (typeof define === "function" && define["amd"])
      define([], function() {
        return WasmBackendModuleThreadedSimd;
      });
    else if (typeof exports === "object")
      exports["WasmBackendModuleThreadedSimd"] = WasmBackendModuleThreadedSimd;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/wasm-out/tfjs-backend-wasm.js
var require_tfjs_backend_wasm = __commonJS({
  "node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/wasm-out/tfjs-backend-wasm.js"(exports, module) {
    var WasmBackendModule = function() {
      var _scriptDir = typeof document !== "undefined" && document.currentScript ? document.currentScript.src : void 0;
      if (typeof __filename !== "undefined")
        _scriptDir = _scriptDir || __filename;
      return function(WasmBackendModule2) {
        WasmBackendModule2 = WasmBackendModule2 || {};
        var Module = typeof WasmBackendModule2 !== "undefined" ? WasmBackendModule2 : {};
        var readyPromiseResolve, readyPromiseReject;
        Module["ready"] = new Promise(function(resolve, reject) {
          readyPromiseResolve = resolve;
          readyPromiseReject = reject;
        });
        var moduleOverrides = {};
        var key;
        for (key in Module) {
          if (Module.hasOwnProperty(key)) {
            moduleOverrides[key] = Module[key];
          }
        }
        var arguments_ = [];
        var thisProgram = "./this.program";
        var quit_ = function(status, toThrow) {
          throw toThrow;
        };
        var ENVIRONMENT_IS_WEB = false;
        var ENVIRONMENT_IS_WORKER = false;
        var ENVIRONMENT_IS_NODE = false;
        var ENVIRONMENT_IS_SHELL = false;
        ENVIRONMENT_IS_WEB = typeof window === "object";
        ENVIRONMENT_IS_WORKER = typeof importScripts === "function";
        ENVIRONMENT_IS_NODE = typeof process === "object" && typeof process.versions === "object" && typeof process.versions.node === "string";
        ENVIRONMENT_IS_SHELL = !ENVIRONMENT_IS_WEB && !ENVIRONMENT_IS_NODE && !ENVIRONMENT_IS_WORKER;
        var scriptDirectory = "";
        function locateFile(path) {
          if (Module["locateFile"]) {
            return Module["locateFile"](path, scriptDirectory);
          }
          return scriptDirectory + path;
        }
        var read_, readAsync, readBinary, setWindowTitle;
        var nodeFS;
        var nodePath;
        if (ENVIRONMENT_IS_NODE) {
          if (ENVIRONMENT_IS_WORKER) {
            scriptDirectory = require_path().dirname(scriptDirectory) + "/";
          } else {
            scriptDirectory = __dirname + "/";
          }
          read_ = function shell_read(filename, binary) {
            if (!nodeFS)
              nodeFS = __require("fs");
            if (!nodePath)
              nodePath = require_path();
            filename = nodePath["normalize"](filename);
            return nodeFS["readFileSync"](filename, binary ? null : "utf8");
          };
          readBinary = function readBinary2(filename) {
            var ret = read_(filename, true);
            if (!ret.buffer) {
              ret = new Uint8Array(ret);
            }
            assert4(ret.buffer);
            return ret;
          };
          if (process["argv"].length > 1) {
            thisProgram = process["argv"][1].replace(/\\/g, "/");
          }
          arguments_ = process["argv"].slice(2);
          process["on"]("uncaughtException", function(ex) {
            if (!(ex instanceof ExitStatus)) {
              throw ex;
            }
          });
          process["on"]("unhandledRejection", abort);
          quit_ = function(status) {
            process["exit"](status);
          };
          Module["inspect"] = function() {
            return "[Emscripten Module object]";
          };
        } else if (ENVIRONMENT_IS_SHELL) {
          if (typeof read != "undefined") {
            read_ = function shell_read(f) {
              return read(f);
            };
          }
          readBinary = function readBinary2(f) {
            var data;
            if (typeof readbuffer === "function") {
              return new Uint8Array(readbuffer(f));
            }
            data = read(f, "binary");
            assert4(typeof data === "object");
            return data;
          };
          if (typeof scriptArgs != "undefined") {
            arguments_ = scriptArgs;
          } else if (typeof arguments != "undefined") {
            arguments_ = arguments;
          }
          if (typeof quit === "function") {
            quit_ = function(status) {
              quit(status);
            };
          }
          if (typeof print !== "undefined") {
            if (typeof console === "undefined")
              console = {};
            console.log = print;
            console.warn = console.error = typeof printErr !== "undefined" ? printErr : print;
          }
        } else if (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER) {
          if (ENVIRONMENT_IS_WORKER) {
            scriptDirectory = self.location.href;
          } else if (typeof document !== "undefined" && document.currentScript) {
            scriptDirectory = document.currentScript.src;
          }
          if (_scriptDir) {
            scriptDirectory = _scriptDir;
          }
          if (scriptDirectory.indexOf("blob:") !== 0) {
            scriptDirectory = scriptDirectory.substr(0, scriptDirectory.lastIndexOf("/") + 1);
          } else {
            scriptDirectory = "";
          }
          {
            read_ = function(url) {
              var xhr = new XMLHttpRequest();
              xhr.open("GET", url, false);
              xhr.send(null);
              return xhr.responseText;
            };
            if (ENVIRONMENT_IS_WORKER) {
              readBinary = function(url) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, false);
                xhr.responseType = "arraybuffer";
                xhr.send(null);
                return new Uint8Array(xhr.response);
              };
            }
            readAsync = function(url, onload, onerror) {
              var xhr = new XMLHttpRequest();
              xhr.open("GET", url, true);
              xhr.responseType = "arraybuffer";
              xhr.onload = function() {
                if (xhr.status == 200 || xhr.status == 0 && xhr.response) {
                  onload(xhr.response);
                  return;
                }
                onerror();
              };
              xhr.onerror = onerror;
              xhr.send(null);
            };
          }
          setWindowTitle = function(title) {
            document.title = title;
          };
        } else {
        }
        var out = Module["print"] || console.log.bind(console);
        var err = Module["printErr"] || console.warn.bind(console);
        for (key in moduleOverrides) {
          if (moduleOverrides.hasOwnProperty(key)) {
            Module[key] = moduleOverrides[key];
          }
        }
        moduleOverrides = null;
        if (Module["arguments"])
          arguments_ = Module["arguments"];
        if (Module["thisProgram"])
          thisProgram = Module["thisProgram"];
        if (Module["quit"])
          quit_ = Module["quit"];
        var wasmBinary;
        if (Module["wasmBinary"])
          wasmBinary = Module["wasmBinary"];
        var noExitRuntime = Module["noExitRuntime"] || true;
        if (typeof WebAssembly !== "object") {
          abort("no native wasm support detected");
        }
        var wasmMemory;
        var ABORT = false;
        var EXITSTATUS;
        function assert4(condition, text) {
          if (!condition) {
            abort("Assertion failed: " + text);
          }
        }
        function getCFunc(ident) {
          var func2 = Module["_" + ident];
          assert4(func2, "Cannot call unknown function " + ident + ", make sure it is exported");
          return func2;
        }
        function ccall(ident, returnType, argTypes, args, opts) {
          var toC = { "string": function(str) {
            var ret2 = 0;
            if (str !== null && str !== void 0 && str !== 0) {
              var len = (str.length << 2) + 1;
              ret2 = stackAlloc(len);
              stringToUTF8(str, ret2, len);
            }
            return ret2;
          }, "array": function(arr) {
            var ret2 = stackAlloc(arr.length);
            writeArrayToMemory(arr, ret2);
            return ret2;
          } };
          function convertReturnValue(ret2) {
            if (returnType === "string")
              return UTF8ToString(ret2);
            if (returnType === "boolean")
              return Boolean(ret2);
            return ret2;
          }
          var func2 = getCFunc(ident);
          var cArgs = [];
          var stack3 = 0;
          if (args) {
            for (var i = 0; i < args.length; i++) {
              var converter = toC[argTypes[i]];
              if (converter) {
                if (stack3 === 0)
                  stack3 = stackSave();
                cArgs[i] = converter(args[i]);
              } else {
                cArgs[i] = args[i];
              }
            }
          }
          var ret = func2.apply(null, cArgs);
          ret = convertReturnValue(ret);
          if (stack3 !== 0)
            stackRestore(stack3);
          return ret;
        }
        function cwrap(ident, returnType, argTypes, opts) {
          argTypes = argTypes || [];
          var numericArgs = argTypes.every(function(type) {
            return type === "number";
          });
          var numericRet = returnType !== "string";
          if (numericRet && numericArgs && !opts) {
            return getCFunc(ident);
          }
          return function() {
            return ccall(ident, returnType, argTypes, arguments, opts);
          };
        }
        var UTF8Decoder = typeof TextDecoder !== "undefined" ? new TextDecoder("utf8") : void 0;
        function UTF8ArrayToString(heap, idx, maxBytesToRead) {
          var endIdx = idx + maxBytesToRead;
          var endPtr = idx;
          while (heap[endPtr] && !(endPtr >= endIdx))
            ++endPtr;
          if (endPtr - idx > 16 && heap.subarray && UTF8Decoder) {
            return UTF8Decoder.decode(heap.subarray(idx, endPtr));
          } else {
            var str = "";
            while (idx < endPtr) {
              var u0 = heap[idx++];
              if (!(u0 & 128)) {
                str += String.fromCharCode(u0);
                continue;
              }
              var u1 = heap[idx++] & 63;
              if ((u0 & 224) == 192) {
                str += String.fromCharCode((u0 & 31) << 6 | u1);
                continue;
              }
              var u2 = heap[idx++] & 63;
              if ((u0 & 240) == 224) {
                u0 = (u0 & 15) << 12 | u1 << 6 | u2;
              } else {
                u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heap[idx++] & 63;
              }
              if (u0 < 65536) {
                str += String.fromCharCode(u0);
              } else {
                var ch = u0 - 65536;
                str += String.fromCharCode(55296 | ch >> 10, 56320 | ch & 1023);
              }
            }
          }
          return str;
        }
        function UTF8ToString(ptr, maxBytesToRead) {
          return ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : "";
        }
        function stringToUTF8Array(str, heap, outIdx, maxBytesToWrite) {
          if (!(maxBytesToWrite > 0))
            return 0;
          var startIdx = outIdx;
          var endIdx = outIdx + maxBytesToWrite - 1;
          for (var i = 0; i < str.length; ++i) {
            var u = str.charCodeAt(i);
            if (u >= 55296 && u <= 57343) {
              var u1 = str.charCodeAt(++i);
              u = 65536 + ((u & 1023) << 10) | u1 & 1023;
            }
            if (u <= 127) {
              if (outIdx >= endIdx)
                break;
              heap[outIdx++] = u;
            } else if (u <= 2047) {
              if (outIdx + 1 >= endIdx)
                break;
              heap[outIdx++] = 192 | u >> 6;
              heap[outIdx++] = 128 | u & 63;
            } else if (u <= 65535) {
              if (outIdx + 2 >= endIdx)
                break;
              heap[outIdx++] = 224 | u >> 12;
              heap[outIdx++] = 128 | u >> 6 & 63;
              heap[outIdx++] = 128 | u & 63;
            } else {
              if (outIdx + 3 >= endIdx)
                break;
              heap[outIdx++] = 240 | u >> 18;
              heap[outIdx++] = 128 | u >> 12 & 63;
              heap[outIdx++] = 128 | u >> 6 & 63;
              heap[outIdx++] = 128 | u & 63;
            }
          }
          heap[outIdx] = 0;
          return outIdx - startIdx;
        }
        function stringToUTF8(str, outPtr, maxBytesToWrite) {
          return stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);
        }
        function writeArrayToMemory(array2, buffer4) {
          HEAP8.set(array2, buffer4);
        }
        function alignUp(x, multiple) {
          if (x % multiple > 0) {
            x += multiple - x % multiple;
          }
          return x;
        }
        var buffer3, HEAP8, HEAPU8, HEAP16, HEAPU16, HEAP32, HEAPU32, HEAPF32, HEAPF64;
        function updateGlobalBufferAndViews(buf) {
          buffer3 = buf;
          Module["HEAP8"] = HEAP8 = new Int8Array(buf);
          Module["HEAP16"] = HEAP16 = new Int16Array(buf);
          Module["HEAP32"] = HEAP32 = new Int32Array(buf);
          Module["HEAPU8"] = HEAPU8 = new Uint8Array(buf);
          Module["HEAPU16"] = HEAPU16 = new Uint16Array(buf);
          Module["HEAPU32"] = HEAPU32 = new Uint32Array(buf);
          Module["HEAPF32"] = HEAPF32 = new Float32Array(buf);
          Module["HEAPF64"] = HEAPF64 = new Float64Array(buf);
        }
        var INITIAL_MEMORY = Module["INITIAL_MEMORY"] || 16777216;
        var wasmTable;
        var __ATPRERUN__ = [];
        var __ATINIT__ = [];
        var __ATMAIN__ = [];
        var __ATPOSTRUN__ = [];
        var runtimeInitialized = false;
        __ATINIT__.push({ func: function() {
          ___wasm_call_ctors();
        } });
        function preRun() {
          if (Module["preRun"]) {
            if (typeof Module["preRun"] == "function")
              Module["preRun"] = [Module["preRun"]];
            while (Module["preRun"].length) {
              addOnPreRun(Module["preRun"].shift());
            }
          }
          callRuntimeCallbacks(__ATPRERUN__);
        }
        function initRuntime() {
          runtimeInitialized = true;
          callRuntimeCallbacks(__ATINIT__);
        }
        function preMain() {
          callRuntimeCallbacks(__ATMAIN__);
        }
        function postRun() {
          if (Module["postRun"]) {
            if (typeof Module["postRun"] == "function")
              Module["postRun"] = [Module["postRun"]];
            while (Module["postRun"].length) {
              addOnPostRun(Module["postRun"].shift());
            }
          }
          callRuntimeCallbacks(__ATPOSTRUN__);
        }
        function addOnPreRun(cb) {
          __ATPRERUN__.unshift(cb);
        }
        function addOnPostRun(cb) {
          __ATPOSTRUN__.unshift(cb);
        }
        var runDependencies = 0;
        var runDependencyWatcher = null;
        var dependenciesFulfilled = null;
        function addRunDependency(id) {
          runDependencies++;
          if (Module["monitorRunDependencies"]) {
            Module["monitorRunDependencies"](runDependencies);
          }
        }
        function removeRunDependency(id) {
          runDependencies--;
          if (Module["monitorRunDependencies"]) {
            Module["monitorRunDependencies"](runDependencies);
          }
          if (runDependencies == 0) {
            if (runDependencyWatcher !== null) {
              clearInterval(runDependencyWatcher);
              runDependencyWatcher = null;
            }
            if (dependenciesFulfilled) {
              var callback = dependenciesFulfilled;
              dependenciesFulfilled = null;
              callback();
            }
          }
        }
        Module["preloadedImages"] = {};
        Module["preloadedAudios"] = {};
        function abort(what) {
          if (Module["onAbort"]) {
            Module["onAbort"](what);
          }
          what += "";
          err(what);
          ABORT = true;
          EXITSTATUS = 1;
          what = "abort(" + what + "). Build with -s ASSERTIONS=1 for more info.";
          var e = new WebAssembly.RuntimeError(what);
          readyPromiseReject(e);
          throw e;
        }
        function hasPrefix(str, prefix) {
          return String.prototype.startsWith ? str.startsWith(prefix) : str.indexOf(prefix) === 0;
        }
        var dataURIPrefix = "data:application/octet-stream;base64,";
        function isDataURI(filename) {
          return hasPrefix(filename, dataURIPrefix);
        }
        var fileURIPrefix = "file://";
        function isFileURI(filename) {
          return hasPrefix(filename, fileURIPrefix);
        }
        var wasmBinaryFile = "tfjs-backend-wasm.wasm";
        if (!isDataURI(wasmBinaryFile)) {
          wasmBinaryFile = locateFile(wasmBinaryFile);
        }
        function getBinary(file) {
          try {
            if (file == wasmBinaryFile && wasmBinary) {
              return new Uint8Array(wasmBinary);
            }
            if (readBinary) {
              return readBinary(file);
            } else {
              throw "both async and sync fetching of the wasm failed";
            }
          } catch (err2) {
            abort(err2);
          }
        }
        function getBinaryPromise() {
          if (!wasmBinary && (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER)) {
            if (typeof fetch === "function" && !isFileURI(wasmBinaryFile)) {
              return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                if (!response["ok"]) {
                  throw "failed to load wasm binary file at '" + wasmBinaryFile + "'";
                }
                return response["arrayBuffer"]();
              }).catch(function() {
                return getBinary(wasmBinaryFile);
              });
            } else {
              if (readAsync) {
                return new Promise(function(resolve, reject) {
                  readAsync(wasmBinaryFile, function(response) {
                    resolve(new Uint8Array(response));
                  }, reject);
                });
              }
            }
          }
          return Promise.resolve().then(function() {
            return getBinary(wasmBinaryFile);
          });
        }
        function createWasm() {
          var info = { "a": asmLibraryArg };
          function receiveInstance(instance, module2) {
            var exports3 = instance.exports;
            Module["asm"] = exports3;
            wasmMemory = Module["asm"]["i"];
            updateGlobalBufferAndViews(wasmMemory.buffer);
            wasmTable = Module["asm"]["o"];
            removeRunDependency("wasm-instantiate");
          }
          addRunDependency("wasm-instantiate");
          function receiveInstantiatedSource(output) {
            receiveInstance(output["instance"]);
          }
          function instantiateArrayBuffer(receiver) {
            return getBinaryPromise().then(function(binary) {
              return WebAssembly.instantiate(binary, info);
            }).then(receiver, function(reason) {
              err("failed to asynchronously prepare wasm: " + reason);
              abort(reason);
            });
          }
          function instantiateAsync() {
            if (!wasmBinary && typeof WebAssembly.instantiateStreaming === "function" && !isDataURI(wasmBinaryFile) && !isFileURI(wasmBinaryFile) && typeof fetch === "function") {
              return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                var result = WebAssembly.instantiateStreaming(response, info);
                return result.then(receiveInstantiatedSource, function(reason) {
                  err("wasm streaming compile failed: " + reason);
                  err("falling back to ArrayBuffer instantiation");
                  return instantiateArrayBuffer(receiveInstantiatedSource);
                });
              });
            } else {
              return instantiateArrayBuffer(receiveInstantiatedSource);
            }
          }
          if (Module["instantiateWasm"]) {
            try {
              var exports2 = Module["instantiateWasm"](info, receiveInstance);
              return exports2;
            } catch (e) {
              err("Module.instantiateWasm callback failed with error: " + e);
              return false;
            }
          }
          instantiateAsync().catch(readyPromiseReject);
          return {};
        }
        function callRuntimeCallbacks(callbacks2) {
          while (callbacks2.length > 0) {
            var callback = callbacks2.shift();
            if (typeof callback == "function") {
              callback(Module);
              continue;
            }
            var func2 = callback.func;
            if (typeof func2 === "number") {
              if (callback.arg === void 0) {
                wasmTable.get(func2)();
              } else {
                wasmTable.get(func2)(callback.arg);
              }
            } else {
              func2(callback.arg === void 0 ? null : callback.arg);
            }
          }
        }
        function _abort() {
          abort();
        }
        function _emscripten_memcpy_big(dest, src, num) {
          HEAPU8.copyWithin(dest, src, src + num);
        }
        function _emscripten_get_heap_size() {
          return HEAPU8.length;
        }
        function emscripten_realloc_buffer(size) {
          try {
            wasmMemory.grow(size - buffer3.byteLength + 65535 >>> 16);
            updateGlobalBufferAndViews(wasmMemory.buffer);
            return 1;
          } catch (e) {
          }
        }
        function _emscripten_resize_heap(requestedSize) {
          var oldSize = _emscripten_get_heap_size();
          var maxHeapSize = 2147483648;
          if (requestedSize > maxHeapSize) {
            return false;
          }
          for (var cutDown = 1; cutDown <= 4; cutDown *= 2) {
            var overGrownHeapSize = oldSize * (1 + 0.2 / cutDown);
            overGrownHeapSize = Math.min(overGrownHeapSize, requestedSize + 100663296);
            var newSize = Math.min(maxHeapSize, alignUp(Math.max(requestedSize, overGrownHeapSize), 65536));
            var replacement = emscripten_realloc_buffer(newSize);
            if (replacement) {
              return true;
            }
          }
          return false;
        }
        var SYSCALLS = { mappings: {}, buffers: [null, [], []], printChar: function(stream, curr) {
          var buffer4 = SYSCALLS.buffers[stream];
          if (curr === 0 || curr === 10) {
            (stream === 1 ? out : err)(UTF8ArrayToString(buffer4, 0));
            buffer4.length = 0;
          } else {
            buffer4.push(curr);
          }
        }, varargs: void 0, get: function() {
          SYSCALLS.varargs += 4;
          var ret = HEAP32[SYSCALLS.varargs - 4 >> 2];
          return ret;
        }, getStr: function(ptr) {
          var ret = UTF8ToString(ptr);
          return ret;
        }, get64: function(low, high) {
          return low;
        } };
        function _fd_close(fd) {
          return 0;
        }
        function _fd_seek(fd, offset_low, offset_high, whence, newOffset) {
        }
        function _fd_write(fd, iov, iovcnt, pnum) {
          var num = 0;
          for (var i = 0; i < iovcnt; i++) {
            var ptr = HEAP32[iov + i * 8 >> 2];
            var len = HEAP32[iov + (i * 8 + 4) >> 2];
            for (var j = 0; j < len; j++) {
              SYSCALLS.printChar(fd, HEAPU8[ptr + j]);
            }
            num += len;
          }
          HEAP32[pnum >> 2] = num;
          return 0;
        }
        function _pthread_create() {
          return 6;
        }
        function setErrNo(value) {
          HEAP32[___errno_location() >> 2] = value;
          return value;
        }
        function _sysconf(name) {
          switch (name) {
            case 30:
              return 16384;
            case 85:
              var maxHeapSize = 2147483648;
              return maxHeapSize / 16384;
            case 132:
            case 133:
            case 12:
            case 137:
            case 138:
            case 15:
            case 235:
            case 16:
            case 17:
            case 18:
            case 19:
            case 20:
            case 149:
            case 13:
            case 10:
            case 236:
            case 153:
            case 9:
            case 21:
            case 22:
            case 159:
            case 154:
            case 14:
            case 77:
            case 78:
            case 139:
            case 82:
            case 68:
            case 67:
            case 164:
            case 11:
            case 29:
            case 47:
            case 48:
            case 95:
            case 52:
            case 51:
            case 46:
              return 200809;
            case 27:
            case 246:
            case 127:
            case 128:
            case 23:
            case 24:
            case 160:
            case 161:
            case 181:
            case 182:
            case 242:
            case 183:
            case 184:
            case 243:
            case 244:
            case 245:
            case 165:
            case 178:
            case 179:
            case 49:
            case 50:
            case 168:
            case 169:
            case 175:
            case 170:
            case 171:
            case 172:
            case 97:
            case 76:
            case 32:
            case 173:
            case 35:
            case 80:
            case 81:
            case 79:
              return -1;
            case 176:
            case 177:
            case 7:
            case 155:
            case 8:
            case 157:
            case 125:
            case 126:
            case 92:
            case 93:
            case 129:
            case 130:
            case 131:
            case 94:
            case 91:
              return 1;
            case 74:
            case 60:
            case 69:
            case 70:
            case 4:
              return 1024;
            case 31:
            case 42:
            case 72:
              return 32;
            case 87:
            case 26:
            case 33:
              return 2147483647;
            case 34:
            case 1:
              return 47839;
            case 38:
            case 36:
              return 99;
            case 43:
            case 37:
              return 2048;
            case 0:
              return 2097152;
            case 3:
              return 65536;
            case 28:
              return 32768;
            case 44:
              return 32767;
            case 75:
              return 16384;
            case 39:
              return 1e3;
            case 89:
              return 700;
            case 71:
              return 256;
            case 40:
              return 255;
            case 2:
              return 100;
            case 180:
              return 64;
            case 25:
              return 20;
            case 5:
              return 16;
            case 6:
              return 6;
            case 73:
              return 4;
            case 84: {
              if (typeof navigator === "object")
                return navigator["hardwareConcurrency"] || 1;
              return 1;
            }
          }
          setErrNo(28);
          return -1;
        }
        var asmLibraryArg = { "a": _abort, "d": _emscripten_memcpy_big, "e": _emscripten_resize_heap, "f": _fd_close, "c": _fd_seek, "b": _fd_write, "g": _pthread_create, "h": _sysconf };
        var asm = createWasm();
        var ___wasm_call_ctors = Module["___wasm_call_ctors"] = function() {
          return (___wasm_call_ctors = Module["___wasm_call_ctors"] = Module["asm"]["j"]).apply(null, arguments);
        };
        var _init = Module["_init"] = function() {
          return (_init = Module["_init"] = Module["asm"]["k"]).apply(null, arguments);
        };
        var _register_tensor = Module["_register_tensor"] = function() {
          return (_register_tensor = Module["_register_tensor"] = Module["asm"]["l"]).apply(null, arguments);
        };
        var _dispose_data = Module["_dispose_data"] = function() {
          return (_dispose_data = Module["_dispose_data"] = Module["asm"]["m"]).apply(null, arguments);
        };
        var _dispose = Module["_dispose"] = function() {
          return (_dispose = Module["_dispose"] = Module["asm"]["n"]).apply(null, arguments);
        };
        var _Abs = Module["_Abs"] = function() {
          return (_Abs = Module["_Abs"] = Module["asm"]["p"]).apply(null, arguments);
        };
        var _Add = Module["_Add"] = function() {
          return (_Add = Module["_Add"] = Module["asm"]["q"]).apply(null, arguments);
        };
        var _AddN = Module["_AddN"] = function() {
          return (_AddN = Module["_AddN"] = Module["asm"]["r"]).apply(null, arguments);
        };
        var _All = Module["_All"] = function() {
          return (_All = Module["_All"] = Module["asm"]["s"]).apply(null, arguments);
        };
        var _Any = Module["_Any"] = function() {
          return (_Any = Module["_Any"] = Module["asm"]["t"]).apply(null, arguments);
        };
        var _ArgMax = Module["_ArgMax"] = function() {
          return (_ArgMax = Module["_ArgMax"] = Module["asm"]["u"]).apply(null, arguments);
        };
        var _AvgPool = Module["_AvgPool"] = function() {
          return (_AvgPool = Module["_AvgPool"] = Module["asm"]["v"]).apply(null, arguments);
        };
        var _BatchMatMul = Module["_BatchMatMul"] = function() {
          return (_BatchMatMul = Module["_BatchMatMul"] = Module["asm"]["w"]).apply(null, arguments);
        };
        var _Ceil = Module["_Ceil"] = function() {
          return (_Ceil = Module["_Ceil"] = Module["asm"]["x"]).apply(null, arguments);
        };
        var _ClipByValue = Module["_ClipByValue"] = function() {
          return (_ClipByValue = Module["_ClipByValue"] = Module["asm"]["y"]).apply(null, arguments);
        };
        var _Conv2D2 = Module["_Conv2D"] = function() {
          return (_Conv2D2 = Module["_Conv2D"] = Module["asm"]["z"]).apply(null, arguments);
        };
        var _Conv2DBackpropInput = Module["_Conv2DBackpropInput"] = function() {
          return (_Conv2DBackpropInput = Module["_Conv2DBackpropInput"] = Module["asm"]["A"]).apply(null, arguments);
        };
        var _Cos = Module["_Cos"] = function() {
          return (_Cos = Module["_Cos"] = Module["asm"]["B"]).apply(null, arguments);
        };
        var _CropAndResize = Module["_CropAndResize"] = function() {
          return (_CropAndResize = Module["_CropAndResize"] = Module["asm"]["C"]).apply(null, arguments);
        };
        var _Cumsum = Module["_Cumsum"] = function() {
          return (_Cumsum = Module["_Cumsum"] = Module["asm"]["D"]).apply(null, arguments);
        };
        var _DepthToSpace = Module["_DepthToSpace"] = function() {
          return (_DepthToSpace = Module["_DepthToSpace"] = Module["asm"]["E"]).apply(null, arguments);
        };
        var _DepthwiseConv2dNative = Module["_DepthwiseConv2dNative"] = function() {
          return (_DepthwiseConv2dNative = Module["_DepthwiseConv2dNative"] = Module["asm"]["F"]).apply(null, arguments);
        };
        var _Equal = Module["_Equal"] = function() {
          return (_Equal = Module["_Equal"] = Module["asm"]["G"]).apply(null, arguments);
        };
        var _Exp = Module["_Exp"] = function() {
          return (_Exp = Module["_Exp"] = Module["asm"]["H"]).apply(null, arguments);
        };
        var _FlipLeftRight = Module["_FlipLeftRight"] = function() {
          return (_FlipLeftRight = Module["_FlipLeftRight"] = Module["asm"]["I"]).apply(null, arguments);
        };
        var _Floor = Module["_Floor"] = function() {
          return (_Floor = Module["_Floor"] = Module["asm"]["J"]).apply(null, arguments);
        };
        var _FloorDiv = Module["_FloorDiv"] = function() {
          return (_FloorDiv = Module["_FloorDiv"] = Module["asm"]["K"]).apply(null, arguments);
        };
        var _FusedBatchNorm = Module["_FusedBatchNorm"] = function() {
          return (_FusedBatchNorm = Module["_FusedBatchNorm"] = Module["asm"]["L"]).apply(null, arguments);
        };
        var _FusedConv2D = Module["_FusedConv2D"] = function() {
          return (_FusedConv2D = Module["_FusedConv2D"] = Module["asm"]["M"]).apply(null, arguments);
        };
        var _FusedDepthwiseConv2D = Module["_FusedDepthwiseConv2D"] = function() {
          return (_FusedDepthwiseConv2D = Module["_FusedDepthwiseConv2D"] = Module["asm"]["N"]).apply(null, arguments);
        };
        var _Gather = Module["_Gather"] = function() {
          return (_Gather = Module["_Gather"] = Module["asm"]["O"]).apply(null, arguments);
        };
        var _GatherNd = Module["_GatherNd"] = function() {
          return (_GatherNd = Module["_GatherNd"] = Module["asm"]["P"]).apply(null, arguments);
        };
        var _Greater = Module["_Greater"] = function() {
          return (_Greater = Module["_Greater"] = Module["asm"]["Q"]).apply(null, arguments);
        };
        var _GreaterEqual = Module["_GreaterEqual"] = function() {
          return (_GreaterEqual = Module["_GreaterEqual"] = Module["asm"]["R"]).apply(null, arguments);
        };
        var _LeakyRelu = Module["_LeakyRelu"] = function() {
          return (_LeakyRelu = Module["_LeakyRelu"] = Module["asm"]["S"]).apply(null, arguments);
        };
        var _Less = Module["_Less"] = function() {
          return (_Less = Module["_Less"] = Module["asm"]["T"]).apply(null, arguments);
        };
        var _LessEqual = Module["_LessEqual"] = function() {
          return (_LessEqual = Module["_LessEqual"] = Module["asm"]["U"]).apply(null, arguments);
        };
        var _Log = Module["_Log"] = function() {
          return (_Log = Module["_Log"] = Module["asm"]["V"]).apply(null, arguments);
        };
        var _LogicalAnd = Module["_LogicalAnd"] = function() {
          return (_LogicalAnd = Module["_LogicalAnd"] = Module["asm"]["W"]).apply(null, arguments);
        };
        var _Max = Module["_Max"] = function() {
          return (_Max = Module["_Max"] = Module["asm"]["X"]).apply(null, arguments);
        };
        var _MaxPool = Module["_MaxPool"] = function() {
          return (_MaxPool = Module["_MaxPool"] = Module["asm"]["Y"]).apply(null, arguments);
        };
        var _Maximum = Module["_Maximum"] = function() {
          return (_Maximum = Module["_Maximum"] = Module["asm"]["Z"]).apply(null, arguments);
        };
        var _Mean = Module["_Mean"] = function() {
          return (_Mean = Module["_Mean"] = Module["asm"]["_"]).apply(null, arguments);
        };
        var _Min = Module["_Min"] = function() {
          return (_Min = Module["_Min"] = Module["asm"]["$"]).apply(null, arguments);
        };
        var _Minimum = Module["_Minimum"] = function() {
          return (_Minimum = Module["_Minimum"] = Module["asm"]["aa"]).apply(null, arguments);
        };
        var _MirrorPad = Module["_MirrorPad"] = function() {
          return (_MirrorPad = Module["_MirrorPad"] = Module["asm"]["ba"]).apply(null, arguments);
        };
        var _Multiply = Module["_Multiply"] = function() {
          return (_Multiply = Module["_Multiply"] = Module["asm"]["ca"]).apply(null, arguments);
        };
        var _Neg = Module["_Neg"] = function() {
          return (_Neg = Module["_Neg"] = Module["asm"]["da"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV3 = Module["_NonMaxSuppressionV3"] = function() {
          return (_NonMaxSuppressionV3 = Module["_NonMaxSuppressionV3"] = Module["asm"]["ea"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV4 = Module["_NonMaxSuppressionV4"] = function() {
          return (_NonMaxSuppressionV4 = Module["_NonMaxSuppressionV4"] = Module["asm"]["fa"]).apply(null, arguments);
        };
        var _NonMaxSuppressionV5 = Module["_NonMaxSuppressionV5"] = function() {
          return (_NonMaxSuppressionV5 = Module["_NonMaxSuppressionV5"] = Module["asm"]["ga"]).apply(null, arguments);
        };
        var _NotEqual = Module["_NotEqual"] = function() {
          return (_NotEqual = Module["_NotEqual"] = Module["asm"]["ha"]).apply(null, arguments);
        };
        var _OneHot = Module["_OneHot"] = function() {
          return (_OneHot = Module["_OneHot"] = Module["asm"]["ia"]).apply(null, arguments);
        };
        var _PadV2 = Module["_PadV2"] = function() {
          return (_PadV2 = Module["_PadV2"] = Module["asm"]["ja"]).apply(null, arguments);
        };
        var _Pow = Module["_Pow"] = function() {
          return (_Pow = Module["_Pow"] = Module["asm"]["ka"]).apply(null, arguments);
        };
        var _Prelu = Module["_Prelu"] = function() {
          return (_Prelu = Module["_Prelu"] = Module["asm"]["la"]).apply(null, arguments);
        };
        var _Prod = Module["_Prod"] = function() {
          return (_Prod = Module["_Prod"] = Module["asm"]["ma"]).apply(null, arguments);
        };
        var _RealDiv = Module["_RealDiv"] = function() {
          return (_RealDiv = Module["_RealDiv"] = Module["asm"]["na"]).apply(null, arguments);
        };
        var _Relu = Module["_Relu"] = function() {
          return (_Relu = Module["_Relu"] = Module["asm"]["oa"]).apply(null, arguments);
        };
        var _Relu6 = Module["_Relu6"] = function() {
          return (_Relu6 = Module["_Relu6"] = Module["asm"]["pa"]).apply(null, arguments);
        };
        var _ResizeBilinear = Module["_ResizeBilinear"] = function() {
          return (_ResizeBilinear = Module["_ResizeBilinear"] = Module["asm"]["qa"]).apply(null, arguments);
        };
        var _Reverse = Module["_Reverse"] = function() {
          return (_Reverse = Module["_Reverse"] = Module["asm"]["ra"]).apply(null, arguments);
        };
        var _RotateWithOffset = Module["_RotateWithOffset"] = function() {
          return (_RotateWithOffset = Module["_RotateWithOffset"] = Module["asm"]["sa"]).apply(null, arguments);
        };
        var _Round = Module["_Round"] = function() {
          return (_Round = Module["_Round"] = Module["asm"]["ta"]).apply(null, arguments);
        };
        var _Rsqrt = Module["_Rsqrt"] = function() {
          return (_Rsqrt = Module["_Rsqrt"] = Module["asm"]["ua"]).apply(null, arguments);
        };
        var _ScatterNd = Module["_ScatterNd"] = function() {
          return (_ScatterNd = Module["_ScatterNd"] = Module["asm"]["va"]).apply(null, arguments);
        };
        var _SelectV2 = Module["_SelectV2"] = function() {
          return (_SelectV2 = Module["_SelectV2"] = Module["asm"]["wa"]).apply(null, arguments);
        };
        var _Sigmoid = Module["_Sigmoid"] = function() {
          return (_Sigmoid = Module["_Sigmoid"] = Module["asm"]["xa"]).apply(null, arguments);
        };
        var _Sin = Module["_Sin"] = function() {
          return (_Sin = Module["_Sin"] = Module["asm"]["ya"]).apply(null, arguments);
        };
        var _Softmax = Module["_Softmax"] = function() {
          return (_Softmax = Module["_Softmax"] = Module["asm"]["za"]).apply(null, arguments);
        };
        var _Sqrt = Module["_Sqrt"] = function() {
          return (_Sqrt = Module["_Sqrt"] = Module["asm"]["Aa"]).apply(null, arguments);
        };
        var _Square = Module["_Square"] = function() {
          return (_Square = Module["_Square"] = Module["asm"]["Ba"]).apply(null, arguments);
        };
        var _SquaredDifference = Module["_SquaredDifference"] = function() {
          return (_SquaredDifference = Module["_SquaredDifference"] = Module["asm"]["Ca"]).apply(null, arguments);
        };
        var _Step = Module["_Step"] = function() {
          return (_Step = Module["_Step"] = Module["asm"]["Da"]).apply(null, arguments);
        };
        var _StridedSlice = Module["_StridedSlice"] = function() {
          return (_StridedSlice = Module["_StridedSlice"] = Module["asm"]["Ea"]).apply(null, arguments);
        };
        var _Sub = Module["_Sub"] = function() {
          return (_Sub = Module["_Sub"] = Module["asm"]["Fa"]).apply(null, arguments);
        };
        var _Sum = Module["_Sum"] = function() {
          return (_Sum = Module["_Sum"] = Module["asm"]["Ga"]).apply(null, arguments);
        };
        var _Tan = Module["_Tan"] = function() {
          return (_Tan = Module["_Tan"] = Module["asm"]["Ha"]).apply(null, arguments);
        };
        var _Tanh = Module["_Tanh"] = function() {
          return (_Tanh = Module["_Tanh"] = Module["asm"]["Ia"]).apply(null, arguments);
        };
        var _Tile = Module["_Tile"] = function() {
          return (_Tile = Module["_Tile"] = Module["asm"]["Ja"]).apply(null, arguments);
        };
        var _TopK = Module["_TopK"] = function() {
          return (_TopK = Module["_TopK"] = Module["asm"]["Ka"]).apply(null, arguments);
        };
        var _Transform = Module["_Transform"] = function() {
          return (_Transform = Module["_Transform"] = Module["asm"]["La"]).apply(null, arguments);
        };
        var _Transpose = Module["_Transpose"] = function() {
          return (_Transpose = Module["_Transpose"] = Module["asm"]["Ma"]).apply(null, arguments);
        };
        var __FusedMatMul = Module["__FusedMatMul"] = function() {
          return (__FusedMatMul = Module["__FusedMatMul"] = Module["asm"]["Na"]).apply(null, arguments);
        };
        var _malloc = Module["_malloc"] = function() {
          return (_malloc = Module["_malloc"] = Module["asm"]["Oa"]).apply(null, arguments);
        };
        var _free = Module["_free"] = function() {
          return (_free = Module["_free"] = Module["asm"]["Pa"]).apply(null, arguments);
        };
        var ___errno_location = Module["___errno_location"] = function() {
          return (___errno_location = Module["___errno_location"] = Module["asm"]["Qa"]).apply(null, arguments);
        };
        var stackSave = Module["stackSave"] = function() {
          return (stackSave = Module["stackSave"] = Module["asm"]["Ra"]).apply(null, arguments);
        };
        var stackRestore = Module["stackRestore"] = function() {
          return (stackRestore = Module["stackRestore"] = Module["asm"]["Sa"]).apply(null, arguments);
        };
        var stackAlloc = Module["stackAlloc"] = function() {
          return (stackAlloc = Module["stackAlloc"] = Module["asm"]["Ta"]).apply(null, arguments);
        };
        Module["cwrap"] = cwrap;
        var calledRun;
        function ExitStatus(status) {
          this.name = "ExitStatus";
          this.message = "Program terminated with exit(" + status + ")";
          this.status = status;
        }
        dependenciesFulfilled = function runCaller() {
          if (!calledRun)
            run();
          if (!calledRun)
            dependenciesFulfilled = runCaller;
        };
        function run(args) {
          args = args || arguments_;
          if (runDependencies > 0) {
            return;
          }
          preRun();
          if (runDependencies > 0) {
            return;
          }
          function doRun() {
            if (calledRun)
              return;
            calledRun = true;
            Module["calledRun"] = true;
            if (ABORT)
              return;
            initRuntime();
            preMain();
            readyPromiseResolve(Module);
            if (Module["onRuntimeInitialized"])
              Module["onRuntimeInitialized"]();
            postRun();
          }
          if (Module["setStatus"]) {
            Module["setStatus"]("Running...");
            setTimeout(function() {
              setTimeout(function() {
                Module["setStatus"]("");
              }, 1);
              doRun();
            }, 1);
          } else {
            doRun();
          }
        }
        Module["run"] = run;
        if (Module["preInit"]) {
          if (typeof Module["preInit"] == "function")
            Module["preInit"] = [Module["preInit"]];
          while (Module["preInit"].length > 0) {
            Module["preInit"].pop()();
          }
        }
        run();
        return WasmBackendModule2.ready;
      };
    }();
    if (typeof exports === "object" && typeof module === "object")
      module.exports = WasmBackendModule;
    else if (typeof define === "function" && define["amd"])
      define([], function() {
        return WasmBackendModule;
      });
    else if (typeof exports === "object")
      exports["WasmBackendModule"] = WasmBackendModule;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs@3.7.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs/package.json
var version = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/package.json
var version2 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/package.json
var version3 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/package.json
var version4 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/package.json
var version5 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/package.json
var version6 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/package.json
var version7 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/package.json
var version8 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/backend.ts
var EPSILON_FLOAT32 = 1e-7;
var EPSILON_FLOAT16 = 1e-4;
var DataStorage = class {
  constructor(backend3, dataMover) {
    this.backend = backend3;
    this.dataMover = dataMover;
    this.data = new WeakMap();
    this.dataIdsCount = 0;
  }
  get(dataId) {
    if (!this.data.has(dataId)) {
      this.dataMover.moveData(this.backend, dataId);
    }
    return this.data.get(dataId);
  }
  set(dataId, value) {
    this.dataIdsCount++;
    this.data.set(dataId, value);
  }
  has(dataId) {
    return this.data.has(dataId);
  }
  delete(dataId) {
    this.dataIdsCount--;
    return this.data.delete(dataId);
  }
  numDataIds() {
    return this.dataIdsCount;
  }
};
var KernelBackend = class {
  refCount(dataId) {
    return notYetImplemented("refCount");
  }
  incRef(dataId) {
    return notYetImplemented("incRef");
  }
  timerAvailable() {
    return true;
  }
  time(f) {
    return notYetImplemented("time");
  }
  read(dataId) {
    return notYetImplemented("read");
  }
  readSync(dataId) {
    return notYetImplemented("readSync");
  }
  numDataIds() {
    return notYetImplemented("numDataIds");
  }
  disposeData(dataId, force) {
    return notYetImplemented("disposeData");
  }
  write(values, shape, dtype) {
    return notYetImplemented("write");
  }
  move(dataId, values, shape, dtype, refCount) {
    return notYetImplemented("move");
  }
  memory() {
    return notYetImplemented("memory");
  }
  floatPrecision() {
    return notYetImplemented("floatPrecision");
  }
  epsilon() {
    return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
  }
  dispose() {
    return notYetImplemented("dispose");
  }
};
function notYetImplemented(kernelName) {
  throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/util_base.ts
function shuffle(array2) {
  let counter = array2.length;
  let temp = 0;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    temp = array2[counter];
    array2[counter] = array2[index];
    array2[index] = temp;
  }
}
function shuffleCombo(array2, array22) {
  if (array2.length !== array22.length) {
    throw new Error(`Array sizes must match to be shuffled together First array length was ${array2.length}Second array length was ${array22.length}`);
  }
  let counter = array2.length;
  let temp, temp2;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    temp = array2[counter];
    temp2 = array22[counter];
    array2[counter] = array2[index];
    array22[counter] = array22[index];
    array2[index] = temp;
    array22[index] = temp2;
  }
}
function clamp(min7, x, max7) {
  return Math.max(min7, Math.min(x, max7));
}
function nearestLargerEven(val) {
  return val % 2 === 0 ? val : val + 1;
}
function sum(arr) {
  let sum8 = 0;
  for (let i = 0; i < arr.length; i++) {
    sum8 += arr[i];
  }
  return sum8;
}
function randUniform(a, b) {
  const r = Math.random();
  return b * r + (1 - r) * a;
}
function distSquared(a, b) {
  let result = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = Number(a[i]) - Number(b[i]);
    result += diff * diff;
  }
  return result;
}
function assert(expr, msg) {
  if (!expr) {
    throw new Error(typeof msg === "string" ? msg : msg());
  }
}
function assertShapesMatch(shapeA, shapeB, errorMessagePrefix = "") {
  assert(arraysEqual(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
}
function assertNonNull(a) {
  assert(a != null, () => `The input to the tensor constructor must be a non-null value.`);
}
function flatten(arr, result = [], skipTypedArray = false) {
  if (result == null) {
    result = [];
  }
  if (Array.isArray(arr) || isTypedArray(arr) && !skipTypedArray) {
    for (let i = 0; i < arr.length; ++i) {
      flatten(arr[i], result, skipTypedArray);
    }
  } else {
    result.push(arr);
  }
  return result;
}
function sizeFromShape(shape) {
  if (shape.length === 0) {
    return 1;
  }
  let size = shape[0];
  for (let i = 1; i < shape.length; i++) {
    size *= shape[i];
  }
  return size;
}
function isScalarShape(shape) {
  return shape.length === 0;
}
function arraysEqual(n1, n2) {
  if (n1 === n2) {
    return true;
  }
  if (n1 == null || n2 == null) {
    return false;
  }
  if (n1.length !== n2.length) {
    return false;
  }
  for (let i = 0; i < n1.length; i++) {
    if (n1[i] !== n2[i]) {
      return false;
    }
  }
  return true;
}
function isInt(a) {
  return a % 1 === 0;
}
function tanh(x) {
  if (Math.tanh != null) {
    return Math.tanh(x);
  }
  if (x === Infinity) {
    return 1;
  } else if (x === -Infinity) {
    return -1;
  } else {
    const e2x = Math.exp(2 * x);
    return (e2x - 1) / (e2x + 1);
  }
}
function sizeToSquarishShape(size) {
  const width = Math.ceil(Math.sqrt(size));
  return [width, Math.ceil(size / width)];
}
function createShuffledIndices(n) {
  const shuffledIndices = new Uint32Array(n);
  for (let i = 0; i < n; ++i) {
    shuffledIndices[i] = i;
  }
  shuffle(shuffledIndices);
  return shuffledIndices;
}
function rightPad(a, size) {
  if (size <= a.length) {
    return a;
  }
  return a + " ".repeat(size - a.length);
}
function repeatedTry(checkFn, delayFn = (counter) => 0, maxCounter) {
  return new Promise((resolve, reject) => {
    let tryCount = 0;
    const tryFn = () => {
      if (checkFn()) {
        resolve();
        return;
      }
      tryCount++;
      const nextBackoff = delayFn(tryCount);
      if (maxCounter != null && tryCount >= maxCounter) {
        reject();
        return;
      }
      setTimeout(tryFn, nextBackoff);
    };
    tryFn();
  });
}
function inferFromImplicitShape(shape, size) {
  let shapeProd = 1;
  let implicitIdx = -1;
  for (let i = 0; i < shape.length; ++i) {
    if (shape[i] >= 0) {
      shapeProd *= shape[i];
    } else if (shape[i] === -1) {
      if (implicitIdx !== -1) {
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
      }
      implicitIdx = i;
    } else if (shape[i] < 0) {
      throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
    }
  }
  if (implicitIdx === -1) {
    if (size > 0 && size !== shapeProd) {
      throw Error(`Size(${size}) must match the product of shape ${shape}`);
    }
    return shape;
  }
  if (shapeProd === 0) {
    throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
  }
  if (size % shapeProd !== 0) {
    throw Error(`The implicit shape can't be a fractional number. Got ${size} / ${shapeProd}`);
  }
  const newShape = shape.slice();
  newShape[implicitIdx] = size / shapeProd;
  return newShape;
}
function parseAxisParam(axis, shape) {
  const rank = shape.length;
  axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
  assert(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
  assert(axis.every((ax) => isInt(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
  return axis.map((a) => a < 0 ? rank + a : a);
}
function squeezeShape(shape, axis) {
  const newShape = [];
  const keptDims = [];
  const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
  const axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
  let j = 0;
  for (let i = 0; i < shape.length; ++i) {
    if (axes != null) {
      if (axes[j] === i && shape[i] !== 1) {
        throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
      }
      if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
      if (axes[j] <= i) {
        j++;
      }
    }
    if (shape[i] !== 1) {
      newShape.push(shape[i]);
      keptDims.push(i);
    }
  }
  return { newShape, keptDims };
}
function getTypedArrayFromDType(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function getArrayFromDType(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else if (dtype === "string") {
    values = new Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function checkConversionForErrors(vals, dtype) {
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
    }
  }
}
function isValidDtype(dtype) {
  return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
}
function hasEncodingLoss(oldType, newType) {
  if (newType === "complex64") {
    return false;
  }
  if (newType === "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "bool" && oldType === "bool") {
    return false;
  }
  return true;
}
function isTypedArray(a) {
  return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array;
}
function bytesPerElement(dtype) {
  if (dtype === "float32" || dtype === "int32") {
    return 4;
  } else if (dtype === "complex64") {
    return 8;
  } else if (dtype === "bool") {
    return 1;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function bytesFromStringArray(arr) {
  if (arr == null) {
    return 0;
  }
  let bytes = 0;
  arr.forEach((x) => bytes += x.length);
  return bytes;
}
function isString(value) {
  return typeof value === "string" || value instanceof String;
}
function isBoolean(value) {
  return typeof value === "boolean";
}
function isNumber(value) {
  return typeof value === "number";
}
function inferDtype(values) {
  if (Array.isArray(values)) {
    return inferDtype(values[0]);
  }
  if (values instanceof Float32Array) {
    return "float32";
  } else if (values instanceof Int32Array || values instanceof Uint8Array) {
    return "int32";
  } else if (isNumber(values)) {
    return "float32";
  } else if (isString(values)) {
    return "string";
  } else if (isBoolean(values)) {
    return "bool";
  }
  return "float32";
}
function isFunction(f) {
  return !!(f && f.constructor && f.call && f.apply);
}
function nearestDivisor(size, start) {
  for (let i = start; i < size; ++i) {
    if (size % i === 0) {
      return i;
    }
  }
  return size;
}
function computeStrides(shape) {
  const rank = shape.length;
  if (rank < 2) {
    return [];
  }
  const strides = new Array(rank - 1);
  strides[rank - 2] = shape[rank - 1];
  for (let i = rank - 3; i >= 0; --i) {
    strides[i] = strides[i + 1] * shape[i + 1];
  }
  return strides;
}
function createNestedArray(offset, shape, a, isComplex = false) {
  const ret = new Array();
  if (shape.length === 1) {
    const d = shape[0] * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = a[offset + i];
    }
  } else {
    const d = shape[0];
    const rest = shape.slice(1);
    const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
    }
  }
  return ret;
}
function toNestedArray(shape, a, isComplex = false) {
  if (shape.length === 0) {
    return a[0];
  }
  const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
  if (size === 0) {
    return [];
  }
  if (size !== a.length) {
    throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
  }
  return createNestedArray(0, shape, a, isComplex);
}
function makeOnesTypedArray(size, dtype) {
  const array2 = makeZerosTypedArray(size, dtype);
  for (let i = 0; i < array2.length; i++) {
    array2[i] = 1;
  }
  return array2;
}
function makeZerosTypedArray(size, dtype) {
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(size);
  } else if (dtype === "int32") {
    return new Int32Array(size);
  } else if (dtype === "bool") {
    return new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function makeZerosNestedTypedArray(shape, dtype) {
  const size = shape.reduce((prev, curr) => prev * curr, 1);
  if (dtype == null || dtype === "float32") {
    return toNestedArray(shape, new Float32Array(size));
  } else if (dtype === "int32") {
    return toNestedArray(shape, new Int32Array(size));
  } else if (dtype === "bool") {
    return toNestedArray(shape, new Uint8Array(size));
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function assertNonNegativeIntegerDimensions(shape) {
  shape.forEach((dimSize) => {
    assert(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
  });
}
function locToIndex(locs, rank, strides) {
  if (rank === 0) {
    return 0;
  } else if (rank === 1) {
    return locs[0];
  }
  let index = locs[locs.length - 1];
  for (let i = 0; i < locs.length - 1; ++i) {
    index += strides[i] * locs[i];
  }
  return index;
}
function indexToLoc(index, rank, strides) {
  if (rank === 0) {
    return [];
  } else if (rank === 1) {
    return [index];
  }
  const locs = new Array(rank);
  for (let i = 0; i < locs.length - 1; ++i) {
    locs[i] = Math.floor(index / strides[i]);
    index -= locs[i] * strides[i];
  }
  locs[locs.length - 1] = index;
  return locs;
}
function isPromise(object) {
  return object && object.then && typeof object.then === "function";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/environment.ts
var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
var Environment = class {
  constructor(global2) {
    this.global = global2;
    this.flags = {};
    this.flagRegistry = {};
    this.urlFlags = {};
    this.getQueryParams = getQueryParams;
    this.populateURLFlags();
  }
  setPlatform(platformName, platform) {
    if (this.platform != null) {
      console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platform}.`);
    }
    this.platformName = platformName;
    this.platform = platform;
  }
  registerFlag(flagName, evaluationFn, setHook) {
    this.flagRegistry[flagName] = { evaluationFn, setHook };
    if (this.urlFlags[flagName] != null) {
      const flagValue = this.urlFlags[flagName];
      console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);
      this.set(flagName, flagValue);
    }
  }
  async getAsync(flagName) {
    if (flagName in this.flags) {
      return this.flags[flagName];
    }
    this.flags[flagName] = await this.evaluateFlag(flagName);
    return this.flags[flagName];
  }
  get(flagName) {
    if (flagName in this.flags) {
      return this.flags[flagName];
    }
    const flagValue = this.evaluateFlag(flagName);
    if (isPromise(flagValue)) {
      throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
    }
    this.flags[flagName] = flagValue;
    return this.flags[flagName];
  }
  getNumber(flagName) {
    return this.get(flagName);
  }
  getBool(flagName) {
    return this.get(flagName);
  }
  getFlags() {
    return this.flags;
  }
  get features() {
    return this.flags;
  }
  set(flagName, value) {
    if (this.flagRegistry[flagName] == null) {
      throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
    }
    this.flags[flagName] = value;
    if (this.flagRegistry[flagName].setHook != null) {
      this.flagRegistry[flagName].setHook(value);
    }
  }
  evaluateFlag(flagName) {
    if (this.flagRegistry[flagName] == null) {
      throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
    }
    return this.flagRegistry[flagName].evaluationFn();
  }
  setFlags(flags) {
    this.flags = Object.assign({}, flags);
  }
  reset() {
    this.flags = {};
    this.urlFlags = {};
    this.populateURLFlags();
  }
  populateURLFlags() {
    if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
      return;
    }
    const urlParams = this.getQueryParams(this.global.location.search);
    if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
      const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
      keyValues.forEach((keyValue) => {
        const [key, value] = keyValue.split(":");
        this.urlFlags[key] = parseValue(key, value);
      });
    }
  }
};
function getQueryParams(queryString) {
  const params = {};
  queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {
    decodeParam(params, t[0], t[1]);
    return t.join("=");
  });
  return params;
}
function decodeParam(params, name, value) {
  params[decodeURIComponent(name)] = decodeURIComponent(value || "");
}
function parseValue(flagName, value) {
  value = value.toLowerCase();
  if (value === "true" || value === "false") {
    return value === "true";
  } else if (`${+value}` === value) {
    return +value;
  }
  throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);
}
function env() {
  return ENV;
}
var ENV = null;
function setEnvironmentGlobal(environment) {
  ENV = environment;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/global_util.ts
var globalNameSpace;
function getGlobalNamespace() {
  if (globalNameSpace == null) {
    let ns;
    if (typeof window !== "undefined") {
      ns = window;
    } else if (typeof global !== "undefined") {
      ns = global;
    } else if (typeof process !== "undefined") {
      ns = process;
    } else if (typeof self !== "undefined") {
      ns = self;
    } else {
      throw new Error("Could not find a global object");
    }
    globalNameSpace = ns;
  }
  return globalNameSpace;
}
function getGlobalMap() {
  const ns = getGlobalNamespace();
  if (ns._tfGlobals == null) {
    ns._tfGlobals = new Map();
  }
  return ns._tfGlobals;
}
function getGlobal(key, init2) {
  const globalMap = getGlobalMap();
  if (globalMap.has(key)) {
    return globalMap.get(key);
  } else {
    const singleton = init2();
    globalMap.set(key, singleton);
    return globalMap.get(key);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/kernel_names.ts
var Abs = "Abs";
var Acos = "Acos";
var Acosh = "Acosh";
var Add = "Add";
var AddN = "AddN";
var All = "All";
var Any = "Any";
var ArgMax = "ArgMax";
var ArgMin = "ArgMin";
var Asin = "Asin";
var Asinh = "Asinh";
var Atan = "Atan";
var Atanh = "Atanh";
var Atan2 = "Atan2";
var AvgPool = "AvgPool";
var AvgPoolGrad = "AvgPoolGrad";
var AvgPool3D = "AvgPool3D";
var AvgPool3DGrad = "AvgPool3DGrad";
var BatchMatMul = "BatchMatMul";
var BatchToSpaceND = "BatchToSpaceND";
var Bincount = "Bincount";
var BroadcastTo = "BroadcastTo";
var Cast = "Cast";
var Ceil = "Ceil";
var ClipByValue = "ClipByValue";
var Complex = "Complex";
var ComplexAbs = "ComplexAbs";
var Concat = "Concat";
var Conv2D = "Conv2D";
var Conv2DBackpropFilter = "Conv2DBackpropFilter";
var Conv2DBackpropInput = "Conv2DBackpropInput";
var Conv3D = "Conv3D";
var Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
var Cos = "Cos";
var Cosh = "Cosh";
var Cumsum = "Cumsum";
var CropAndResize = "CropAndResize";
var DenseBincount = "DenseBincount";
var DepthToSpace = "DepthToSpace";
var DepthwiseConv2dNative = "DepthwiseConv2dNative";
var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
var Diag = "Diag";
var Dilation2D = "Dilation2D";
var Dilation2DBackpropInput = "Dilation2DBackpropInput";
var Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
var RealDiv = "RealDiv";
var Einsum = "Einsum";
var Elu = "Elu";
var EluGrad = "EluGrad";
var Erf = "Erf";
var Equal = "Equal";
var Exp = "Exp";
var ExpandDims = "ExpandDims";
var Expm1 = "Expm1";
var FFT = "FFT";
var Fill = "Fill";
var FlipLeftRight = "FlipLeftRight";
var Floor = "Floor";
var FloorDiv = "FloorDiv";
var FusedBatchNorm = "FusedBatchNorm";
var GatherV2 = "GatherV2";
var GatherNd = "GatherNd";
var Greater = "Greater";
var GreaterEqual = "GreaterEqual";
var Identity = "Identity";
var IFFT = "IFFT";
var Imag = "Imag";
var IsFinite = "IsFinite";
var IsInf = "IsInf";
var IsNan = "IsNan";
var LeakyRelu = "LeakyRelu";
var Less = "Less";
var LessEqual = "LessEqual";
var LinSpace = "LinSpace";
var Log = "Log";
var Log1p = "Log1p";
var LogicalAnd = "LogicalAnd";
var LogicalNot = "LogicalNot";
var LogicalOr = "LogicalOr";
var LogSoftmax = "LogSoftmax";
var LRN = "LRN";
var LRNGrad = "LRNGrad";
var Max = "Max";
var Maximum = "Maximum";
var MaxPool = "MaxPool";
var MaxPoolGrad = "MaxPoolGrad";
var MaxPool3D = "MaxPool3D";
var MaxPool3DGrad = "MaxPool3DGrad";
var MaxPoolWithArgmax = "MaxPoolWithArgmax";
var Mean = "Mean";
var Min = "Min";
var Minimum = "Minimum";
var MirrorPad = "MirrorPad";
var Mod = "Mod";
var Multinomial = "Multinomial";
var Multiply = "Multiply";
var Neg = "Neg";
var NotEqual = "NotEqual";
var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
var OnesLike = "OnesLike";
var OneHot = "OneHot";
var Pack = "Pack";
var PadV2 = "PadV2";
var Pool = "Pool";
var Pow = "Pow";
var Prelu = "Prelu";
var Prod = "Prod";
var Range = "Range";
var Real = "Real";
var Reciprocal = "Reciprocal";
var Relu = "Relu";
var Reshape = "Reshape";
var ResizeNearestNeighbor = "ResizeNearestNeighbor";
var ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
var ResizeBilinear = "ResizeBilinear";
var ResizeBilinearGrad = "ResizeBilinearGrad";
var Relu6 = "Relu6";
var Reverse = "Reverse";
var Round = "Round";
var Rsqrt = "Rsqrt";
var ScatterNd = "ScatterNd";
var Select = "Select";
var Selu = "Selu";
var Slice = "Slice";
var Sin = "Sin";
var Sinh = "Sinh";
var Sign = "Sign";
var Sigmoid = "Sigmoid";
var Softplus = "Softplus";
var Sqrt = "Sqrt";
var Sum = "Sum";
var SpaceToBatchND = "SpaceToBatchND";
var SplitV = "SplitV";
var Softmax = "Softmax";
var SparseFillEmptyRows = "SparseFillEmptyRows";
var SparseReshape = "SparseReshape";
var SparseSegmentMean = "SparseSegmentMean";
var SparseSegmentSum = "SparseSegmentSum";
var SparseToDense = "SparseToDense";
var SquaredDifference = "SquaredDifference";
var Square = "Square";
var StridedSlice = "StridedSlice";
var StringNGrams = "StringNGrams";
var StringSplit = "StringSplit";
var StringToHashBucketFast = "StringToHashBucketFast";
var Sub = "Sub";
var Tan = "Tan";
var Tanh = "Tanh";
var Tile = "Tile";
var TopK = "TopK";
var Transform = "Transform";
var Transpose = "Transpose";
var Unique = "Unique";
var Unpack = "Unpack";
var UnsortedSegmentSum = "UnsortedSegmentSum";
var ZerosLike = "ZerosLike";
var Step = "Step";
var FromPixels = "FromPixels";
var RotateWithOffset = "RotateWithOffset";
var _FusedMatMul = "_FusedMatMul";
var FusedConv2D = "FusedConv2D";
var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/kernel_registry.ts
var kernelRegistry = getGlobal("kernelRegistry", () => new Map());
var gradRegistry = getGlobal("gradRegistry", () => new Map());
function getKernel(kernelName, backendName) {
  const key = makeKey(kernelName, backendName);
  return kernelRegistry.get(key);
}
function getGradient(kernelName) {
  return gradRegistry.get(kernelName);
}
function getKernelsForBackend(backendName) {
  const it = kernelRegistry.entries();
  const result = [];
  while (true) {
    const { done, value } = it.next();
    if (done) {
      break;
    }
    const [key, config] = value;
    const [backend3] = key.split("_");
    if (backend3 === backendName) {
      result.push(config);
    }
  }
  return result;
}
function registerKernel(config) {
  const { kernelName, backendName } = config;
  const key = makeKey(kernelName, backendName);
  if (kernelRegistry.has(key)) {
    console.warn(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
  }
  kernelRegistry.set(key, config);
}
function registerGradient(config) {
  const { kernelName } = config;
  if (gradRegistry.has(kernelName)) {
    if (env().getBool("DEBUG")) {
      console.warn(`Overriding the gradient for '${kernelName}'`);
    }
  }
  gradRegistry.set(kernelName, config);
}
function unregisterKernel(kernelName, backendName) {
  const key = makeKey(kernelName, backendName);
  if (!kernelRegistry.has(key)) {
    throw new Error(`The kernel '${kernelName}' for backend '${backendName}' is not registered`);
  }
  kernelRegistry.delete(key);
}
function unregisterGradient(kernelName) {
  if (!gradRegistry.has(kernelName)) {
    throw new Error(`The gradient '${kernelName}' for backend is not registered`);
  }
  gradRegistry.delete(kernelName);
}
function copyRegisteredKernels(registeredBackendName, newBackendName) {
  const kernels = getKernelsForBackend(registeredBackendName);
  kernels.forEach((kernelConfig) => {
    const newKernelConfig = Object.assign({}, kernelConfig, { backendName: newBackendName });
    registerKernel(newKernelConfig);
  });
}
function makeKey(kernelName, backendName) {
  return `${backendName}_${kernelName}`;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/util.ts
var util_exports = {};
__export(util_exports, {
  arraysEqual: () => arraysEqual,
  assert: () => assert,
  assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions,
  assertNonNull: () => assertNonNull,
  assertShapesMatch: () => assertShapesMatch,
  bytesFromStringArray: () => bytesFromStringArray,
  bytesPerElement: () => bytesPerElement,
  checkConversionForErrors: () => checkConversionForErrors,
  clamp: () => clamp,
  computeStrides: () => computeStrides,
  createScalarValue: () => createScalarValue,
  createShuffledIndices: () => createShuffledIndices,
  decodeString: () => decodeString,
  distSquared: () => distSquared,
  encodeString: () => encodeString,
  fetch: () => fetch3,
  fingerPrint64: () => fingerPrint64,
  flatten: () => flatten,
  getArrayFromDType: () => getArrayFromDType,
  getTypedArrayFromDType: () => getTypedArrayFromDType,
  hasEncodingLoss: () => hasEncodingLoss,
  hexToLong: () => hexToLong,
  indexToLoc: () => indexToLoc,
  inferDtype: () => inferDtype,
  inferFromImplicitShape: () => inferFromImplicitShape,
  isBoolean: () => isBoolean,
  isFunction: () => isFunction,
  isInt: () => isInt,
  isNumber: () => isNumber,
  isPromise: () => isPromise,
  isScalarShape: () => isScalarShape,
  isString: () => isString,
  isTypedArray: () => isTypedArray,
  isValidDtype: () => isValidDtype,
  locToIndex: () => locToIndex,
  makeOnesTypedArray: () => makeOnesTypedArray,
  makeZerosNestedTypedArray: () => makeZerosNestedTypedArray,
  makeZerosTypedArray: () => makeZerosTypedArray,
  nearestDivisor: () => nearestDivisor,
  nearestLargerEven: () => nearestLargerEven,
  now: () => now,
  parseAxisParam: () => parseAxisParam,
  randUniform: () => randUniform,
  repeatedTry: () => repeatedTry,
  rightPad: () => rightPad,
  shuffle: () => shuffle,
  shuffleCombo: () => shuffleCombo,
  sizeFromShape: () => sizeFromShape,
  sizeToSquarishShape: () => sizeToSquarishShape,
  squeezeShape: () => squeezeShape,
  sum: () => sum,
  tanh: () => tanh,
  toNestedArray: () => toNestedArray,
  toTypedArray: () => toTypedArray
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/hash_util.ts
var LongExports = __toModule(require_long());
var Long = LongExports.default || LongExports;
function hexToLong(hex) {
  return Long.fromString(hex, true, 16);
}
var k0 = hexToLong("c3a5c85c97cb3127");
var k1 = hexToLong("b492b66fbe98f273");
var k2 = hexToLong("9ae16a3b2f90404f");
function shiftMix(val) {
  return val.xor(val.shru(47));
}
function fetch2(s, offset, numBytes) {
  const bytes = s.slice(offset, offset + numBytes);
  return Long.fromBytes(Array.from(bytes), true, true);
}
function fetch64(s, offset) {
  return fetch2(s, offset, 8);
}
function fetch32(s, offset) {
  return fetch2(s, offset, 4);
}
function rotate64(val, shift) {
  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
}
function hashLen16(u, v, mul3 = hexToLong("9ddfea08eb382d69")) {
  let a = u.xor(v).mul(mul3);
  a = a.xor(a.shru(47));
  let b = v.xor(a).mul(mul3);
  b = b.xor(b.shru(47));
  b = b.mul(mul3);
  return b;
}
function weakHashLen32WithSeeds(w, x, y, z, a, b) {
  a = a.add(w);
  b = rotate64(b.add(a).add(z), 21);
  const c = a;
  a = a.add(x);
  a = a.add(y);
  b = b.add(rotate64(a, 44));
  return [a.add(z), b.add(c)];
}
function weakHashLen32WithSeedsStr(s, offset, a, b) {
  return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
}
function hashLen0to16(s, len = s.length) {
  if (len >= 8) {
    const mul3 = k2.add(len * 2);
    const a = fetch64(s, 0).add(k2);
    const b = fetch64(s, len - 8);
    const c = rotate64(b, 37).mul(mul3).add(a);
    const d = rotate64(a, 25).add(b).mul(mul3);
    return hashLen16(c, d, mul3);
  }
  if (len >= 4) {
    const mul3 = k2.add(len * 2);
    const a = fetch32(s, 0);
    return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul3);
  }
  if (len > 0) {
    const a = s[0];
    const b = s[len >> 1];
    const c = s[len - 1];
    const y = a + (b << 8);
    const z = len + (c << 2);
    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
  }
  return k2;
}
function hashLen17to32(s, len = s.length) {
  const mul3 = k2.add(len * 2);
  const a = fetch64(s, 0).mul(k1);
  const b = fetch64(s, 8);
  const c = fetch64(s, len - 8).mul(mul3);
  const d = fetch64(s, len - 16).mul(k2);
  return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul3);
}
function hashLen33to64(s, len = s.length) {
  const mul3 = k2.add(len * 2);
  const a = fetch64(s, 0).mul(k2);
  const b = fetch64(s, 8);
  const c = fetch64(s, len - 8).mul(mul3);
  const d = fetch64(s, len - 16).mul(k2);
  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul3);
  const e = fetch64(s, 16).mul(mul3);
  const f = fetch64(s, 24);
  const g = y.add(fetch64(s, len - 32)).mul(mul3);
  const h = z.add(fetch64(s, len - 24)).mul(mul3);
  return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul3);
}
function fingerPrint64(s, len = s.length) {
  const seed = Long.fromNumber(81, true);
  if (len <= 32) {
    if (len <= 16) {
      return hashLen0to16(s, len);
    } else {
      return hashLen17to32(s, len);
    }
  } else if (len <= 64) {
    return hashLen33to64(s, len);
  }
  let x = seed;
  let y = seed.mul(k1).add(113);
  let z = shiftMix(y.mul(k2).add(113)).mul(k2);
  let v = [Long.UZERO, Long.UZERO];
  let w = [Long.UZERO, Long.UZERO];
  x = x.mul(k2).add(fetch64(s, 0));
  let offset = 0;
  const end = (len - 1 >> 6) * 64;
  const last64 = end + (len - 1 & 63) - 63;
  do {
    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
    x = x.xor(w[1]);
    y = y.add(v[0]).add(fetch64(s, offset + 40));
    z = rotate64(z.add(w[0]), 33).mul(k1);
    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
    [z, x] = [x, z];
    offset += 64;
  } while (offset !== end);
  const mul3 = k1.add(z.and(255).shl(1));
  offset = last64;
  w[0] = w[0].add(len - 1 & 63);
  v[0] = v[0].add(w[0]);
  w[0] = w[0].add(v[0]);
  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul3);
  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul3);
  x = x.xor(w[1].mul(9));
  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
  z = rotate64(z.add(w[0]), 33).mul(mul3);
  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul3), x.add(w[0]));
  w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
  [z, x] = [x, z];
  return hashLen16(hashLen16(v[0], w[0], mul3).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul3).add(x), mul3);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/util.ts
function createScalarValue(value, dtype) {
  if (dtype === "string") {
    return encodeString(value);
  }
  return toTypedArray([value], dtype);
}
function noConversionNeeded(a, dtype) {
  return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
}
function toTypedArray(a, dtype) {
  if (dtype === "string") {
    throw new Error("Cannot convert a string[] to a TypedArray");
  }
  if (Array.isArray(a)) {
    a = flatten(a);
  }
  if (env().getBool("DEBUG")) {
    checkConversionForErrors(a, dtype);
  }
  if (noConversionNeeded(a, dtype)) {
    return a;
  }
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(a);
  } else if (dtype === "int32") {
    return new Int32Array(a);
  } else if (dtype === "bool") {
    const bool = new Uint8Array(a.length);
    for (let i = 0; i < bool.length; ++i) {
      if (Math.round(a[i]) !== 0) {
        bool[i] = 1;
      }
    }
    return bool;
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function now() {
  return env().platform.now();
}
function fetch3(path, requestInits) {
  return env().platform.fetch(path, requestInits);
}
function encodeString(s, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.encode(s, encoding);
}
function decodeString(bytes, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.decode(bytes, encoding);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/profiler.ts
var Profiler = class {
  constructor(backendTimer, logger) {
    this.backendTimer = backendTimer;
    this.logger = logger;
    if (logger == null) {
      this.logger = new Logger();
    }
  }
  profileKernel(kernelName, inputs, f) {
    let outputs;
    const holdResultWrapperFn = () => {
      outputs = f();
    };
    let timer;
    const start = now();
    if (this.backendTimer.timerAvailable()) {
      timer = this.backendTimer.time(holdResultWrapperFn);
    } else {
      holdResultWrapperFn();
      for (const output of outputs) {
        output.dataSync();
      }
      timer = Promise.resolve({ kernelMs: now() - start });
    }
    if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
      for (let i = 0; i < outputs.length; i++) {
        const output = outputs[i];
        output.data().then((tensorVals) => {
          checkComputationForErrors(tensorVals, output.dtype, kernelName);
        });
      }
    }
    const kernelProfile = {
      kernelName,
      outputs,
      inputs,
      timeMs: timer.then((timing) => timing.kernelMs),
      extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
    };
    return kernelProfile;
  }
  logKernelProfile(kernelProfile) {
    const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;
    outputs.forEach((result) => {
      Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
        this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
      });
    });
  }
};
function checkComputationForErrors(vals, dtype, kernelName) {
  if (dtype !== "float32") {
    return false;
  }
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      console.warn(`Found ${num} in the result of '${kernelName}'`);
      return true;
    }
  }
  return false;
}
var Logger = class {
  logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
    const time2 = typeof timeMs === "number" ? rightPad(`${timeMs}ms`, 9) : timeMs["error"];
    const paddedName = rightPad(name, 25);
    const rank = result.rank;
    const size = result.size;
    const shape = rightPad(result.shape.toString(), 14);
    let inputShapesDescription = "";
    for (const name2 in inputs) {
      const input2 = inputs[name2];
      if (input2 != null) {
        const inputShape = input2.shape || result.shape;
        const inputRank = inputShape.length;
        inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
      }
    }
    console.log(`%c${paddedName}	%c${time2}	%c${rank}D ${shape}	%c${size}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tape.ts
function getFilteredNodesXToY(tape, xs, y) {
  const tensorsFromX = {};
  const nodesFromX = {};
  for (let i = 0; i < xs.length; i++) {
    tensorsFromX[xs[i].id] = true;
  }
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (const inputName in nodeInputs) {
      const input2 = nodeInputs[inputName];
      let anyInputFromX = false;
      for (let j = 0; j < xs.length; j++) {
        if (tensorsFromX[input2.id]) {
          node.outputs.forEach((output) => tensorsFromX[output.id] = true);
          anyInputFromX = true;
          nodesFromX[node.id] = true;
          break;
        }
      }
      if (anyInputFromX) {
        break;
      }
    }
  }
  const tensorsLeadToY = {};
  tensorsLeadToY[y.id] = true;
  const nodesToY = {};
  for (let i = tape.length - 1; i >= 0; i--) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (let j = 0; j < node.outputs.length; j++) {
      if (tensorsLeadToY[node.outputs[j].id]) {
        for (const inputName in nodeInputs) {
          tensorsLeadToY[nodeInputs[inputName].id] = true;
          nodesToY[node.id] = true;
        }
        break;
      }
    }
  }
  const filteredTape = [];
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    if (nodesFromX[node.id] && nodesToY[node.id]) {
      const prunedInputs = {};
      for (const inputName in node.inputs) {
        const nodeInput = node.inputs[inputName];
        if (tensorsFromX[nodeInput.id]) {
          prunedInputs[inputName] = nodeInput;
        }
      }
      const prunedNode = Object.assign({}, node);
      prunedNode.inputs = prunedInputs;
      prunedNode.outputs = node.outputs;
      filteredTape.push(prunedNode);
    }
  }
  return filteredTape;
}
function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy3, add8) {
  for (let i = filteredTape.length - 1; i >= 0; i--) {
    const node = filteredTape[i];
    const dys = [];
    node.outputs.forEach((o) => {
      const gradTensor = tensorAccumulatedGradientMap[o.id];
      if (gradTensor != null) {
        dys.push(gradTensor);
      } else {
        dys.push(null);
      }
    });
    if (node.gradient == null) {
      throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
    }
    const inputGradients = node.gradient(dys);
    for (const inputName in node.inputs) {
      if (!(inputName in inputGradients)) {
        throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
      }
      const dx = tidy3(() => inputGradients[inputName]());
      if (dx.dtype !== "float32") {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
      }
      const x = node.inputs[inputName];
      if (!arraysEqual(dx.shape, x.shape)) {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
      }
      if (tensorAccumulatedGradientMap[x.id] == null) {
        tensorAccumulatedGradientMap[x.id] = dx;
      } else {
        const curGradient = tensorAccumulatedGradientMap[x.id];
        tensorAccumulatedGradientMap[x.id] = add8(curGradient, dx);
        curGradient.dispose();
      }
    }
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tensor_format.ts
var FORMAT_LIMIT_NUM_VALS = 20;
var FORMAT_NUM_FIRST_LAST_VALS = 3;
var FORMAT_NUM_SIG_DIGITS = 7;
function tensorToString(vals, shape, dtype, verbose) {
  const strides = computeStrides(shape);
  const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
  const rank = shape.length;
  const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
  const lines = ["Tensor"];
  if (verbose) {
    lines.push(`  dtype: ${dtype}`);
    lines.push(`  rank: ${rank}`);
    lines.push(`  shape: [${shape}]`);
    lines.push(`  values:`);
  }
  lines.push(valsLines.map((l) => "    " + l).join("\n"));
  return lines.join("\n");
}
function computeMaxSizePerColumn(vals, shape, dtype, strides) {
  const n = sizeFromShape(shape);
  const numCols = strides[strides.length - 1];
  const padPerCol = new Array(numCols).fill(0);
  const rank = shape.length;
  const valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
  if (rank > 1) {
    for (let row = 0; row < n / numCols; row++) {
      const offset = row * numCols;
      for (let j = 0; j < numCols; j++) {
        padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
      }
    }
  }
  return padPerCol;
}
function valToString(val, pad4, dtype) {
  let valStr;
  if (Array.isArray(val)) {
    valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;
  } else if (isString(val)) {
    valStr = `'${val}'`;
  } else if (dtype === "bool") {
    valStr = boolNumToString(val);
  } else {
    valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
  }
  return rightPad(valStr, pad4);
}
function boolNumToString(v) {
  return v === 0 ? "false" : "true";
}
function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast = true) {
  const storagePerElement = dtype === "complex64" ? 2 : 1;
  const size = shape[0];
  const rank = shape.length;
  if (rank === 0) {
    if (dtype === "complex64") {
      const complexTuple = createComplexTuples(vals);
      return [valToString(complexTuple[0], 0, dtype)];
    }
    if (dtype === "bool") {
      return [boolNumToString(vals[0])];
    }
    return [vals[0].toString()];
  }
  if (rank === 1) {
    if (size > FORMAT_LIMIT_NUM_VALS) {
      const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
      let firstVals = Array.from(vals.slice(0, firstValsSize));
      let lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
      if (dtype === "complex64") {
        firstVals = createComplexTuples(firstVals);
        lastVals = createComplexTuples(lastVals);
      }
      return [
        "[" + firstVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype)).join(", ") + "]"
      ];
    }
    const displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
    return [
      "[" + displayVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + "]"
    ];
  }
  const subshape = shape.slice(1);
  const substrides = strides.slice(1);
  const stride = strides[0] * storagePerElement;
  const lines = [];
  if (size > FORMAT_LIMIT_NUM_VALS) {
    for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, false));
    }
    lines.push("...");
    for (let i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1));
    }
  } else {
    for (let i = 0; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1));
    }
  }
  const sep = rank === 2 ? "," : "";
  lines[0] = "[" + lines[0] + sep;
  for (let i = 1; i < lines.length - 1; i++) {
    lines[i] = " " + lines[i] + sep;
  }
  let newLineSep = ",\n";
  for (let i = 2; i < rank; i++) {
    newLineSep += "\n";
  }
  lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
  return lines;
}
function createComplexTuples(vals) {
  const complexTuples = [];
  for (let i = 0; i < vals.length; i += 2) {
    complexTuples.push([vals[i], vals[i + 1]]);
  }
  return complexTuples;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tensor.ts
var TensorBuffer = class {
  constructor(shape, dtype, values) {
    this.dtype = dtype;
    this.shape = shape.slice();
    this.size = sizeFromShape(shape);
    if (values != null) {
      const n = values.length;
      assert(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
    }
    if (dtype === "complex64") {
      throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
    }
    this.values = values || getArrayFromDType(dtype, this.size);
    this.strides = computeStrides(shape);
  }
  set(value, ...locs) {
    if (locs.length === 0) {
      locs = [0];
    }
    assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
    const index = this.locToIndex(locs);
    this.values[index] = value;
  }
  get(...locs) {
    if (locs.length === 0) {
      locs = [0];
    }
    let i = 0;
    for (const loc of locs) {
      if (loc < 0 || loc >= this.shape[i]) {
        const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
        throw new Error(msg);
      }
      i++;
    }
    let index = locs[locs.length - 1];
    for (let i2 = 0; i2 < locs.length - 1; ++i2) {
      index += this.strides[i2] * locs[i2];
    }
    return this.values[index];
  }
  locToIndex(locs) {
    if (this.rank === 0) {
      return 0;
    } else if (this.rank === 1) {
      return locs[0];
    }
    let index = locs[locs.length - 1];
    for (let i = 0; i < locs.length - 1; ++i) {
      index += this.strides[i] * locs[i];
    }
    return index;
  }
  indexToLoc(index) {
    if (this.rank === 0) {
      return [];
    } else if (this.rank === 1) {
      return [index];
    }
    const locs = new Array(this.shape.length);
    for (let i = 0; i < locs.length - 1; ++i) {
      locs[i] = Math.floor(index / this.strides[i]);
      index -= locs[i] * this.strides[i];
    }
    locs[locs.length - 1] = index;
    return locs;
  }
  get rank() {
    return this.shape.length;
  }
  toTensor() {
    return trackerFn().makeTensor(this.values, this.shape, this.dtype);
  }
};
var trackerFn = null;
var opHandler = null;
var deprecationWarningFn = null;
function setTensorTracker(fn) {
  trackerFn = fn;
}
function setOpHandler(handler) {
  opHandler = handler;
}
function setDeprecationWarningFn(fn) {
  deprecationWarningFn = fn;
}
var Tensor = class {
  constructor(shape, dtype, dataId, id) {
    this.kept = false;
    this.isDisposedInternal = false;
    this.shape = shape.slice();
    this.dtype = dtype || "float32";
    this.size = sizeFromShape(shape);
    this.strides = computeStrides(shape);
    this.dataId = dataId;
    this.id = id;
    this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }
  get rank() {
    return this.shape.length;
  }
  async buffer() {
    const vals = await this.data();
    return opHandler.buffer(this.shape, this.dtype, vals);
  }
  bufferSync() {
    return opHandler.buffer(this.shape, this.dtype, this.dataSync());
  }
  async array() {
    const vals = await this.data();
    return toNestedArray(this.shape, vals, this.dtype === "complex64");
  }
  arraySync() {
    return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
  }
  async data() {
    this.throwIfDisposed();
    const data = trackerFn().read(this.dataId);
    if (this.dtype === "string") {
      const bytes = await data;
      try {
        return bytes.map((b) => decodeString(b));
      } catch (e) {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return data;
  }
  dataSync() {
    this.throwIfDisposed();
    const data = trackerFn().readSync(this.dataId);
    if (this.dtype === "string") {
      try {
        return data.map((b) => decodeString(b));
      } catch (e) {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return data;
  }
  async bytes() {
    this.throwIfDisposed();
    const data = await trackerFn().read(this.dataId);
    if (this.dtype === "string") {
      return data;
    } else {
      return new Uint8Array(data.buffer);
    }
  }
  dispose() {
    if (this.isDisposed) {
      return;
    }
    trackerFn().disposeTensor(this);
    this.isDisposedInternal = true;
  }
  get isDisposed() {
    return this.isDisposedInternal;
  }
  throwIfDisposed() {
    if (this.isDisposed) {
      throw new Error(`Tensor is disposed.`);
    }
  }
  print(verbose = false) {
    return opHandler.print(this, verbose);
  }
  clone() {
    this.throwIfDisposed();
    return opHandler.clone(this);
  }
  toString(verbose = false) {
    const vals = this.dataSync();
    return tensorToString(vals, this.shape, this.dtype, verbose);
  }
  cast(dtype) {
    this.throwIfDisposed();
    return opHandler.cast(this, dtype);
  }
  variable(trainable = true, name, dtype) {
    this.throwIfDisposed();
    return trackerFn().makeVariable(this, trainable, name, dtype);
  }
};
Object.defineProperty(Tensor, Symbol.hasInstance, {
  value: (instance) => {
    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
  }
});
function getGlobalTensorClass() {
  return getGlobal("Tensor", () => {
    return Tensor;
  });
}
getGlobalTensorClass();
var Variable = class extends Tensor {
  constructor(initialValue, trainable, name, tensorId) {
    super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
    this.trainable = trainable;
    this.name = name;
  }
  assign(newValue) {
    if (newValue.dtype !== this.dtype) {
      throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
    }
    if (!arraysEqual(newValue.shape, this.shape)) {
      throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
    }
    trackerFn().disposeTensor(this);
    this.dataId = newValue.dataId;
    trackerFn().incRef(this, null);
  }
  dispose() {
    trackerFn().disposeVariable(this);
    this.isDisposedInternal = true;
  }
};
Object.defineProperty(Variable, Symbol.hasInstance, {
  value: (instance) => {
    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tensor_util.ts
var tensor_util_exports = {};
__export(tensor_util_exports, {
  assertTypesMatch: () => assertTypesMatch,
  getTensorsInContainer: () => getTensorsInContainer,
  isTensorInList: () => isTensorInList,
  makeTypesMatch: () => makeTypesMatch
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/types.ts
var Rank;
(function(Rank16) {
  Rank16["R0"] = "R0";
  Rank16["R1"] = "R1";
  Rank16["R2"] = "R2";
  Rank16["R3"] = "R3";
  Rank16["R4"] = "R4";
  Rank16["R5"] = "R5";
  Rank16["R6"] = "R6";
})(Rank || (Rank = {}));
var UpcastInt32AndMap;
(function(UpcastInt32AndMap3) {
  UpcastInt32AndMap3["float32"] = "float32";
  UpcastInt32AndMap3["int32"] = "int32";
  UpcastInt32AndMap3["bool"] = "int32";
  UpcastInt32AndMap3["complex64"] = "complex64";
})(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
var UpcastBoolAndMap;
(function(UpcastBoolAndMap3) {
  UpcastBoolAndMap3["float32"] = "float32";
  UpcastBoolAndMap3["int32"] = "int32";
  UpcastBoolAndMap3["bool"] = "bool";
  UpcastBoolAndMap3["complex64"] = "complex64";
})(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
var UpcastFloat32AndMap;
(function(UpcastFloat32AndMap3) {
  UpcastFloat32AndMap3["float32"] = "float32";
  UpcastFloat32AndMap3["int32"] = "float32";
  UpcastFloat32AndMap3["bool"] = "float32";
  UpcastFloat32AndMap3["complex64"] = "complex64";
})(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
var UpcastComplex64AndMap;
(function(UpcastComplex64AndMap3) {
  UpcastComplex64AndMap3["float32"] = "complex64";
  UpcastComplex64AndMap3["int32"] = "complex64";
  UpcastComplex64AndMap3["bool"] = "complex64";
  UpcastComplex64AndMap3["complex64"] = "complex64";
})(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
var upcastTypeMap = {
  "float32": UpcastFloat32AndMap,
  "int32": UpcastInt32AndMap,
  "bool": UpcastBoolAndMap,
  "complex64": UpcastComplex64AndMap
};
function upcastType(typeA, typeB) {
  if (typeA === "string" || typeB === "string") {
    if (typeA === "string" && typeB === "string") {
      return "string";
    }
    throw new Error(`Can not upcast ${typeA} with ${typeB}`);
  }
  return upcastTypeMap[typeA][typeB];
}
function sumOutType(type) {
  return upcastType(type, "int32");
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tensor_util.ts
function makeTypesMatch(a, b) {
  if (a.dtype === b.dtype) {
    return [a, b];
  }
  const dtype = upcastType(a.dtype, b.dtype);
  return [a.cast(dtype), b.cast(dtype)];
}
function assertTypesMatch(a, b) {
  assert(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
}
function isTensorInList(tensor3, tensorList) {
  return tensorList.some((x) => x.id === tensor3.id);
}
function getTensorsInContainer(result) {
  const list = [];
  const seen = new Set();
  walkTensorContainer(result, list, seen);
  return list;
}
function walkTensorContainer(container, list, seen) {
  if (container == null) {
    return;
  }
  if (container instanceof Tensor) {
    list.push(container);
    return;
  }
  if (!isIterable(container)) {
    return;
  }
  const iterable = container;
  for (const k in iterable) {
    const val = iterable[k];
    if (!seen.has(val)) {
      seen.add(val);
      walkTensorContainer(val, list, seen);
    }
  }
}
function isIterable(obj) {
  return Array.isArray(obj) || typeof obj === "object";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/engine.ts
function isRegisteredKernelInvocation(kernelInvocation) {
  return kernelInvocation.kernelName != null;
}
var EngineState = class {
  constructor() {
    this.registeredVariables = {};
    this.nextTapeNodeId = 0;
    this.numBytes = 0;
    this.numTensors = 0;
    this.numStringTensors = 0;
    this.numDataBuffers = 0;
    this.gradientDepth = 0;
    this.kernelDepth = 0;
    this.scopeStack = [];
    this.numDataMovesStack = [];
    this.nextScopeId = 0;
    this.tensorInfo = new WeakMap();
    this.profiling = false;
    this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,
      get kernelNames() {
        return Array.from(new Set(this.kernels.map((k) => k.name)));
      }
    };
  }
  dispose() {
    for (const variableName in this.registeredVariables) {
      this.registeredVariables[variableName].dispose();
    }
  }
};
var _Engine = class {
  constructor(ENV7) {
    this.ENV = ENV7;
    this.registry = {};
    this.registryFactory = {};
    this.pendingBackendInitId = 0;
    this.state = new EngineState();
  }
  async ready() {
    if (this.pendingBackendInit != null) {
      return this.pendingBackendInit.then(() => {
      });
    }
    if (this.backendInstance != null) {
      return;
    }
    const sortedBackends = this.getSortedBackends();
    for (let i = 0; i < sortedBackends.length; i++) {
      const backendName = sortedBackends[i];
      const success = await this.initializeBackend(backendName).success;
      if (success) {
        await this.setBackend(backendName);
        return;
      }
    }
    throw new Error(`Could not initialize any backends, all backend initializations failed.`);
  }
  get backend() {
    if (this.pendingBackendInit != null) {
      throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
    }
    if (this.backendInstance == null) {
      const { name, asyncInit } = this.initializeBackendsAndReturnBest();
      if (asyncInit) {
        throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      }
      this.setBackend(name);
    }
    return this.backendInstance;
  }
  backendNames() {
    return Object.keys(this.registryFactory);
  }
  findBackend(backendName) {
    if (!(backendName in this.registry)) {
      if (backendName in this.registryFactory) {
        const { asyncInit } = this.initializeBackend(backendName);
        if (asyncInit) {
          return null;
        }
      } else {
        return null;
      }
    }
    return this.registry[backendName];
  }
  findBackendFactory(backendName) {
    if (!(backendName in this.registryFactory)) {
      return null;
    }
    return this.registryFactory[backendName].factory;
  }
  registerBackend(backendName, factory, priority = 1) {
    if (backendName in this.registryFactory) {
      console.warn(`${backendName} backend was already registered. Reusing existing backend factory.`);
      return false;
    }
    this.registryFactory[backendName] = { factory, priority };
    return true;
  }
  async setBackend(backendName) {
    if (this.registryFactory[backendName] == null) {
      throw new Error(`Backend name '${backendName}' not found in registry`);
    }
    this.backendName = backendName;
    if (this.registry[backendName] == null) {
      this.backendInstance = null;
      const { success, asyncInit } = this.initializeBackend(backendName);
      const result = asyncInit ? await success : success;
      if (!result) {
        return false;
      }
    }
    this.backendInstance = this.registry[backendName];
    this.setupRegisteredKernels();
    this.profiler = new Profiler(this.backendInstance);
    return true;
  }
  setupRegisteredKernels() {
    const kernels = getKernelsForBackend(this.backendName);
    kernels.forEach((kernel) => {
      if (kernel.setupFunc != null) {
        kernel.setupFunc(this.backendInstance);
      }
    });
  }
  disposeRegisteredKernels(backendName) {
    const kernels = getKernelsForBackend(backendName);
    kernels.forEach((kernel) => {
      if (kernel.disposeFunc != null) {
        kernel.disposeFunc(this.registry[backendName]);
      }
    });
  }
  initializeBackend(backendName) {
    const registryFactoryEntry = this.registryFactory[backendName];
    if (registryFactoryEntry == null) {
      throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
    }
    try {
      const backend3 = registryFactoryEntry.factory();
      if (backend3 && !(backend3 instanceof KernelBackend) && typeof backend3.then === "function") {
        const promiseId = ++this.pendingBackendInitId;
        const success = backend3.then((backendInstance) => {
          if (promiseId < this.pendingBackendInitId) {
            return false;
          }
          this.registry[backendName] = backendInstance;
          this.pendingBackendInit = null;
          return true;
        }).catch((err) => {
          if (promiseId < this.pendingBackendInitId) {
            return false;
          }
          this.pendingBackendInit = null;
          console.warn(`Initialization of backend ${backendName} failed`);
          console.warn(err.stack || err.message);
          return false;
        });
        this.pendingBackendInit = success;
        return { success, asyncInit: true };
      } else {
        this.registry[backendName] = backend3;
        return { success: true, asyncInit: false };
      }
    } catch (err) {
      console.warn(`Initialization of backend ${backendName} failed`);
      console.warn(err.stack || err.message);
      return { success: false, asyncInit: false };
    }
  }
  removeBackend(backendName) {
    if (!(backendName in this.registryFactory)) {
      throw new Error(`${backendName} backend not found in registry`);
    }
    if (this.backendName === backendName && this.pendingBackendInit != null) {
      this.pendingBackendInitId++;
    }
    if (backendName in this.registry) {
      this.disposeRegisteredKernels(backendName);
      this.registry[backendName].dispose();
      delete this.registry[backendName];
    }
    delete this.registryFactory[backendName];
    if (this.backendName === backendName) {
      this.pendingBackendInit = null;
      this.backendName = null;
      this.backendInstance = null;
    }
  }
  getSortedBackends() {
    if (Object.keys(this.registryFactory).length === 0) {
      throw new Error("No backend found in registry.");
    }
    return Object.keys(this.registryFactory).sort((a, b) => {
      return this.registryFactory[b].priority - this.registryFactory[a].priority;
    });
  }
  initializeBackendsAndReturnBest() {
    const sortedBackends = this.getSortedBackends();
    for (let i = 0; i < sortedBackends.length; i++) {
      const backendName = sortedBackends[i];
      const { success, asyncInit } = this.initializeBackend(backendName);
      if (asyncInit || success) {
        return { name: backendName, asyncInit };
      }
    }
    throw new Error(`Could not initialize any backends, all backend initializations failed.`);
  }
  moveData(backend3, dataId) {
    const info = this.state.tensorInfo.get(dataId);
    const srcBackend = info.backend;
    const values = this.readSync(dataId);
    const refCount = srcBackend.refCount(dataId);
    srcBackend.disposeData(dataId, true);
    info.backend = backend3;
    backend3.move(dataId, values, info.shape, info.dtype, refCount);
    if (this.shouldCheckForMemLeaks()) {
      this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
    }
  }
  tidy(nameOrFn, fn) {
    let name = null;
    if (fn == null) {
      if (typeof nameOrFn !== "function") {
        throw new Error("Please provide a function to tidy()");
      }
      fn = nameOrFn;
    } else {
      if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
        throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      }
      if (typeof fn !== "function") {
        throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      }
      name = nameOrFn;
    }
    let result;
    return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
      result = fn();
      if (result instanceof Promise) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      return result;
    });
  }
  scopedRun(start, end, f) {
    start();
    try {
      const res = f();
      end();
      return res;
    } catch (ex) {
      end();
      throw ex;
    }
  }
  nextTensorId() {
    return _Engine.nextTensorId++;
  }
  nextVariableId() {
    return _Engine.nextVariableId++;
  }
  clone(x) {
    const y = ENGINE.runKernel(Identity, { x });
    const inputs = { x };
    const grad3 = (dy) => ({
      x: () => {
        const dtype = "float32";
        const gradInputs = { x: dy };
        const attrs = { dtype };
        return ENGINE.runKernel(Cast, gradInputs, attrs);
      }
    });
    const saved = [];
    this.addTapeNode(this.state.activeScope.name, inputs, [y], grad3, saved, {});
    return y;
  }
  runKernel(kernelName, inputs, attrs) {
    const hasKernel = getKernel(kernelName, this.backendName) != null;
    if (!hasKernel) {
      throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
    }
    return this.runKernelFunc({ kernelName, inputs, attrs });
  }
  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }
  checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
    const numDataIdsAfter = this.backend.numDataIds();
    let numOutputDataIds = 0;
    outInfos.forEach((info) => {
      numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
    });
    const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
    const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
    if (dataIdsLeaked > 0) {
      throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
    }
  }
  runKernelFunc(kernelParams) {
    let outputs;
    let saved = [];
    const isTapeOn = this.isTapeOn();
    const startingBytecount = this.state.numBytes;
    const startingNumTensors = this.state.numTensors;
    if (this.shouldCheckForMemLeaks()) {
      this.state.numDataMovesStack.push(0);
    }
    let kernelFunc3;
    if (this.backendName == null) {
      this.backend;
    }
    let out;
    const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
    if (isRegisteredKernelInvocation(kernelParams)) {
      const { kernelName, inputs: inputs2, attrs: attrs2 } = kernelParams;
      if (this.backendName == null) {
        this.backend;
      }
      const kernel = getKernel(kernelName, this.backendName);
      assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
      kernelFunc3 = () => {
        const numDataIdsBefore = this.backend.numDataIds();
        out = kernel.kernelFunc({ inputs: inputs2, attrs: attrs2, backend: this.backend });
        const outInfos = Array.isArray(out) ? out : [out];
        if (this.shouldCheckForMemLeaks()) {
          this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
        }
        const outTensors = outInfos.map((outInfo) => {
          if (outInfo.rank != null) {
            return outInfo;
          }
          const { dataId, shape, dtype } = outInfo;
          return this.makeTensorFromDataId(dataId, shape, dtype);
        });
        if (isTapeOn) {
          const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
          saved = this.saveTensorsForBackwardMode(tensorsToSave);
        }
        return outTensors;
      };
    } else {
      const { forwardFunc } = kernelParams;
      const saveFunc = (tensors) => {
        if (!isTapeOn) {
          return;
        }
        saved = tensors.map((tensor3) => this.keep(this.clone(tensor3)));
      };
      kernelFunc3 = () => {
        const numDataIdsBefore = this.backend.numDataIds();
        out = this.tidy(() => forwardFunc(this.backend, saveFunc));
        const outs = Array.isArray(out) ? out : [out];
        if (this.shouldCheckForMemLeaks()) {
          this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
        }
        return outs;
      };
    }
    const { inputs, attrs } = kernelParams;
    const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
    let kernelProfile;
    this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
      if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
        outputs = kernelFunc3();
      } else {
        kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc3());
        if (this.ENV.getBool("DEBUG")) {
          this.profiler.logKernelProfile(kernelProfile);
        }
        outputs = kernelProfile.outputs;
      }
    });
    if (isTapeOn) {
      this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
    }
    if (this.state.profiling) {
      this.state.activeProfile.kernels.push({
        name: kernelOrScopeName,
        bytesAdded: this.state.numBytes - startingBytecount,
        totalBytesSnapshot: this.state.numBytes,
        tensorsAdded: this.state.numTensors - startingNumTensors,
        totalTensorsSnapshot: this.state.numTensors,
        inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
        outputShapes: outputs.map((item) => item.shape),
        kernelTimeMs: kernelProfile.timeMs,
        extraInfo: kernelProfile.extraInfo
      });
    }
    return Array.isArray(out) ? outputs : outputs[0];
  }
  saveTensorsForBackwardMode(tensors) {
    const saved = tensors.map((tensor3) => this.keep(this.clone(tensor3)));
    return saved;
  }
  getTensorsForGradient(kernelName, inputs, outputs) {
    const gradConfig = getGradient(kernelName);
    if (gradConfig != null) {
      const inputsToSave = gradConfig.inputsToSave || [];
      const outputsToSave = gradConfig.outputsToSave || [];
      let inputTensorsToSave;
      if (gradConfig.saveAllInputs) {
        assert(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
        inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
      } else {
        inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
      }
      const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);
      return inputTensorsToSave.concat(outputTensorsToSave);
    }
    return [];
  }
  makeTensor(values, shape, dtype, backend3) {
    if (values == null) {
      throw new Error("Values passed to engine.makeTensor() are null");
    }
    dtype = dtype || "float32";
    backend3 = backend3 || this.backend;
    let backendVals = values;
    if (dtype === "string" && isString(values[0])) {
      backendVals = values.map((d) => encodeString(d));
    }
    const dataId = backend3.write(backendVals, shape, dtype);
    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
    this.trackTensor(t, backend3);
    if (dtype === "string") {
      const info = this.state.tensorInfo.get(dataId);
      const newBytes = bytesFromStringArray(backendVals);
      this.state.numBytes += newBytes - info.bytes;
      info.bytes = newBytes;
    }
    return t;
  }
  makeTensorFromDataId(dataId, shape, dtype, backend3) {
    dtype = dtype || "float32";
    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
    this.trackTensor(t, backend3);
    return t;
  }
  makeVariable(initialValue, trainable = true, name, dtype) {
    name = name || this.nextVariableId().toString();
    if (dtype != null && dtype !== initialValue.dtype) {
      initialValue = initialValue.cast(dtype);
    }
    const v = new Variable(initialValue, trainable, name, this.nextTensorId());
    if (this.state.registeredVariables[v.name] != null) {
      throw new Error(`Variable with name ${v.name} was already registered`);
    }
    this.state.registeredVariables[v.name] = v;
    this.incRef(v, this.backend);
    return v;
  }
  trackTensor(a, backend3) {
    this.state.numTensors++;
    if (a.dtype === "string") {
      this.state.numStringTensors++;
    }
    let bytes = 0;
    if (a.dtype !== "complex64" && a.dtype !== "string") {
      bytes = a.size * bytesPerElement(a.dtype);
    }
    this.state.numBytes += bytes;
    if (!this.state.tensorInfo.has(a.dataId)) {
      this.state.numDataBuffers++;
      this.state.tensorInfo.set(a.dataId, {
        backend: backend3 || this.backend,
        dtype: a.dtype,
        shape: a.shape,
        bytes
      });
    }
    if (!(a instanceof Variable)) {
      this.track(a);
    }
  }
  incRef(a, backend3) {
    this.trackTensor(a, backend3);
    this.backend.incRef(a.dataId);
  }
  removeDataId(dataId, backend3) {
    if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend3) {
      this.state.tensorInfo.delete(dataId);
      this.state.numDataBuffers--;
    }
  }
  disposeTensor(a) {
    if (!this.state.tensorInfo.has(a.dataId)) {
      return;
    }
    const info = this.state.tensorInfo.get(a.dataId);
    this.state.numTensors--;
    if (a.dtype === "string") {
      this.state.numStringTensors--;
      this.state.numBytes -= info.bytes;
    }
    if (a.dtype !== "complex64" && a.dtype !== "string") {
      const bytes = a.size * bytesPerElement(a.dtype);
      this.state.numBytes -= bytes;
    }
    if (info.backend.disposeData(a.dataId)) {
      this.removeDataId(a.dataId, info.backend);
    }
  }
  disposeVariables() {
    for (const varName in this.state.registeredVariables) {
      const v = this.state.registeredVariables[varName];
      this.disposeVariable(v);
    }
  }
  disposeVariable(v) {
    this.disposeTensor(v);
    if (this.state.registeredVariables[v.name] != null) {
      delete this.state.registeredVariables[v.name];
    }
  }
  memory() {
    const info = this.backend.memory();
    info.numTensors = this.state.numTensors;
    info.numDataBuffers = this.state.numDataBuffers;
    info.numBytes = this.state.numBytes;
    if (this.state.numStringTensors > 0) {
      info.unreliable = true;
      if (info.reasons == null) {
        info.reasons = [];
      }
      info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
    }
    return info;
  }
  async profile(query) {
    this.state.profiling = true;
    const startBytes = this.state.numBytes;
    const startNumTensors = this.state.numTensors;
    this.state.activeProfile.kernels = [];
    this.state.activeProfile.result = await query();
    this.state.profiling = false;
    this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
    this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
    this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
    for (const kernel of this.state.activeProfile.kernels) {
      kernel.kernelTimeMs = await kernel.kernelTimeMs;
      kernel.extraInfo = await kernel.extraInfo;
    }
    return this.state.activeProfile;
  }
  isTapeOn() {
    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
  }
  addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
    const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
    const gradConfig = getGradient(kernelName);
    if (gradConfig != null) {
      gradientsFunc = gradConfig.gradFunc;
    }
    if (gradientsFunc != null) {
      tapeNode.gradient = (dys) => {
        dys = dys.map((dy, i) => {
          if (dy == null) {
            const output = outputs[i];
            const vals = makeZerosTypedArray(output.size, output.dtype);
            return this.makeTensor(vals, output.shape, output.dtype);
          }
          return dy;
        });
        return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
      };
    }
    this.state.activeTape.push(tapeNode);
  }
  keep(result) {
    result.kept = true;
    return result;
  }
  startTape() {
    if (this.state.gradientDepth === 0) {
      this.state.activeTape = [];
    }
    this.state.gradientDepth++;
  }
  endTape() {
    this.state.gradientDepth--;
  }
  startScope(name) {
    const scopeInfo = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    if (name) {
      scopeInfo.name = name;
    }
    this.state.scopeStack.push(scopeInfo);
    this.state.activeScope = scopeInfo;
  }
  endScope(result) {
    const tensorsToTrackInParent = getTensorsInContainer(result);
    const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t) => t.id));
    for (let i = 0; i < this.state.activeScope.track.length; i++) {
      const tensor3 = this.state.activeScope.track[i];
      if (!tensor3.kept && !tensorsToTrackInParentSet.has(tensor3.id)) {
        tensor3.dispose();
      }
    }
    const oldScope = this.state.scopeStack.pop();
    this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
    tensorsToTrackInParent.forEach((tensor3) => {
      if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
        this.track(tensor3);
      }
    });
  }
  gradients(f, xs, dy, allowNoGradients = false) {
    assert(xs.length > 0, () => "gradients() received an empty list of xs.");
    if (dy != null && dy.dtype !== "float32") {
      throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
    }
    const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
    assert(y instanceof Tensor, () => "The result y returned by f() must be a tensor.");
    const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
    if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
      throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    }
    return this.tidy("backward", () => {
      const accumulatedGradientMap = {};
      accumulatedGradientMap[y.id] = dy == null ? ones(y.shape) : dy;
      backpropagateGradients(accumulatedGradientMap, filteredTape, (f2) => this.tidy(f2), add);
      const grads3 = xs.map((x) => accumulatedGradientMap[x.id]);
      if (this.state.gradientDepth === 0) {
        this.state.activeTape.forEach((node) => {
          for (const tensor3 of node.saved) {
            tensor3.dispose();
          }
        });
        this.state.activeTape = null;
      }
      return { value: y, grads: grads3 };
    });
  }
  customGrad(f) {
    assert(isFunction(f), () => "The f passed in customGrad(f) must be a function.");
    return (...inputs) => {
      assert(inputs.every((t) => t instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      let res;
      const inputMap = {};
      inputs.forEach((input2, i) => {
        inputMap[i] = input2;
      });
      const forwardFunc = (_, save) => {
        res = f(...[...inputs, save]);
        assert(res.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
        assert(isFunction(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
        return res.value;
      };
      const backwardsFunc = (dy, saved) => {
        const gradRes = res.gradFunc(dy, saved);
        const grads3 = Array.isArray(gradRes) ? gradRes : [gradRes];
        assert(grads3.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
        assert(grads3.every((t) => t instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
        const gradMap = {};
        grads3.forEach((grad3, i) => {
          gradMap[i] = () => grad3;
        });
        return gradMap;
      };
      return this.runKernelFunc({
        forwardFunc,
        backwardsFunc,
        inputs: inputMap
      });
    };
  }
  readSync(dataId) {
    const info = this.state.tensorInfo.get(dataId);
    return info.backend.readSync(dataId);
  }
  read(dataId) {
    const info = this.state.tensorInfo.get(dataId);
    return info.backend.read(dataId);
  }
  async time(query) {
    const start = now();
    const timingInfo = await this.backend.time(query);
    timingInfo.wallMs = now() - start;
    return timingInfo;
  }
  track(result) {
    if (this.state.activeScope != null) {
      result.scopeId = this.state.activeScope.id;
      this.state.activeScope.track.push(result);
    }
    return result;
  }
  get registeredVariables() {
    return this.state.registeredVariables;
  }
  reset() {
    this.pendingBackendInitId++;
    this.state.dispose();
    this.ENV.reset();
    this.state = new EngineState();
    for (const backendName in this.registry) {
      this.disposeRegisteredKernels(backendName);
      this.registry[backendName].dispose();
      delete this.registry[backendName];
    }
    this.backendName = null;
    this.backendInstance = null;
    this.pendingBackendInit = null;
  }
};
var Engine = _Engine;
Engine.nextTensorId = 0;
Engine.nextVariableId = 0;
function ones(shape) {
  const values = makeOnesTypedArray(sizeFromShape(shape), "float32");
  return ENGINE.makeTensor(values, shape, "float32");
}
function getOrMakeEngine() {
  const ns = getGlobalNamespace();
  if (ns._tfengine == null) {
    const environment = new Environment(ns);
    ns._tfengine = new Engine(environment);
  }
  setEnvironmentGlobal(ns._tfengine.ENV);
  setTensorTracker(() => ns._tfengine);
  return ns._tfengine;
}
var ENGINE = getOrMakeEngine();
function add(a, b) {
  const inputs = { a, b };
  return ENGINE.runKernel(Add, inputs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/device_util.ts
var device_util_exports = {};
__export(device_util_exports, {
  isBrowser: () => isBrowser,
  isMobile: () => isMobile
});
function _isNavigatorDefined() {
  return typeof navigator !== "undefined" && navigator != null;
}
function isMobile(nav) {
  if (nav || _isNavigatorDefined()) {
    if (!nav) {
      nav = navigator;
    }
    if (nav.product === "ReactNative") {
      return true;
    }
    const a = nav.userAgent || nav.vendor || window.opera;
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
  }
  return false;
}
function isBrowser() {
  return typeof window !== "undefined" && window.document != null || typeof WorkerGlobalScope !== "undefined";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/flags.ts
var ENV2 = env();
ENV2.registerFlag("DEBUG", () => false, (debugValue) => {
  if (debugValue) {
    console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
  }
});
ENV2.registerFlag("IS_BROWSER", () => isBrowser());
ENV2.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
ENV2.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
ENV2.registerFlag("PROD", () => false);
ENV2.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV2.getBool("DEBUG"));
ENV2.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
ENV2.registerFlag("IS_TEST", () => false);
ENV2.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
ENV2.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/tensor_util_env.ts
function inferShape(val, dtype) {
  let firstElem = val;
  if (isTypedArray(val)) {
    return dtype === "string" ? [] : [val.length];
  }
  if (!Array.isArray(val)) {
    return [];
  }
  const shape = [];
  while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
    shape.push(firstElem.length);
    firstElem = firstElem[0];
  }
  if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
    deepAssertShapeConsistency(val, shape, []);
  }
  return shape;
}
function deepAssertShapeConsistency(val, shape, indices) {
  indices = indices || [];
  if (!Array.isArray(val) && !isTypedArray(val)) {
    assert(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
    return;
  }
  assert(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
  assert(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
  const subShape = shape.slice(1);
  for (let i = 0; i < val.length; ++i) {
    deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
  }
}
function assertDtype(expectedDtype, actualDType, argName, functionName) {
  if (expectedDtype === "string_or_numeric") {
    return;
  }
  if (expectedDtype == null) {
    throw new Error(`Expected dtype cannot be null.`);
  }
  if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
  }
}
function convertToTensor(x, argName, functionName, parseAsDtype = "numeric") {
  if (x instanceof Tensor) {
    assertDtype(parseAsDtype, x.dtype, argName, functionName);
    return x;
  }
  let inferredDtype = inferDtype(x);
  if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
    inferredDtype = parseAsDtype;
  }
  assertDtype(parseAsDtype, inferredDtype, argName, functionName);
  if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
    const type = x == null ? "null" : x.constructor.name;
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
  }
  const inferredShape = inferShape(x, inferredDtype);
  if (!isTypedArray(x) && !Array.isArray(x)) {
    x = [x];
  }
  const skipTypedArray = true;
  const values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
  return ENGINE.makeTensor(values, inferredShape, inferredDtype);
}
function convertToTensorArray(arg, argName, functionName, parseAsDtype = "numeric") {
  if (!Array.isArray(arg)) {
    throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
  }
  const tensors = arg;
  return tensors.map((t, i) => convertToTensor(t, `${argName}[${i}]`, functionName, parseAsDtype));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/operation.ts
var OP_SCOPE_SUFFIX = "__op";
function op(f) {
  const keys = Object.keys(f);
  if (keys.length !== 1) {
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
  }
  let opName = keys[0];
  const fn = f[opName];
  if (opName.endsWith("_")) {
    opName = opName.substring(0, opName.length - 1);
  }
  opName = opName + OP_SCOPE_SUFFIX;
  const f2 = (...args) => {
    ENGINE.startScope(opName);
    try {
      const result = fn(...args);
      if (isPromise(result)) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      ENGINE.endScope(result);
      return result;
    } catch (ex) {
      ENGINE.endScope(null);
      throw ex;
    }
  };
  Object.defineProperty(f2, "name", { value: opName, configurable: true });
  return f2;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/complex.ts
function complex_(real6, imag5) {
  const $real = convertToTensor(real6, "real", "complex");
  const $imag = convertToTensor(imag5, "imag", "complex");
  assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
  const inputs = { real: $real, imag: $imag };
  return ENGINE.runKernel(Complex, inputs);
}
var complex = op({ complex_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor_ops_util.ts
function makeTensor(values, shape, inferredShape, dtype) {
  if (dtype == null) {
    dtype = inferDtype(values);
  }
  if (dtype === "complex64") {
    throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
  }
  if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  }
  if (shape != null) {
    assertNonNegativeIntegerDimensions(shape);
    const providedSize = sizeFromShape(shape);
    const inferredSize = sizeFromShape(inferredShape);
    assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
    for (let i = 0; i < inferredShape.length; ++i) {
      const inferred = inferredShape[i];
      const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
      assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
    }
  }
  if (!isTypedArray(values) && !Array.isArray(values)) {
    values = [values];
  }
  shape = shape || inferredShape;
  values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
  return ENGINE.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor.ts
function tensor(values, shape, dtype) {
  const inferredShape = inferShape(values, dtype);
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/types.ts
var DTYPE_VALUE_SIZE_MAP = {
  "float32": 4,
  "float16": 2,
  "int32": 4,
  "uint16": 2,
  "uint8": 1,
  "bool": 1,
  "complex64": 8
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/io_utils.ts
var NUM_BYTES_STRING_LENGTH = 4;
async function encodeWeights(tensors, group) {
  const specs = [];
  const dataPromises = [];
  const names = Array.isArray(tensors) ? tensors.map((tensor3) => tensor3.name) : Object.keys(tensors);
  for (let i = 0; i < names.length; ++i) {
    const name = names[i];
    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
    if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);
    }
    const spec = { name, shape: t.shape, dtype: t.dtype };
    if (t.dtype === "string") {
      const utf8bytes = new Promise(async (resolve) => {
        const vals = await t.bytes();
        const totalNumBytes = vals.reduce((p2, c) => p2 + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
        const bytes = new Uint8Array(totalNumBytes);
        let offset = 0;
        for (let i2 = 0; i2 < vals.length; i2++) {
          const val = vals[i2];
          const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
          bytes.set(bytesOfLength, offset);
          offset += NUM_BYTES_STRING_LENGTH;
          bytes.set(val, offset);
          offset += val.length;
        }
        resolve(bytes);
      });
      dataPromises.push(utf8bytes);
    } else {
      dataPromises.push(t.data());
    }
    if (group != null) {
      spec.group = group;
    }
    specs.push(spec);
  }
  const tensorValues = await Promise.all(dataPromises);
  return { data: concatenateTypedArrays(tensorValues), specs };
}
function decodeWeights(buffer3, specs) {
  const out = {};
  let float16Decode;
  let offset = 0;
  for (const spec of specs) {
    const name = spec.name;
    const dtype = spec.dtype;
    const shape = spec.shape;
    const size = sizeFromShape(shape);
    let values;
    if ("quantization" in spec) {
      const quantization = spec.quantization;
      if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
        if (!("min" in quantization && "scale" in quantization)) {
          throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
        }
      } else if (quantization.dtype === "float16") {
        if (dtype !== "float32") {
          throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
        }
      } else {
        throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
      }
      const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
      const byteBuffer = buffer3.slice(offset, offset + size * quantizationSizeFactor);
      const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
      if (dtype === "float32") {
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          values = new Float32Array(quantizedArray.length);
          for (let i = 0; i < quantizedArray.length; i++) {
            const v = quantizedArray[i];
            values[i] = v * quantization.scale + quantization.min;
          }
        } else if (quantization.dtype === "float16") {
          if (float16Decode === void 0) {
            float16Decode = getFloat16Decoder();
          }
          values = float16Decode(quantizedArray);
        } else {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
        }
      } else if (dtype === "int32") {
        if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
        }
        values = new Int32Array(quantizedArray.length);
        for (let i = 0; i < quantizedArray.length; i++) {
          const v = quantizedArray[i];
          values[i] = Math.round(v * quantization.scale + quantization.min);
        }
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * quantizationSizeFactor;
    } else if (dtype === "string") {
      const size2 = sizeFromShape(spec.shape);
      values = [];
      for (let i = 0; i < size2; i++) {
        const byteLength = new Uint32Array(buffer3.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
        offset += NUM_BYTES_STRING_LENGTH;
        const bytes = new Uint8Array(buffer3.slice(offset, offset + byteLength));
        values.push(bytes);
        offset += byteLength;
      }
    } else {
      const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
      const byteBuffer = buffer3.slice(offset, offset + size * dtypeFactor);
      if (dtype === "float32") {
        values = new Float32Array(byteBuffer);
      } else if (dtype === "int32") {
        values = new Int32Array(byteBuffer);
      } else if (dtype === "bool") {
        values = new Uint8Array(byteBuffer);
      } else if (dtype === "complex64") {
        values = new Float32Array(byteBuffer);
        const real6 = new Float32Array(values.length / 2);
        const image4 = new Float32Array(values.length / 2);
        for (let i = 0; i < real6.length; i++) {
          real6[i] = values[i * 2];
          image4[i] = values[i * 2 + 1];
        }
        const realTensor = tensor(real6, shape, "float32");
        const imageTensor = tensor(image4, shape, "float32");
        out[name] = complex(realTensor, imageTensor);
        realTensor.dispose();
        imageTensor.dispose();
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * dtypeFactor;
    }
    if (dtype !== "complex64") {
      out[name] = tensor(values, shape, dtype);
    }
  }
  return out;
}
function concatenateTypedArrays(xs) {
  if (xs === null) {
    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
  }
  let totalByteLength = 0;
  const normalizedXs = [];
  xs.forEach((x) => {
    totalByteLength += x.byteLength;
    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
    }
  });
  const y = new Uint8Array(totalByteLength);
  let offset = 0;
  normalizedXs.forEach((x) => {
    y.set(new Uint8Array(x.buffer), offset);
    offset += x.byteLength;
  });
  return y.buffer;
}
var useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
function stringByteLength(str) {
  if (useNodeBuffer) {
    return Buffer.byteLength(str);
  }
  return new Blob([str]).size;
}
function arrayBufferToBase64String(buffer3) {
  if (useNodeBuffer) {
    return Buffer.from(buffer3).toString("base64");
  }
  const buf = new Uint8Array(buffer3);
  let s = "";
  for (let i = 0, l = buf.length; i < l; i++) {
    s += String.fromCharCode(buf[i]);
  }
  return btoa(s);
}
function base64StringToArrayBuffer(str) {
  if (useNodeBuffer) {
    const buf = Buffer.from(str, "base64");
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
  }
  const s = atob(str);
  const buffer3 = new Uint8Array(s.length);
  for (let i = 0; i < s.length; ++i) {
    buffer3.set([s.charCodeAt(i)], i);
  }
  return buffer3.buffer;
}
function concatenateArrayBuffers(buffers) {
  if (buffers.length === 1) {
    return buffers[0];
  }
  let totalByteLength = 0;
  buffers.forEach((buffer3) => {
    totalByteLength += buffer3.byteLength;
  });
  const temp = new Uint8Array(totalByteLength);
  let offset = 0;
  buffers.forEach((buffer3) => {
    temp.set(new Uint8Array(buffer3), offset);
    offset += buffer3.byteLength;
  });
  return temp.buffer;
}
function basename(path) {
  const SEPARATOR = "/";
  path = path.trim();
  while (path.endsWith(SEPARATOR)) {
    path = path.slice(0, path.length - 1);
  }
  const items = path.split(SEPARATOR);
  return items[items.length - 1];
}
function getModelArtifactsInfoForJSON(modelArtifacts) {
  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  }
  return {
    dateSaved: new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
    weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
  };
}
function computeFloat16MantisaTable() {
  const convertMantissa = (i) => {
    let m = i << 13;
    let e = 0;
    while ((m & 8388608) === 0) {
      e -= 8388608;
      m <<= 1;
    }
    m &= ~8388608;
    e += 947912704;
    return m | e;
  };
  const mantisaTable = new Uint32Array(2048);
  mantisaTable[0] = 0;
  for (let i = 1; i < 1024; i++) {
    mantisaTable[i] = convertMantissa(i);
  }
  for (let i = 1024; i < 2048; i++) {
    mantisaTable[i] = 939524096 + (i - 1024 << 13);
  }
  return mantisaTable;
}
function computeFloat16ExponentTable() {
  const exponentTable = new Uint32Array(64);
  exponentTable[0] = 0;
  exponentTable[31] = 1199570944;
  exponentTable[32] = 2147483648;
  exponentTable[63] = 3347054592;
  for (let i = 1; i < 31; i++) {
    exponentTable[i] = i << 23;
  }
  for (let i = 33; i < 63; i++) {
    exponentTable[i] = 2147483648 + (i - 32 << 23);
  }
  return exponentTable;
}
function computeFloat16OffsetTable() {
  const offsetTable = new Uint32Array(64);
  for (let i = 0; i < 64; i++) {
    offsetTable[i] = 1024;
  }
  offsetTable[0] = offsetTable[32] = 0;
  return offsetTable;
}
function getFloat16Decoder() {
  const mantisaTable = computeFloat16MantisaTable();
  const exponentTable = computeFloat16ExponentTable();
  const offsetTable = computeFloat16OffsetTable();
  return (quantizedArray) => {
    const buffer3 = new ArrayBuffer(4 * quantizedArray.length);
    const bufferUint32View = new Uint32Array(buffer3);
    for (let index = 0; index < quantizedArray.length; index++) {
      const float16Bits = quantizedArray[index];
      const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
      bufferUint32View[index] = float32Bits;
    }
    return new Float32Array(buffer3);
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/router_registry.ts
var IORouterRegistry = class {
  constructor() {
    this.saveRouters = [];
    this.loadRouters = [];
  }
  static getInstance() {
    if (IORouterRegistry.instance == null) {
      IORouterRegistry.instance = new IORouterRegistry();
    }
    return IORouterRegistry.instance;
  }
  static registerSaveRouter(saveRouter) {
    IORouterRegistry.getInstance().saveRouters.push(saveRouter);
  }
  static registerLoadRouter(loadRouter) {
    IORouterRegistry.getInstance().loadRouters.push(loadRouter);
  }
  static getSaveHandlers(url) {
    return IORouterRegistry.getHandlers(url, "save");
  }
  static getLoadHandlers(url, loadOptions) {
    return IORouterRegistry.getHandlers(url, "load", loadOptions);
  }
  static getHandlers(url, handlerType, loadOptions) {
    const validHandlers = [];
    const routers = handlerType === "load" ? IORouterRegistry.getInstance().loadRouters : IORouterRegistry.getInstance().saveRouters;
    routers.forEach((router) => {
      const handler = router(url, loadOptions);
      if (handler !== null) {
        validHandlers.push(handler);
      }
    });
    return validHandlers;
  }
};
var registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);
var registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);
var getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);
var getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/indexed_db.ts
var DATABASE_NAME = "tensorflowjs";
var DATABASE_VERSION = 1;
var MODEL_STORE_NAME = "models_store";
var INFO_STORE_NAME = "model_info_store";
function getIndexedDBFactory() {
  if (!env().getBool("IS_BROWSER")) {
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  }
  const theWindow = typeof window === "undefined" ? self : window;
  const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
  if (factory == null) {
    throw new Error("The current browser does not appear to support IndexedDB.");
  }
  return factory;
}
function setUpDatabase(openRequest) {
  const db = openRequest.result;
  db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
  db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
}
var BrowserIndexedDB = class {
  constructor(modelPath) {
    this.indexedDB = getIndexedDBFactory();
    if (modelPath == null || !modelPath) {
      throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    }
    this.modelPath = modelPath;
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    }
    return this.databaseAction(this.modelPath, modelArtifacts);
  }
  async load() {
    return this.databaseAction(this.modelPath);
  }
  databaseAction(modelPath, modelArtifacts) {
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
      openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        if (modelArtifacts == null) {
          const modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
          const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
          const getRequest = modelStore.get(this.modelPath);
          getRequest.onsuccess = () => {
            if (getRequest.result == null) {
              db.close();
              return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
            } else {
              resolve(getRequest.result.modelArtifacts);
            }
          };
          getRequest.onerror = (error) => {
            db.close();
            return reject(getRequest.error);
          };
          modelTx.oncomplete = () => db.close();
        } else {
          const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
          const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
          let infoStore = infoTx.objectStore(INFO_STORE_NAME);
          const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });
          let modelTx;
          putInfoRequest.onsuccess = () => {
            modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
            const putModelRequest = modelStore.put({
              modelPath: this.modelPath,
              modelArtifacts,
              modelArtifactsInfo
            });
            putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });
            putModelRequest.onerror = (error) => {
              infoStore = infoTx.objectStore(INFO_STORE_NAME);
              const deleteInfoRequest = infoStore.delete(this.modelPath);
              deleteInfoRequest.onsuccess = () => {
                db.close();
                return reject(putModelRequest.error);
              };
              deleteInfoRequest.onerror = (error2) => {
                db.close();
                return reject(putModelRequest.error);
              };
            };
          };
          putInfoRequest.onerror = (error) => {
            db.close();
            return reject(putInfoRequest.error);
          };
          infoTx.oncomplete = () => {
            if (modelTx == null) {
              db.close();
            } else {
              modelTx.oncomplete = () => db.close();
            }
          };
        }
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
};
BrowserIndexedDB.URL_SCHEME = "indexeddb://";
var indexedDBRouter = (url) => {
  if (!env().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
      return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry.registerSaveRouter(indexedDBRouter);
IORouterRegistry.registerLoadRouter(indexedDBRouter);
function browserIndexedDB(modelPath) {
  return new BrowserIndexedDB(modelPath);
}
function maybeStripScheme(key) {
  return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
}
var BrowserIndexedDBManager = class {
  constructor() {
    this.indexedDB = getIndexedDBFactory();
  }
  async listModels() {
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
      openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        const tx = db.transaction(INFO_STORE_NAME, "readonly");
        const store = tx.objectStore(INFO_STORE_NAME);
        const getAllInfoRequest = store.getAll();
        getAllInfoRequest.onsuccess = () => {
          const out = {};
          for (const item of getAllInfoRequest.result) {
            out[item.modelPath] = item.modelArtifactsInfo;
          }
          resolve(out);
        };
        getAllInfoRequest.onerror = (error) => {
          db.close();
          return reject(getAllInfoRequest.error);
        };
        tx.oncomplete = () => db.close();
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
  async removeModel(path) {
    path = maybeStripScheme(path);
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
      openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
        const infoStore = infoTx.objectStore(INFO_STORE_NAME);
        const getInfoRequest = infoStore.get(path);
        let modelTx;
        getInfoRequest.onsuccess = () => {
          if (getInfoRequest.result == null) {
            db.close();
            return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
          } else {
            const deleteInfoRequest = infoStore.delete(path);
            const deleteModelData = () => {
              modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
              const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
              const deleteModelRequest = modelStore.delete(path);
              deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
              deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
            };
            deleteInfoRequest.onsuccess = deleteModelData;
            deleteInfoRequest.onerror = (error) => {
              deleteModelData();
              db.close();
              return reject(getInfoRequest.error);
            };
          }
        };
        getInfoRequest.onerror = (error) => {
          db.close();
          return reject(getInfoRequest.error);
        };
        infoTx.oncomplete = () => {
          if (modelTx == null) {
            db.close();
          } else {
            modelTx.oncomplete = () => db.close();
          }
        };
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/local_storage.ts
var PATH_SEPARATOR = "/";
var PATH_PREFIX = "tensorflowjs_models";
var INFO_SUFFIX = "info";
var MODEL_TOPOLOGY_SUFFIX = "model_topology";
var WEIGHT_SPECS_SUFFIX = "weight_specs";
var WEIGHT_DATA_SUFFIX = "weight_data";
var MODEL_METADATA_SUFFIX = "model_metadata";
function getModelKeys(path) {
  return {
    info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
    topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
    weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
    weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
    modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
  };
}
function getModelPathFromKey(key) {
  const items = key.split(PATH_SEPARATOR);
  if (items.length < 3) {
    throw new Error(`Invalid key format: ${key}`);
  }
  return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
}
function maybeStripScheme2(key) {
  return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
}
var BrowserLocalStorage = class {
  constructor(modelPath) {
    if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
      throw new Error("The current environment does not support local storage.");
    }
    this.LS = window.localStorage;
    if (modelPath == null || !modelPath) {
      throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    }
    this.modelPath = modelPath;
    this.keys = getModelKeys(this.modelPath);
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    } else {
      const topology = JSON.stringify(modelArtifacts.modelTopology);
      const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
      const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
      try {
        this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
        this.LS.setItem(this.keys.topology, topology);
        this.LS.setItem(this.keys.weightSpecs, weightSpecs);
        this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));
        const result = {
          format: modelArtifacts.format,
          generatedBy: modelArtifacts.generatedBy,
          convertedBy: modelArtifacts.convertedBy
        };
        if (modelArtifacts.signature != null) {
          result.signature = modelArtifacts.signature;
        }
        if (modelArtifacts.userDefinedMetadata != null) {
          result.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
        }
        if (modelArtifacts.modelInitializer != null) {
          result.modelInitializer = modelArtifacts.modelInitializer;
        }
        this.LS.setItem(this.keys.modelMetadata, JSON.stringify(result));
        return { modelArtifactsInfo };
      } catch (err) {
        this.LS.removeItem(this.keys.info);
        this.LS.removeItem(this.keys.topology);
        this.LS.removeItem(this.keys.weightSpecs);
        this.LS.removeItem(this.keys.weightData);
        this.LS.removeItem(this.keys.modelMetadata);
        throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
      }
    }
  }
  async load() {
    const info = JSON.parse(this.LS.getItem(this.keys.info));
    if (info == null) {
      throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
    }
    if (info.modelTopologyType !== "JSON") {
      throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
    }
    const out = {};
    const topology = JSON.parse(this.LS.getItem(this.keys.topology));
    if (topology == null) {
      throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
    }
    out.modelTopology = topology;
    const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
    if (weightSpecs == null) {
      throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
    }
    out.weightSpecs = weightSpecs;
    const metadataString = this.LS.getItem(this.keys.modelMetadata);
    if (metadataString != null) {
      const metadata = JSON.parse(metadataString);
      out.format = metadata["format"];
      out.generatedBy = metadata["generatedBy"];
      out.convertedBy = metadata["convertedBy"];
      if (metadata["signature"] != null) {
        out.signature = metadata["signature"];
      }
      if (metadata["userDefinedMetadata"] != null) {
        out.userDefinedMetadata = metadata["userDefinedMetadata"];
      }
      if (metadata["modelInitializer"] != null) {
        out.modelInitializer = metadata["modelInitializer"];
      }
    }
    const weightDataBase64 = this.LS.getItem(this.keys.weightData);
    if (weightDataBase64 == null) {
      throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
    }
    out.weightData = base64StringToArrayBuffer(weightDataBase64);
    return out;
  }
};
BrowserLocalStorage.URL_SCHEME = "localstorage://";
var localStorageRouter = (url) => {
  if (!env().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
      return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry.registerSaveRouter(localStorageRouter);
IORouterRegistry.registerLoadRouter(localStorageRouter);
function browserLocalStorage(modelPath) {
  return new BrowserLocalStorage(modelPath);
}
var BrowserLocalStorageManager = class {
  constructor() {
    assert(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
    assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
    this.LS = window.localStorage;
  }
  async listModels() {
    const out = {};
    const prefix = PATH_PREFIX + PATH_SEPARATOR;
    const suffix = PATH_SEPARATOR + INFO_SUFFIX;
    for (let i = 0; i < this.LS.length; ++i) {
      const key = this.LS.key(i);
      if (key.startsWith(prefix) && key.endsWith(suffix)) {
        const modelPath = getModelPathFromKey(key);
        out[modelPath] = JSON.parse(this.LS.getItem(key));
      }
    }
    return out;
  }
  async removeModel(path) {
    path = maybeStripScheme2(path);
    const keys = getModelKeys(path);
    if (this.LS.getItem(keys.info) == null) {
      throw new Error(`Cannot find model at path '${path}'`);
    }
    const info = JSON.parse(this.LS.getItem(keys.info));
    this.LS.removeItem(keys.info);
    this.LS.removeItem(keys.topology);
    this.LS.removeItem(keys.weightSpecs);
    this.LS.removeItem(keys.weightData);
    return info;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/model_management.ts
var URL_SCHEME_SUFFIX = "://";
var ModelStoreManagerRegistry = class {
  constructor() {
    this.managers = {};
  }
  static getInstance() {
    if (ModelStoreManagerRegistry.instance == null) {
      ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();
    }
    return ModelStoreManagerRegistry.instance;
  }
  static registerManager(scheme, manager) {
    assert(scheme != null, () => "scheme must not be undefined or null.");
    if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
      scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
    }
    assert(scheme.length > 0, () => "scheme must not be an empty string.");
    const registry = ModelStoreManagerRegistry.getInstance();
    assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
    registry.managers[scheme] = manager;
  }
  static getManager(scheme) {
    const manager = this.getInstance().managers[scheme];
    if (manager == null) {
      throw new Error(`Cannot find model manager for scheme '${scheme}'`);
    }
    return manager;
  }
  static getSchemes() {
    return Object.keys(this.getInstance().managers);
  }
};
function parseURL(url) {
  if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);
  }
  return {
    scheme: url.split(URL_SCHEME_SUFFIX)[0],
    path: url.split(URL_SCHEME_SUFFIX)[1]
  };
}
async function cloneModelInternal(sourceURL, destURL, deleteSource = false) {
  assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
  const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
  assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
  assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
  const loadHandler = loadHandlers[0];
  const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
  assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
  assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
  const saveHandler = saveHandlers[0];
  const sourceScheme = parseURL(sourceURL).scheme;
  const sourcePath = parseURL(sourceURL).path;
  const sameMedium = sourceScheme === parseURL(sourceURL).scheme;
  const modelArtifacts = await loadHandler.load();
  if (deleteSource && sameMedium) {
    await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
  }
  const saveResult = await saveHandler.save(modelArtifacts);
  if (deleteSource && !sameMedium) {
    await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
  }
  return saveResult.modelArtifactsInfo;
}
async function listModels() {
  const schemes = ModelStoreManagerRegistry.getSchemes();
  const out = {};
  for (const scheme of schemes) {
    const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();
    for (const path in schemeOut) {
      const url = scheme + URL_SCHEME_SUFFIX + path;
      out[url] = schemeOut[path];
    }
  }
  return out;
}
async function removeModel(url) {
  const schemeAndPath = parseURL(url);
  const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
  return manager.removeModel(schemeAndPath.path);
}
async function copyModel(sourceURL, destURL) {
  const deleteSource = false;
  return cloneModelInternal(sourceURL, destURL, deleteSource);
}
async function moveModel(sourceURL, destURL) {
  const deleteSource = true;
  return cloneModelInternal(sourceURL, destURL, deleteSource);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/platforms/platform_browser.ts
var PlatformBrowser = class {
  fetch(path, init2) {
    return fetch(path, init2);
  }
  now() {
    return performance.now();
  }
  encode(text, encoding) {
    if (encoding !== "utf-8" && encoding !== "utf8") {
      throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
    }
    if (this.textEncoder == null) {
      this.textEncoder = new TextEncoder();
    }
    return this.textEncoder.encode(text);
  }
  decode(bytes, encoding) {
    return new TextDecoder(encoding).decode(bytes);
  }
};
if (env().get("IS_BROWSER")) {
  env().setPlatform("browser", new PlatformBrowser());
  try {
    ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
  } catch (err) {
  }
  try {
    ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
  } catch (err) {
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/platforms/platform_node.ts
var getNodeFetch = {
  importFetch: () => require_browser()
};
var systemFetch;
var PlatformNode = class {
  constructor() {
    this.util = __require("util");
    this.textEncoder = new this.util.TextEncoder();
  }
  fetch(path, requestInits) {
    if (env().global.fetch != null) {
      return env().global.fetch(path, requestInits);
    }
    if (systemFetch == null) {
      systemFetch = getNodeFetch.importFetch();
    }
    return systemFetch(path, requestInits);
  }
  now() {
    const time2 = process.hrtime();
    return time2[0] * 1e3 + time2[1] / 1e6;
  }
  encode(text, encoding) {
    if (encoding !== "utf-8" && encoding !== "utf8") {
      throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
    }
    return this.textEncoder.encode(text);
  }
  decode(bytes, encoding) {
    if (bytes.length === 0) {
      return "";
    }
    return new this.util.TextDecoder(encoding).decode(bytes);
  }
};
if (env().get("IS_NODE")) {
  env().setPlatform("node", new PlatformNode());
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/buffer.ts
function buffer(shape, dtype = "float32", values) {
  dtype = dtype || "float32";
  assertNonNegativeIntegerDimensions(shape);
  return new TensorBuffer(shape, dtype, values);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/cast.ts
function cast_(x, dtype) {
  const $x = convertToTensor(x, "x", "cast");
  if (!isValidDtype(dtype)) {
    throw new Error(`Failed to cast to unknown dtype ${dtype}`);
  }
  if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
    throw new Error("Only strings can be casted to strings");
  }
  const inputs = { x: $x };
  const attrs = { dtype };
  return ENGINE.runKernel(Cast, inputs, attrs);
}
var cast = op({ cast_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/clone.ts
function clone_(x) {
  const $x = convertToTensor(x, "x", "clone", "string_or_numeric");
  const inputs = { x: $x };
  return ENGINE.runKernel(Identity, inputs);
}
var clone = op({ clone_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/print.ts
function print2(x, verbose = false) {
  console.log(x.toString(verbose));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/base_side_effects.ts
getOrMakeEngine();
var opHandler2 = {
  buffer,
  cast,
  clone,
  print: print2
};
setOpHandler(opHandler2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/io.ts
var io_exports = {};
__export(io_exports, {
  browserFiles: () => browserFiles,
  browserHTTPRequest: () => browserHTTPRequest,
  concatenateArrayBuffers: () => concatenateArrayBuffers,
  copyModel: () => copyModel,
  decodeWeights: () => decodeWeights,
  encodeWeights: () => encodeWeights,
  fromMemory: () => fromMemory,
  getLoadHandlers: () => getLoadHandlers,
  getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON,
  getSaveHandlers: () => getSaveHandlers,
  http: () => http,
  isHTTPScheme: () => isHTTPScheme,
  listModels: () => listModels,
  loadWeights: () => loadWeights,
  moveModel: () => moveModel,
  registerLoadRouter: () => registerLoadRouter,
  registerSaveRouter: () => registerSaveRouter,
  removeModel: () => removeModel,
  weightsLoaderFactory: () => weightsLoaderFactory,
  withSaveHandler: () => withSaveHandler
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/browser_files.ts
var DEFAULT_FILE_NAME_PREFIX = "model";
var DEFAULT_JSON_EXTENSION_NAME = ".json";
var DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
function defer(f) {
  return new Promise((resolve) => setTimeout(resolve)).then(f);
}
var _BrowserDownloads = class {
  constructor(fileNamePrefix) {
    if (!env().getBool("IS_BROWSER")) {
      throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    }
    if (fileNamePrefix.startsWith(_BrowserDownloads.URL_SCHEME)) {
      fileNamePrefix = fileNamePrefix.slice(_BrowserDownloads.URL_SCHEME.length);
    }
    if (fileNamePrefix == null || fileNamePrefix.length === 0) {
      fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
    }
    this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
    this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
  }
  async save(modelArtifacts) {
    if (typeof document === "undefined") {
      throw new Error("Browser downloads are not supported in this environment since `document` is not present");
    }
    const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
    } else {
      const weightsManifest = [{
        paths: ["./" + this.weightDataFileName],
        weights: modelArtifacts.weightSpecs
      }];
      const modelTopologyAndWeightManifest = {
        modelTopology: modelArtifacts.modelTopology,
        format: modelArtifacts.format,
        generatedBy: modelArtifacts.generatedBy,
        convertedBy: modelArtifacts.convertedBy,
        weightsManifest
      };
      if (modelArtifacts.signature != null) {
        modelTopologyAndWeightManifest.signature = modelArtifacts.signature;
      }
      if (modelArtifacts.userDefinedMetadata != null) {
        modelTopologyAndWeightManifest.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
      }
      if (modelArtifacts.modelInitializer != null) {
        modelTopologyAndWeightManifest.modelInitializer = modelArtifacts.modelInitializer;
      }
      const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: "application/json" }));
      const jsonAnchor = this.jsonAnchor == null ? document.createElement("a") : this.jsonAnchor;
      jsonAnchor.download = this.modelTopologyFileName;
      jsonAnchor.href = modelTopologyAndWeightManifestURL;
      await defer(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
      if (modelArtifacts.weightData != null) {
        const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
        weightDataAnchor.download = this.weightDataFileName;
        weightDataAnchor.href = weightsURL;
        await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
      }
      return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };
    }
  }
};
var BrowserDownloads = _BrowserDownloads;
BrowserDownloads.URL_SCHEME = "downloads://";
var BrowserFiles = class {
  constructor(files) {
    if (files == null || files.length < 1) {
      throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
    }
    this.files = files;
  }
  async load() {
    const jsonFile = this.files[0];
    const weightFiles = this.files.slice(1);
    return new Promise((resolve, reject) => {
      const jsonReader = new FileReader();
      jsonReader.onload = (event) => {
        const modelJSON = JSON.parse(event.target.result);
        const modelTopology = modelJSON.modelTopology;
        if (modelTopology == null) {
          reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));
          return;
        }
        if (weightFiles.length === 0) {
          resolve({ modelTopology });
        }
        const weightsManifest = modelJSON.weightsManifest;
        if (weightsManifest == null) {
          reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));
          return;
        }
        let pathToFile;
        try {
          pathToFile = this.checkManifestAndWeightFiles(weightsManifest, weightFiles);
        } catch (err) {
          reject(err);
          return;
        }
        const weightSpecs = [];
        const paths = [];
        const perFileBuffers = [];
        weightsManifest.forEach((weightsGroup) => {
          weightsGroup.paths.forEach((path) => {
            paths.push(path);
            perFileBuffers.push(null);
          });
          weightSpecs.push(...weightsGroup.weights);
        });
        weightsManifest.forEach((weightsGroup) => {
          weightsGroup.paths.forEach((path) => {
            const weightFileReader = new FileReader();
            weightFileReader.onload = (event2) => {
              const weightData = event2.target.result;
              const index = paths.indexOf(path);
              perFileBuffers[index] = weightData;
              if (perFileBuffers.indexOf(null) === -1) {
                const result = {
                  modelTopology,
                  weightSpecs,
                  weightData: concatenateArrayBuffers(perFileBuffers),
                  format: modelJSON.format,
                  generatedBy: modelJSON.generatedBy,
                  convertedBy: modelJSON.convertedBy
                };
                if (modelJSON.signature != null) {
                  result.signature = modelJSON.signature;
                }
                if (modelJSON.userDefinedMetadata != null) {
                  result.userDefinedMetadata = modelJSON.userDefinedMetadata;
                }
                if (modelJSON.modelInitializer != null) {
                  result.modelInitializer = modelJSON.modelInitializer;
                }
                resolve(result);
              }
            };
            weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
            weightFileReader.readAsArrayBuffer(pathToFile[path]);
          });
        });
      };
      jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
      jsonReader.readAsText(jsonFile);
    });
  }
  checkManifestAndWeightFiles(manifest, files) {
    const basenames = [];
    const fileNames = files.map((file) => basename(file.name));
    const pathToFile = {};
    for (const group of manifest) {
      group.paths.forEach((path) => {
        const pathBasename = basename(path);
        if (basenames.indexOf(pathBasename) !== -1) {
          throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
        }
        basenames.push(pathBasename);
        if (fileNames.indexOf(pathBasename) === -1) {
          throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
        } else {
          pathToFile[path] = files[fileNames.indexOf(pathBasename)];
        }
      });
    }
    if (basenames.length !== files.length) {
      throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${files.length}).`);
    }
    return pathToFile;
  }
};
var browserDownloadsRouter = (url) => {
  if (!env().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
      return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
function browserDownloads(fileNamePrefix = "model") {
  return new BrowserDownloads(fileNamePrefix);
}
function browserFiles(files) {
  return new BrowserFiles(files);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/progress.ts
function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
  checkPromises(promises);
  startFraction = startFraction == null ? 0 : startFraction;
  endFraction = endFraction == null ? 1 : endFraction;
  checkFraction(startFraction, endFraction);
  let resolvedPromise = 0;
  const registerMonitor = (promise) => {
    promise.then((value) => {
      const fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
      onProgress(fraction);
      return value;
    });
    return promise;
  };
  function checkPromises(promises2) {
    assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
  }
  function checkFraction(startFraction2, endFraction2) {
    assert(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
    assert(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
    assert(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
  }
  return Promise.all(promises.map(registerMonitor));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/weights_loader.ts
async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
  if (loadOptions == null) {
    loadOptions = {};
  }
  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
  const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));
  const fetchStartFraction = 0;
  const fetchEndFraction = 0.5;
  const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
  const bufferPromises = responses.map((response) => response.arrayBuffer());
  const bufferStartFraction = 0.5;
  const bufferEndFraction = 1;
  const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
  return buffers;
}
async function loadWeights(manifest, filePathPrefix = "", weightNames, requestInit) {
  const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
  const loadWeights3 = weightsLoaderFactory(fetchWeights);
  return loadWeights3(manifest, filePathPrefix, weightNames);
}
function weightsLoaderFactory(fetchWeightsFunction) {
  return async (manifest, filePathPrefix = "", weightNames) => {
    const groupIndicesToFetchMap = manifest.map(() => false);
    const groupWeightsToFetch = {};
    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
    const allManifestWeightNames = [];
    manifest.forEach((manifestGroupConfig, groupIndex) => {
      let groupOffset = 0;
      manifestGroupConfig.weights.forEach((weightsEntry) => {
        const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
        const enqueueWeightsForFetchingFn = () => {
          groupIndicesToFetchMap[groupIndex] = true;
          if (groupWeightsToFetch[groupIndex] == null) {
            groupWeightsToFetch[groupIndex] = [];
          }
          groupWeightsToFetch[groupIndex].push({
            manifestEntry: weightsEntry,
            groupOffset,
            sizeBytes: weightsBytes
          });
        };
        if (weightNames != null) {
          weightNames.forEach((weightName, weightIndex) => {
            if (weightName === weightsEntry.name) {
              enqueueWeightsForFetchingFn();
              weightsFound[weightIndex] = true;
            }
          });
        } else {
          enqueueWeightsForFetchingFn();
        }
        allManifestWeightNames.push(weightsEntry.name);
        groupOffset += weightsBytes;
      });
    });
    if (!weightsFound.every((found) => found)) {
      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);
      throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
    }
    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
      if (shouldFetch) {
        accumulator.push(i);
      }
      return accumulator;
    }, []);
    const fetchUrls = [];
    groupIndicesToFetch.forEach((i) => {
      manifest[i].paths.forEach((filepath) => {
        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
        fetchUrls.push(fetchUrl);
      });
    });
    const buffers = await fetchWeightsFunction(fetchUrls);
    const weightsTensorMap = {};
    let bufferIndexOffset = 0;
    groupIndicesToFetch.forEach((i) => {
      const numBuffers = manifest[i].paths.length;
      let groupBytes = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        groupBytes += buffers[bufferIndexOffset + i2].byteLength;
      }
      const groupBuffer = new ArrayBuffer(groupBytes);
      const groupByteBuffer = new Uint8Array(groupBuffer);
      let groupBufferOffset = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        const buffer3 = new Uint8Array(buffers[bufferIndexOffset + i2]);
        groupByteBuffer.set(buffer3, groupBufferOffset);
        groupBufferOffset += buffer3.byteLength;
      }
      const weightsEntries = groupWeightsToFetch[i];
      weightsEntries.forEach((weightsEntry) => {
        const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
        const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
        for (const name in nameToTensorMap) {
          weightsTensorMap[name] = nameToTensorMap[name];
        }
      });
      bufferIndexOffset += numBuffers;
    });
    return weightsTensorMap;
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/http.ts
var OCTET_STREAM_MIME_TYPE = "application/octet-stream";
var JSON_TYPE = "application/json";
var HTTPRequest = class {
  constructor(path, loadOptions) {
    this.DEFAULT_METHOD = "POST";
    if (loadOptions == null) {
      loadOptions = {};
    }
    this.weightPathPrefix = loadOptions.weightPathPrefix;
    this.onProgress = loadOptions.onProgress;
    this.weightUrlConverter = loadOptions.weightUrlConverter;
    if (loadOptions.fetchFunc != null) {
      assert(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
      this.fetch = loadOptions.fetchFunc;
    } else {
      this.fetch = env().platform.fetch;
    }
    assert(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
    if (Array.isArray(path)) {
      assert(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
    }
    this.path = path;
    if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
      throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    }
    this.requestInit = loadOptions.requestInit || {};
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
    }
    const init2 = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
    init2.body = new FormData();
    const weightsManifest = [{
      paths: ["./model.weights.bin"],
      weights: modelArtifacts.weightSpecs
    }];
    const modelTopologyAndWeightManifest = {
      modelTopology: modelArtifacts.modelTopology,
      format: modelArtifacts.format,
      generatedBy: modelArtifacts.generatedBy,
      convertedBy: modelArtifacts.convertedBy,
      weightsManifest
    };
    if (modelArtifacts.signature != null) {
      modelTopologyAndWeightManifest.signature = modelArtifacts.signature;
    }
    if (modelArtifacts.userDefinedMetadata != null) {
      modelTopologyAndWeightManifest.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
    }
    if (modelArtifacts.modelInitializer != null) {
      modelTopologyAndWeightManifest.modelInitializer = modelArtifacts.modelInitializer;
    }
    init2.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
    if (modelArtifacts.weightData != null) {
      init2.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
    }
    const response = await this.fetch(this.path, init2);
    if (response.ok) {
      return {
        modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
        responses: [response]
      };
    } else {
      throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
    }
  }
  async load() {
    const modelConfigRequest = await this.fetch(this.path, this.requestInit);
    if (!modelConfigRequest.ok) {
      throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
    }
    let modelConfig;
    try {
      modelConfig = await modelConfigRequest.json();
    } catch (e) {
      let message = `Failed to parse model JSON of response from ${this.path}.`;
      if (this.path.endsWith(".pb")) {
        message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
      } else {
        message += " Please make sure the server is serving valid JSON for this request.";
      }
      throw new Error(message);
    }
    const modelTopology = modelConfig.modelTopology;
    const weightsManifest = modelConfig.weightsManifest;
    const generatedBy = modelConfig.generatedBy;
    const convertedBy = modelConfig.convertedBy;
    const format = modelConfig.format;
    const signature = modelConfig.signature;
    const userDefinedMetadata = modelConfig.userDefinedMetadata;
    if (modelTopology == null && weightsManifest == null) {
      throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
    }
    let weightSpecs;
    let weightData;
    if (weightsManifest != null) {
      const results = await this.loadWeights(weightsManifest);
      [weightSpecs, weightData] = results;
    }
    const artifacts = {
      modelTopology,
      weightSpecs,
      weightData,
      generatedBy,
      convertedBy,
      format
    };
    if (signature != null) {
      artifacts.signature = signature;
    }
    if (userDefinedMetadata != null) {
      artifacts.userDefinedMetadata = userDefinedMetadata;
    }
    const initializer = modelConfig.modelInitializer;
    if (initializer) {
      artifacts.modelInitializer = initializer;
    }
    return artifacts;
  }
  async loadWeights(weightsManifest) {
    const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
    const [prefix, suffix] = parseUrl(weightPath);
    const pathPrefix = this.weightPathPrefix || prefix;
    const weightSpecs = [];
    for (const entry of weightsManifest) {
      weightSpecs.push(...entry.weights);
    }
    const fetchURLs = [];
    const urlPromises = [];
    for (const weightsGroup of weightsManifest) {
      for (const path of weightsGroup.paths) {
        if (this.weightUrlConverter != null) {
          urlPromises.push(this.weightUrlConverter(path));
        } else {
          fetchURLs.push(pathPrefix + path + suffix);
        }
      }
    }
    if (this.weightUrlConverter) {
      fetchURLs.push(...await Promise.all(urlPromises));
    }
    const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {
      requestInit: this.requestInit,
      fetchFunc: this.fetch,
      onProgress: this.onProgress
    });
    return [weightSpecs, concatenateArrayBuffers(buffers)];
  }
};
HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
function parseUrl(url) {
  const lastSlash = url.lastIndexOf("/");
  const lastSearchParam = url.lastIndexOf("?");
  const prefix = url.substring(0, lastSlash);
  const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
  return [prefix + "/", suffix];
}
function isHTTPScheme(url) {
  return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
}
var httpRouter = (url, loadOptions) => {
  if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
    return null;
  } else {
    let isHTTP = true;
    if (Array.isArray(url)) {
      isHTTP = url.every((urlItem) => isHTTPScheme(urlItem));
    } else {
      isHTTP = isHTTPScheme(url);
    }
    if (isHTTP) {
      return http(url, loadOptions);
    }
  }
  return null;
};
IORouterRegistry.registerSaveRouter(httpRouter);
IORouterRegistry.registerLoadRouter(httpRouter);
function http(path, loadOptions) {
  return new HTTPRequest(path, loadOptions);
}
function browserHTTPRequest(path, loadOptions) {
  return http(path, loadOptions);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/io/passthrough.ts
var PassthroughLoader = class {
  constructor(modelArtifacts) {
    this.modelArtifacts = modelArtifacts;
  }
  async load() {
    return this.modelArtifacts;
  }
};
var PassthroughSaver = class {
  constructor(saveHandler) {
    this.saveHandler = saveHandler;
  }
  async save(modelArtifacts) {
    return this.saveHandler(modelArtifacts);
  }
};
function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  if (arguments.length === 1) {
    const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
    if (isModelArtifacts) {
      return new PassthroughLoader(modelArtifacts);
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader({ modelTopology: modelArtifacts });
    }
  } else {
    console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
    return new PassthroughLoader({
      modelTopology: modelArtifacts,
      weightSpecs,
      weightData,
      trainingConfig
    });
  }
}
function withSaveHandler(saveHandler) {
  return new PassthroughSaver(saveHandler);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/math.ts
var math_exports = {};
__export(math_exports, {
  confusionMatrix: () => confusionMatrix
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/mat_mul.ts
function matMul_(a, b, transposeA = false, transposeB = false) {
  let $a = convertToTensor(a, "a", "matMul");
  let $b = convertToTensor(b, "b", "matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  const attrs = { transposeA, transposeB };
  return ENGINE.runKernel(BatchMatMul, inputs, attrs);
}
var matMul = op({ matMul_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/one_hot.ts
function oneHot_(indices, depth, onValue = 1, offValue = 0) {
  if (depth < 2) {
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
  }
  const $indices = convertToTensor(indices, "indices", "oneHot", "int32");
  const inputs = { indices: $indices };
  const attrs = { depth, onValue, offValue };
  return ENGINE.runKernel(OneHot, inputs, attrs);
}
var oneHot = op({ oneHot_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/transpose.ts
function transpose_(x, perm) {
  const $x = convertToTensor(x, "x", "transpose");
  if (perm == null) {
    perm = $x.shape.map((s, i) => i).reverse();
  }
  assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
  perm.forEach((axis) => {
    assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
  });
  if ($x.rank <= 1) {
    return $x.clone();
  }
  const inputs = { x: $x };
  const attrs = { perm };
  return ENGINE.runKernel(Transpose, inputs, attrs);
}
var transpose = op({ transpose_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/confusion_matrix.ts
function confusionMatrix_(labels, predictions, numClasses) {
  const $labels = convertToTensor(labels, "labels", "confusionMatrix");
  const $predictions = convertToTensor(predictions, "predictions", "confusionMatrix");
  assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), () => `If provided, numClasses must be a positive integer, but got ${numClasses}`);
  assert($labels.rank === 1, () => `Expected the rank of labels to be 1, but got ${$labels.rank}`);
  assert($predictions.rank === 1, () => `Expected the rank of predictions to be 1, but got ${$predictions.rank}`);
  assert($labels.shape[0] === $predictions.shape[0], () => `Mismatch in the number of examples: ${$labels.shape[0]} vs. ${$predictions.shape[0]}. Labels and predictions should have the same number of elements.`);
  assert(numClasses > 0 && Number.isInteger(numClasses), () => `numClasses is required to be a positive integer, but got ${numClasses}`);
  const oneHotLabels = oneHot(cast($labels, "int32"), numClasses);
  const oneHotPredictions = oneHot(cast($predictions, "int32"), numClasses);
  const oneHotLabelsT = transpose(oneHotLabels);
  const product = matMul(oneHotLabelsT, oneHotPredictions);
  return cast(product, "int32");
}
var confusionMatrix = op({ confusionMatrix_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/browser.ts
var browser_exports = {};
__export(browser_exports, {
  fromPixels: () => fromPixels,
  fromPixelsAsync: () => fromPixelsAsync,
  toPixels: () => toPixels
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor3d.ts
function tensor3d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 3) {
    throw new Error("tensor3d() requires shape to have three numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 3 && inferredShape.length !== 1) {
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/browser.ts
var fromPixels2DContext;
function fromPixels_(pixels, numChannels = 3) {
  if (numChannels > 4) {
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  }
  if (pixels == null) {
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  }
  let isPixelData3 = false;
  let isImageData = false;
  let isVideo = false;
  let isImage = false;
  let isCanvasLike = false;
  let isImageBitmap = false;
  if (pixels.data instanceof Uint8Array) {
    isPixelData3 = true;
  } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
    isImageData = true;
  } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
    isVideo = true;
  } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
    isImage = true;
  } else if (pixels.getContext != null) {
    isCanvasLike = true;
  } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
    isImageBitmap = true;
  } else {
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${pixels.constructor.name}`);
  }
  if (isVideo) {
    const HAVE_CURRENT_DATA_READY_STATE = 2;
    if (isVideo && pixels.readyState < HAVE_CURRENT_DATA_READY_STATE) {
      throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.");
    }
  }
  const kernel = getKernel(FromPixels, ENGINE.backendName);
  if (kernel != null) {
    const inputs = { pixels };
    const attrs = { numChannels };
    return ENGINE.runKernel(FromPixels, inputs, attrs);
  }
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  let vals;
  if (isCanvasLike) {
    vals = pixels.getContext("2d").getImageData(0, 0, width, height).data;
  } else if (isImageData || isPixelData3) {
    vals = pixels.data;
  } else if (isImage || isVideo || isImageBitmap) {
    if (fromPixels2DContext == null) {
      fromPixels2DContext = document.createElement("canvas").getContext("2d");
    }
    fromPixels2DContext.canvas.width = width;
    fromPixels2DContext.canvas.height = height;
    fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
    vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
  }
  let values;
  if (numChannels === 4) {
    values = new Int32Array(vals);
  } else {
    const numPixels = width * height;
    values = new Int32Array(numPixels * numChannels);
    for (let i = 0; i < numPixels; i++) {
      for (let channel = 0; channel < numChannels; ++channel) {
        values[i * numChannels + channel] = vals[i * 4 + channel];
      }
    }
  }
  const outShape = [height, width, numChannels];
  return tensor3d(values, outShape, "int32");
}
function isPixelData(pixels) {
  return pixels != null && pixels.data instanceof Uint8Array;
}
function isImageBitmapFullySupported() {
  return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
}
function isNonEmptyPixels(pixels) {
  return pixels != null && pixels.width !== 0 && pixels.height !== 0;
}
function canWrapPixelsToImageBitmap(pixels) {
  return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
}
async function fromPixelsAsync(pixels, numChannels = 3) {
  let inputs = null;
  if (env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)) {
    let imageBitmap;
    try {
      imageBitmap = await createImageBitmap(pixels, { premultiplyAlpha: "none" });
    } catch (e) {
      imageBitmap = null;
    }
    if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
      inputs = imageBitmap;
    } else {
      inputs = pixels;
    }
  } else {
    inputs = pixels;
  }
  return fromPixels_(inputs, numChannels);
}
async function toPixels(img, canvas) {
  let $img = convertToTensor(img, "img", "toPixels");
  if (!(img instanceof Tensor)) {
    const originalImgTensor = $img;
    $img = cast(originalImgTensor, "int32");
    originalImgTensor.dispose();
  }
  if ($img.rank !== 2 && $img.rank !== 3) {
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);
  }
  const [height, width] = $img.shape.slice(0, 2);
  const depth = $img.rank === 2 ? 1 : $img.shape[2];
  if (depth > 4 || depth === 2) {
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${depth}`);
  }
  if ($img.dtype !== "float32" && $img.dtype !== "int32") {
    throw new Error(`Unsupported type for toPixels: ${$img.dtype}. Please use float32 or int32 tensors.`);
  }
  const data = await $img.data();
  const multiplier = $img.dtype === "float32" ? 255 : 1;
  const bytes = new Uint8ClampedArray(width * height * 4);
  for (let i = 0; i < height * width; ++i) {
    const rgba = [0, 0, 0, 255];
    for (let d = 0; d < depth; d++) {
      const value = data[i * depth + d];
      if ($img.dtype === "float32") {
        if (value < 0 || value > 1) {
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`);
        }
      } else if ($img.dtype === "int32") {
        if (value < 0 || value > 255) {
          throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);
        }
      }
      if (depth === 1) {
        rgba[0] = value * multiplier;
        rgba[1] = value * multiplier;
        rgba[2] = value * multiplier;
      } else {
        rgba[d] = value * multiplier;
      }
    }
    const j = i * 4;
    bytes[j + 0] = Math.round(rgba[0]);
    bytes[j + 1] = Math.round(rgba[1]);
    bytes[j + 2] = Math.round(rgba[2]);
    bytes[j + 3] = Math.round(rgba[3]);
  }
  if (canvas != null) {
    canvas.width = width;
    canvas.height = height;
    const ctx = canvas.getContext("2d");
    const imageData = new ImageData(bytes, width, height);
    ctx.putImageData(imageData, 0, 0);
  }
  if ($img !== img) {
    $img.dispose();
  }
  return bytes;
}
var fromPixels = op({ fromPixels_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/gather_nd_util.ts
var gather_nd_util_exports = {};
__export(gather_nd_util_exports, {
  prepareAndValidate: () => prepareAndValidate
});
function prepareAndValidate(tensor3, indices) {
  const tensorRank = tensor3.shape.length;
  const indicesRank = indices.shape.length;
  if (tensorRank < 1) {
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
  }
  if (indicesRank < 1) {
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
  }
  if (indices.shape[indicesRank - 1] > tensorRank) {
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
  }
  if (sizeFromShape(tensor3.shape) === 0) {
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor3.shape}.`);
  }
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  let nResult = 1;
  for (let i = 0; i < indicesShape.length - 1; ++i) {
    nResult *= indicesShape[i];
  }
  const inputShape = tensor3.shape;
  const resultShape = indicesShape.slice();
  resultShape.pop();
  let sliceSize = 1;
  for (let i = sliceRank; i < tensorRank; ++i) {
    sliceSize *= inputShape[i];
    resultShape.push(inputShape[i]);
  }
  const strides = [
    ...computeStrides(tensor3.shape).map((stride) => stride / sliceSize),
    1
  ].slice(0, sliceRank);
  return [resultShape, nResult, sliceSize, strides];
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/scatter_nd_util.ts
var scatter_nd_util_exports = {};
__export(scatter_nd_util_exports, {
  calculateShapes: () => calculateShapes,
  validateInput: () => validateInput,
  validateUpdateShape: () => validateUpdateShape
});
function validateUpdateShape(shape, indices, updates) {
  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
  const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
  if (updates.rank < batchDim) {
    throw new Error(shapeError + ` update.rank < ${batchDim}. `);
  }
  if (shape.length < sliceDim + (updates.rank - batchDim)) {
    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
  }
  if (updates.rank !== batchDim + shape.length - sliceDim) {
    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
  }
  for (let d = 0; d < batchDim; ++d) {
    if (updates.shape[d] !== indices.shape[d]) {
      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
    }
  }
  for (let d = 0; d < updates.rank - batchDim; ++d) {
    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
    }
  }
}
function validateInput(updates, indices, shape) {
  if (indices.rank < 1) {
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
  }
  if (updates.rank < 1) {
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
  }
  if (shape.length < 1) {
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
  }
  if (shape.length === 0) {
    if (indices.size === 0) {
      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
    }
    if (updates.size === 0) {
      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
    }
  }
  validateUpdateShape(shape, indices, updates);
}
function calculateShapes(updates, indices, shape) {
  const indicesRank = indices.shape.length;
  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
  const totalNd = shape.length;
  let sliceSize = 1;
  for (let i = sliceRank; i < totalNd; ++i) {
    sliceSize *= shape[i];
  }
  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];
  const outputSize = sizeFromShape(shape);
  return { sliceRank, numUpdates, sliceSize, strides, outputSize };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice_util.ts
var slice_util_exports = {};
__export(slice_util_exports, {
  assertParamsValid: () => assertParamsValid,
  computeFlatOffset: () => computeFlatOffset,
  computeOutShape: () => computeOutShape,
  getNormalizedAxes: () => getNormalizedAxes,
  isSliceContinous: () => isSliceContinous,
  maskToAxes: () => maskToAxes,
  parseSliceParams: () => parseSliceParams,
  sliceInfo: () => sliceInfo,
  startForAxis: () => startForAxis,
  startIndicesWithElidedDims: () => startIndicesWithElidedDims,
  stopForAxis: () => stopForAxis,
  stopIndicesWithElidedDims: () => stopIndicesWithElidedDims,
  stridesForAxis: () => stridesForAxis,
  stridesWithElidedDims: () => stridesWithElidedDims
});
function assertParamsValid(input2, begin, size) {
  const inputRank = input2.shape.length;
  assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
  assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must match the rank of the array (${inputRank}).`);
  for (let i = 0; i < inputRank; ++i) {
    assert(begin[i] + size[i] <= input2.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size[i]}) would overflow input.shape[${i}] (${input2.shape[i]})`);
  }
}
function maskToAxes(mask) {
  const axes = [];
  let axis = 0;
  while (mask > 0) {
    if (mask & 1) {
      axes.push(axis);
    }
    mask /= 2;
    axis++;
  }
  return axes;
}
function computeOutShape(begin, end, strides) {
  const size = [];
  for (let axis = 0; axis < begin.length; axis++) {
    size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
  }
  return size;
}
function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
  const newStrides = [...strides];
  for (let i = newStrides.length; i < inputShape.length; i++) {
    newStrides.push(1);
  }
  for (let i = 0; i < numElidedAxes; i++) {
    if (i === 0) {
      newStrides[ellipsisInsertionIndex] = 1;
    } else {
      newStrides.splice(ellipsisInsertionIndex, 0, 1);
      newStrides.pop();
    }
  }
  return newStrides;
}
function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
  if (normalizedAxis <= ellipsisInsertionIndex) {
    return normalizedAxis;
  }
  return normalizedAxis - (numElidedAxes - 1);
}
function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
  const elidedAxes = [];
  for (let i = 0; i < numElidedAxes; i++) {
    elidedAxes.push(ellipsisInsertionIndex + i);
  }
  return elidedAxes;
}
function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
  const inputRank = inputShape.length;
  let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
  if (ellipsisAxes.length && numInterpolatedAxes > 0) {
    const fullIndex = ellipsisAxes[0];
    const numElidedAxes = numInterpolatedAxes + 1;
    normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
    normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
    normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
  } else {
    for (let axis = 0; axis < inputRank; axis++) {
      normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
      normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
      normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
    }
  }
  return {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  };
}
function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = 0;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalBegin[originalAxis];
      if (beginMask & 1 << originalAxis) {
        originalValue = 0;
      }
      newIndices[axis] = originalValue;
    }
  }
  return newIndices;
}
function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = Number.MAX_SAFE_INTEGER;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalEnd[originalAxis];
      if (endMask & 1 << originalAxis) {
        originalValue = Number.MAX_SAFE_INTEGER;
      }
      newIndices[axis] = originalValue;
    }
  }
  for (let i = 0; i < newIndices.length; i++) {
    const axisSize = inputShape[i];
    if (newIndices[i] < 0) {
      newIndices[i] += axisSize;
    }
    newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
  }
  return newIndices;
}
function stridesForAxis(strides, axis, ellipsisMask) {
  let stride = strides[axis];
  if (ellipsisMask & 1 << axis || stride == null) {
    stride = 1;
  }
  return stride;
}
function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
  let start = startIndices[axis];
  const stride = strides[axis] || 1;
  if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
    if (stride > 0) {
      start = Number.MIN_SAFE_INTEGER;
    } else {
      start = Number.MAX_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (start < 0) {
    start += axisSize;
  }
  start = clamp(0, start, axisSize - 1);
  return start;
}
function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
  let stop = stopIndices[axis];
  const stride = strides[axis] || 1;
  if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
    if (stride > 0) {
      stop = Number.MAX_SAFE_INTEGER;
    } else {
      stop = Number.MIN_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (stop < 0) {
    stop += axisSize;
  }
  if (stride > 0) {
    stop = clamp(0, stop, axisSize);
  } else {
    stop = clamp(-1, stop, axisSize - 1);
  }
  return stop;
}
function isSliceContinous(shape, begin, size) {
  let firstNonOneAxis = size.length;
  for (let i = 0; i < size.length; i++) {
    if (size[i] > 1) {
      firstNonOneAxis = i;
      break;
    }
  }
  for (let i = firstNonOneAxis + 1; i < size.length; i++) {
    if (begin[i] > 0 || size[i] !== shape[i]) {
      return false;
    }
  }
  return true;
}
function computeFlatOffset(begin, strides) {
  let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
  for (let i = 0; i < begin.length - 1; i++) {
    flatOffset += begin[i] * strides[i];
  }
  return flatOffset;
}
function parseSliceParams(x, begin, size) {
  let begin_;
  const xRank = x.shape.length;
  if (typeof begin === "number") {
    begin_ = [begin, ...new Array(xRank - 1).fill(0)];
  } else if (begin.length < xRank) {
    begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
  } else {
    begin_ = begin.slice();
  }
  begin_.forEach((d) => {
    assert(d !== -1, () => "slice() does not support negative begin indexing.");
  });
  let size_;
  if (size == null) {
    size_ = new Array(xRank).fill(-1);
  } else if (typeof size === "number") {
    size_ = [size, ...new Array(xRank - 1).fill(-1)];
  } else if (size.length < xRank) {
    size_ = size.concat(new Array(xRank - size.length).fill(-1));
  } else {
    size_ = size;
  }
  size_ = size_.map((d, i) => {
    if (d >= 0) {
      return d;
    } else {
      assert(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
      return x.shape[i] - begin_[i];
    }
  });
  return [begin_, size_];
}
function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
  let $begin = begin.slice();
  let $end = end.slice();
  let $strides = strides;
  if (strides == null) {
    $strides = new Array($begin.length);
  }
  const ellipsisAxes = maskToAxes(ellipsisMask);
  if (ellipsisAxes.length > 1) {
    throw new Error("Multiple ellipses in slice is not allowed.");
  }
  if (ellipsisMask !== 0 && newAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");
  }
  if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");
  }
  const numInterpolatedAxes = xShape.length - $begin.length;
  const expandAxes = maskToAxes(newAxisMask);
  const newShape = xShape.slice();
  expandAxes.forEach((axis) => {
    $begin[axis] = 0;
    $end[axis] = 1;
    newShape.splice(axis, 0, 1);
  });
  const {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  } = getNormalizedAxes(newShape, ellipsisAxes, numInterpolatedAxes, $begin, $end, $strides, beginMask, endMask, ellipsisMask);
  $begin = normalizedBegin;
  $end = normalizedEnd;
  $strides = normalizedStrides;
  const shrinkAxes = maskToAxes(shrinkAxisMask);
  shrinkAxes.forEach((axis) => {
    $end[axis] = $begin[axis] + 1;
    $strides[axis] = 1;
  });
  const size = computeOutShape($begin, $end, $strides);
  const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);
  const nonStrided = $strides.every((v) => v === 1);
  return { nonStrided, $begin, $end, $strides, size, newShape, outShape };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/serialization.ts
var serialization_exports = {};
__export(serialization_exports, {
  Serializable: () => Serializable,
  SerializationMap: () => SerializationMap,
  registerClass: () => registerClass
});
var Serializable = class {
  getClassName() {
    return this.constructor.className;
  }
  static fromConfig(cls, config) {
    return new cls(config);
  }
};
var SerializationMap = class {
  constructor() {
    this.classNameMap = {};
  }
  static getMap() {
    if (SerializationMap.instance == null) {
      SerializationMap.instance = new SerializationMap();
    }
    return SerializationMap.instance;
  }
  static register(cls) {
    SerializationMap.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
  }
};
function registerClass(cls) {
  assert(cls.className != null, () => `Class being registered does not have the static className property defined.`);
  assert(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
  assert(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
  SerializationMap.register(cls);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/test_util.ts
var test_util_exports = {};
__export(test_util_exports, {
  TEST_EPSILON_FLOAT16: () => TEST_EPSILON_FLOAT16,
  encodeStrings: () => encodeStrings,
  expectArrayBuffersEqual: () => expectArrayBuffersEqual,
  expectArraysClose: () => expectArraysClose,
  expectArraysEqual: () => expectArraysEqual,
  expectNumbersClose: () => expectNumbersClose,
  expectPromiseToFail: () => expectPromiseToFail,
  expectValuesInRange: () => expectValuesInRange,
  testEpsilon: () => testEpsilon
});
var TEST_EPSILON_FLOAT32 = 1e-3;
var TEST_EPSILON_FLOAT16 = 0.1;
function expectArraysClose(actual, expected, epsilon3) {
  if (epsilon3 == null) {
    epsilon3 = testEpsilon();
  }
  return expectArraysPredicate(actual, expected, (a, b) => areClose(a, b, epsilon3));
}
function testEpsilon() {
  return ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 : TEST_EPSILON_FLOAT16;
}
function expectArraysPredicate(actual, expected, predicate) {
  let checkClassType = true;
  if (isTypedArray(actual) || isTypedArray(expected)) {
    checkClassType = false;
  }
  if (isTypedArray(actual) && isTypedArray(expected)) {
    checkClassType = true;
  }
  if (checkClassType) {
    const aType = actual.constructor.name;
    const bType = expected.constructor.name;
    if (aType !== bType) {
      throw new Error(`Arrays are of different type. Actual: ${aType}. Expected: ${bType}`);
    }
  }
  if (Array.isArray(actual) && Array.isArray(expected)) {
    const actualShape = inferShape(actual);
    const expectedShape = inferShape(expected);
    if (!arraysEqual(actualShape, expectedShape)) {
      throw new Error(`Arrays have different shapes. Actual: [${actualShape}]. Expected: [${expectedShape}]`);
    }
  }
  const actualFlat = isTypedArray(actual) ? actual : flatten(actual);
  const expectedFlat = isTypedArray(expected) ? expected : flatten(expected);
  if (actualFlat.length !== expectedFlat.length) {
    throw new Error(`Arrays have different lengths actual: ${actualFlat.length} vs expected: ${expectedFlat.length}.
Actual:   ${actualFlat}.
Expected: ${expectedFlat}.`);
  }
  for (let i = 0; i < expectedFlat.length; ++i) {
    const a = actualFlat[i];
    const e = expectedFlat[i];
    if (!predicate(a, e)) {
      throw new Error(`Arrays differ: actual[${i}] = ${a}, expected[${i}] = ${e}.
Actual:   ${actualFlat}.
Expected: ${expectedFlat}.`);
    }
  }
}
function expectPromiseToFail(fn, done) {
  fn().then(() => done.fail(), () => done());
}
function expectArraysEqual(actual, expected) {
  const exp6 = typeof expected === "string" || typeof expected === "number" || typeof expected === "boolean" ? [expected] : expected;
  if (isString(actual) || isString(actual[0]) || isString(expected) || isString(expected[0])) {
    return expectArraysPredicate(actual, exp6, (a, b) => a == b);
  }
  return expectArraysPredicate(actual, expected, (a, b) => areClose(a, b, 0));
}
function expectNumbersClose(a, e, epsilon3) {
  if (epsilon3 == null) {
    epsilon3 = testEpsilon();
  }
  if (!areClose(a, e, epsilon3)) {
    throw new Error(`Numbers differ: actual === ${a}, expected === ${e}`);
  }
}
function areClose(a, e, epsilon3) {
  if (!isFinite(a) && !isFinite(e)) {
    return true;
  }
  if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon3) {
    return false;
  }
  return true;
}
function expectValuesInRange(actual, low, high) {
  for (let i = 0; i < actual.length; i++) {
    if (actual[i] < low || actual[i] > high) {
      throw new Error(`Value out of range:${actual[i]} low: ${low}, high: ${high}`);
    }
  }
}
function expectArrayBuffersEqual(actual, expected) {
  expect(new Float32Array(actual)).toEqual(new Float32Array(expected));
}
function encodeStrings(a) {
  for (let i = 0; i < a.length; i++) {
    const val = a[i];
    if (Array.isArray(val)) {
      encodeStrings(val);
    } else {
      a[i] = encodeString(val);
    }
  }
  return a;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/version.ts
var version9 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/globals.ts
function enableProdMode() {
  env().set("PROD", true);
}
function enableDebugMode() {
  env().set("DEBUG", true);
}
function disableDeprecationWarnings() {
  env().set("DEPRECATION_WARNINGS_ENABLED", false);
  console.warn(`TensorFlow.js deprecation warnings have been disabled.`);
}
function deprecationWarn(msg) {
  if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
    console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
  }
}
setDeprecationWarningFn(deprecationWarn);
function disposeVariables() {
  ENGINE.disposeVariables();
}
function engine() {
  return ENGINE;
}
function memory() {
  return ENGINE.memory();
}
function profile(f) {
  return ENGINE.profile(f);
}
function tidy(nameOrFn, fn) {
  return ENGINE.tidy(nameOrFn, fn);
}
function dispose(container) {
  const tensors = getTensorsInContainer(container);
  tensors.forEach((tensor3) => tensor3.dispose());
}
function keep(result) {
  return ENGINE.keep(result);
}
function time(f) {
  return ENGINE.time(f);
}
function setBackend(backendName) {
  return ENGINE.setBackend(backendName);
}
function ready() {
  return ENGINE.ready();
}
function getBackend() {
  return ENGINE.backendName;
}
function removeBackend(name) {
  ENGINE.removeBackend(name);
}
function findBackend(name) {
  return ENGINE.findBackend(name);
}
function findBackendFactory(name) {
  return ENGINE.findBackendFactory(name);
}
function registerBackend(name, factory, priority = 1) {
  return ENGINE.registerBackend(name, factory, priority);
}
function backend() {
  return ENGINE.backend;
}
function setPlatform(platformName, platform) {
  env().setPlatform(platformName, platform);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/add.ts
function add_(a, b) {
  let $a = convertToTensor(a, "a", "add");
  let $b = convertToTensor(b, "b", "add");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Add, inputs);
}
var add2 = op({ add_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/floorDiv.ts
function floorDiv_(a, b) {
  let $a = convertToTensor(a, "a", "floorDiv");
  let $b = convertToTensor(b, "b", "floorDiv");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(FloorDiv, inputs);
}
var floorDiv = op({ floorDiv_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/div.ts
function div_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "int32" && $b.dtype === "int32") {
    return floorDiv($a, $b);
  }
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE.runKernel(RealDiv, inputs, attrs);
}
var div = op({ div_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/mul.ts
function mul_(a, b) {
  let $a = convertToTensor(a, "a", "mul");
  let $b = convertToTensor(b, "b", "mul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Multiply, inputs);
}
var mul = op({ mul_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/abs.ts
function abs_(x) {
  const $x = convertToTensor(x, "x", "abs");
  if ($x.dtype === "complex64") {
    const inputs = { x: $x };
    return ENGINE.runKernel(ComplexAbs, inputs);
  } else {
    const inputs = { x: $x };
    return ENGINE.runKernel(Abs, inputs);
  }
}
var abs = op({ abs_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/acos.ts
function acos_(x) {
  const $x = convertToTensor(x, "x", "acos");
  const inputs = { x: $x };
  return ENGINE.runKernel(Acos, inputs);
}
var acos = op({ acos_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/acosh.ts
function acosh_(x) {
  const $x = convertToTensor(x, "x", "acosh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Acosh, inputs);
}
var acosh = op({ acosh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/add_n.ts
function addN_(tensors) {
  assert(Array.isArray(tensors), () => "The argument passed to tf.addN() must be a list of tensors");
  assert(tensors.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${tensors.length}`);
  const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, "addN"));
  const firstTensor = $tensors[0];
  $tensors.forEach((t) => {
    if (t.dtype !== firstTensor.dtype) {
      throw new Error("All tensors passed to tf.addN() must have the same dtype");
    }
  });
  $tensors.forEach((t) => {
    if (!arraysEqual(t.shape, firstTensor.shape)) {
      throw new Error("All tensors passed to tf.addN() must have the same shape");
    }
  });
  const inputs = $tensors;
  return ENGINE.runKernel(AddN, inputs);
}
var addN = op({ addN_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/all.ts
function all_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "all", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(All, inputs, attrs);
}
var all = op({ all_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/any.ts
function any_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "any", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Any, inputs, attrs);
}
var any = op({ any_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/arg_max.ts
function argMax_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMax");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE.runKernel(ArgMax, inputs, attrs);
}
var argMax = op({ argMax_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/arg_min.ts
function argMin_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMin");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE.runKernel(ArgMin, inputs, attrs);
}
var argMin = op({ argMin_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/asin.ts
function asin_(x) {
  const $x = convertToTensor(x, "x", "asin");
  const inputs = { x: $x };
  return ENGINE.runKernel(Asin, inputs);
}
var asin = op({ asin_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/asinh.ts
function asinh_(x) {
  const $x = convertToTensor(x, "x", "asinh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Asinh, inputs);
}
var asinh = op({ asinh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/atan.ts
function atan_(x) {
  const $x = convertToTensor(x, "x", "atan");
  const inputs = { x: $x };
  return ENGINE.runKernel(Atan, inputs);
}
var atan = op({ atan_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/atan2.ts
function atan2_(a, b) {
  let $a = convertToTensor(a, "a", "atan2");
  let $b = convertToTensor(b, "b", "atan2");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Atan2, inputs);
}
var atan2 = op({ atan2_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/atanh.ts
function atanh_(x) {
  const $x = convertToTensor(x, "x", "atanh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Atanh, inputs);
}
var atanh = op({ atanh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv_util.ts
function computeDilation2DInfo(inputShape, filterShape, strides, pad4, dataFormat = "NHWC", dilations) {
  const inputChannels = inputShape[3];
  const $filterShape = [...filterShape, inputChannels];
  const $dataFormat = convertConv2DDataFormat(dataFormat);
  return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad4, null, null, $dataFormat);
}
function computePool2DInfo(inShape, filterSize, strides, dilations, pad4, roundingMode, dataFormat = "channelsLast") {
  const [filterHeight, filterWidth] = parseTupleParam(filterSize);
  let filterShape;
  if (dataFormat === "channelsLast") {
    filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
  } else if (dataFormat === "channelsFirst") {
    filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv2DInfo(inShape, filterShape, strides, dilations, pad4, roundingMode, false, dataFormat);
}
function computePool3DInfo(inShape, filterSize, strides, dilations, pad4, roundingMode, dataFormat = "NDHWC") {
  const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);
  let filterShape;
  let $dataFormat;
  if (dataFormat === "NDHWC") {
    $dataFormat = "channelsLast";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
  } else if (dataFormat === "NCDHW") {
    $dataFormat = "channelsFirst";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv3DInfo(inShape, filterShape, strides, dilations, pad4, false, $dataFormat, roundingMode);
}
function computeConv2DInfo(inShape, filterShape, strides, dilations, pad4, roundingMode, depthwise = false, dataFormat = "channelsLast") {
  let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideHeight, strideWidth] = parseTupleParam(strides);
  const [dilationHeight, dilationWidth] = parseTupleParam(dilations);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad4, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inHeight,
    inWidth,
    inChannels,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideHeight,
    strideWidth,
    filterHeight,
    filterWidth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeConv3DInfo(inShape, filterShape, strides, dilations, pad4, depthwise = false, dataFormat = "channelsLast", roundingMode) {
  let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);
  const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);
  const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad4, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inDepth,
    inHeight,
    inWidth,
    inChannels,
    outDepth,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideDepth,
    strideHeight,
    strideWidth,
    filterDepth,
    filterHeight,
    filterWidth,
    effectiveFilterDepth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationDepth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, fieldSize, stride);
  }
  const inputRows = inShape[0];
  const inputCols = inShape[1];
  const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputRows, outputCols];
}
function computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, fieldSize, stride);
  }
  const inputDepth = inShape[0];
  const inputRows = inShape[1];
  const inputCols = inShape[2];
  const outputDepths = round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputDepths, outputRows, outputCols, outChannels];
}
function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {
  const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
  return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
}
function parseTupleParam(param) {
  if (typeof param === "number") {
    return [param, param, param];
  }
  if (param.length === 2) {
    return [param[0], param[1], 1];
  }
  return param;
}
function parse3TupleParam(param) {
  return typeof param === "number" ? [param, param, param] : param;
}
function getEffectiveFilterSize(filterSize, dilation) {
  if (dilation <= 1) {
    return filterSize;
  }
  return filterSize + (filterSize - 1) * (dilation - 1);
}
function getPadAndOutInfo(pad4, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
  let padInfo;
  let outHeight;
  let outWidth;
  if (typeof pad4 === "number") {
    const padType = pad4 === 0 ? "VALID" : "NUMBER";
    padInfo = { top: pad4, bottom: pad4, left: pad4, right: pad4, type: padType };
    const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad4, roundingMode);
    outHeight = outShape[0];
    outWidth = outShape[1];
  } else if (pad4 === "same") {
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
    const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, type: "SAME" };
  } else if (pad4 === "valid") {
    padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else if (typeof pad4 === "object") {
    const top = dataFormat === "channelsLast" ? pad4[1][0] : pad4[2][0];
    const bottom = dataFormat === "channelsLast" ? pad4[1][1] : pad4[2][1];
    const left = dataFormat === "channelsLast" ? pad4[2][0] : pad4[3][0];
    const right = dataFormat === "channelsLast" ? pad4[2][1] : pad4[3][1];
    const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
    padInfo = { top, bottom, left, right, type: padType };
    outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
    outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
  } else {
    throw Error(`Unknown padding parameter: ${pad4}`);
  }
  return { padInfo, outHeight, outWidth };
}
function get3DPadAndOutInfo(pad4, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
  let padInfo;
  let outDepth;
  let outHeight;
  let outWidth;
  if (typeof pad4 === "number") {
    const padType = pad4 === 0 ? "VALID" : "NUMBER";
    padInfo = {
      top: pad4,
      bottom: pad4,
      left: pad4,
      right: pad4,
      front: pad4,
      back: pad4,
      type: padType
    };
    const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad4, roundingMode);
    outDepth = outShape[0];
    outHeight = outShape[1];
    outWidth = outShape[2];
  } else if (pad4 === "same") {
    outDepth = Math.ceil(inDepth / strideDepth);
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
    const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
    const front = Math.floor(padAlongDepth / 2);
    const back = padAlongDepth - front;
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, front, back, type: "SAME" };
  } else if (pad4 === "valid") {
    padInfo = {
      top: 0,
      bottom: 0,
      left: 0,
      right: 0,
      front: 0,
      back: 0,
      type: "VALID"
    };
    outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else {
    throw Error(`Unknown padding parameter: ${pad4}`);
  }
  return { padInfo, outDepth, outHeight, outWidth };
}
function round(value, roundingMode) {
  if (!roundingMode) {
    return Math.trunc(value);
  }
  switch (roundingMode) {
    case "round":
      return Math.round(value);
    case "ceil":
      return Math.ceil(value);
    case "floor":
      return Math.floor(value);
    default:
      throw new Error(`Unknown roundingMode ${roundingMode}`);
  }
}
function tupleValuesAreOne(param) {
  const [dimA, dimB, dimC] = parseTupleParam(param);
  return dimA === 1 && dimB === 1 && dimC === 1;
}
function eitherStridesOrDilationsAreOne(strides, dilations) {
  return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
}
function convertConv2DDataFormat(dataFormat) {
  if (dataFormat === "NHWC") {
    return "channelsLast";
  } else if (dataFormat === "NCHW") {
    return "channelsFirst";
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reshape.ts
function reshape_(x, shape) {
  const $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = { shape };
  return ENGINE.runKernel(Reshape, inputs, attrs);
}
var reshape = op({ reshape_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/avg_pool.ts
function avgPool_(x, filterSize, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "avgPool", "float32");
  const dilations = 1;
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in avgPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  let res = ENGINE.runKernel(AvgPool, inputs, attrs);
  res = cast(res, $x.dtype);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPool = op({ avgPool_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/avg_pool_3d.ts
function avgPool3d_(x, filterSize, strides, pad4, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "avgPool3d", "float32");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat };
  let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
  res = cast(res, x5D.dtype);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3d = op({ avgPool3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat.ts
function concat_(tensors, axis = 0) {
  assert(tensors.length >= 1, () => "Pass at least one tensor to concat");
  const $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
  if ($tensors[0].dtype === "complex64") {
    $tensors.forEach((tensor3) => {
      if (tensor3.dtype !== "complex64") {
        throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor3.dtype}. `);
      }
    });
  }
  if ($tensors.length === 1) {
    return clone($tensors[0]);
  }
  const inputs = $tensors;
  const attr = { axis };
  return ENGINE.runKernel(Concat, inputs, attr);
}
var concat = op({ concat_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sigmoid.ts
function sigmoid_(x) {
  const $x = convertToTensor(x, "x", "sigmoid");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sigmoid, inputs);
}
var sigmoid = op({ sigmoid_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice.ts
function slice_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice", "string_or_numeric");
  if ($x.rank === 0) {
    throw new Error("Slicing scalar is not possible");
  }
  const inputs = { x: $x };
  const attrs = { begin, size };
  return ENGINE.runKernel(Slice, inputs, attrs);
}
var slice = op({ slice_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tanh.ts
function tanh_(x) {
  const $x = convertToTensor(x, "x", "tanh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Tanh, inputs);
}
var tanh2 = op({ tanh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/basic_lstm_cell.ts
function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
  const $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
  const $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
  const $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
  const $data = convertToTensor(data, "data", "basicLSTMCell");
  const $c = convertToTensor(c, "c", "basicLSTMCell");
  const $h = convertToTensor(h, "h", "basicLSTMCell");
  const combined = concat([$data, $h], 1);
  const weighted = matMul(combined, $lstmKernel);
  const res = add2(weighted, $lstmBias);
  const batchSize = res.shape[0];
  const sliceCols = res.shape[1] / 4;
  const sliceSize = [batchSize, sliceCols];
  const i = slice(res, [0, 0], sliceSize);
  const j = slice(res, [0, sliceCols], sliceSize);
  const f = slice(res, [0, sliceCols * 2], sliceSize);
  const o = slice(res, [0, sliceCols * 3], sliceSize);
  const newC = add2(mul(sigmoid(i), tanh2(j)), mul($c, sigmoid(add2($forgetBias, f))));
  const newH = mul(tanh2(newC), sigmoid(o));
  return [newC, newH];
}
var basicLSTMCell = op({ basicLSTMCell_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batch_to_space_nd.ts
function batchToSpaceND_(x, blockShape, crops) {
  const $x = convertToTensor(x, "x", "batchToSpaceND");
  const prod6 = blockShape.reduce((a, b) => a * b);
  assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
  assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
  assert($x.shape[0] % prod6 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod6}`);
  const inputs = { x: $x };
  const attrs = { blockShape, crops };
  return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
}
var batchToSpaceND = op({ batchToSpaceND_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batchnorm_util.ts
function xAs4D(x) {
  let x4D;
  if (x.rank === 0 || x.rank === 1) {
    x4D = reshape(x, [1, 1, 1, x.size]);
  } else if (x.rank === 2) {
    x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
  } else if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  } else {
    x4D = x;
  }
  return x4D;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batchnorm.ts
function batchNorm_(x, mean5, variance, offset, scale2, varianceEpsilon) {
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean5, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  assert($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  assert($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const x4D = xAs4D($x);
  const inputs = {
    x: x4D,
    scale: $scale,
    offset: $offset,
    mean: $mean,
    variance: $variance
  };
  const attrs = { varianceEpsilon };
  const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
  return reshape(res, $x.shape);
}
var batchNorm = op({ batchNorm_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batchnorm2d.ts
function batchNorm2d_(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean5, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
  assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm2d = op({ batchNorm2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batchnorm3d.ts
function batchNorm3d_(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean5, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
  assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm3d = op({ batchNorm3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/batchnorm4d.ts
function batchNorm4d_(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean5, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
  assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm4d = op({ batchNorm4d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/bincount.ts
function bincount_(x, weights, size) {
  const $x = convertToTensor(x, "x", "bincount");
  const $weights = convertToTensor(weights, "weights", "bincount");
  assert($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size };
  return ENGINE.runKernel(Bincount, inputs, attrs);
}
var bincount = op({ bincount_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/broadcast_to.ts
function broadcastTo_(x, shape) {
  let input2 = convertToTensor(x, "broadcastTo", "x");
  const xShape = input2.shape;
  if (shape.some((d) => !(d > 0) || d % 1 !== 0)) {
    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);
  }
  if (shape.length < input2.rank) {
    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input2.rank}.`);
  }
  if (shape.length > input2.rank) {
    const newShape = input2.shape.slice();
    while (newShape.length < shape.length) {
      newShape.unshift(1);
    }
    input2 = reshape(input2, newShape);
  }
  const inputShape = input2.shape;
  const reps = Array.from(shape);
  for (let i = shape.length - 1; i >= 0; i--) {
    if (inputShape[i] === shape[i]) {
      reps[i] = 1;
    } else if (input2.shape[i] !== 1) {
      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
    }
  }
  const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
  if (axes.length === 0) {
    return clone(input2);
  }
  const inputs = { x: input2 };
  const attrs = { reps };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var broadcastTo = op({ broadcastTo_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/ceil.ts
function ceil_(x) {
  const $x = convertToTensor(x, "x", "ceil");
  const inputs = { x: $x };
  return ENGINE.runKernel(Ceil, inputs);
}
var ceil = op({ ceil_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/clip_by_value.ts
function clipByValue_(x, clipValueMin, clipValueMax) {
  const $x = convertToTensor(x, "x", "clipByValue");
  assert(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
  const inputs = { x: $x };
  const attrs = { clipValueMin, clipValueMax };
  return ENGINE.runKernel(ClipByValue, inputs, attrs);
}
var clipByValue = op({ clipByValue_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat_1d.ts
function concat1d_(tensors) {
  return concat(tensors, 0);
}
var concat1d = op({ concat1d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat_2d.ts
function concat2d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat2d = op({ concat2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat_3d.ts
function concat3d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat3d = op({ concat3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat_4d.ts
function concat4d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat4d = op({ concat4d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv2d.ts
function conv2d_(x, filter, strides, pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2d");
  const $filter = convertToTensor(filter, "filter", "conv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE.runKernel(Conv2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2d = op({ conv2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv1d.ts
function conv1d_(x, filter, stride, pad4, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv1d");
  const $filter = convertToTensor(filter, "filter", "conv1d");
  let x3D = $x;
  let reshapedTo3D = false;
  if ($x.rank === 2) {
    reshapedTo3D = true;
    x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
  }
  assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
  assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in conv1d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
  assert(eitherStridesOrDilationsAreOne(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
  assert(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
  const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
  const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
  const strides = [1, stride];
  const dilations = [1, dilation];
  const conv2dDataFormat = "NHWC";
  const res = conv2d(input4D, filter4D, strides, pad4, conv2dDataFormat, dilations, dimRoundingMode);
  if (reshapedTo3D) {
    return reshape(res, [res.shape[2], res.shape[3]]);
  }
  return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
}
var conv1d = op({ conv1d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv2d_backprop_input.ts
function conv2DBackpropInput_(xShape, dy, filter, strides, pad4, dataFormat = "NHWC", dimRoundingMode) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape4D = xShape;
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    xShape4D = [1, xShape[0], xShape[1], xShape[2]];
  }
  assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
  assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
  const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
  assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad4, dataFormat, dimRoundingMode, inputShape: xShape4D };
  const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2DBackpropInput = op({ conv2DBackpropInput_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv2d_transpose.ts
function conv2dTranspose_(x, filter, outputShape, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv2dTranspose");
  return conv2DBackpropInput(outputShape, $x, $filter, strides, pad4, "NHWC", dimRoundingMode);
}
var conv2dTranspose = op({ conv2dTranspose_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv3d.ts
function conv3d_(x, filter, strides, pad4, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
  const $x = convertToTensor(x, "x", "conv3d");
  const $filter = convertToTensor(filter, "filter", "conv3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
  assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
  assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
  const inputs = { x: x5D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations };
  const res = ENGINE.runKernel(Conv3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3d = op({ conv3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv3d_backprop_input.ts
function conv3DBackpropInput_(xShape, dy, filter, strides, pad4) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape5D = xShape;
  let dy5D = dy;
  let reshapedTo5D = false;
  if (dy.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
  }
  const inDepth = xShape5D[4];
  const outDepth = dy5D.shape[4];
  assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
  assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
  assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
  assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
  assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
  const inputs = { dy: dy5D, filter };
  const attrs = { pad: pad4, strides, inputShape: xShape5D };
  const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3DBackpropInput = op({ conv3DBackpropInput_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv3d_transpose.ts
function conv3dTranspose_(x, filter, outputShape, strides, pad4) {
  const $x = convertToTensor(x, "x", "conv3dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv3dTranspose");
  return conv3DBackpropInput(outputShape, $x, $filter, strides, pad4);
}
var conv3dTranspose = op({ conv3dTranspose_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/cos.ts
function cos_(x) {
  const $x = convertToTensor(x, "x", "cos");
  const inputs = { x: $x };
  return ENGINE.runKernel(Cos, inputs);
}
var cos = op({ cos_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/cosh.ts
function cosh_(x) {
  const $x = convertToTensor(x, "x", "cosh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Cosh, inputs);
}
var cosh = op({ cosh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/cumsum.ts
function cumsum_(x, axis = 0, exclusive = false, reverse6 = false) {
  const $x = convertToTensor(x, "x", "cumsum");
  const inputs = { x: $x };
  const attrs = { axis, exclusive, reverse: reverse6 };
  return ENGINE.runKernel(Cumsum, inputs, attrs);
}
var cumsum = op({ cumsum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/dense_bincount.ts
function denseBincount_(x, weights, size, binaryOutput = false) {
  const $x = convertToTensor(x, "x", "denseBincount");
  const $weights = convertToTensor(weights, "weights", "denseBincount");
  assert($x.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${$x.dtype}`);
  assert($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${$x.rank}.`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size, binaryOutput };
  return ENGINE.runKernel(DenseBincount, inputs, attrs);
}
var denseBincount = op({ denseBincount_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/depth_to_space.ts
function depthToSpace_(x, blockSize, dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "depthToSpace");
  const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
  assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
  assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
  assert(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
  const inputs = { x: $x };
  const attrs = { blockSize, dataFormat };
  return ENGINE.runKernel(DepthToSpace, inputs, attrs);
}
var depthToSpace = op({ depthToSpace_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/depthwise_conv2d.ts
function depthwiseConv2d_(x, filter, strides, pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "depthwiseConv2d");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2d = op({ depthwiseConv2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/diag.ts
function diag_(x) {
  const $x = convertToTensor(x, "x", "diag");
  const inputs = { x: $x };
  return ENGINE.runKernel(Diag, inputs);
}
var diag = op({ diag_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/dilation2d.ts
function dilation2d_(x, filter, strides, pad4, dilations = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "dilation2d");
  const $filter = convertToTensor(filter, "filter", "dilation2d");
  assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
  assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
  assert(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    reshapedTo4D = true;
  }
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dilations };
  const res = ENGINE.runKernel(Dilation2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var dilation2d = op({ dilation2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/broadcast_util.ts
function getBroadcastDims(inShape, outShape) {
  const inRank = inShape.length;
  const dims = [];
  for (let i = 0; i < inRank; i++) {
    const dim = inRank - 1 - i;
    const a = inShape[dim] || 1;
    const b = outShape[outShape.length - 1 - i] || 1;
    if (b > 1 && a === 1) {
      dims.unshift(dim);
    }
  }
  return dims;
}
function getReductionAxes(inShape, outShape) {
  const result = [];
  for (let i = 0; i < outShape.length; i++) {
    const inDim = inShape[inShape.length - i - 1];
    const outAxis = outShape.length - i - 1;
    const outDim = outShape[outAxis];
    if (inDim == null || inDim === 1 && outDim > 1) {
      result.unshift(outAxis);
    }
  }
  return result;
}
function assertAndGetBroadcastShape(shapeA, shapeB) {
  const result = [];
  const l = Math.max(shapeA.length, shapeB.length);
  for (let i = 0; i < l; i++) {
    let a = shapeA[shapeA.length - i - 1];
    if (a == null) {
      a = 1;
    }
    let b = shapeB[shapeB.length - i - 1];
    if (b == null) {
      b = 1;
    }
    if (a === 1) {
      result.unshift(b);
    } else if (b === 1) {
      result.unshift(a);
    } else if (a !== b) {
      const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
      throw Error(errMsg);
    } else {
      result.unshift(a);
    }
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/equal.ts
function equal_(a, b) {
  let $a = convertToTensor(a, "a", "equal", "string_or_numeric");
  let $b = convertToTensor(b, "b", "equal", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Equal, inputs);
}
var equal = op({ equal_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/where.ts
function where_(condition, a, b) {
  const $a = convertToTensor(a, "a", "where");
  const $b = convertToTensor(b, "b", "where");
  const $condition = convertToTensor(condition, "condition", "where", "bool");
  const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
  const $broadcastedCondition = broadcastTo($condition, broadcastShape);
  const $broadcastedA = broadcastTo($a, broadcastShape);
  const $broadcastedB = broadcastTo($b, broadcastShape);
  const inputs = {
    condition: $broadcastedCondition,
    t: $broadcastedA,
    e: $broadcastedB
  };
  return ENGINE.runKernel(Select, inputs);
}
var where = op({ where_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/zeros_like.ts
function zerosLike_(x) {
  const $x = convertToTensor(x, "x", "zerosLike");
  const inputs = { x: $x };
  return ENGINE.runKernel(ZerosLike, inputs);
}
var zerosLike = op({ zerosLike_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/div_no_nan.ts
function divNoNan_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  const divResult = div($a, $b);
  const zeros6 = zerosLike(divResult);
  const bEqualsZero = equal($b, zeros6);
  return where(bEqualsZero, zeros6, divResult);
}
var divNoNan = op({ divNoNan_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/dot.ts
function dot_(t1, t2) {
  const $t1 = convertToTensor(t1, "t1", "dot");
  const $t2 = convertToTensor(t2, "t2", "dot");
  assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
  const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
  const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
  assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
  if ($t1.rank === 1 && $t2.rank === 1) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, []);
  } else if ($t1.rank === 1 && $t2.rank === 2) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else if ($t1.rank === 2 && $t2.rank === 1) {
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul($t1, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else {
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul($t1, t22D);
    return t1t2;
  }
}
var dot = op({ dot_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/einsum.ts
function einsum_(equation, ...tensors) {
  const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, "einsum"));
  const attrs = { equation };
  return ENGINE.runKernel(Einsum, $tensors, attrs);
}
var einsum = op({ einsum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/elu.ts
function elu_(x) {
  const $x = convertToTensor(x, "x", "elu");
  const inputs = { x: $x };
  return ENGINE.runKernel(Elu, inputs);
}
var elu = op({ elu_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/erf.ts
function erf_(x) {
  let $x = convertToTensor(x, "x", "erf");
  assert($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
  if ($x.dtype === "int32") {
    $x = cast($x, "float32");
  }
  const inputs = { x: $x };
  return ENGINE.runKernel(Erf, inputs);
}
var erf = op({ erf_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/exp.ts
function exp_(x) {
  const $x = convertToTensor(x, "x", "exp");
  const inputs = { x: $x };
  return ENGINE.runKernel(Exp, inputs);
}
var exp = op({ exp_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/expand_dims.ts
function expandDims_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
  assert(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
  const inputs = { input: $x };
  const attrs = { dim: axis };
  return ENGINE.runKernel(ExpandDims, inputs, attrs);
}
var expandDims = op({ expandDims_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/expm1.ts
function expm1_(x) {
  const $x = convertToTensor(x, "x", "expm1");
  const inputs = { x: $x };
  return ENGINE.runKernel(Expm1, inputs);
}
var expm1 = op({ expm1_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tile.ts
function tile_(x, reps) {
  const $x = convertToTensor(x, "x", "tile", "string_or_numeric");
  assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
  const inputs = { x: $x };
  const attrs = { reps };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var tile = op({ tile_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/eye.ts
function eye_(numRows, numColumns, batchShape, dtype = "float32") {
  if (numColumns == null) {
    numColumns = numRows;
  }
  const buff = buffer([numRows, numColumns], dtype);
  const n = numRows <= numColumns ? numRows : numColumns;
  for (let i = 0; i < n; ++i) {
    buff.set(1, i, i);
  }
  const out = reshape(buff.toTensor(), [numRows, numColumns]);
  if (batchShape == null) {
    return out;
  } else {
    if (batchShape.length === 1) {
      return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
    } else if (batchShape.length === 2) {
      return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
    } else if (batchShape.length === 3) {
      return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
        batchShape[0],
        batchShape[1],
        batchShape[2],
        1,
        1
      ]);
    } else {
      throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
    }
  }
}
var eye = op({ eye_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fill.ts
function fill(shape, value, dtype) {
  const attrs = { shape, value, dtype };
  return ENGINE.runKernel(Fill, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/floor.ts
function floor_(x) {
  const $x = convertToTensor(x, "x", "floor");
  const inputs = { x: $x };
  return ENGINE.runKernel(Floor, inputs);
}
var floor = op({ floor_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/gather.ts
function gather_(x, indices, axis = 0, batchDims = 0) {
  const $x = convertToTensor(x, "x", "gather");
  const $indices = convertToTensor(indices, "indices", "gather", "int32");
  const inputs = { x: $x, indices: $indices };
  const attrs = { axis, batchDims };
  return ENGINE.runKernel(GatherV2, inputs, attrs);
}
var gather = op({ gather_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/greater.ts
function greater_(a, b) {
  let $a = convertToTensor(a, "a", "greater", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greater", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Greater, inputs);
}
var greater = op({ greater_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/greater_equal.ts
function greaterEqual_(a, b) {
  let $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(GreaterEqual, inputs);
}
var greaterEqual = op({ greaterEqual_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/imag.ts
function imag_(input2) {
  const $input = convertToTensor(input2, "input", "imag");
  const inputs = { input: $input };
  return ENGINE.runKernel(Imag, inputs);
}
var imag = op({ imag_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/is_finite.ts
function isFinite_(x) {
  const $x = convertToTensor(x, "x", "isFinite");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsFinite, inputs);
}
var isFinite2 = op({ isFinite_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/is_inf.ts
function isInf_(x) {
  const $x = convertToTensor(x, "x", "isInf");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsInf, inputs);
}
var isInf = op({ isInf_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/is_nan.ts
function isNaN_(x) {
  const $x = convertToTensor(x, "x", "isNaN");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsNan, inputs);
}
var isNaN2 = op({ isNaN_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/leaky_relu.ts
function leakyRelu_(x, alpha = 0.2) {
  const $x = convertToTensor(x, "x", "leakyRelu");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE.runKernel(LeakyRelu, inputs, attrs);
}
var leakyRelu = op({ leakyRelu_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/less.ts
function less_(a, b) {
  let $a = convertToTensor(a, "a", "less", "string_or_numeric");
  let $b = convertToTensor(b, "b", "less", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Less, inputs);
}
var less = op({ less_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/less_equal.ts
function lessEqual_(a, b) {
  let $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LessEqual, inputs);
}
var lessEqual = op({ lessEqual_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/linspace.ts
function linspace(start, stop, num) {
  if (num <= 0) {
    throw new Error("The number of values should be positive.");
  }
  const attrs = { start, stop, num };
  return ENGINE.runKernel(LinSpace, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/local_response_normalization.ts
function localResponseNormalization_(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const $x = convertToTensor(x, "x", "localResponseNormalization");
  assert($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
  assert(isInt(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  const inputs = { x: x4D };
  const attrs = { depthRadius, bias, alpha, beta };
  const res = ENGINE.runKernel(LRN, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  } else {
    return res;
  }
}
var localResponseNormalization = op({ localResponseNormalization_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/log.ts
function log_(x) {
  const $x = convertToTensor(x, "x", "log");
  const inputs = { x: $x };
  return ENGINE.runKernel(Log, inputs);
}
var log = op({ log_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/log1p.ts
function log1p_(x) {
  const $x = convertToTensor(x, "x", "log1p");
  const inputs = { x: $x };
  return ENGINE.runKernel(Log1p, inputs);
}
var log1p = op({ log1p_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/gradients.ts
function grad(f) {
  assert(isFunction(f), () => "The f passed in grad(f) must be a function");
  return (x, dy) => {
    const $x = convertToTensor(x, "x", "tf.grad", "string_or_numeric");
    const $dy = dy != null ? convertToTensor(dy, "dy", "tf.grad") : null;
    return ENGINE.tidy(() => {
      const { value, grads: grads3 } = ENGINE.gradients(() => f($x), [$x], $dy);
      if ($dy != null) {
        assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)");
      }
      checkGrads(grads3);
      return grads3[0];
    });
  };
}
function grads(f) {
  assert(isFunction(f), () => "The f passed in grads(f) must be a function");
  return (args, dy) => {
    assert(Array.isArray(args), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    const $args = convertToTensorArray(args, "args", "tf.grads", "string_or_numeric");
    const $dy = dy != null ? convertToTensor(dy, "dy", "tf.grads") : null;
    return ENGINE.tidy(() => {
      const { value, grads: grads3 } = ENGINE.gradients(() => f(...$args), $args, $dy);
      if ($dy != null) {
        assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
      }
      checkGrads(grads3);
      return grads3;
    });
  };
}
function valueAndGrad(f) {
  assert(isFunction(f), () => "The f passed in valueAndGrad(f) must be a function");
  return (x, dy) => {
    assert(x instanceof Tensor, () => "The x passed in valueAndGrad(f)(x) must be a tensor");
    assert(dy == null || dy instanceof Tensor, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    const { grads: grads3, value } = ENGINE.gradients(() => f(x), [x], dy);
    checkGrads(grads3);
    return { grad: grads3[0], value };
  };
}
function valueAndGrads(f) {
  assert(isFunction(f), () => "The f passed in valueAndGrads(f) must be a function");
  return (args, dy) => {
    assert(Array.isArray(args) && args.every((arg) => arg instanceof Tensor), () => "The args passed in valueAndGrads(f)(args) must be array of tensors");
    assert(dy == null || dy instanceof Tensor, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    const res = ENGINE.gradients(() => f(...args), args, dy);
    if (dy != null) {
      assertShapesMatch(res.value.shape, dy.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
    }
    checkGrads(res.grads);
    return res;
  };
}
function variableGrads(f, varList) {
  assert(isFunction(f), () => "The f passed in variableGrads(f) must be a function");
  assert(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const specifiedVarList = varList != null;
  if (!specifiedVarList) {
    varList = [];
    for (const varName in ENGINE.registeredVariables) {
      varList.push(ENGINE.registeredVariables[varName]);
    }
  }
  const specifiedNonTrainable = specifiedVarList ? varList.filter((variable3) => !variable3.trainable) : null;
  const originalVarCount = varList.length;
  varList = varList.filter((variable3) => variable3.trainable);
  assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
  const allowNoGradients = true;
  const { value, grads: grads3 } = ENGINE.gradients(f, varList, null, allowNoGradients);
  assert(grads3.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
  assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
  const namedGrads = {};
  varList.forEach((v, i) => {
    if (grads3[i] != null) {
      namedGrads[v.name] = grads3[i];
    }
  });
  if (specifiedNonTrainable != null) {
    specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
  }
  return { value, grads: namedGrads };
}
function customGrad(f) {
  return ENGINE.customGrad(f);
}
function checkGrads(grads3) {
  const numNullGradients = grads3.filter((g) => g == null).length;
  if (numNullGradients > 0) {
    throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that
    the f you passed encloses all operations that lead from x to y.`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/neg.ts
function neg_(x) {
  const $x = convertToTensor(x, "x", "neg");
  const inputs = { x: $x };
  return ENGINE.runKernel(Neg, inputs);
}
var neg = op({ neg_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/softplus.ts
function softplus_(x) {
  const $x = convertToTensor(x, "x", "softplus");
  const inputs = { x: $x };
  return ENGINE.runKernel(Softplus, inputs);
}
var softplus = op({ softplus_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/log_sigmoid.ts
function logSigmoid_(x) {
  const $x = convertToTensor(x, "x", "logSigmoid");
  const customOp = customGrad((x2) => {
    const value = neg(softplus(neg(x2)));
    const gradFunc = (dy) => {
      const derX = mul(dy, sigmoid(neg(x2)));
      return derX;
    };
    return { value, gradFunc };
  });
  return customOp($x);
}
var logSigmoid = op({ logSigmoid_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/max.ts
function max_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "max");
  const inputs = { x: $x };
  const attrs = { reductionIndices: axis, keepDims };
  return ENGINE.runKernel(Max, inputs, attrs);
}
var max = op({ max_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sub.ts
function sub_(a, b) {
  let $a = convertToTensor(a, "a", "sub");
  let $b = convertToTensor(b, "b", "sub");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Sub, inputs);
}
var sub = op({ sub_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sum.ts
function sum_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "sum");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Sum, inputs, attrs);
}
var sum2 = op({ sum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/log_softmax.ts
function logSoftmax_(logits, axis = -1) {
  const $logits = convertToTensor(logits, "logits", "logSoftmax");
  if (axis === -1) {
    axis = $logits.rank - 1;
  }
  if (axis !== $logits.rank - 1) {
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
  }
  const customOp = customGrad((logits2, save) => {
    const keepDims = true;
    const xMax = max(logits2, axis, true);
    const shifted = sub(logits2, xMax);
    const value = sub(cast(shifted, "float32"), log(sum2(exp(shifted), axis, keepDims)));
    save([value]);
    const gradFunc = (dy, saved) => {
      const [value2] = saved;
      const keepDims2 = true;
      const softmax7 = exp(value2);
      return sub(dy, mul(sum2(dy, axis, keepDims2), softmax7));
    };
    return { value, gradFunc };
  });
  return customOp($logits);
}
var logSoftmax = op({ logSoftmax_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/axis_util.ts
function axesAreInnerMostDims(axes, rank) {
  for (let i = 0; i < axes.length; ++i) {
    if (axes[axes.length - i - 1] !== rank - 1 - i) {
      return false;
    }
  }
  return true;
}
function combineLocations(outputLoc, reduceLoc, axes) {
  const rank = outputLoc.length + reduceLoc.length;
  const loc = [];
  let outIdx = 0;
  let reduceIdx = 0;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      loc.push(outputLoc[outIdx++]);
    } else {
      loc.push(reduceLoc[reduceIdx++]);
    }
  }
  return loc;
}
function computeOutAndReduceShapes(aShape, axes) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      outShape.push(aShape[dim]);
    }
  }
  const reduceShape = axes.map((dim) => aShape[dim]);
  return [outShape, reduceShape];
}
function expandShapeToKeepDim(shape, axes) {
  const reduceSubShape = axes.map((x) => 1);
  return combineLocations(shape, reduceSubShape, axes);
}
function assertAxesAreInnerMostDims(msg, axes, rank) {
  assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
}
function getAxesPermutation(axes, rank) {
  if (axesAreInnerMostDims(axes, rank)) {
    return null;
  }
  const result = [];
  for (let i = 0; i < rank; ++i) {
    if (axes.indexOf(i) === -1) {
      result.push(i);
    }
  }
  axes.forEach((axis) => result.push(axis));
  return result;
}
function getUndoAxesPermutation(axes) {
  return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
}
function getInnerMostAxes(numAxes, rank) {
  const res = [];
  for (let i = rank - numAxes; i < rank; ++i) {
    res.push(i);
  }
  return res;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/log_sum_exp.ts
function logSumExp_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "logSumExp");
  const axes = parseAxisParam(axis, $x.shape);
  const xMax = max($x, axes, true);
  const a = sub($x, xMax);
  const b = exp(a);
  const c = sum2(b, axes);
  const d = log(c);
  const res = add2(reshape(xMax, d.shape), d);
  if (keepDims) {
    const newShape = expandShapeToKeepDim(res.shape, axes);
    return reshape(res, newShape);
  }
  return res;
}
var logSumExp = op({ logSumExp_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/logical_and.ts
function logicalAnd_(a, b) {
  const $a = convertToTensor(a, "a", "logicalAnd", "bool");
  const $b = convertToTensor(b, "b", "logicalAnd", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LogicalAnd, inputs);
}
var logicalAnd = op({ logicalAnd_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/logical_not.ts
function logicalNot_(x) {
  const $x = convertToTensor(x, "x", "logicalNot", "bool");
  const inputs = { x: $x };
  return ENGINE.runKernel(LogicalNot, inputs);
}
var logicalNot = op({ logicalNot_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/logical_or.ts
function logicalOr_(a, b) {
  const $a = convertToTensor(a, "a", "logicalOr", "bool");
  const $b = convertToTensor(b, "b", "logicalOr", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LogicalOr, inputs);
}
var logicalOr = op({ logicalOr_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/logical_xor.ts
function logicalXor_(a, b) {
  const $a = convertToTensor(a, "a", "logicalXor", "bool");
  const $b = convertToTensor(b, "b", "logicalXor", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
}
var logicalXor = op({ logicalXor_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/max_pool.ts
function maxPool_(x, filterSize, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "maxPool");
  const dilations = 1;
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in maxPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  const res = ENGINE.runKernel(MaxPool, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var maxPool = op({ maxPool_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/max_pool_3d.ts
function maxPool3d_(x, filterSize = [1, 1, 1], strides, pad4, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "maxPool3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat };
  const res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3d = op({ maxPool3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/max_pool_with_argmax.ts
function maxPoolWithArgmax_(x, filterSize, strides, pad4, includeBatchInIndex = false) {
  const $x = convertToTensor(x, "x", "maxPoolWithArgmax");
  const inputs = { x: $x };
  const attrs = { filterSize, strides, pad: pad4, includeBatchInIndex };
  const result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
  return { result: result[0], indexes: result[1] };
}
var maxPoolWithArgmax = op({ maxPoolWithArgmax_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/maximum.ts
function maximum_(a, b) {
  let $a = convertToTensor(a, "a", "maximum");
  let $b = convertToTensor(b, "b", "maximum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Maximum, inputs);
}
var maximum = op({ maximum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/mean.ts
function mean_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "mean");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Mean, inputs, attrs);
}
var mean = op({ mean_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/zeros.ts
function zeros(shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = zeros(shape, "float32");
    const imag5 = zeros(shape, "float32");
    return complex(real6, imag5);
  }
  const values = makeZerosTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/ones.ts
function ones2(shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = ones2(shape, "float32");
    const imag5 = zeros(shape, "float32");
    return complex(real6, imag5);
  }
  const values = makeOnesTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/meshgrid.ts
function meshgrid(x, y, { indexing = "xy" } = {}) {
  if (indexing !== "xy" && indexing !== "ij") {
    throw new TypeError(`${indexing} is not a valid third argument to meshgrid`);
  }
  if (x === void 0) {
    return [];
  }
  let $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
  if (y === void 0) {
    return [$x];
  }
  let $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
  const w = sizeFromShape($x.shape);
  const h = sizeFromShape($y.shape);
  if (indexing === "xy") {
    $x = reshape($x, [1, -1]);
    $y = reshape($y, [-1, 1]);
    return [
      matMul(ones2([h, 1], $x.dtype), $x),
      matMul($y, ones2([1, w], $y.dtype))
    ];
  }
  $x = reshape($x, [-1, 1]);
  $y = reshape($y, [1, -1]);
  return [
    matMul($x, ones2([1, h], $x.dtype)),
    matMul(ones2([w, 1], $y.dtype), $y)
  ];
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/min.ts
function min_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "min");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Min, inputs, attrs);
}
var min = op({ min_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/minimum.ts
function minimum_(a, b) {
  let $a = convertToTensor(a, "a", "minimum");
  let $b = convertToTensor(b, "b", "minimum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Minimum, inputs);
}
var minimum = op({ minimum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/mirror_pad.ts
function mirrorPad_(x, paddings, mode) {
  assert(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
  const $x = convertToTensor(x, "x", "mirrorPad");
  if ($x.rank === 0) {
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  }
  assert(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
  const shapeOffset = mode === "reflect" ? 1 : 0;
  for (let i = 0; i < $x.rank; i++) {
    assert(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
    assert(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
  }
  const attrs = { paddings, mode };
  const inputs = { x: $x };
  return ENGINE.runKernel(MirrorPad, inputs, attrs);
}
var mirrorPad = op({ mirrorPad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/mod.ts
function mod_(a, b) {
  let $a = convertToTensor(a, "a", "mod");
  let $b = convertToTensor(b, "b", "mod");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Mod, inputs);
}
var mod = op({ mod_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/square.ts
function square_(x) {
  const $x = convertToTensor(x, "x", "square");
  const attrs = {};
  return ENGINE.runKernel("Square", { x: $x }, attrs);
}
var square = op({ square_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/moments.ts
function moments_(x, axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "moments");
  const axes = parseAxisParam(axis, x.shape);
  const xMean = mean(x, axes, keepDims);
  let keepDimsShape = xMean.shape;
  if (!keepDims) {
    keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
  }
  const devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
  const variance = mean(devSquared, axes, keepDims);
  return { mean: xMean, variance };
}
var moments = op({ moments_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/multi_rnn_cell.ts
function multiRNNCell_(lstmCells, data, c, h) {
  const $data = convertToTensor(data, "data", "multiRNNCell");
  const $c = convertToTensorArray(c, "c", "multiRNNCell");
  const $h = convertToTensorArray(h, "h", "multiRNNCell");
  let input2 = $data;
  const newStates = [];
  for (let i = 0; i < lstmCells.length; i++) {
    const output = lstmCells[i](input2, $c[i], $h[i]);
    newStates.push(output[0]);
    newStates.push(output[1]);
    input2 = output[1];
  }
  const newC = [];
  const newH = [];
  for (let i = 0; i < newStates.length; i += 2) {
    newC.push(newStates[i]);
    newH.push(newStates[i + 1]);
  }
  return [newC, newH];
}
var multiRNNCell = op({ multiRNNCell_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/multinomial.ts
function multinomial_(logits, numSamples, seed, normalized = false) {
  const $logits = convertToTensor(logits, "logits", "multinomial");
  const numOutcomes = $logits.size;
  const origRank = $logits.rank;
  if (numOutcomes < 2) {
    throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${numOutcomes}.`);
  }
  if (origRank > 2) {
    throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`);
  }
  seed = seed || Math.random();
  const logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
  const inputs = { logits: logits2D };
  const attrs = { numSamples, seed, normalized };
  const res = ENGINE.runKernel(Multinomial, inputs, attrs);
  return origRank === 1 ? reshape(res, [res.size]) : res;
}
var multinomial = op({ multinomial_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/not_equal.ts
function notEqual_(a, b) {
  let $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(NotEqual, inputs);
}
var notEqual = op({ notEqual_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/ones_like.ts
function onesLike_(x) {
  const $x = convertToTensor(x, "x", "onesLike");
  const inputs = { x: $x };
  return ENGINE.runKernel(OnesLike, inputs);
}
var onesLike = op({ onesLike_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/outer_product.ts
function outerProduct_(v1, v2) {
  const $v1 = convertToTensor(v1, "v1", "outerProduct");
  const $v2 = convertToTensor(v2, "v2", "outerProduct");
  assert($v1.rank === 1 && $v2.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${$v1.rank} and ${$v2.rank}.`);
  const v12D = reshape($v1, [-1, 1]);
  const v22D = reshape($v2, [1, -1]);
  return matMul(v12D, v22D);
}
var outerProduct = op({ outerProduct_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pad.ts
function pad_(x, paddings, constantValue = 0) {
  const $x = convertToTensor(x, "x", "pad");
  if ($x.rank === 0) {
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  }
  const attrs = { paddings, constantValue };
  const inputs = { x: $x };
  return ENGINE.runKernel(PadV2, inputs, attrs);
}
var pad = op({ pad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pad1d.ts
function pad1d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 2, () => "Invalid number of paddings. Must be length of 2.");
  return pad(x, [paddings], constantValue);
}
var pad1d = op({ pad1d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pad2d.ts
function pad2d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad2d = op({ pad2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pad3d.ts
function pad3d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad3d = op({ pad3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pad4d.ts
function pad4d_(x, paddings, constantValue = 0) {
  assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad(x, paddings, constantValue);
}
var pad4d = op({ pad4d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/space_to_batch_nd.ts
function spaceToBatchND_(x, blockShape, paddings) {
  const $x = convertToTensor(x, "x", "spaceToBatchND");
  assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
  assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
  assert($x.shape.reduce((a, b, i) => {
    if (i > 0 && i <= blockShape.length) {
      return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
    }
    return a;
  }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
  const inputs = { x: $x };
  const attrs = { blockShape, paddings };
  return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
}
var spaceToBatchND = op({ spaceToBatchND_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pool.ts
function pool_(input2, windowShape, poolingType, pad4, dilations, strides) {
  if (dilations == null) {
    dilations = [1, 1];
  }
  if (strides == null) {
    strides = 1;
  }
  if (pad4 === 0) {
    pad4 = "valid";
  }
  const $x = convertToTensor(input2, "x", "maxPool");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad4);
  const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
  let basePadding;
  if (pad4 === "same") {
    basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
  } else {
    basePadding = [[0, 0], [0, 0]];
  }
  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
  const convertedPad = isDilationOne ? pad4 : "valid";
  const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
  const forwardOp = poolingType === "avg" ? () => avgPool(convertedX, windowShape, strides, convertedPad) : () => maxPool(convertedX, windowShape, strides, convertedPad);
  const y = forwardOp();
  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
  const padStart = basePadding.map((b) => b[0]);
  const origPadEnd = basePadding.map((b) => b[1]);
  const fullInputShape = inputShape.concat(padStart, origPadEnd);
  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);
  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);
  return [paddings, crops];
}
function withSpaceToBatchBasePaddings(filterShape, dilation) {
  const dilatedFilterShape = filterShape.map((s, i) => {
    return s + (s - 1) * (dilation[i] - 1);
  });
  const padExtraShape = dilatedFilterShape.map((s) => s - 1);
  const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
  return padExtraShape.map((_, i) => {
    return [padExtraStart[i], padExtraEnd[i]];
  });
}
var pool = op({ pool_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/pow.ts
function pow_(base3, exp6) {
  let $base = convertToTensor(base3, "base", "pow");
  let $exp = convertToTensor(exp6, "exp", "pow");
  [$base, $exp] = makeTypesMatch($base, $exp);
  const inputs = { a: $base, b: $exp };
  return ENGINE.runKernel(Pow, inputs);
}
var pow = op({ pow_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/prelu.ts
function prelu_(x, alpha) {
  const $x = convertToTensor(x, "x", "prelu");
  const $alpha = convertToTensor(alpha, "alpha", "prelu");
  const inputs = { x: $x, alpha: $alpha };
  return ENGINE.runKernel(Prelu, inputs);
}
var prelu = op({ prelu_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/prod.ts
function prod_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "prod");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Prod, inputs, attrs);
}
var prod = op({ prod_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/rand.ts
function rand_(shape, randFunction, dtype) {
  const size = sizeFromShape(shape);
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  for (let i = 0; i < size; i++) {
    values[i] = randFunction();
  }
  return ENGINE.makeTensor(values, shape, dtype);
}
var rand = op({ rand_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/rand_util.ts
var seedrandom = __toModule(require_seedrandom2());
var MPRandGauss = class {
  constructor(mean5, stdDeviation, dtype, truncated, seed) {
    this.mean = mean5;
    this.stdDev = stdDeviation;
    this.dtype = dtype;
    this.nextVal = NaN;
    this.truncated = truncated;
    if (this.truncated) {
      this.upper = this.mean + this.stdDev * 2;
      this.lower = this.mean - this.stdDev * 2;
    }
    const seedValue = seed ? seed : Math.random();
    this.random = seedrandom.alea(seedValue.toString());
  }
  nextValue() {
    if (!isNaN(this.nextVal)) {
      const value = this.nextVal;
      this.nextVal = NaN;
      return value;
    }
    let resultX, resultY;
    let isValid = false;
    while (!isValid) {
      let v1, v2, s;
      do {
        v1 = 2 * this.random() - 1;
        v2 = 2 * this.random() - 1;
        s = v1 * v1 + v2 * v2;
      } while (s >= 1 || s === 0);
      const mul3 = Math.sqrt(-2 * Math.log(s) / s);
      resultX = this.mean + this.stdDev * v1 * mul3;
      resultY = this.mean + this.stdDev * v2 * mul3;
      if (!this.truncated || this.isValidTruncated(resultX)) {
        isValid = true;
      }
    }
    if (!this.truncated || this.isValidTruncated(resultY)) {
      this.nextVal = this.convertValue(resultY);
    }
    return this.convertValue(resultX);
  }
  convertValue(value) {
    if (this.dtype == null || this.dtype === "float32") {
      return value;
    }
    return Math.round(value);
  }
  isValidTruncated(value) {
    return value <= this.upper && value >= this.lower;
  }
};
var RandGamma = class {
  constructor(alpha, beta, dtype, seed) {
    this.alpha = alpha;
    this.beta = 1 / beta;
    this.dtype = dtype;
    const seedValue = seed ? seed : Math.random();
    this.randu = seedrandom.alea(seedValue.toString());
    this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
    if (alpha < 1) {
      this.d = alpha + 2 / 3;
    } else {
      this.d = alpha - 1 / 3;
    }
    this.c = 1 / Math.sqrt(9 * this.d);
  }
  nextValue() {
    let x2, v0, v1, x, u, v;
    while (true) {
      do {
        x = this.randn.nextValue();
        v = 1 + this.c * x;
      } while (v <= 0);
      v *= v * v;
      x2 = x * x;
      v0 = 1 - 0.331 * x2 * x2;
      v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
      u = this.randu();
      if (u < v0 || Math.log(u) < v1) {
        break;
      }
    }
    v = 1 / this.beta * this.d * v;
    if (this.alpha < 1) {
      v *= Math.pow(this.randu(), 1 / this.alpha);
    }
    return this.convertValue(v);
  }
  convertValue(value) {
    if (this.dtype === "float32") {
      return value;
    }
    return Math.round(value);
  }
};
var UniformRandom = class {
  constructor(min7 = 0, max7 = 1, dtype, seed) {
    this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
    this.min = min7;
    this.range = max7 - min7;
    this.dtype = dtype;
    if (seed == null) {
      seed = Math.random();
    }
    if (typeof seed === "number") {
      seed = seed.toString();
    }
    if (!this.canReturnFloat() && this.range <= 1) {
      throw new Error(`The difference between ${min7} - ${max7} <= 1 and dtype is not float`);
    }
    this.random = seedrandom.alea(seed);
  }
  convertValue(value) {
    if (this.canReturnFloat()) {
      return value;
    }
    return Math.round(value);
  }
  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/random_gamma.ts
function randomGamma_(shape, alpha, beta = 1, dtype = "float32", seed) {
  if (beta == null) {
    beta = 1;
  }
  if (dtype == null) {
    dtype = "float32";
  }
  if (dtype !== "float32" && dtype !== "int32") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const rgamma = new RandGamma(alpha, beta, dtype, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = rgamma.nextValue();
  }
  return res.toTensor();
}
var randomGamma = op({ randomGamma_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/random_normal.ts
function randomNormal_(shape, mean5 = 0, stdDev = 1, dtype, seed) {
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const randGauss = new MPRandGauss(mean5, stdDev, dtype, false, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var randomNormal = op({ randomNormal_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/random_uniform.ts
function randomUniform_(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
  const res = buffer(shape, dtype);
  const random = new UniformRandom(minval, maxval, null, seed);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = random.nextValue();
  }
  return res.toTensor();
}
var randomUniform = op({ randomUniform_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/range.ts
function range(start, stop, step6 = 1, dtype = "float32") {
  if (step6 === 0) {
    throw new Error("Cannot have a step of zero");
  }
  const attrs = { start, stop, step: step6, dtype };
  return ENGINE.runKernel(Range, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/real.ts
function real_(input2) {
  const $input = convertToTensor(input2, "input", "real");
  const inputs = { input: $input };
  return ENGINE.runKernel(Real, inputs);
}
var real = op({ real_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reciprocal.ts
function reciprocal_(x) {
  const $x = convertToTensor(x, "x", "reciprocal");
  const inputs = { x: $x };
  return ENGINE.runKernel(Reciprocal, inputs);
}
var reciprocal = op({ reciprocal_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/relu.ts
function relu_(x) {
  const $x = convertToTensor(x, "x", "relu");
  const inputs = { x: $x };
  return ENGINE.runKernel(Relu, inputs);
}
var relu = op({ relu_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/relu6.ts
function relu6_(x) {
  const $x = convertToTensor(x, "x", "relu6");
  const inputs = { x: $x };
  return ENGINE.runKernel(Relu6, inputs);
}
var relu6 = op({ relu6_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reverse.ts
function reverse_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  const inputs = { x: $x };
  const attrs = { dims: axis };
  return ENGINE.runKernel(Reverse, inputs, attrs);
}
var reverse = op({ reverse_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reverse_1d.ts
function reverse1d_(x) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`);
  return reverse($x, 0);
}
var reverse1d = op({ reverse1d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reverse_2d.ts
function reverse2d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse2d = op({ reverse2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reverse_3d.ts
function reverse3d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse3d = op({ reverse3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reverse_4d.ts
function reverse4d_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  assert($x.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`);
  return reverse($x, axis);
}
var reverse4d = op({ reverse4d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/round.ts
function round_(x) {
  const $x = convertToTensor(x, "x", "round");
  const inputs = { x: $x };
  return ENGINE.runKernel(Round, inputs);
}
var round2 = op({ round_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/rsqrt.ts
function rsqrt_(x) {
  const $x = convertToTensor(x, "x", "rsqrt");
  const inputs = { x: $x };
  return ENGINE.runKernel(Rsqrt, inputs);
}
var rsqrt = op({ rsqrt_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/scalar.ts
function scalar(value, dtype) {
  if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  }
  if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  }
  const shape = [];
  const inferredShape = [];
  return makeTensor(value, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/selu.ts
function selu_(x) {
  const $x = convertToTensor(x, "x", "selu");
  const inputs = { x: $x };
  return ENGINE.runKernel(Selu, inputs);
}
var selu = op({ selu_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/separable_conv2d.ts
function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad4, dilation = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "separableConv2d");
  const $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
  const $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  if (dataFormat === "NCHW") {
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  }
  assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
  assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
  const inChannels = $depthwiseFilter.shape[2];
  const channelMultiplier = $depthwiseFilter.shape[3];
  assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
  const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad4, dataFormat, dilation);
  const pointwiseStride = 1;
  const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var separableConv2d = op({ separableConv2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/setdiff1d_async.ts
async function setdiff1dAsync_(x, y) {
  const $x = convertToTensor(x, "x", "setdiff1d");
  const $y = convertToTensor(y, "y", "setdiff1d");
  assert($x.dtype === $y.dtype, () => `x and y should have the same dtype, but got x (${$x.dtype}) and y (${$y.dtype}).`);
  assert($x.rank === 1, () => `x should be 1D tensor, but got x (${$x.shape}).`);
  assert($y.rank === 1, () => `y should be 1D tensor, but got y (${$y.shape}).`);
  const xVals = await $x.data();
  const yVals = await $y.data();
  const ySet = new Set(yVals);
  let outputSize = 0;
  for (let i = 0; i < xVals.length; i++) {
    if (!ySet.has(xVals[i])) {
      outputSize++;
    }
  }
  const buffer3 = new TensorBuffer([outputSize], $x.dtype);
  const indices = new TensorBuffer([outputSize], "int32");
  for (let i = 0, p2 = 0; i < xVals.length; i++) {
    if (!ySet.has(xVals[i])) {
      buffer3.values[p2] = xVals[i];
      indices.values[p2] = i;
      p2++;
    }
  }
  return [buffer3.toTensor(), indices.toTensor()];
}
var setdiff1dAsync = setdiff1dAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sign.ts
function sign_(x) {
  const $x = convertToTensor(x, "x", "sign");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sign, inputs);
}
var sign = op({ sign_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sin.ts
function sin_(x) {
  const $x = convertToTensor(x, "x", "sin");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sin, inputs);
}
var sin = op({ sin_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sinh.ts
function sinh_(x) {
  const $x = convertToTensor(x, "x", "sinh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sinh, inputs);
}
var sinh = op({ sinh_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice1d.ts
function slice1d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice1d");
  assert($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, [begin], [size]);
}
var slice1d = op({ slice1d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice2d.ts
function slice2d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice2d");
  assert($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice2d = op({ slice2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice3d.ts
function slice3d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice3d");
  assert($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice3d = op({ slice3d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/slice4d.ts
function slice4d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice4d");
  assert($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice4d = op({ slice4d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/softmax.ts
function softmax_(logits, dim = -1) {
  const $logits = convertToTensor(logits, "logits", "softmax", "float32");
  if (dim === -1) {
    dim = $logits.rank - 1;
  }
  if (dim !== $logits.rank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
  }
  const inputs = { logits: $logits };
  const attrs = { dim };
  return ENGINE.runKernel(Softmax, inputs, attrs);
}
var softmax = op({ softmax_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/spectral/fft.ts
function fft_(input2) {
  assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE.runKernel(FFT, inputs);
}
var fft = op({ fft_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/spectral/ifft.ts
function ifft_(input2) {
  assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE.runKernel(IFFT, inputs);
}
var ifft = op({ ifft_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/spectral/irfft.ts
function irfft_(input2) {
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let ret;
  if (innerDimensionSize <= 2) {
    const complexInput = reshape(input2, [batch, innerDimensionSize]);
    ret = ifft(complexInput);
  } else {
    const outputShape = [batch, 2 * (innerDimensionSize - 1)];
    const realInput = reshape(real(input2), [batch, innerDimensionSize]);
    const imagInput = reshape(imag(input2), [batch, innerDimensionSize]);
    const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
    const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
    const r = concat([realInput, realConjugate], 1);
    const i = concat([imagInput, imagConjugate], 1);
    const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
    ret = ifft(complexInput);
  }
  ret = real(ret);
  if (input2.rank === 3 && input2.shape[0] !== 0) {
    const temp = ret;
    const batch2 = input2.shape[0];
    ret = reshape(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
    temp.dispose();
  }
  return ret;
}
var irfft = op({ irfft_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/split.ts
function split_(x, numOrSizeSplits, axis = 0) {
  const $x = convertToTensor(x, "x", "split");
  const inputs = { x: $x };
  const attr = { numOrSizeSplits, axis };
  return ENGINE.runKernel(SplitV, inputs, attr);
}
var split = op({ split_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/spectral/rfft.ts
function rfft_(input2, fftLength) {
  assert(input2.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input2.dtype}`);
  let innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let adjustedInput;
  if (fftLength != null && fftLength < innerDimensionSize) {
    const begin = input2.shape.map((v) => 0);
    const size = input2.shape.map((v) => v);
    size[input2.shape.length - 1] = fftLength;
    adjustedInput = slice(input2, begin, size);
    innerDimensionSize = fftLength;
  } else if (fftLength != null && fftLength > innerDimensionSize) {
    const zerosShape = input2.shape.map((v) => v);
    zerosShape[input2.shape.length - 1] = fftLength - innerDimensionSize;
    adjustedInput = concat([input2, zeros(zerosShape)], input2.shape.length - 1);
    innerDimensionSize = fftLength;
  } else {
    adjustedInput = input2;
  }
  const zerosInput = zerosLike(adjustedInput);
  const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
  const ret = fft(complexInput);
  const half = Math.floor(innerDimensionSize / 2) + 1;
  const realValues = real(ret);
  const imagValues = imag(ret);
  const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
  const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
  const outputShape = adjustedInput.shape.slice();
  outputShape[adjustedInput.shape.length - 1] = half;
  return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
}
var rfft = op({ rfft_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sqrt.ts
function sqrt_(x) {
  const $x = convertToTensor(x, "x", "sqrt");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sqrt, inputs);
}
var sqrt = op({ sqrt_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/squared_difference.ts
function squaredDifference_(a, b) {
  let $a = convertToTensor(a, "a", "squaredDifference");
  let $b = convertToTensor(b, "b", "squaredDifference");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE.runKernel(SquaredDifference, inputs, attrs);
}
var squaredDifference = op({ squaredDifference_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/squeeze.ts
function squeeze_(x, axis) {
  const $x = convertToTensor(x, "x", "squeeze");
  return reshape($x, squeezeShape($x.shape, axis).newShape);
}
var squeeze = op({ squeeze_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/stack.ts
function stack_(tensors, axis = 0) {
  const $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
  assert($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
  if ($tensors.length > 0) {
    assert(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
  }
  const inputs = $tensors;
  const attrs = { axis };
  return ENGINE.runKernel(Pack, inputs, attrs);
}
var stack = op({ stack_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/step.ts
function step_(x, alpha = 0) {
  const $x = convertToTensor(x, "x", "step");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE.runKernel(Step, inputs, attrs);
}
var step = op({ step_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/strided_slice.ts
function stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
  const $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  return ENGINE.runKernel(StridedSlice, inputs, attrs);
}
var stridedSlice = op({ stridedSlice_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tan.ts
function tan_(x) {
  const $x = convertToTensor(x, "x", "tan");
  const inputs = { x: $x };
  return ENGINE.runKernel(Tan, inputs);
}
var tan = op({ tan_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor1d.ts
function tensor1d(values, dtype) {
  assertNonNull(values);
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 1) {
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  }
  const shape = null;
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor2d.ts
function tensor2d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 2) {
    throw new Error("tensor2d() requires shape to have two numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 2 && inferredShape.length !== 1) {
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor4d.ts
function tensor4d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 4) {
    throw new Error("tensor4d() requires shape to have four numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 4 && inferredShape.length !== 1) {
    throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor5d.ts
function tensor5d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 5) {
    throw new Error("tensor5d() requires shape to have five numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 5 && inferredShape.length !== 1) {
    throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/tensor6d.ts
function tensor6d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 6) {
    throw new Error("tensor6d() requires shape to have six numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 6 && inferredShape.length !== 1) {
    throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  }
  shape = shape || inferredShape;
  return makeTensor(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/topk.ts
function topk_(x, k = 1, sorted = true) {
  const $x = convertToTensor(x, "x", "topk");
  if ($x.rank === 0) {
    throw new Error("topk() expects the input to be of rank 1 or higher");
  }
  const lastDim = $x.shape[$x.shape.length - 1];
  if (k > lastDim) {
    throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k}`);
  }
  const inputs = { x: $x };
  const attrs = { k, sorted };
  const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);
  return { values, indices };
}
var topk = op({ topk_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/truncated_normal.ts
function truncatedNormal_(shape, mean5 = 0, stdDev = 1, dtype, seed) {
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type $ { dtype }`);
  }
  const randGauss = new MPRandGauss(mean5, stdDev, dtype, true, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var truncatedNormal = op({ truncatedNormal_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/unique.ts
function unique_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unique", "string_or_numeric");
  assert($x.rank > 0, () => "The input tensor must be at least 1D");
  const inputs = { x: $x };
  const attrs = { axis };
  const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);
  return { values, indices };
}
var unique = op({ unique_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/unsorted_segment_sum.ts
function unsortedSegmentSum_(x, segmentIds, numSegments) {
  const $x = convertToTensor(x, "x", "unsortedSegmentSum");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
  assert(isInt(numSegments), () => "numSegments must be of dtype int");
  const inputs = { x: $x, segmentIds: $segmentIds };
  const attrs = { numSegments };
  return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
}
var unsortedSegmentSum = op({ unsortedSegmentSum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/unstack.ts
function unstack_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
  assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
  const inputs = { value: $x };
  const attrs = { axis };
  return ENGINE.runKernel(Unpack, inputs, attrs);
}
var unstack = op({ unstack_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/variable.ts
function variable(initialValue, trainable = true, name, dtype) {
  return ENGINE.makeVariable(initialValue, trainable, name, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/where_impl.ts
function whereImpl(condShape, condVals) {
  const indices = [];
  for (let i = 0; i < condVals.length; i++) {
    if (condVals[i]) {
      indices.push(i);
    }
  }
  const inBuffer = buffer(condShape, "int32");
  const out = buffer([indices.length, condShape.length], "int32");
  for (let i = 0; i < indices.length; i++) {
    const loc = inBuffer.indexToLoc(indices[i]);
    const offset = i * condShape.length;
    out.values.set(loc, offset);
  }
  return out.toTensor();
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/where_async.ts
async function whereAsync_(condition) {
  const $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
  const vals = await $condition.data();
  const res = whereImpl($condition.shape, vals);
  if (condition !== $condition) {
    $condition.dispose();
  }
  return res;
}
var whereAsync = whereAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/boolean_mask.ts
async function booleanMaskAsync_(tensor3, mask, axis) {
  const $tensor = convertToTensor(tensor3, "tensor", "boolMask");
  const $mask = convertToTensor(mask, "mask", "boolMask", "bool");
  const axisFrom = axis == null ? 0 : axis;
  const maskDim = $mask.rank;
  const tensorShape = $tensor.shape;
  assert(maskDim > 0, () => "mask cannot be scalar");
  assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, `mask's shape must match the first K dimensions of tensor's shape,`);
  let leadingSize = 1;
  for (let i = axisFrom; i < axisFrom + maskDim; i++) {
    leadingSize *= tensorShape[i];
  }
  const targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
  const reshapedTensor = reshape($tensor, targetTensorShape);
  const reshapedMask = reshape($mask, [-1]);
  const positivePositions = await whereAsync(reshapedMask);
  const indices = squeeze(positivePositions, [1]);
  const res = gather(reshapedTensor, indices, axisFrom);
  if (tensor3 !== $tensor) {
    $tensor.dispose();
  }
  if (mask !== $mask) {
    $mask.dispose();
  }
  indices.dispose();
  reshapedTensor.dispose();
  reshapedMask.dispose();
  positivePositions.dispose();
  return res;
}
var booleanMaskAsync = booleanMaskAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/norm.ts
function norm_(x, ord = "euclidean", axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "norm");
  const norm3 = normImpl(x, ord, axis);
  let keepDimsShape = norm3.shape;
  if (keepDims) {
    const axes = parseAxisParam(axis, x.shape);
    keepDimsShape = expandShapeToKeepDim(norm3.shape, axes);
  }
  return reshape(norm3, keepDimsShape);
}
function normImpl(x, p2, axis = null) {
  if (x.rank === 0) {
    return abs(x);
  }
  if (x.rank !== 1 && axis === null) {
    return normImpl(reshape(x, [-1]), p2, axis);
  }
  if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
    if (p2 === 1) {
      return sum2(abs(x), axis);
    }
    if (p2 === Infinity) {
      return max(abs(x), axis);
    }
    if (p2 === -Infinity) {
      return min(abs(x), axis);
    }
    if (p2 === "euclidean" || p2 === 2) {
      return sqrt(sum2(pow(abs(x), scalar(2, "int32")), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  if (Array.isArray(axis) && axis.length === 2) {
    if (p2 === 1) {
      return max(sum2(abs(x), axis[0]), axis[1] - 1);
    }
    if (p2 === Infinity) {
      return max(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p2 === -Infinity) {
      return min(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p2 === "fro" || p2 === "euclidean") {
      return sqrt(sum2(square(x), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  throw new Error(`Error in norm: invalid axis: ${axis}`);
}
var norm = op({ norm_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/moving_average.ts
function movingAverage_(v, x, decay, step6, zeroDebias = true) {
  const $v = convertToTensor(v, "v", "movingAverage");
  const $x = convertToTensor(x, "x", "movingAverage");
  const $decay = convertToTensor(decay, "decay", "movingAverage");
  assertTypesMatch($v, $x);
  assert(arraysEqual($v.shape, $x.shape), () => "Shape mismatch in v and x");
  const one = scalar(1);
  const oneMinusDecay = sub(one, $decay);
  let update = mul(sub($x, $v), oneMinusDecay);
  if (zeroDebias) {
    assert(step6 != null, () => "When using zeroDebias: true, step is required.");
    const $step = convertToTensor(step6, "step", "movingAverage");
    update = div(update, sub(one, pow($decay, $step)));
  }
  return add2($v, update);
}
var movingAverage = op({ movingAverage_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/scatter_nd.ts
function scatterND_(indices, updates, shape) {
  const $indices = convertToTensor(indices, "indices", "scatterND", "int32");
  const $updates = convertToTensor(updates, "updates", "scatterND");
  validateInput($updates, $indices, shape);
  const inputs = { indices: $indices, updates: $updates };
  const attrs = { shape };
  return ENGINE.runKernel(ScatterNd, inputs, attrs);
}
var scatterND = op({ scatterND_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse_to_dense_util.ts
function validateInput2(sparseIndices, sparseValues, outputShape, defaultValues) {
  if (sparseIndices.dtype !== "int32") {
    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${sparseIndices.dtype}.`);
  }
  if (sparseIndices.rank > 2) {
    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${sparseIndices.shape}.`);
  }
  const numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
  const numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
  if (outputShape.length !== numDims) {
    throw new Error(`outputShape has incorrect number of elements:, ${outputShape.length}, should be: ${numDims}.`);
  }
  const numValues = sparseValues.size;
  if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
    throw new Error(`sparseValues has incorrect shape ${sparseValues.shape}, should be [] or [${numElems}]`);
  }
  if (sparseValues.dtype !== defaultValues.dtype) {
    throw new Error("sparseValues.dtype must match defaultValues.dtype");
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse_to_dense.ts
function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue = 0) {
  const $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
  const $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense");
  const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
  validateInput2($sparseIndices, $sparseValues, outputShape, $defaultValue);
  const inputs = {
    sparseIndices: $sparseIndices,
    sparseValues: $sparseValues,
    defaultValue: $defaultValue
  };
  const attrs = { outputShape };
  return ENGINE.runKernel(SparseToDense, inputs, attrs);
}
var sparseToDense = op({ sparseToDense_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/gather_nd.ts
function gatherND_(x, indices) {
  const $indices = convertToTensor(indices, "indices", "gatherND", "int32");
  const $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
  const inputs = { params: $x, indices: $indices };
  return ENGINE.runKernel(GatherNd, inputs);
}
var gatherND = op({ gatherND_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/dropout_util.ts
function getNoiseShape(x, noiseShape) {
  if (noiseShape == null) {
    return x.shape.slice();
  }
  if (arraysEqual(x.shape, noiseShape)) {
    return noiseShape;
  }
  if (x.shape.length === noiseShape.length) {
    const newDimension = [];
    for (let i = 0; i < x.shape.length; i++) {
      if (noiseShape[i] == null && x.shape[i] != null) {
        newDimension.push(x.shape[i]);
      } else {
        newDimension.push(noiseShape[i]);
      }
    }
    return newDimension;
  }
  return noiseShape;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/dropout.ts
function dropout_(x, rate, noiseShape, seed) {
  const $x = convertToTensor(x, "x", "dropout");
  assert($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
  assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
  if (rate === 0) {
    return x instanceof Tensor ? $x.clone() : $x;
  }
  const $noiseShape = getNoiseShape($x, noiseShape);
  const keepProb = 1 - rate;
  const multiplier = div(floor(add2(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
  return mul($x, multiplier);
}
var dropout = op({ dropout_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/signal_ops_util.ts
function enclosingPowerOfTwo(value) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
}
function cosineWindow(windowLength, a, b) {
  const even = 1 - windowLength % 2;
  const newValues = new Float32Array(windowLength);
  for (let i = 0; i < windowLength; ++i) {
    const cosArg = 2 * Math.PI * i / (windowLength + even - 1);
    newValues[i] = a - b * Math.cos(cosArg);
  }
  return tensor1d(newValues, "float32");
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/in_top_k.ts
async function inTopKAsync_(predictions, targets, k = 1) {
  const $predictions = convertToTensor(predictions, "predictions", "inTopK");
  const $targets = convertToTensor(targets, "targets", "inTopK");
  assert($predictions.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${$predictions.rank}`);
  assert($predictions.rank - 1 === $targets.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${$predictions.rank} and targets rank ${$targets.rank}`);
  assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, `predictions's shape should be align with the targets' shape, except the last dimension.`);
  const lastDim = $predictions.shape[$predictions.shape.length - 1];
  assert(k > 0 && k <= lastDim, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${lastDim}), but got ${k}`);
  const predictionsVals = await $predictions.data();
  const targetsVals = await $targets.data();
  const [batch, size] = [predictionsVals.length / lastDim, lastDim];
  const precision3 = getTypedArrayFromDType("bool", batch);
  for (let b = 0; b < batch; b++) {
    const offset = b * size;
    const vals = predictionsVals.subarray(offset, offset + size);
    const valAndInd = [];
    for (let i = 0; i < vals.length; i++) {
      valAndInd.push({ value: vals[i], index: i });
    }
    valAndInd.sort((a, b2) => b2.value - a.value);
    precision3[b] = 0;
    for (let i = 0; i < k; i++) {
      if (valAndInd[i].index === targetsVals[b]) {
        precision3[b] = 1;
        break;
      }
    }
  }
  if (predictions !== $predictions) {
    $predictions.dispose();
  }
  if (targets !== $targets) {
    $targets.dispose();
  }
  return tensor(precision3, $targets.shape, "bool");
}
var inTopKAsync = inTopKAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fused_ops.ts
var fused_ops_exports = {};
__export(fused_ops_exports, {
  conv2d: () => conv2d2,
  depthwiseConv2d: () => depthwiseConv2d2,
  matMul: () => matMul2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/conv2d_backprop_filter.ts
function conv2DBackpropFilter_(x, dy, filterShape, strides, pad4, dataFormat = "NHWC", dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
  assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
  assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad4, dataFormat, dimRoundingMode, filterShape };
  return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
}
var conv2DBackpropFilter = op({ conv2DBackpropFilter_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fused_util.ts
function getFusedDyActivation(dy, y, activation2) {
  if (activation2 == null || activation2 === "linear") {
    return dy;
  }
  if (activation2 === "relu") {
    return mul(dy, step(y));
  }
  throw new Error(`Cannot compute gradient for fused activation ${activation2}.`);
}
function getFusedBiasGradient(bias, dyActivation) {
  let res = dyActivation;
  const reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
  if (reduceAxes.length > 0) {
    res = sum2(res, reduceAxes);
  }
  return reshape(res, bias.shape);
}
function applyActivation(x, activation2, preluActivationWeights, leakyreluAlpha) {
  if (activation2 === "linear") {
    return x;
  } else if (activation2 === "relu") {
    return relu(x);
  } else if (activation2 === "elu") {
    return elu(x);
  } else if (activation2 === "relu6") {
    return relu6(x);
  } else if (activation2 === "prelu") {
    return prelu(x, preluActivationWeights);
  } else if (activation2 === "leakyrelu") {
    return leakyRelu(x, leakyreluAlpha);
  } else if (activation2 === "sigmoid") {
    return sigmoid(x);
  }
  throw new Error(`Unknown fused activation ${activation2}.`);
}
var shouldFuse = (gradientDepth, activation2) => {
  const gradientMode = gradientDepth > 0;
  return !gradientMode || activation2 === "linear";
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fused/conv2d.ts
function fusedConv2d_({
  x,
  filter,
  strides,
  pad: pad4,
  dataFormat = "NHWC",
  dilations = [1, 1],
  dimRoundingMode,
  bias,
  activation: activation2 = "linear",
  preluActivationWeights,
  leakyreluAlpha
}) {
  activation2 = activation2 || "linear";
  if (shouldFuse(ENGINE.state.gradientDepth, activation2) === false) {
    let result = conv2d(x, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "conv2d");
  const $filter = convertToTensor(filter, "filter", "conv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in conv2d: depth of input (${x4D.shape[3]}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(dataFormat === "NHWC", () => `Error in conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
  const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad4, dimRoundingMode);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
  }
  const grad3 = (dy, saved) => {
    const [$filter2, x4D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation2);
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    const xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad4);
    const filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad4);
    const der = [xDer, filterDer];
    if ($bias2 != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      der.push(biasDer);
    }
    return der;
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var conv2d2 = op({ fusedConv2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/depthwise_conv2d_native_backprop_filter.ts
function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad4, dilations = [1, 1], dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad4, dimRoundingMode, dilations, filterShape };
  return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
}
var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/depthwise_conv2d_native_backprop_input.ts
function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad4, dilations = [1, 1], dimRoundingMode) {
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad4, dimRoundingMode, dilations, inputShape: xShape };
  const res = ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fused/depthwise_conv2d.ts
function fusedDepthwiseConv2d_({
  x,
  filter,
  strides,
  pad: pad4,
  dataFormat = "NHWC",
  dilations = [1, 1],
  dimRoundingMode,
  bias,
  activation: activation2 = "linear",
  preluActivationWeights,
  leakyreluAlpha
}) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation2) === false) {
    let result = depthwiseConv2d(x, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "depthwiseConv2d");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dilations == null) {
    dilations = [1, 1];
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  if (dimRoundingMode != null) {
    assert(isInt(pad4), () => `Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad4, dimRoundingMode, true);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
  }
  const grad3 = (dy, saved) => {
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
    const [$filter2, x4D2, y, bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation2);
    const xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad4, dilations, dimRoundingMode);
    const filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad4, dilations, dimRoundingMode);
    if (bias2 != null) {
      const biasDer = getFusedBiasGradient($bias, dyActivation);
      return [xDer, filterDer, biasDer];
    }
    return [xDer, filterDer];
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var depthwiseConv2d2 = op({ fusedDepthwiseConv2d_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/fused/mat_mul.ts
function fusedMatMul_({
  a,
  b,
  transposeA = false,
  transposeB = false,
  bias,
  activation: activation2 = "linear",
  preluActivationWeights,
  leakyreluAlpha
}) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation2) === false) {
    let result = matMul(a, b, transposeA, transposeB);
    if (bias != null) {
      result = add2(result, bias);
    }
    return applyActivation(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  let $a = convertToTensor(a, "a", "fused matMul");
  let $b = convertToTensor(b, "b", "fused matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
  const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
  const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
  const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
  const outerDimsA = $a.shape.slice(0, -2);
  const outerDimsB = $b.shape.slice(0, -2);
  const batchDimA = sizeFromShape(outerDimsA);
  const batchDimB = sizeFromShape(outerDimsB);
  assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, () => `Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${$a.rank} and ${$b.rank}.`);
  assert(arraysEqual(outerDimsA, outerDimsB), () => `Error in fused matMul: outer dimensions (${outerDimsA}) and (${outerDimsB}) of Tensors with shapes ${$a.shape} and ${$b.shape} must match.`);
  assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);
  const a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
  const b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused matMul");
    [$bias] = makeTypesMatch($bias, $a);
    assertAndGetBroadcastShape(outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
  }
  const grad3 = (dy, saved) => {
    const [a3D2, b3D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation2);
    let aDer;
    let bDer;
    if (!transposeA && !transposeB) {
      aDer = matMul(dyActivation, b3D2, false, true);
      bDer = matMul(a3D2, dyActivation, true, false);
    } else if (!transposeA && transposeB) {
      aDer = matMul(dyActivation, b3D2, false, false);
      bDer = matMul(dyActivation, a3D2, true, false);
    } else if (transposeA && !transposeB) {
      aDer = matMul(b3D2, dyActivation, false, true);
      bDer = matMul(a3D2, dyActivation, false, false);
    } else {
      aDer = matMul(b3D2, dyActivation, true, true);
      bDer = matMul(dyActivation, a3D2, true, true);
    }
    if (bias != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      return [aDer, bDer, biasDer];
    } else {
      return [aDer, bDer];
    }
  };
  const inputs = {
    a: a3D,
    b: b3D,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = { transposeA, transposeB, activation: activation2, leakyreluAlpha };
  if (bias == null) {
    const customOp = customGrad((a3D2, b3D2, save) => {
      const res = ENGINE.runKernel(_FusedMatMul, inputs, attrs);
      save([a3D2, b3D2, res]);
      return { value: reshape(res, outShape), gradFunc: grad3 };
    });
    return customOp(a3D, b3D);
  } else {
    const customOpWithBias = customGrad((a3D2, b3D2, $bias2, save) => {
      const res = ENGINE.runKernel(_FusedMatMul, inputs, attrs);
      save([a3D2, b3D2, res, $bias2]);
      return { value: reshape(res, outShape), gradFunc: grad3 };
    });
    return customOpWithBias(a3D, b3D, $bias);
  }
}
var matMul2 = op({ fusedMatMul_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/signal/hamming_window.ts
function hammingWindow_(windowLength) {
  return cosineWindow(windowLength, 0.54, 0.46);
}
var hammingWindow = op({ hammingWindow_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/signal/hann_window.ts
function hannWindow_(windowLength) {
  return cosineWindow(windowLength, 0.5, 0.5);
}
var hannWindow = op({ hannWindow_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/signal/frame.ts
function frame_(signal2, frameLength, frameStep, padEnd = false, padValue = 0) {
  let start = 0;
  const output = [];
  while (start + frameLength <= signal2.size) {
    output.push(slice(signal2, start, frameLength));
    start += frameStep;
  }
  if (padEnd) {
    while (start < signal2.size) {
      const padLen = start + frameLength - signal2.size;
      const pad4 = concat([
        slice(signal2, start, frameLength - padLen),
        fill([padLen], padValue)
      ]);
      output.push(pad4);
      start += frameStep;
    }
  }
  if (output.length === 0) {
    return tensor2d([], [0, frameLength]);
  }
  return reshape(concat(output), [output.length, frameLength]);
}
var frame = op({ frame_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/signal/stft.ts
function stft_(signal2, frameLength, frameStep, fftLength, windowFn = hannWindow) {
  if (fftLength == null) {
    fftLength = enclosingPowerOfTwo(frameLength);
  }
  const framedSignal = frame(signal2, frameLength, frameStep);
  const windowedSignal = mul(framedSignal, windowFn(frameLength));
  return rfft(windowedSignal, fftLength);
}
var stft = op({ stft_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/crop_and_resize.ts
function cropAndResize_(image4, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
  const $image = convertToTensor(image4, "image", "cropAndResize");
  const $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
  const $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
  const numBoxes = $boxes.shape[0];
  assert($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
  assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
  assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
  assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
  assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
  assert(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
  const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
  const attrs = { method, extrapolationValue, cropSize };
  const res = ENGINE.runKernel(CropAndResize, inputs, attrs);
  return res;
}
var cropAndResize = op({ cropAndResize_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/flip_left_right.ts
function flipLeftRight_(image4) {
  const $image = convertToTensor(image4, "image", "flipLeftRight", "float32");
  assert($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const res = ENGINE.runKernel(FlipLeftRight, inputs, {});
  return res;
}
var flipLeftRight = op({ flipLeftRight_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/rotate_with_offset.ts
function rotateWithOffset_(image4, radians, fillValue = 0, center = 0.5) {
  const $image = convertToTensor(image4, "image", "rotateWithOffset", "float32");
  assert($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const attrs = { radians, fillValue, center };
  const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
  return res;
}
var rotateWithOffset = op({ rotateWithOffset_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/nonmax_util.ts
function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  if (iouThreshold == null) {
    iouThreshold = 0.5;
  }
  if (scoreThreshold == null) {
    scoreThreshold = Number.NEGATIVE_INFINITY;
  }
  if (softNmsSigma == null) {
    softNmsSigma = 0;
  }
  const numBoxes = boxes.shape[0];
  maxOutputSize = Math.min(maxOutputSize, numBoxes);
  assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
  assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
  assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
  assert(scores.rank === 1, () => "scores must be a 1D tensor");
  assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
  assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
  return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression.ts
function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold };
  return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
}
var nonMaxSuppression = op({ nonMaxSuppression_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/non_max_suppression_util.ts
function binaryInsert(arr, element, comparator) {
  const index = binarySearch(arr, element, comparator);
  const insertionPoint = index < 0 ? -(index + 1) : index;
  arr.splice(insertionPoint, 0, element);
}
function binarySearch(arr, target, comparator) {
  return binarySearch_(arr, target, comparator || defaultComparator);
}
function defaultComparator(a, b) {
  return a > b ? 1 : a < b ? -1 : 0;
}
function binarySearch_(arr, target, comparator) {
  let left = 0;
  let right = arr.length;
  let middle = 0;
  let found = false;
  while (left < right) {
    middle = left + (right - left >>> 1);
    const compareResult = comparator(target, arr[middle]);
    if (compareResult > 0) {
      left = middle + 1;
    } else {
      right = middle;
      found = !compareResult;
    }
  }
  return found ? left : -left - 1;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/non_max_suppression_impl.ts
function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
  return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0);
}
function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
  return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0, false, padToMaxOutputSize, true);
}
function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true);
}
function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
  const candidates = [];
  for (let i = 0; i < scores.length; i++) {
    if (scores[i] > scoreThreshold) {
      candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
    }
  }
  candidates.sort(ascendingComparator);
  const scale2 = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
  const selectedIndices = [];
  const selectedScores = [];
  while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
    const candidate = candidates.pop();
    const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;
    if (originalScore < scoreThreshold) {
      break;
    }
    let ignoreCandidate = false;
    for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
      const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
      if (iou >= iouThreshold) {
        ignoreCandidate = true;
        break;
      }
      candidate.score = candidate.score * suppressWeight(iouThreshold, scale2, iou);
      if (candidate.score <= scoreThreshold) {
        break;
      }
    }
    candidate.suppressBeginIndex = selectedIndices.length;
    if (!ignoreCandidate) {
      if (candidate.score === originalScore) {
        selectedIndices.push(boxIndex);
        selectedScores.push(candidate.score);
      } else if (candidate.score > scoreThreshold) {
        binaryInsert(candidates, candidate, ascendingComparator);
      }
    }
  }
  const validOutputs = selectedIndices.length;
  const elemsToPad = maxOutputSize - validOutputs;
  if (padToMaxOutputSize && elemsToPad > 0) {
    selectedIndices.push(...new Array(elemsToPad).fill(0));
    selectedScores.push(...new Array(elemsToPad).fill(0));
  }
  const result = { selectedIndices };
  if (returnScoresTensor) {
    result["selectedScores"] = selectedScores;
  }
  if (returnValidOutputs) {
    result["validOutputs"] = validOutputs;
  }
  return result;
}
function intersectionOverUnion(boxes, i, j) {
  const iCoord = boxes.subarray(i * 4, i * 4 + 4);
  const jCoord = boxes.subarray(j * 4, j * 4 + 4);
  const yminI = Math.min(iCoord[0], iCoord[2]);
  const xminI = Math.min(iCoord[1], iCoord[3]);
  const ymaxI = Math.max(iCoord[0], iCoord[2]);
  const xmaxI = Math.max(iCoord[1], iCoord[3]);
  const yminJ = Math.min(jCoord[0], jCoord[2]);
  const xminJ = Math.min(jCoord[1], jCoord[3]);
  const ymaxJ = Math.max(jCoord[0], jCoord[2]);
  const xmaxJ = Math.max(jCoord[1], jCoord[3]);
  const areaI = (ymaxI - yminI) * (xmaxI - xminI);
  const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
  if (areaI <= 0 || areaJ <= 0) {
    return 0;
  }
  const intersectionYmin = Math.max(yminI, yminJ);
  const intersectionXmin = Math.max(xminI, xminJ);
  const intersectionYmax = Math.min(ymaxI, ymaxJ);
  const intersectionXmax = Math.min(xmaxI, xmaxJ);
  const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
  return intersectionArea / (areaI + areaJ - intersectionArea);
}
function suppressWeight(iouThreshold, scale2, iou) {
  const weight = Math.exp(scale2 * iou * iou);
  return iou <= iouThreshold ? weight : 0;
}
function ascendingComparator(c1, c2) {
  return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression_async.ts
async function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return tensor1d(selectedIndices, "int32");
}
var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression_with_score.ts
function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
  const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
  return { selectedIndices: result[0], selectedScores: result[1] };
}
var nonMaxSuppressionWithScore = op({ nonMaxSuppressionWithScore_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression_with_score_async.ts
async function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d(selectedIndices, "int32"),
    selectedScores: tensor1d(selectedScores)
  };
}
var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression_padded.ts
function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = {
    maxOutputSize: $maxOutputSize,
    iouThreshold: $iouThreshold,
    scoreThreshold: $scoreThreshold,
    padToMaxOutputSize
  };
  const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
  return { selectedIndices: result[0], validOutputs: result[1] };
}
var nonMaxSuppressionPadded = op({ nonMaxSuppressionPadded_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/non_max_suppression_padded_async.ts
async function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const [boxesVals, scoresVals] = await Promise.all([$boxes.data(), $scores.data()]);
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d(selectedIndices, "int32"),
    validOutputs: scalar(validOutputs, "int32")
  };
}
var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/resize_bilinear.ts
function resizeBilinear_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeBilinear");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size}.`);
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeBilinear = op({ resizeBilinear_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/resize_nearest_neighbor.ts
function resizeNearestNeighbor_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeNearestNeighbor");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size}.`);
  assert($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeNearestNeighbor = op({ resizeNearestNeighbor_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/threshold.ts
function threshold_(image4, method = "binary", inverted = false, threshValue = 0.5) {
  const $image = convertToTensor(image4, "image", "threshold");
  const RED_INTENCITY_COEF = 0.2989;
  const GREEN_INTENCITY_COEF = 0.587;
  const BLUE_INTENCITY_COEF = 0.114;
  const totalPixelsInImage = $image.shape[0] * $image.shape[1];
  let $threshold = mul(tensor1d([threshValue]), 255);
  let r, g, b, grayscale;
  assert($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
  assert($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
  assert($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
  assert(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
  if ($image.shape[2] === 3) {
    [r, g, b] = split($image, [1, 1, 1], -1);
    const $r = mul(r, RED_INTENCITY_COEF);
    const $g = mul(g, GREEN_INTENCITY_COEF);
    const $b = mul(b, BLUE_INTENCITY_COEF);
    grayscale = add2(add2($r, $g), $b);
  } else {
    grayscale = image4;
  }
  if (method === "otsu") {
    const $histogram = bincount(cast(round2(grayscale), "int32"), tensor([]), 256);
    $threshold = otsu($histogram, totalPixelsInImage);
  }
  const invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
  const result = cast(mul(invCondition, 255), "int32");
  return result;
}
function otsu(histogram, total) {
  let bestThresh = tensor1d([-1]);
  let bestInBetVar = tensor1d([0]);
  let cInBetVar = tensor1d([0]);
  let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
  for (let index = 0; index < histogram.size - 1; index++) {
    classFirst = slice(histogram, 0, index + 1);
    classSecond = slice(histogram, index + 1);
    weightForeground = div(sum2(classFirst), total);
    weightBack = div(sum2(classSecond), total);
    const meanFirstDivA = sum2(mul(classFirst, range(0, classFirst.size)));
    meanFirst = div(meanFirstDivA, sum2(classFirst));
    const meanSecFill = fill(classSecond.shape, classFirst.size);
    const meanSecAdd = add2(range(0, classSecond.size), meanSecFill);
    const meanSecMul = mul(classSecond, meanSecAdd);
    meanSec = div(sum2(meanSecMul), sum2(classSecond));
    const cInBetVarSubA = sub(meanFirst, meanSec);
    const cInBetVarSubB = sub(meanFirst, meanSec);
    const cInBetVarMul = mul(weightForeground, weightBack);
    cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
    const condition = greater(cInBetVar, bestInBetVar);
    bestInBetVar = where(condition, cInBetVar, bestInBetVar);
    bestThresh = where(condition, tensor1d([index]), bestThresh);
  }
  return bestThresh;
}
var threshold = op({ threshold_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/image/transform.ts
function transform_(image4, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
  const $image = convertToTensor(image4, "image", "transform", "float32");
  const $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
  assert($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
  assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
  assert(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
  const inputs = { image: $image, transforms: $transforms };
  const attrs = { interpolation, fillMode, fillValue, outputShape };
  return ENGINE.runKernel(Transform, inputs, attrs);
}
var transform = op({ transform_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/linalg/band_part.ts
function bandPart_(a, numLower, numUpper) {
  assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
  assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
  const $a = convertToTensor(a, "a", "bandPart");
  assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
  const shape = $a.shape;
  const [M, N] = $a.shape.slice(-2);
  if (!(numLower <= M)) {
    throw new Error(`bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
  }
  if (!(numUpper <= N)) {
    throw new Error(`bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N}).`);
  }
  if (numLower < 0) {
    numLower = M;
  }
  if (numUpper < 0) {
    numUpper = N;
  }
  const i = reshape(range(0, M, 1, "int32"), [-1, 1]);
  const j = range(0, N, 1, "int32");
  const ij = sub(i, j);
  const inBand = logicalAnd(lessEqual(ij, scalar(+numLower, "int32")), greaterEqual(ij, scalar(-numUpper, "int32")));
  const zero = zeros([M, N], $a.dtype);
  return reshape(stack(unstack(reshape($a, [-1, M, N])).map((mat) => where(inBand, mat, zero))), shape);
}
var bandPart = op({ bandPart_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/linalg/gram_schmidt.ts
function gramSchmidt_(xs) {
  let inputIsTensor2D;
  if (Array.isArray(xs)) {
    inputIsTensor2D = false;
    assert(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const dim = xs[0].shape[0];
    for (let i = 1; i < xs.length; ++i) {
      assert(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
    }
  } else {
    inputIsTensor2D = true;
    xs = split(xs, xs.shape[0], 0).map((x) => squeeze(x, [0]));
  }
  assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
  const ys = [];
  const xs1d = xs;
  for (let i = 0; i < xs.length; ++i) {
    ys.push(ENGINE.tidy(() => {
      let x = xs1d[i];
      if (i > 0) {
        for (let j = 0; j < i; ++j) {
          const proj = mul(sum2(mul(ys[j], x)), ys[j]);
          x = sub(x, proj);
        }
      }
      return div(x, norm(x, "euclidean"));
    }));
  }
  if (inputIsTensor2D) {
    return stack(ys, 0);
  } else {
    return ys;
  }
}
var gramSchmidt = op({ gramSchmidt_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/linalg/qr.ts
function qr_(x, fullMatrices = false) {
  assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
  if (x.rank === 2) {
    return qr2d(x, fullMatrices);
  } else {
    const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
    const x2ds = unstack(reshape(x, [
      outerDimsProd,
      x.shape[x.shape.length - 2],
      x.shape[x.shape.length - 1]
    ]), 0);
    const q2ds = [];
    const r2ds = [];
    x2ds.forEach((x2d) => {
      const [q2d, r2d] = qr2d(x2d, fullMatrices);
      q2ds.push(q2d);
      r2ds.push(r2d);
    });
    const q = reshape(stack(q2ds, 0), x.shape);
    const r = reshape(stack(r2ds, 0), x.shape);
    return [q, r];
  }
}
function qr2d(x, fullMatrices = false) {
  return ENGINE.tidy(() => {
    assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
    const m = x.shape[0];
    const n = x.shape[1];
    let q = eye(m);
    let r = clone(x);
    const one2D = tensor2d([[1]], [1, 1]);
    let w = clone(one2D);
    const iters = m >= n ? n : m;
    for (let j = 0; j < iters; ++j) {
      const rTemp = r;
      const wTemp = w;
      const qTemp = q;
      [w, r, q] = ENGINE.tidy(() => {
        const rjEnd1 = slice(r, [j, j], [m - j, 1]);
        const normX = norm(rjEnd1);
        const rjj = slice(r, [j, j], [1, 1]);
        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
        const u1 = sub(rjj, mul(s, normX));
        const wPre = div(rjEnd1, u1);
        if (wPre.shape[0] === 1) {
          w = clone(one2D);
        } else {
          w = concat([
            one2D,
            slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
          ], 0);
        }
        const tau = neg(div(matMul(s, u1), normX));
        const rjEndAll = slice(r, [j, 0], [m - j, n]);
        const tauTimesW = mul(tau, w);
        const wT = transpose(w);
        if (j === 0) {
          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
        } else {
          const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);
        }
        const tawTimesWT = transpose(tauTimesW);
        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);
        if (j === 0) {
          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
        } else {
          const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);
        }
        return [w, r, q];
      });
      dispose([rTemp, wTemp, qTemp]);
    }
    if (!fullMatrices && m > n) {
      q = slice(q, [0, 0], [m, n]);
      r = slice(r, [0, 0], [n, n]);
    }
    return [q, r];
  });
}
var qr = op({ qr_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/loss_ops_utils.ts
var Reduction;
(function(Reduction3) {
  Reduction3[Reduction3["NONE"] = 0] = "NONE";
  Reduction3[Reduction3["MEAN"] = 1] = "MEAN";
  Reduction3[Reduction3["SUM"] = 2] = "SUM";
  Reduction3[Reduction3["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(Reduction || (Reduction = {}));

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/compute_weighted_loss.ts
function computeWeightedLoss_(losses4, weights, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $losses = convertToTensor(losses4, "losses", "computeWeightedLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
  }
  const weightedLoss = $weights == null ? $losses : mul($losses, $weights);
  if (reduction2 === Reduction.NONE) {
    return weightedLoss;
  }
  if (reduction2 === Reduction.SUM) {
    return sum2(weightedLoss);
  }
  if (reduction2 === Reduction.MEAN) {
    if ($weights == null) {
      return mean(weightedLoss);
    } else {
      const broadcastFactor = $losses.size / $weights.size;
      const result = div(sum2(weightedLoss), sum2($weights));
      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
    }
  }
  if (reduction2 === Reduction.SUM_BY_NONZERO_WEIGHTS) {
    if ($weights == null) {
      return div(sum2(weightedLoss), scalar($losses.size));
    } else {
      const broadcastedWeights = mul($weights, ones2($losses.shape));
      const numNonZeros = cast(sum2(notEqual(broadcastedWeights, scalar(0))), "float32");
      return div(sum2(weightedLoss), numNonZeros);
    }
  }
  throw Error(`Unknown reduction: ${reduction2}`);
}
var computeWeightedLoss = op({ computeWeightedLoss_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/absolute_difference.ts
function absoluteDifference_(labels, predictions, weights, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "absoluteDifference");
  const $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "absoluteDifference");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
  const losses4 = abs(sub($labels, $predictions));
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var absoluteDifference = op({ absoluteDifference_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/cosine_distance.ts
function cosineDistance_(labels, predictions, axis, weights, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "cosineDistance");
  const $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "cosineDistance");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
  const one = scalar(1);
  const losses4 = sub(one, sum2(mul($labels, $predictions), axis, true));
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var cosineDistance = op({ cosineDistance_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/hinge_loss.ts
function hingeLoss_(labels, predictions, weights, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $labels = convertToTensor(labels, "labels", "hingeLoss");
  const $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "hingeLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
  const one = scalar(1);
  $labels = sub(mul(scalar(2), $labels), one);
  const losses4 = relu(sub(one, mul($labels, $predictions)));
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var hingeLoss = op({ hingeLoss_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/huber_loss.ts
function huberLoss_(labels, predictions, weights, delta = 1, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "huberLoss");
  const $predictions = convertToTensor(predictions, "predictions", "huberLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "huberLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
  const deltaScalar = scalar(delta);
  const error = abs(sub($predictions, $labels));
  const quadratic = minimum(error, deltaScalar);
  const linear = sub(error, quadratic);
  const losses4 = add2(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var huberLoss = op({ huberLoss_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/log_loss.ts
function logLoss_(labels, predictions, weights, epsilon3 = 1e-7, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "logLoss");
  const $predictions = convertToTensor(predictions, "predictions", "logLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "logLoss");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
  const one = scalar(1);
  const epsilonScalar = scalar(epsilon3);
  const l13 = neg(mul($labels, log(add2($predictions, epsilonScalar))));
  const l23 = mul(sub(one, $labels), log(add2(sub(one, $predictions), epsilonScalar)));
  const losses4 = sub(l13, l23);
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var logLoss = op({ logLoss_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/mean_squared_error.ts
function meanSquaredError_(labels, predictions, weights, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor(labels, "labels", "meanSquaredError");
  const $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "meanSquaredError");
  }
  assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
  const losses4 = squaredDifference($labels, $predictions);
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var meanSquaredError = op({ meanSquaredError_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/sigmoid_cross_entropy.ts
function sigmoidCrossEntropyWithLogits_(labels, logits) {
  const $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
  const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
  assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  const maxOutput = relu($logits);
  const outputXTarget = mul($logits, $labels);
  const sigmoidOutput = log1p(exp(neg(abs($logits))));
  return add2(sub(maxOutput, outputXTarget), sigmoidOutput);
}
function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing = 0, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
  const $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
  }
  assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar(labelSmoothing);
    const one = scalar(1);
    const half = scalar(0.5);
    $multiClassLabels = add2(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
  }
  const losses4 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var sigmoidCrossEntropy = op({ sigmoidCrossEntropy_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/losses/softmax_cross_entropy.ts
function softmaxCrossEntropyWithLogits_(labels, logits, dim = -1) {
  if (dim === -1) {
    dim = logits.rank - 1;
  }
  if (dim !== logits.rank - 1) {
    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${logits.rank} and dim was ${dim}`);
  }
  const customOp = customGrad((labels2, logits2, save) => {
    const keepDims = true;
    const lse = logSumExp(logits2, [dim], keepDims);
    const logResult = sub(cast(logits2, "float32"), lse);
    save([labels2, logResult]);
    const costVector = neg(mul(logResult, labels2));
    const value = sum2(costVector, [dim]);
    const gradFunc = (dy, saved) => {
      const [labels3, logResult2] = saved;
      const dyShape = expandShapeToKeepDim(dy.shape, [dim]);
      return [
        mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
        mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
      ];
    };
    return { value, gradFunc };
  });
  return customOp(labels, logits);
}
function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing = 0, reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS) {
  let $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
  const $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
  }
  assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar(labelSmoothing);
    const one = scalar(1);
    const numClasses = scalar($onehotLabels.shape[1]);
    $onehotLabels = add2(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
  }
  const losses4 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
  return computeWeightedLoss(losses4, $weights, reduction2);
}
var softmaxCrossEntropy = op({ softmaxCrossEntropy_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse/sparse_fill_empty_rows.ts
function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
  const $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows");
  const $values = convertToTensor(values, "values", "sparseFillEmptyRows");
  const $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows");
  const $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
  if ($indices.rank !== 2) {
    throw new Error(`Indices should be Tensor2D but received shape
        ${$indices.shape}`);
  }
  if ($values.rank !== 1) {
    throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);
  }
  if ($denseShape.rank !== 1) {
    throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);
  }
  if ($defaultValue.rank !== 0) {
    throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);
  }
  const inputs = {
    indices: $indices,
    values: $values,
    denseShape: $denseShape,
    defaultValue: $defaultValue
  };
  const result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
  return {
    outputIndices: result[0],
    outputValues: result[1],
    emptyRowIndicator: result[2],
    reverseIndexMap: result[3]
  };
}
var sparseFillEmptyRows = op({ sparseFillEmptyRows_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse/sparse_reshape.ts
function sparseReshape_(inputIndices, inputShape, newShape) {
  const $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape");
  const $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape");
  const $newShape = convertToTensor(newShape, "newShape", "sparseReshape");
  if ($inputIndices.rank !== 2) {
    throw new Error(`Input indices should be Tensor2D but received shape
        ${$inputIndices.shape}`);
  }
  if ($inputShape.rank !== 1) {
    throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);
  }
  if ($newShape.rank !== 1) {
    throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);
  }
  const inputs = {
    inputIndices: $inputIndices,
    inputShape: $inputShape,
    newShape: $newShape
  };
  const result = ENGINE.runKernel(SparseReshape, inputs);
  return { outputIndices: result[0], outputShape: result[1] };
}
var sparseReshape = op({ sparseReshape_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse/sparse_segment_mean.ts
function sparseSegmentMean_(data, indices, segmentIds) {
  const $data = convertToTensor(data, "data", "sparseSegmentMean");
  const $indices = convertToTensor(indices, "indices", "sparseSegmentMean");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
          ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
          ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE.runKernel(SparseSegmentMean, inputs);
}
var sparseSegmentMean = op({ sparseSegmentMean_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/sparse/sparse_segment_sum.ts
function sparseSegmentSum_(data, indices, segmentIds) {
  const $data = convertToTensor(data, "data", "sparseSegmentSum");
  const $indices = convertToTensor(indices, "indices", "sparseSegmentSum");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
         ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
         ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE.runKernel(SparseSegmentSum, inputs);
}
var sparseSegmentSum = op({ sparseSegmentSum_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/string/string_n_grams.ts
function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
  const $data = convertToTensor(data, "data", "stringNGrams", "string");
  if ($data.dtype !== "string") {
    throw new Error("Data must be of datatype string");
  }
  if ($data.shape.length !== 1) {
    throw new Error(`Data must be a vector, saw: ${$data.shape}`);
  }
  const $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
  if ($dataSplits.dtype !== "int32") {
    throw new Error("Data splits must be of datatype int32");
  }
  const attrs = {
    separator,
    nGramWidths,
    leftPad,
    rightPad: rightPad3,
    padWidth,
    preserveShortSequences
  };
  const inputs = { data: $data, dataSplits: $dataSplits };
  const result = ENGINE.runKernel(StringNGrams, inputs, attrs);
  return { nGrams: result[0], nGramsSplits: result[1] };
}
var stringNGrams = op({ stringNGrams_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/string/string_split.ts
function stringSplit_(input2, delimiter, skipEmpty = true) {
  const $input = convertToTensor(input2, "input", "stringSplit", "string");
  const $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
  if ($input.rank !== 1) {
    throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);
  }
  if ($delimiter.rank !== 0) {
    throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);
  }
  const attrs = { skipEmpty };
  const inputs = { input: $input, delimiter: $delimiter };
  const result = ENGINE.runKernel(StringSplit, inputs, attrs);
  return { indices: result[0], values: result[1], shape: result[2] };
}
var stringSplit = op({ stringSplit_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/string/string_to_hash_bucket_fast.ts
function stringToHashBucketFast_(input2, numBuckets) {
  const $input = convertToTensor(input2, "input", "stringToHashBucketFast", "string");
  const attrs = { numBuckets };
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const inputs = { input: $input };
  return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
}
var stringToHashBucketFast = op({ stringToHashBucketFast_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/ops.ts
var spectral = {
  fft,
  ifft,
  rfft,
  irfft
};
var signal = {
  hammingWindow,
  hannWindow,
  frame,
  stft
};
var image = {
  flipLeftRight,
  resizeNearestNeighbor,
  resizeBilinear,
  rotateWithOffset,
  cropAndResize,
  nonMaxSuppression,
  nonMaxSuppressionAsync,
  nonMaxSuppressionWithScore,
  nonMaxSuppressionWithScoreAsync,
  nonMaxSuppressionPadded,
  nonMaxSuppressionPaddedAsync,
  threshold,
  transform
};
var linalg = {
  bandPart,
  gramSchmidt,
  qr
};
var losses = {
  absoluteDifference,
  computeWeightedLoss,
  cosineDistance,
  hingeLoss,
  huberLoss,
  logLoss,
  meanSquaredError,
  sigmoidCrossEntropy,
  softmaxCrossEntropy
};
var sparse = {
  sparseFillEmptyRows,
  sparseReshape,
  sparseSegmentMean,
  sparseSegmentSum
};
var string = {
  stringNGrams,
  stringSplit,
  stringToHashBucketFast
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/optimizer.ts
var Optimizer = class extends Serializable {
  minimize(f, returnCost = false, varList) {
    const { value, grads: grads3 } = this.computeGradients(f, varList);
    if (varList != null) {
      const gradArray = varList.map((v) => ({ name: v.name, tensor: grads3[v.name] }));
      this.applyGradients(gradArray);
    } else {
      this.applyGradients(grads3);
    }
    dispose(grads3);
    if (returnCost) {
      return value;
    } else {
      value.dispose();
      return null;
    }
  }
  get iterations() {
    if (this.iterations_ == null) {
      this.iterations_ = 0;
    }
    return this.iterations_;
  }
  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }
  computeGradients(f, varList) {
    return variableGrads(f, varList);
  }
  dispose() {
    if (this.iterations_ != null) {
      dispose(this.iterations_);
    }
  }
  async saveIterations() {
    if (this.iterations_ == null) {
      this.iterations_ = 0;
    }
    return {
      name: "iter",
      tensor: scalar(this.iterations_, "int32")
    };
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for this optimizer yet.");
  }
  async setWeights(weightValues) {
    throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
  }
  async extractIterations(weightValues) {
    this.iterations_ = (await weightValues[0].tensor.data())[0];
    return weightValues.slice(1);
  }
};
Object.defineProperty(Optimizer, Symbol.hasInstance, {
  value: (instance) => {
    return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/adadelta_optimizer.ts
var AdadeltaOptimizer = class extends Optimizer {
  constructor(learningRate, rho, epsilon3 = null) {
    super();
    this.learningRate = learningRate;
    this.rho = rho;
    this.epsilon = epsilon3;
    this.accumulatedGrads = [];
    this.accumulatedUpdates = [];
    if (epsilon3 == null) {
      this.epsilon = ENGINE.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE.registeredVariables[name];
      const trainable = false;
      if (this.accumulatedGrads[i] == null) {
        this.accumulatedGrads[i] = {
          originalName: `${name}/accum_grad`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      if (this.accumulatedUpdates[i] == null) {
        this.accumulatedUpdates[i] = {
          originalName: `${name}/accum_var`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedGrad = this.accumulatedGrads[i].variable;
      const accumulatedUpdate = this.accumulatedUpdates[i].variable;
      tidy(() => {
        const newAccumulatedGrad = add2(mul(accumulatedGrad, this.rho), mul(square(gradient), 1 - this.rho));
        const updates = mul(div(sqrt(add2(accumulatedUpdate, this.epsilon)), sqrt(add2(accumulatedGrad, this.epsilon))), gradient);
        const newAccumulatedUpdate = add2(mul(accumulatedUpdate, this.rho), mul(square(updates), 1 - this.rho));
        accumulatedGrad.assign(newAccumulatedGrad);
        accumulatedUpdate.assign(newAccumulatedUpdate);
        const newValue = add2(mul(updates, -this.learningRate), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedUpdates != null) {
      dispose(this.accumulatedGrads.map((v) => v.variable));
      dispose(this.accumulatedUpdates.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const variableCount = weightValues.length / 2;
    const trainable = false;
    this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "rho": this.rho,
      "epsilon": this.epsilon
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["rho"], config["epsilon"]);
  }
};
AdadeltaOptimizer.className = "Adadelta";
registerClass(AdadeltaOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/adagrad_optimizer.ts
var AdagradOptimizer = class extends Optimizer {
  constructor(learningRate, initialAccumulatorValue = 0.1) {
    super();
    this.learningRate = learningRate;
    this.initialAccumulatorValue = initialAccumulatorValue;
    this.accumulatedGrads = [];
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE.registeredVariables[name];
      if (this.accumulatedGrads[i] == null) {
        const trainable = false;
        this.accumulatedGrads[i] = {
          originalName: `${name}/accumulator`,
          variable: tidy(() => fill(value.shape, this.initialAccumulatorValue).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedGrad = this.accumulatedGrads[i].variable;
      tidy(() => {
        const newAccumulatedGrad = add2(accumulatedGrad, square(gradient));
        accumulatedGrad.assign(newAccumulatedGrad);
        const newValue = add2(mul(div(gradient, sqrt(add2(newAccumulatedGrad, ENGINE.backend.epsilon()))), -this.learningRate), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedGrads != null) {
      dispose(this.accumulatedGrads.map((v) => v.variable));
    }
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const trainable = false;
    this.accumulatedGrads = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "initialAccumulatorValue": this.initialAccumulatorValue
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["initialAccumulatorValue"]);
  }
};
AdagradOptimizer.className = "Adagrad";
registerClass(AdagradOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/adam_optimizer.ts
var AdamOptimizer = class extends Optimizer {
  constructor(learningRate, beta1, beta2, epsilon3 = null) {
    super();
    this.learningRate = learningRate;
    this.beta1 = beta1;
    this.beta2 = beta2;
    this.epsilon = epsilon3;
    this.accumulatedFirstMoment = [];
    this.accumulatedSecondMoment = [];
    tidy(() => {
      this.accBeta1 = scalar(beta1).variable();
      this.accBeta2 = scalar(beta2).variable();
    });
    if (epsilon3 == null) {
      this.epsilon = ENGINE.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
    tidy(() => {
      const oneMinusAccBeta1 = sub(1, this.accBeta1);
      const oneMinusAccBeta2 = sub(1, this.accBeta2);
      varNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedFirstMoment[i] == null) {
          this.accumulatedFirstMoment[i] = {
            originalName: `${name}/m`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        if (this.accumulatedSecondMoment[i] == null) {
          this.accumulatedSecondMoment[i] = {
            originalName: `${name}/v`,
            variable: tidy(() => zerosLike(value).variable(trainable))
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const firstMoment = this.accumulatedFirstMoment[i].variable;
        const secondMoment = this.accumulatedSecondMoment[i].variable;
        const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
        const newSecondMoment = add2(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));
        const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
        const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
        firstMoment.assign(newFirstMoment);
        secondMoment.assign(newSecondMoment);
        const newValue = add2(mul(div(biasCorrectedFirstMoment, add2(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
        value.assign(newValue);
      });
      this.accBeta1.assign(mul(this.accBeta1, this.beta1));
      this.accBeta2.assign(mul(this.accBeta2, this.beta2));
    });
    this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose();
    this.accBeta2.dispose();
    if (this.accumulatedFirstMoment != null) {
      dispose(this.accumulatedFirstMoment.map((v) => v.variable));
    }
    if (this.accumulatedSecondMoment != null) {
      dispose(this.accumulatedSecondMoment.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    tidy(() => {
      this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));
      this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));
    });
    const variableCount = weightValues.length / 2;
    const trainable = false;
    this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "beta1": this.beta1,
      "beta2": this.beta2,
      "epsilon": this.epsilon
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
  }
};
AdamOptimizer.className = "Adam";
registerClass(AdamOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/adamax_optimizer.ts
var AdamaxOptimizer = class extends Optimizer {
  constructor(learningRate, beta1, beta2, epsilon3 = null, decay = 0) {
    super();
    this.learningRate = learningRate;
    this.beta1 = beta1;
    this.beta2 = beta2;
    this.epsilon = epsilon3;
    this.decay = decay;
    this.accumulatedFirstMoment = [];
    this.accumulatedWeightedInfNorm = [];
    tidy(() => {
      this.iteration = scalar(0).variable();
      this.accBeta1 = scalar(beta1).variable();
    });
    if (epsilon3 == null) {
      this.epsilon = ENGINE.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    tidy(() => {
      const oneMinusAccBeta1 = sub(1, this.accBeta1);
      const lr = div(-this.learningRate, add2(mul(this.iteration, this.decay), 1));
      variableNames.forEach((name, i) => {
        const value = ENGINE.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedFirstMoment[i] == null) {
          this.accumulatedFirstMoment[i] = {
            originalName: `${name}/m`,
            variable: zerosLike(value).variable(trainable)
          };
        }
        if (this.accumulatedWeightedInfNorm[i] == null) {
          this.accumulatedWeightedInfNorm[i] = {
            originalName: `${name}/v`,
            variable: zerosLike(value).variable(trainable)
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const firstMoment = this.accumulatedFirstMoment[i].variable;
        const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
        const newFirstMoment = add2(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));
        const ut0 = mul(weightedInfNorm, this.beta2);
        const ut1 = abs(gradient);
        const newWeightedInfNorm = maximum(ut0, ut1);
        firstMoment.assign(newFirstMoment);
        weightedInfNorm.assign(newWeightedInfNorm);
        const newValue = add2(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add2(newWeightedInfNorm, this.epsilon))), value);
        value.assign(newValue);
      });
      this.iteration.assign(add2(this.iteration, 1));
      this.accBeta1.assign(mul(this.accBeta1, this.beta1));
    });
    this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose();
    this.iteration.dispose();
    if (this.accumulatedFirstMoment != null) {
      dispose(this.accumulatedFirstMoment.map((v) => v.variable));
    }
    if (this.accumulatedWeightedInfNorm != null) {
      dispose(this.accumulatedWeightedInfNorm.map((v) => v.variable));
    }
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for Adamax yet.");
  }
  async setWeights(weightValues) {
    throw new Error("setWeights() is not implemented for Adamax yet.");
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "beta1": this.beta1,
      "beta2": this.beta2,
      "epsilon": this.epsilon,
      "decay": this.decay
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
  }
};
AdamaxOptimizer.className = "Adamax";
registerClass(AdamaxOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/sgd_optimizer.ts
var SGDOptimizer = class extends Optimizer {
  constructor(learningRate) {
    super();
    this.learningRate = learningRate;
    this.setLearningRate(learningRate);
  }
  applyGradients(variableGradients) {
    const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
    varNames.forEach((name, i) => {
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const value = ENGINE.registeredVariables[name];
      tidy(() => {
        const newValue = add2(mul(this.c, gradient), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  setLearningRate(learningRate) {
    this.learningRate = learningRate;
    if (this.c != null) {
      this.c.dispose();
    }
    this.c = keep(scalar(-learningRate));
  }
  dispose() {
    this.c.dispose();
  }
  async getWeights() {
    return [await this.saveIterations()];
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    if (weightValues.length !== 0) {
      throw new Error("SGD optimizer does not have settable weights.");
    }
  }
  getConfig() {
    return { "learningRate": this.learningRate };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"]);
  }
};
SGDOptimizer.className = "SGD";
registerClass(SGDOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/momentum_optimizer.ts
var MomentumOptimizer = class extends SGDOptimizer {
  constructor(learningRate, momentum, useNesterov = false) {
    super(learningRate);
    this.learningRate = learningRate;
    this.momentum = momentum;
    this.useNesterov = useNesterov;
    this.accumulations = [];
    this.m = scalar(this.momentum);
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE.registeredVariables[name];
      if (this.accumulations[i] == null) {
        const trainable = false;
        this.accumulations[i] = {
          originalName: `${name}/momentum`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      const accumulation = this.accumulations[i].variable;
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      tidy(() => {
        let newValue;
        const newAccumulation = add2(mul(this.m, accumulation), gradient);
        if (this.useNesterov) {
          newValue = add2(mul(this.c, add2(gradient, mul(newAccumulation, this.m))), value);
        } else {
          newValue = add2(mul(this.c, newAccumulation), value);
        }
        accumulation.assign(newAccumulation);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    this.m.dispose();
    if (this.accumulations != null) {
      dispose(this.accumulations.map((v) => v.variable));
    }
  }
  setMomentum(momentum) {
    this.momentum = momentum;
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulations.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const trainable = false;
    this.accumulations = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "momentum": this.momentum,
      "useNesterov": this.useNesterov
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
  }
};
MomentumOptimizer.className = "Momentum";
registerClass(MomentumOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/rmsprop_optimizer.ts
var RMSPropOptimizer = class extends Optimizer {
  constructor(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
    super();
    this.learningRate = learningRate;
    this.decay = decay;
    this.momentum = momentum;
    this.epsilon = epsilon3;
    this.accumulatedMeanSquares = [];
    this.accumulatedMoments = [];
    this.accumulatedMeanGrads = [];
    this.centered = centered;
    if (epsilon3 == null) {
      this.epsilon = ENGINE.backend.epsilon();
    }
    if (learningRate == null) {
      throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE.registeredVariables[name];
      const trainable = false;
      if (this.accumulatedMeanSquares[i] == null) {
        this.accumulatedMeanSquares[i] = {
          originalName: `${name}/rms`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      if (this.accumulatedMoments[i] == null) {
        this.accumulatedMoments[i] = {
          originalName: `${name}/momentum`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      if (this.accumulatedMeanGrads[i] == null && this.centered) {
        this.accumulatedMeanGrads[i] = {
          originalName: `${name}/mg`,
          variable: tidy(() => zerosLike(value).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
      const accumulatedMoments = this.accumulatedMoments[i].variable;
      tidy(() => {
        const newAccumulatedMeanSquare = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
        if (this.centered) {
          const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
          const newAccumulatedMeanGrad = add2(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));
          const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add2(square(newAccumulatedMeanGrad), this.epsilon))));
          const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), gradContribution);
          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
          accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
          accumulatedMoments.assign(newAccumulatedMoments);
          const newValue = sub(value, newAccumulatedMoments);
          value.assign(newValue);
        } else {
          const newAccumulatedMeanSquare2 = add2(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));
          const newAccumulatedMoments = add2(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add2(newAccumulatedMeanSquare2, this.epsilon))));
          accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
          accumulatedMoments.assign(newAccumulatedMoments);
          const newValue = sub(value, newAccumulatedMoments);
          value.assign(newValue);
        }
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedMeanSquares != null) {
      dispose(this.accumulatedMeanSquares.map((v) => v.variable));
    }
    if (this.accumulatedMeanGrads != null && this.centered) {
      dispose(this.accumulatedMeanGrads.map((v) => v.variable));
    }
    if (this.accumulatedMoments != null) {
      dispose(this.accumulatedMoments.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
    if (this.centered) {
      variables.push(...this.accumulatedMeanGrads);
    }
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
    const trainable = false;
    this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    if (this.centered) {
      this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
    }
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "decay": this.decay,
      "momentum": this.momentum,
      "epsilon": this.epsilon,
      "centered": this.centered
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
  }
};
RMSPropOptimizer.className = "RMSProp";
registerClass(RMSPropOptimizer);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/optimizers/optimizer_constructors.ts
var OptimizerConstructors = class {
  static sgd(learningRate) {
    return new SGDOptimizer(learningRate);
  }
  static momentum(learningRate, momentum, useNesterov = false) {
    return new MomentumOptimizer(learningRate, momentum, useNesterov);
  }
  static rmsprop(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
    return new RMSPropOptimizer(learningRate, decay, momentum, epsilon3, centered);
  }
  static adam(learningRate = 1e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null) {
    return new AdamOptimizer(learningRate, beta1, beta2, epsilon3);
  }
  static adadelta(learningRate = 1e-3, rho = 0.95, epsilon3 = null) {
    return new AdadeltaOptimizer(learningRate, rho, epsilon3);
  }
  static adamax(learningRate = 2e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null, decay = 0) {
    return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon3, decay);
  }
  static adagrad(learningRate, initialAccumulatorValue = 0.1) {
    return new AdagradOptimizer(learningRate, initialAccumulatorValue);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/train.ts
var train = {
  sgd: OptimizerConstructors.sgd,
  momentum: OptimizerConstructors.momentum,
  adadelta: OptimizerConstructors.adadelta,
  adagrad: OptimizerConstructors.adagrad,
  rmsprop: OptimizerConstructors.rmsprop,
  adamax: OptimizerConstructors.adamax,
  adam: OptimizerConstructors.adam
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/browser_util.ts
var delayCallback = (() => {
  if (typeof requestAnimationFrame !== "undefined") {
    return requestAnimationFrame;
  } else if (typeof setImmediate !== "undefined") {
    return setImmediate;
  }
  return (f) => f();
})();
function nextFrame() {
  return new Promise((resolve) => delayCallback(() => resolve()));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/backend_util.ts
var backend_util_exports = {};
__export(backend_util_exports, {
  ERF_A1: () => ERF_A1,
  ERF_A2: () => ERF_A2,
  ERF_A3: () => ERF_A3,
  ERF_A4: () => ERF_A4,
  ERF_A5: () => ERF_A5,
  ERF_P: () => ERF_P,
  PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD,
  SELU_SCALE: () => SELU_SCALE,
  SELU_SCALEALPHA: () => SELU_SCALEALPHA,
  applyActivation: () => applyActivation,
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
  assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims,
  assertParamsConsistent: () => assertParamsConsistent,
  assignToTypedArray: () => assignToTypedArray,
  axesAreInnerMostDims: () => axesAreInnerMostDims,
  calculateShapes: () => calculateShapes,
  checkEinsumDimSizes: () => checkEinsumDimSizes,
  combineLocations: () => combineLocations,
  complexWithEvenIndex: () => complexWithEvenIndex,
  complexWithOddIndex: () => complexWithOddIndex,
  computeConv2DInfo: () => computeConv2DInfo,
  computeConv3DInfo: () => computeConv3DInfo,
  computeDefaultPad: () => computeDefaultPad,
  computeDilation2DInfo: () => computeDilation2DInfo,
  computeOptimalWindowSize: () => computeOptimalWindowSize,
  computeOutAndReduceShapes: () => computeOutAndReduceShapes,
  computeOutShape: () => computeOutShape2,
  computePool2DInfo: () => computePool2DInfo,
  computePool3DInfo: () => computePool3DInfo,
  convertConv2DDataFormat: () => convertConv2DDataFormat,
  decodeEinsumEquation: () => decodeEinsumEquation,
  eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne,
  expandShapeToKeepDim: () => expandShapeToKeepDim,
  exponent: () => exponent,
  exponents: () => exponents,
  fromStringArrayToUint8: () => fromStringArrayToUint8,
  fromUint8ToStringArray: () => fromUint8ToStringArray,
  getAxesPermutation: () => getAxesPermutation,
  getBroadcastDims: () => getBroadcastDims,
  getComplexWithIndex: () => getComplexWithIndex,
  getEinsumComputePath: () => getEinsumComputePath,
  getEinsumPermutation: () => getEinsumPermutation,
  getFusedBiasGradient: () => getFusedBiasGradient,
  getFusedDyActivation: () => getFusedDyActivation,
  getImageCenter: () => getImageCenter,
  getInnerMostAxes: () => getInnerMostAxes,
  getPermuted: () => getPermuted,
  getReductionAxes: () => getReductionAxes,
  getReshaped: () => getReshaped,
  getReshapedPermuted: () => getReshapedPermuted,
  getSliceBeginCoords: () => getSliceBeginCoords,
  getSliceSize: () => getSliceSize,
  getUndoAxesPermutation: () => getUndoAxesPermutation,
  isIdentityPermutation: () => isIdentityPermutation,
  log: () => log2,
  mergeRealAndImagArrays: () => mergeRealAndImagArrays,
  prepareAndValidate: () => prepareAndValidate,
  prepareSplitSize: () => prepareSplitSize,
  segment_util: () => segment_util_exports,
  shouldFuse: () => shouldFuse,
  slice_util: () => slice_util_exports,
  splitRealAndImagArrays: () => splitRealAndImagArrays,
  tupleValuesAreOne: () => tupleValuesAreOne,
  upcastType: () => upcastType,
  validateInput: () => validateInput,
  validateUpdateShape: () => validateUpdateShape,
  warn: () => warn
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/concat_util.ts
function assertParamsConsistent(shapes, axis) {
  const rank = shapes[0].length;
  shapes.forEach((shape, i) => {
    assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
  });
  assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
  const firstShape = shapes[0];
  shapes.forEach((shape, i) => {
    for (let r = 0; r < rank; r++) {
      assert(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
    }
  });
}
function computeOutShape2(shapes, axis) {
  const outputShape = shapes[0].slice();
  for (let i = 1; i < shapes.length; i++) {
    outputShape[axis] += shapes[i][axis];
  }
  return outputShape;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/reduce_util.ts
var PARALLELIZE_THRESHOLD = 30;
function computeOptimalWindowSize(inSize) {
  if (inSize <= PARALLELIZE_THRESHOLD) {
    return inSize;
  }
  return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/rotate_util.ts
function getImageCenter(center, imageHeight, imageWidth) {
  const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
  const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
  return [centerX, centerY];
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/array_ops_util.ts
function getReshaped(inputShape, blockShape, prod6, batchToSpace = true) {
  let reshaped = [];
  if (batchToSpace) {
    reshaped = reshaped.concat(blockShape.slice(0));
    reshaped.push(inputShape[0] / prod6);
    reshaped = reshaped.concat(inputShape.slice(1));
  } else {
    reshaped = reshaped.concat(inputShape[0]);
    const spatialLength = blockShape.length;
    for (let i = 0; i < spatialLength; ++i) {
      reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
    }
    reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
  }
  return reshaped;
}
function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {
  const permuted = [];
  if (batchToSpace) {
    permuted.push(blockShapeRank);
    for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
      if (i <= 2 * blockShapeRank) {
        permuted.push(i);
        permuted.push(i - (blockShapeRank + 1));
      } else {
        permuted.push(i);
      }
    }
  } else {
    const permutedBeforeBatch = [];
    const permutedAfterBatch = [];
    for (let i = 1; i < reshapedRank; ++i) {
      if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
        permutedAfterBatch.push(i);
      } else {
        permutedBeforeBatch.push(i);
      }
    }
    permuted.push(...permutedBeforeBatch);
    permuted.push(0);
    permuted.push(...permutedAfterBatch);
  }
  return permuted;
}
function getReshapedPermuted(inputShape, blockShape, prod6, batchToSpace = true) {
  const reshapedPermuted = [];
  if (batchToSpace) {
    reshapedPermuted.push(inputShape[0] / prod6);
  } else {
    reshapedPermuted.push(inputShape[0] * prod6);
  }
  for (let i = 1; i < inputShape.length; ++i) {
    if (i <= blockShape.length) {
      if (batchToSpace) {
        reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
      } else {
        reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
      }
    } else {
      reshapedPermuted.push(inputShape[i]);
    }
  }
  return reshapedPermuted;
}
function getSliceBeginCoords(crops, blockShape) {
  const sliceBeginCoords = [0];
  for (let i = 0; i < blockShape; ++i) {
    sliceBeginCoords.push(crops[i][0]);
  }
  return sliceBeginCoords;
}
function getSliceSize(uncroppedShape, crops, blockShape) {
  const sliceSize = uncroppedShape.slice(0, 1);
  for (let i = 0; i < blockShape; ++i) {
    sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
  }
  return sliceSize;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/selu_util.ts
var SELU_SCALEALPHA = 1.7580993408473768;
var SELU_SCALE = 1.0507009873554805;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/erf_util.ts
var ERF_P = 0.3275911;
var ERF_A1 = 0.254829592;
var ERF_A2 = -0.284496736;
var ERF_A3 = 1.421413741;
var ERF_A4 = -1.453152027;
var ERF_A5 = 1.061405429;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/log.ts
function warn(...msg) {
  if (!env().getBool("IS_TEST")) {
    console.warn(...msg);
  }
}
function log2(...msg) {
  if (!env().getBool("IS_TEST")) {
    console.log(...msg);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/complex_util.ts
function mergeRealAndImagArrays(real6, imag5) {
  if (real6.length !== imag5.length) {
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real6.length}, imag: ${imag5.length}.`);
  }
  const result = new Float32Array(real6.length * 2);
  for (let i = 0; i < result.length; i += 2) {
    result[i] = real6[i / 2];
    result[i + 1] = imag5[i / 2];
  }
  return result;
}
function splitRealAndImagArrays(complex6) {
  const real6 = new Float32Array(complex6.length / 2);
  const imag5 = new Float32Array(complex6.length / 2);
  for (let i = 0; i < complex6.length; i += 2) {
    real6[i / 2] = complex6[i];
    imag5[i / 2] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function complexWithEvenIndex(complex6) {
  const len = Math.ceil(complex6.length / 4);
  const real6 = new Float32Array(len);
  const imag5 = new Float32Array(len);
  for (let i = 0; i < complex6.length; i += 4) {
    real6[Math.floor(i / 4)] = complex6[i];
    imag5[Math.floor(i / 4)] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function complexWithOddIndex(complex6) {
  const len = Math.floor(complex6.length / 4);
  const real6 = new Float32Array(len);
  const imag5 = new Float32Array(len);
  for (let i = 2; i < complex6.length; i += 4) {
    real6[Math.floor(i / 4)] = complex6[i];
    imag5[Math.floor(i / 4)] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function getComplexWithIndex(complex6, index) {
  const real6 = complex6[index * 2];
  const imag5 = complex6[index * 2 + 1];
  return { real: real6, imag: imag5 };
}
function assignToTypedArray(data, real6, imag5, index) {
  data[index * 2] = real6;
  data[index * 2 + 1] = imag5;
}
function exponents(n, inverse) {
  const real6 = new Float32Array(n / 2);
  const imag5 = new Float32Array(n / 2);
  for (let i = 0; i < Math.ceil(n / 2); i++) {
    const x = (inverse ? 2 : -2) * Math.PI * (i / n);
    real6[i] = Math.cos(x);
    imag5[i] = Math.sin(x);
  }
  return { real: real6, imag: imag5 };
}
function exponent(k, n, inverse) {
  const x = (inverse ? 2 : -2) * Math.PI * (k / n);
  const real6 = Math.cos(x);
  const imag5 = Math.sin(x);
  return { real: real6, imag: imag5 };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/einsum_util.ts
var ARROW = "->";
var ARROW_REGEX = /->/g;
var COMMA = ",";
var ELLIPSIS = "...";
function decodeEinsumEquation(equation, numTensors) {
  equation = equation.replace(/\s/g, "");
  const numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
  if (numArrows < 1) {
    throw new Error("Equations without an arrow are not supported.");
  } else if (numArrows > 1) {
    throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);
  }
  const [inputString, outputString] = equation.split(ARROW);
  assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);
  const inputTerms = inputString.split(COMMA);
  const numInputs = inputTerms.length;
  if (numTensors !== numInputs) {
    throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
  }
  if (numInputs > 2) {
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  }
  const allDims = [];
  for (let i = 0; i < outputString.length; ++i) {
    const dimName = outputString[i];
    if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
      throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
    }
    if (allDims.indexOf(dimName) === -1) {
      allDims.push(dimName);
    }
  }
  for (let i = 0; i < inputString.length; ++i) {
    const dimName = inputString[i];
    if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
      allDims.push(dimName);
    }
  }
  const idDims = new Array(inputTerms.length);
  for (let i = 0; i < numInputs; ++i) {
    if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
      throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
    }
    idDims[i] = [];
    for (let j = 0; j < inputTerms[i].length; ++j) {
      idDims[i].push(allDims.indexOf(inputTerms[i][j]));
    }
  }
  const numDims = allDims.length;
  const numOutDims = outputString.length;
  const summedDims = [];
  for (let i = numOutDims; i < numDims; ++i) {
    summedDims.push(i);
  }
  return { allDims, summedDims, idDims };
}
function getEinsumPermutation(nDims, idDims) {
  let permutationIndices = new Array(nDims);
  permutationIndices.fill(-1);
  for (let i = 0; i < idDims.length; ++i) {
    permutationIndices[idDims[i]] = i;
  }
  const expandDims7 = [];
  for (let i = 0; i < nDims; ++i) {
    if (permutationIndices[i] === -1) {
      expandDims7.push(i);
    }
  }
  permutationIndices = permutationIndices.filter((d) => d !== -1);
  return { permutationIndices, expandDims: expandDims7 };
}
function checkEinsumDimSizes(nDims, idDims, tensors) {
  const dimSizes = new Array(nDims);
  for (let i = 0; i < tensors.length; ++i) {
    const shape = tensors[i].shape;
    for (let j = 0; j < idDims[i].length; ++j) {
      if (dimSizes[idDims[i][j]] === void 0) {
        dimSizes[idDims[i][j]] = shape[j];
      } else {
        assert(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j]}`);
      }
    }
  }
}
function getEinsumComputePath(summedDims, idDims) {
  const path = summedDims;
  const steps = [];
  let nSteps = 0;
  if (summedDims.length === 0) {
    path.push(-1);
  }
  nSteps = summedDims.length + 1;
  for (let i = 0; i < nSteps; ++i) {
    steps.push([]);
  }
  const computedTermIndices = [];
  for (let i = 0; i < path.length; ++i) {
    const summedDim = path[i];
    const termIndices = findTermsWithDim(idDims, summedDim);
    for (const termIndex of termIndices) {
      if (computedTermIndices.indexOf(termIndex) === -1) {
        steps[i].push(termIndex);
        computedTermIndices.push(termIndex);
      }
    }
  }
  return { path, steps };
}
function isIdentityPermutation(perm) {
  return perm.every((dim, index) => dim === index);
}
function findTermsWithDim(idDims, dim) {
  const termIndices = [];
  for (let i = 0; i < idDims.length; ++i) {
    if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
      termIndices.push(i);
    }
  }
  return termIndices;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/split_util.ts
function prepareSplitSize(x, numOrSizeSplits, axis = 0) {
  let splitSizes = [];
  if (typeof numOrSizeSplits === "number") {
    assert(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
    splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
  } else {
    const numOfNegs = numOrSizeSplits.reduce((count2, value) => {
      if (value === -1) {
        count2 += 1;
      }
      return count2;
    }, 0);
    assert(numOfNegs <= 1, () => "There should be only one negative value in split array.");
    const negIndex = numOrSizeSplits.indexOf(-1);
    if (negIndex !== -1) {
      const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
      numOrSizeSplits[negIndex] = x.shape[axis] - total;
    }
    assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
    splitSizes = numOrSizeSplits;
  }
  return splitSizes;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/ops/segment_util.ts
var segment_util_exports = {};
__export(segment_util_exports, {
  collectGatherOpShapeInfo: () => collectGatherOpShapeInfo,
  computeOutShape: () => computeOutShape3,
  segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize
});
function segOpComputeOptimalWindowSize(inSize, numSegments) {
  let done = false;
  let res;
  if (inSize <= PARALLELIZE_THRESHOLD) {
    res = inSize;
    done = true;
  } else {
    res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
  }
  while (!done) {
    if (res > numSegments || res === inSize) {
      done = true;
    } else {
      res = nearestDivisor(inSize, res + 1);
    }
  }
  return res;
}
function computeOutShape3(aShape, axis, numSegments) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (dim !== axis) {
      outShape.push(aShape[dim]);
    } else {
      outShape.push(numSegments);
    }
  }
  return outShape;
}
function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
  const indicesRank = indices.shape.length;
  const xRank = x.shape.length;
  if (batchDims !== 0) {
    if (batchDims < -indicesRank || batchDims > indicesRank) {
      throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
    }
  }
  if (batchDims < 0) {
    batchDims += indicesRank;
  }
  if (batchDims > xRank) {
    throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
  }
  if (axis < batchDims) {
    throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
  }
  for (let i = 0; i < batchDims; ++i) {
    if (x.shape[i] !== indices.shape[i]) {
      throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
    }
  }
  const dimSize = x.shape[axis];
  const outputShape = [];
  let batchSize = 1;
  let outerSize = 1;
  let sliceSize = 1;
  for (let i = 0; i < batchDims; ++i) {
    outputShape.push(x.shape[i]);
    batchSize *= x.shape[i];
  }
  for (let i = batchDims; i < axis; i++) {
    outputShape.push(x.shape[i]);
    outerSize *= x.shape[i];
  }
  for (let i = batchDims; i < indicesRank; i++) {
    outputShape.push(indices.shape[i]);
  }
  for (let i = axis + 1; i < xRank; i++) {
    outputShape.push(x.shape[i]);
    sliceSize *= x.shape[i];
  }
  return { batchSize, sliceSize, outerSize, dimSize, outputShape };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/backend_util.ts
function fromUint8ToStringArray(vals) {
  try {
    return vals.map((val) => decodeString(val));
  } catch (err) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
  }
}
function fromStringArrayToUint8(strings) {
  return strings.map((s) => encodeString(s));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/src/backends/kernel_impls.ts
var kernel_impls_exports = {};
__export(kernel_impls_exports, {
  nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl,
  nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl,
  nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl,
  whereImpl: () => whereImpl
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/backend.js
var EPSILON_FLOAT322 = 1e-7;
var EPSILON_FLOAT162 = 1e-4;
var DataStorage2 = class {
  constructor(backend3, dataMover) {
    this.backend = backend3;
    this.dataMover = dataMover;
    this.data = new WeakMap();
    this.dataIdsCount = 0;
  }
  get(dataId) {
    if (!this.data.has(dataId)) {
      this.dataMover.moveData(this.backend, dataId);
    }
    return this.data.get(dataId);
  }
  set(dataId, value) {
    this.dataIdsCount++;
    this.data.set(dataId, value);
  }
  has(dataId) {
    return this.data.has(dataId);
  }
  delete(dataId) {
    this.dataIdsCount--;
    return this.data.delete(dataId);
  }
  numDataIds() {
    return this.dataIdsCount;
  }
};
var KernelBackend2 = class {
  refCount(dataId) {
    return notYetImplemented2("refCount");
  }
  incRef(dataId) {
    return notYetImplemented2("incRef");
  }
  timerAvailable() {
    return true;
  }
  time(f) {
    return notYetImplemented2("time");
  }
  read(dataId) {
    return notYetImplemented2("read");
  }
  readSync(dataId) {
    return notYetImplemented2("readSync");
  }
  numDataIds() {
    return notYetImplemented2("numDataIds");
  }
  disposeData(dataId, force) {
    return notYetImplemented2("disposeData");
  }
  write(values, shape, dtype) {
    return notYetImplemented2("write");
  }
  move(dataId, values, shape, dtype, refCount) {
    return notYetImplemented2("move");
  }
  memory() {
    return notYetImplemented2("memory");
  }
  floatPrecision() {
    return notYetImplemented2("floatPrecision");
  }
  epsilon() {
    return this.floatPrecision() === 32 ? EPSILON_FLOAT322 : EPSILON_FLOAT162;
  }
  dispose() {
    return notYetImplemented2("dispose");
  }
};
function notYetImplemented2(kernelName) {
  throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/util_base.js
function shuffle2(array2) {
  let counter = array2.length;
  let temp = 0;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    temp = array2[counter];
    array2[counter] = array2[index];
    array2[index] = temp;
  }
}
function shuffleCombo2(array2, array22) {
  if (array2.length !== array22.length) {
    throw new Error(`Array sizes must match to be shuffled together First array length was ${array2.length}Second array length was ${array22.length}`);
  }
  let counter = array2.length;
  let temp, temp2;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    temp = array2[counter];
    temp2 = array22[counter];
    array2[counter] = array2[index];
    array22[counter] = array22[index];
    array2[index] = temp;
    array22[index] = temp2;
  }
}
function clamp2(min7, x, max7) {
  return Math.max(min7, Math.min(x, max7));
}
function nearestLargerEven2(val) {
  return val % 2 === 0 ? val : val + 1;
}
function sum3(arr) {
  let sum8 = 0;
  for (let i = 0; i < arr.length; i++) {
    sum8 += arr[i];
  }
  return sum8;
}
function randUniform2(a, b) {
  const r = Math.random();
  return b * r + (1 - r) * a;
}
function distSquared2(a, b) {
  let result = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = Number(a[i]) - Number(b[i]);
    result += diff * diff;
  }
  return result;
}
function assert2(expr, msg) {
  if (!expr) {
    throw new Error(typeof msg === "string" ? msg : msg());
  }
}
function assertShapesMatch2(shapeA, shapeB, errorMessagePrefix = "") {
  assert2(arraysEqual2(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
}
function assertNonNull2(a) {
  assert2(a != null, () => `The input to the tensor constructor must be a non-null value.`);
}
function flatten2(arr, result = [], skipTypedArray = false) {
  if (result == null) {
    result = [];
  }
  if (Array.isArray(arr) || isTypedArray2(arr) && !skipTypedArray) {
    for (let i = 0; i < arr.length; ++i) {
      flatten2(arr[i], result, skipTypedArray);
    }
  } else {
    result.push(arr);
  }
  return result;
}
function sizeFromShape2(shape) {
  if (shape.length === 0) {
    return 1;
  }
  let size = shape[0];
  for (let i = 1; i < shape.length; i++) {
    size *= shape[i];
  }
  return size;
}
function isScalarShape2(shape) {
  return shape.length === 0;
}
function arraysEqual2(n1, n2) {
  if (n1 === n2) {
    return true;
  }
  if (n1 == null || n2 == null) {
    return false;
  }
  if (n1.length !== n2.length) {
    return false;
  }
  for (let i = 0; i < n1.length; i++) {
    if (n1[i] !== n2[i]) {
      return false;
    }
  }
  return true;
}
function isInt2(a) {
  return a % 1 === 0;
}
function tanh3(x) {
  if (Math.tanh != null) {
    return Math.tanh(x);
  }
  if (x === Infinity) {
    return 1;
  } else if (x === -Infinity) {
    return -1;
  } else {
    const e2x = Math.exp(2 * x);
    return (e2x - 1) / (e2x + 1);
  }
}
function sizeToSquarishShape2(size) {
  const width = Math.ceil(Math.sqrt(size));
  return [width, Math.ceil(size / width)];
}
function createShuffledIndices2(n) {
  const shuffledIndices = new Uint32Array(n);
  for (let i = 0; i < n; ++i) {
    shuffledIndices[i] = i;
  }
  shuffle2(shuffledIndices);
  return shuffledIndices;
}
function rightPad2(a, size) {
  if (size <= a.length) {
    return a;
  }
  return a + " ".repeat(size - a.length);
}
function repeatedTry2(checkFn, delayFn = (counter) => 0, maxCounter) {
  return new Promise((resolve, reject) => {
    let tryCount = 0;
    const tryFn = () => {
      if (checkFn()) {
        resolve();
        return;
      }
      tryCount++;
      const nextBackoff = delayFn(tryCount);
      if (maxCounter != null && tryCount >= maxCounter) {
        reject();
        return;
      }
      setTimeout(tryFn, nextBackoff);
    };
    tryFn();
  });
}
function inferFromImplicitShape2(shape, size) {
  let shapeProd = 1;
  let implicitIdx = -1;
  for (let i = 0; i < shape.length; ++i) {
    if (shape[i] >= 0) {
      shapeProd *= shape[i];
    } else if (shape[i] === -1) {
      if (implicitIdx !== -1) {
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
      }
      implicitIdx = i;
    } else if (shape[i] < 0) {
      throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
    }
  }
  if (implicitIdx === -1) {
    if (size > 0 && size !== shapeProd) {
      throw Error(`Size(${size}) must match the product of shape ${shape}`);
    }
    return shape;
  }
  if (shapeProd === 0) {
    throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
  }
  if (size % shapeProd !== 0) {
    throw Error(`The implicit shape can't be a fractional number. Got ${size} / ${shapeProd}`);
  }
  const newShape = shape.slice();
  newShape[implicitIdx] = size / shapeProd;
  return newShape;
}
function parseAxisParam2(axis, shape) {
  const rank = shape.length;
  axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
  assert2(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
  assert2(axis.every((ax) => isInt2(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
  return axis.map((a) => a < 0 ? rank + a : a);
}
function squeezeShape2(shape, axis) {
  const newShape = [];
  const keptDims = [];
  const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
  const axes = axis == null || isEmptyArray ? null : parseAxisParam2(axis, shape).sort();
  let j = 0;
  for (let i = 0; i < shape.length; ++i) {
    if (axes != null) {
      if (axes[j] === i && shape[i] !== 1) {
        throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
      }
      if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
      if (axes[j] <= i) {
        j++;
      }
    }
    if (shape[i] !== 1) {
      newShape.push(shape[i]);
      keptDims.push(i);
    }
  }
  return { newShape, keptDims };
}
function getTypedArrayFromDType2(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function getArrayFromDType2(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else if (dtype === "string") {
    values = new Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function checkConversionForErrors2(vals, dtype) {
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
    }
  }
}
function isValidDtype2(dtype) {
  return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
}
function hasEncodingLoss2(oldType, newType) {
  if (newType === "complex64") {
    return false;
  }
  if (newType === "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "bool" && oldType === "bool") {
    return false;
  }
  return true;
}
function isTypedArray2(a) {
  return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array;
}
function bytesPerElement2(dtype) {
  if (dtype === "float32" || dtype === "int32") {
    return 4;
  } else if (dtype === "complex64") {
    return 8;
  } else if (dtype === "bool") {
    return 1;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function bytesFromStringArray2(arr) {
  if (arr == null) {
    return 0;
  }
  let bytes = 0;
  arr.forEach((x) => bytes += x.length);
  return bytes;
}
function isString2(value) {
  return typeof value === "string" || value instanceof String;
}
function isBoolean2(value) {
  return typeof value === "boolean";
}
function isNumber2(value) {
  return typeof value === "number";
}
function inferDtype2(values) {
  if (Array.isArray(values)) {
    return inferDtype2(values[0]);
  }
  if (values instanceof Float32Array) {
    return "float32";
  } else if (values instanceof Int32Array || values instanceof Uint8Array) {
    return "int32";
  } else if (isNumber2(values)) {
    return "float32";
  } else if (isString2(values)) {
    return "string";
  } else if (isBoolean2(values)) {
    return "bool";
  }
  return "float32";
}
function isFunction2(f) {
  return !!(f && f.constructor && f.call && f.apply);
}
function nearestDivisor2(size, start) {
  for (let i = start; i < size; ++i) {
    if (size % i === 0) {
      return i;
    }
  }
  return size;
}
function computeStrides2(shape) {
  const rank = shape.length;
  if (rank < 2) {
    return [];
  }
  const strides = new Array(rank - 1);
  strides[rank - 2] = shape[rank - 1];
  for (let i = rank - 3; i >= 0; --i) {
    strides[i] = strides[i + 1] * shape[i + 1];
  }
  return strides;
}
function createNestedArray2(offset, shape, a, isComplex = false) {
  const ret = new Array();
  if (shape.length === 1) {
    const d = shape[0] * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = a[offset + i];
    }
  } else {
    const d = shape[0];
    const rest = shape.slice(1);
    const len = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = createNestedArray2(offset + i * len, rest, a, isComplex);
    }
  }
  return ret;
}
function toNestedArray2(shape, a, isComplex = false) {
  if (shape.length === 0) {
    return a[0];
  }
  const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
  if (size === 0) {
    return [];
  }
  if (size !== a.length) {
    throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
  }
  return createNestedArray2(0, shape, a, isComplex);
}
function makeOnesTypedArray2(size, dtype) {
  const array2 = makeZerosTypedArray2(size, dtype);
  for (let i = 0; i < array2.length; i++) {
    array2[i] = 1;
  }
  return array2;
}
function makeZerosTypedArray2(size, dtype) {
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(size);
  } else if (dtype === "int32") {
    return new Int32Array(size);
  } else if (dtype === "bool") {
    return new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function makeZerosNestedTypedArray2(shape, dtype) {
  const size = shape.reduce((prev, curr) => prev * curr, 1);
  if (dtype == null || dtype === "float32") {
    return toNestedArray2(shape, new Float32Array(size));
  } else if (dtype === "int32") {
    return toNestedArray2(shape, new Int32Array(size));
  } else if (dtype === "bool") {
    return toNestedArray2(shape, new Uint8Array(size));
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function assertNonNegativeIntegerDimensions2(shape) {
  shape.forEach((dimSize) => {
    assert2(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
  });
}
function locToIndex2(locs, rank, strides) {
  if (rank === 0) {
    return 0;
  } else if (rank === 1) {
    return locs[0];
  }
  let index = locs[locs.length - 1];
  for (let i = 0; i < locs.length - 1; ++i) {
    index += strides[i] * locs[i];
  }
  return index;
}
function indexToLoc2(index, rank, strides) {
  if (rank === 0) {
    return [];
  } else if (rank === 1) {
    return [index];
  }
  const locs = new Array(rank);
  for (let i = 0; i < locs.length - 1; ++i) {
    locs[i] = Math.floor(index / strides[i]);
    index -= locs[i] * strides[i];
  }
  locs[locs.length - 1] = index;
  return locs;
}
function isPromise2(object) {
  return object && object.then && typeof object.then === "function";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/environment.js
var TENSORFLOWJS_FLAGS_PREFIX2 = "tfjsflags";
var Environment2 = class {
  constructor(global2) {
    this.global = global2;
    this.flags = {};
    this.flagRegistry = {};
    this.urlFlags = {};
    this.getQueryParams = getQueryParams2;
    this.populateURLFlags();
  }
  setPlatform(platformName, platform) {
    if (this.platform != null) {
      console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platform}.`);
    }
    this.platformName = platformName;
    this.platform = platform;
  }
  registerFlag(flagName, evaluationFn, setHook) {
    this.flagRegistry[flagName] = { evaluationFn, setHook };
    if (this.urlFlags[flagName] != null) {
      const flagValue = this.urlFlags[flagName];
      console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);
      this.set(flagName, flagValue);
    }
  }
  async getAsync(flagName) {
    if (flagName in this.flags) {
      return this.flags[flagName];
    }
    this.flags[flagName] = await this.evaluateFlag(flagName);
    return this.flags[flagName];
  }
  get(flagName) {
    if (flagName in this.flags) {
      return this.flags[flagName];
    }
    const flagValue = this.evaluateFlag(flagName);
    if (isPromise2(flagValue)) {
      throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
    }
    this.flags[flagName] = flagValue;
    return this.flags[flagName];
  }
  getNumber(flagName) {
    return this.get(flagName);
  }
  getBool(flagName) {
    return this.get(flagName);
  }
  getFlags() {
    return this.flags;
  }
  get features() {
    return this.flags;
  }
  set(flagName, value) {
    if (this.flagRegistry[flagName] == null) {
      throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
    }
    this.flags[flagName] = value;
    if (this.flagRegistry[flagName].setHook != null) {
      this.flagRegistry[flagName].setHook(value);
    }
  }
  evaluateFlag(flagName) {
    if (this.flagRegistry[flagName] == null) {
      throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
    }
    return this.flagRegistry[flagName].evaluationFn();
  }
  setFlags(flags) {
    this.flags = Object.assign({}, flags);
  }
  reset() {
    this.flags = {};
    this.urlFlags = {};
    this.populateURLFlags();
  }
  populateURLFlags() {
    if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
      return;
    }
    const urlParams = this.getQueryParams(this.global.location.search);
    if (TENSORFLOWJS_FLAGS_PREFIX2 in urlParams) {
      const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX2].split(",");
      keyValues.forEach((keyValue) => {
        const [key, value] = keyValue.split(":");
        this.urlFlags[key] = parseValue2(key, value);
      });
    }
  }
};
function getQueryParams2(queryString) {
  const params = {};
  queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {
    decodeParam2(params, t[0], t[1]);
    return t.join("=");
  });
  return params;
}
function decodeParam2(params, name, value) {
  params[decodeURIComponent(name)] = decodeURIComponent(value || "");
}
function parseValue2(flagName, value) {
  value = value.toLowerCase();
  if (value === "true" || value === "false") {
    return value === "true";
  } else if (`${+value}` === value) {
    return +value;
  }
  throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);
}
function env2() {
  return ENV3;
}
var ENV3 = null;
function setEnvironmentGlobal2(environment) {
  ENV3 = environment;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/global_util.js
var globalNameSpace2;
function getGlobalNamespace2() {
  if (globalNameSpace2 == null) {
    let ns;
    if (typeof window !== "undefined") {
      ns = window;
    } else if (typeof global !== "undefined") {
      ns = global;
    } else if (typeof process !== "undefined") {
      ns = process;
    } else if (typeof self !== "undefined") {
      ns = self;
    } else {
      throw new Error("Could not find a global object");
    }
    globalNameSpace2 = ns;
  }
  return globalNameSpace2;
}
function getGlobalMap2() {
  const ns = getGlobalNamespace2();
  if (ns._tfGlobals == null) {
    ns._tfGlobals = new Map();
  }
  return ns._tfGlobals;
}
function getGlobal2(key, init2) {
  const globalMap = getGlobalMap2();
  if (globalMap.has(key)) {
    return globalMap.get(key);
  } else {
    const singleton = init2();
    globalMap.set(key, singleton);
    return globalMap.get(key);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/kernel_names.js
var Abs2 = "Abs";
var Acos2 = "Acos";
var Acosh2 = "Acosh";
var Add2 = "Add";
var AddN2 = "AddN";
var All2 = "All";
var Any2 = "Any";
var ArgMax2 = "ArgMax";
var ArgMin2 = "ArgMin";
var Asin2 = "Asin";
var Asinh2 = "Asinh";
var Atan3 = "Atan";
var Atanh2 = "Atanh";
var Atan22 = "Atan2";
var AvgPool2 = "AvgPool";
var AvgPoolGrad2 = "AvgPoolGrad";
var AvgPool3D2 = "AvgPool3D";
var AvgPool3DGrad2 = "AvgPool3DGrad";
var BatchMatMul2 = "BatchMatMul";
var BatchToSpaceND2 = "BatchToSpaceND";
var Bincount2 = "Bincount";
var BroadcastTo2 = "BroadcastTo";
var Cast2 = "Cast";
var Ceil2 = "Ceil";
var ClipByValue2 = "ClipByValue";
var Complex2 = "Complex";
var ComplexAbs2 = "ComplexAbs";
var Concat2 = "Concat";
var Conv2D2 = "Conv2D";
var Conv2DBackpropFilter2 = "Conv2DBackpropFilter";
var Conv2DBackpropInput2 = "Conv2DBackpropInput";
var Conv3D2 = "Conv3D";
var Conv3DBackpropFilterV22 = "Conv3DBackpropFilterV2";
var Conv3DBackpropInputV22 = "Conv3DBackpropInputV2";
var Cos2 = "Cos";
var Cosh2 = "Cosh";
var Cumsum2 = "Cumsum";
var CropAndResize2 = "CropAndResize";
var DenseBincount2 = "DenseBincount";
var DepthToSpace2 = "DepthToSpace";
var DepthwiseConv2dNative2 = "DepthwiseConv2dNative";
var DepthwiseConv2dNativeBackpropFilter2 = "DepthwiseConv2dNativeBackpropFilter";
var DepthwiseConv2dNativeBackpropInput2 = "DepthwiseConv2dNativeBackpropInput";
var Diag2 = "Diag";
var Dilation2D2 = "Dilation2D";
var Dilation2DBackpropInput2 = "Dilation2DBackpropInput";
var Dilation2DBackpropFilter2 = "Dilation2DBackpropFilter";
var RealDiv2 = "RealDiv";
var Einsum2 = "Einsum";
var Elu2 = "Elu";
var EluGrad2 = "EluGrad";
var Erf2 = "Erf";
var Equal2 = "Equal";
var Exp2 = "Exp";
var ExpandDims2 = "ExpandDims";
var Expm12 = "Expm1";
var FFT2 = "FFT";
var Fill2 = "Fill";
var FlipLeftRight2 = "FlipLeftRight";
var Floor2 = "Floor";
var FloorDiv2 = "FloorDiv";
var FusedBatchNorm2 = "FusedBatchNorm";
var GatherV22 = "GatherV2";
var GatherNd2 = "GatherNd";
var Greater2 = "Greater";
var GreaterEqual2 = "GreaterEqual";
var Identity2 = "Identity";
var IFFT2 = "IFFT";
var Imag2 = "Imag";
var IsFinite2 = "IsFinite";
var IsInf2 = "IsInf";
var IsNan2 = "IsNan";
var LeakyRelu2 = "LeakyRelu";
var Less2 = "Less";
var LessEqual2 = "LessEqual";
var LinSpace2 = "LinSpace";
var Log2 = "Log";
var Log1p2 = "Log1p";
var LogicalAnd2 = "LogicalAnd";
var LogicalNot2 = "LogicalNot";
var LogicalOr2 = "LogicalOr";
var LogSoftmax2 = "LogSoftmax";
var LRN2 = "LRN";
var LRNGrad2 = "LRNGrad";
var Max2 = "Max";
var Maximum2 = "Maximum";
var MaxPool2 = "MaxPool";
var MaxPoolGrad2 = "MaxPoolGrad";
var MaxPool3D2 = "MaxPool3D";
var MaxPool3DGrad2 = "MaxPool3DGrad";
var MaxPoolWithArgmax2 = "MaxPoolWithArgmax";
var Mean2 = "Mean";
var Min2 = "Min";
var Minimum2 = "Minimum";
var MirrorPad2 = "MirrorPad";
var Mod2 = "Mod";
var Multinomial2 = "Multinomial";
var Multiply2 = "Multiply";
var Neg2 = "Neg";
var NotEqual2 = "NotEqual";
var NonMaxSuppressionV32 = "NonMaxSuppressionV3";
var NonMaxSuppressionV42 = "NonMaxSuppressionV4";
var NonMaxSuppressionV52 = "NonMaxSuppressionV5";
var OnesLike2 = "OnesLike";
var OneHot2 = "OneHot";
var Pack2 = "Pack";
var PadV22 = "PadV2";
var Pow2 = "Pow";
var Prelu2 = "Prelu";
var Prod2 = "Prod";
var Range2 = "Range";
var Real2 = "Real";
var Reciprocal2 = "Reciprocal";
var Relu2 = "Relu";
var Reshape2 = "Reshape";
var ResizeNearestNeighbor2 = "ResizeNearestNeighbor";
var ResizeNearestNeighborGrad2 = "ResizeNearestNeighborGrad";
var ResizeBilinear2 = "ResizeBilinear";
var ResizeBilinearGrad2 = "ResizeBilinearGrad";
var Relu62 = "Relu6";
var Reverse2 = "Reverse";
var Round2 = "Round";
var Rsqrt2 = "Rsqrt";
var ScatterNd2 = "ScatterNd";
var Select2 = "Select";
var Selu2 = "Selu";
var Slice2 = "Slice";
var Sin2 = "Sin";
var Sinh2 = "Sinh";
var Sign2 = "Sign";
var Sigmoid2 = "Sigmoid";
var Softplus2 = "Softplus";
var Sqrt2 = "Sqrt";
var Sum2 = "Sum";
var SpaceToBatchND2 = "SpaceToBatchND";
var SplitV2 = "SplitV";
var Softmax2 = "Softmax";
var SparseFillEmptyRows2 = "SparseFillEmptyRows";
var SparseReshape2 = "SparseReshape";
var SparseSegmentMean2 = "SparseSegmentMean";
var SparseSegmentSum2 = "SparseSegmentSum";
var SparseToDense2 = "SparseToDense";
var SquaredDifference2 = "SquaredDifference";
var Square2 = "Square";
var StridedSlice2 = "StridedSlice";
var StringNGrams2 = "StringNGrams";
var StringSplit2 = "StringSplit";
var StringToHashBucketFast2 = "StringToHashBucketFast";
var Sub2 = "Sub";
var Tan2 = "Tan";
var Tanh2 = "Tanh";
var Tile2 = "Tile";
var TopK2 = "TopK";
var Transform2 = "Transform";
var Transpose2 = "Transpose";
var Unique2 = "Unique";
var Unpack2 = "Unpack";
var UnsortedSegmentSum2 = "UnsortedSegmentSum";
var ZerosLike2 = "ZerosLike";
var Step2 = "Step";
var FromPixels2 = "FromPixels";
var RotateWithOffset2 = "RotateWithOffset";
var _FusedMatMul2 = "_FusedMatMul";
var FusedConv2D2 = "FusedConv2D";
var FusedDepthwiseConv2D2 = "FusedDepthwiseConv2D";

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js
var kernelRegistry2 = getGlobal2("kernelRegistry", () => new Map());
var gradRegistry2 = getGlobal2("gradRegistry", () => new Map());
function getKernel2(kernelName, backendName) {
  const key = makeKey2(kernelName, backendName);
  return kernelRegistry2.get(key);
}
function getGradient2(kernelName) {
  return gradRegistry2.get(kernelName);
}
function getKernelsForBackend2(backendName) {
  const it = kernelRegistry2.entries();
  const result = [];
  while (true) {
    const { done, value } = it.next();
    if (done) {
      break;
    }
    const [key, config] = value;
    const [backend3] = key.split("_");
    if (backend3 === backendName) {
      result.push(config);
    }
  }
  return result;
}
function registerKernel2(config) {
  const { kernelName, backendName } = config;
  const key = makeKey2(kernelName, backendName);
  if (kernelRegistry2.has(key)) {
    console.warn(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
  }
  kernelRegistry2.set(key, config);
}
function registerGradient2(config) {
  const { kernelName } = config;
  if (gradRegistry2.has(kernelName)) {
    if (env2().getBool("DEBUG")) {
      console.warn(`Overriding the gradient for '${kernelName}'`);
    }
  }
  gradRegistry2.set(kernelName, config);
}
function makeKey2(kernelName, backendName) {
  return `${backendName}_${kernelName}`;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/util.js
var util_exports2 = {};
__export(util_exports2, {
  arraysEqual: () => arraysEqual2,
  assert: () => assert2,
  assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions2,
  assertNonNull: () => assertNonNull2,
  assertShapesMatch: () => assertShapesMatch2,
  bytesFromStringArray: () => bytesFromStringArray2,
  bytesPerElement: () => bytesPerElement2,
  checkConversionForErrors: () => checkConversionForErrors2,
  clamp: () => clamp2,
  computeStrides: () => computeStrides2,
  createScalarValue: () => createScalarValue2,
  createShuffledIndices: () => createShuffledIndices2,
  decodeString: () => decodeString2,
  distSquared: () => distSquared2,
  encodeString: () => encodeString2,
  fetch: () => fetch5,
  fingerPrint64: () => fingerPrint642,
  flatten: () => flatten2,
  getArrayFromDType: () => getArrayFromDType2,
  getTypedArrayFromDType: () => getTypedArrayFromDType2,
  hasEncodingLoss: () => hasEncodingLoss2,
  hexToLong: () => hexToLong2,
  indexToLoc: () => indexToLoc2,
  inferDtype: () => inferDtype2,
  inferFromImplicitShape: () => inferFromImplicitShape2,
  isBoolean: () => isBoolean2,
  isFunction: () => isFunction2,
  isInt: () => isInt2,
  isNumber: () => isNumber2,
  isPromise: () => isPromise2,
  isScalarShape: () => isScalarShape2,
  isString: () => isString2,
  isTypedArray: () => isTypedArray2,
  isValidDtype: () => isValidDtype2,
  locToIndex: () => locToIndex2,
  makeOnesTypedArray: () => makeOnesTypedArray2,
  makeZerosNestedTypedArray: () => makeZerosNestedTypedArray2,
  makeZerosTypedArray: () => makeZerosTypedArray2,
  nearestDivisor: () => nearestDivisor2,
  nearestLargerEven: () => nearestLargerEven2,
  now: () => now2,
  parseAxisParam: () => parseAxisParam2,
  randUniform: () => randUniform2,
  repeatedTry: () => repeatedTry2,
  rightPad: () => rightPad2,
  shuffle: () => shuffle2,
  shuffleCombo: () => shuffleCombo2,
  sizeFromShape: () => sizeFromShape2,
  sizeToSquarishShape: () => sizeToSquarishShape2,
  squeezeShape: () => squeezeShape2,
  sum: () => sum3,
  tanh: () => tanh3,
  toNestedArray: () => toNestedArray2,
  toTypedArray: () => toTypedArray2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/hash_util.js
var LongExports2 = __toModule(require_long());
var Long2 = LongExports2.default || LongExports2;
function hexToLong2(hex) {
  return Long2.fromString(hex, true, 16);
}
var k02 = hexToLong2("c3a5c85c97cb3127");
var k12 = hexToLong2("b492b66fbe98f273");
var k22 = hexToLong2("9ae16a3b2f90404f");
function shiftMix2(val) {
  return val.xor(val.shru(47));
}
function fetch4(s, offset, numBytes) {
  const bytes = s.slice(offset, offset + numBytes);
  return Long2.fromBytes(Array.from(bytes), true, true);
}
function fetch642(s, offset) {
  return fetch4(s, offset, 8);
}
function fetch322(s, offset) {
  return fetch4(s, offset, 4);
}
function rotate642(val, shift) {
  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
}
function hashLen162(u, v, mul3 = hexToLong2("9ddfea08eb382d69")) {
  let a = u.xor(v).mul(mul3);
  a = a.xor(a.shru(47));
  let b = v.xor(a).mul(mul3);
  b = b.xor(b.shru(47));
  b = b.mul(mul3);
  return b;
}
function weakHashLen32WithSeeds2(w, x, y, z, a, b) {
  a = a.add(w);
  b = rotate642(b.add(a).add(z), 21);
  const c = a;
  a = a.add(x);
  a = a.add(y);
  b = b.add(rotate642(a, 44));
  return [a.add(z), b.add(c)];
}
function weakHashLen32WithSeedsStr2(s, offset, a, b) {
  return weakHashLen32WithSeeds2(fetch642(s, offset), fetch642(s, offset + 8), fetch642(s, offset + 16), fetch642(s, offset + 24), a, b);
}
function hashLen0to162(s, len = s.length) {
  if (len >= 8) {
    const mul3 = k22.add(len * 2);
    const a = fetch642(s, 0).add(k22);
    const b = fetch642(s, len - 8);
    const c = rotate642(b, 37).mul(mul3).add(a);
    const d = rotate642(a, 25).add(b).mul(mul3);
    return hashLen162(c, d, mul3);
  }
  if (len >= 4) {
    const mul3 = k22.add(len * 2);
    const a = fetch322(s, 0);
    return hashLen162(a.shl(3).add(len), fetch322(s, len - 4), mul3);
  }
  if (len > 0) {
    const a = s[0];
    const b = s[len >> 1];
    const c = s[len - 1];
    const y = a + (b << 8);
    const z = len + (c << 2);
    return shiftMix2(k22.mul(y).xor(k02.mul(z))).mul(k22);
  }
  return k22;
}
function hashLen17to322(s, len = s.length) {
  const mul3 = k22.add(len * 2);
  const a = fetch642(s, 0).mul(k12);
  const b = fetch642(s, 8);
  const c = fetch642(s, len - 8).mul(mul3);
  const d = fetch642(s, len - 16).mul(k22);
  return hashLen162(rotate642(a.add(b), 43).add(rotate642(c, 30)).add(d), a.add(rotate642(b.add(k22), 18)).add(c), mul3);
}
function hashLen33to642(s, len = s.length) {
  const mul3 = k22.add(len * 2);
  const a = fetch642(s, 0).mul(k22);
  const b = fetch642(s, 8);
  const c = fetch642(s, len - 8).mul(mul3);
  const d = fetch642(s, len - 16).mul(k22);
  const y = rotate642(a.add(b), 43).add(rotate642(c, 30)).add(d);
  const z = hashLen162(y, a.add(rotate642(b.add(k22), 18)).add(c), mul3);
  const e = fetch642(s, 16).mul(mul3);
  const f = fetch642(s, 24);
  const g = y.add(fetch642(s, len - 32)).mul(mul3);
  const h = z.add(fetch642(s, len - 24)).mul(mul3);
  return hashLen162(rotate642(e.add(f), 43).add(rotate642(g, 30)).add(h), e.add(rotate642(f.add(a), 18)).add(g), mul3);
}
function fingerPrint642(s, len = s.length) {
  const seed = Long2.fromNumber(81, true);
  if (len <= 32) {
    if (len <= 16) {
      return hashLen0to162(s, len);
    } else {
      return hashLen17to322(s, len);
    }
  } else if (len <= 64) {
    return hashLen33to642(s, len);
  }
  let x = seed;
  let y = seed.mul(k12).add(113);
  let z = shiftMix2(y.mul(k22).add(113)).mul(k22);
  let v = [Long2.UZERO, Long2.UZERO];
  let w = [Long2.UZERO, Long2.UZERO];
  x = x.mul(k22).add(fetch642(s, 0));
  let offset = 0;
  const end = (len - 1 >> 6) * 64;
  const last64 = end + (len - 1 & 63) - 63;
  do {
    x = rotate642(x.add(y).add(v[0]).add(fetch642(s, offset + 8)), 37).mul(k12);
    y = rotate642(y.add(v[1]).add(fetch642(s, offset + 48)), 42).mul(k12);
    x = x.xor(w[1]);
    y = y.add(v[0]).add(fetch642(s, offset + 40));
    z = rotate642(z.add(w[0]), 33).mul(k12);
    v = weakHashLen32WithSeedsStr2(s, offset, v[1].mul(k12), x.add(w[0]));
    w = weakHashLen32WithSeedsStr2(s, offset + 32, z.add(w[1]), y.add(fetch642(s, offset + 16)));
    [z, x] = [x, z];
    offset += 64;
  } while (offset !== end);
  const mul3 = k12.add(z.and(255).shl(1));
  offset = last64;
  w[0] = w[0].add(len - 1 & 63);
  v[0] = v[0].add(w[0]);
  w[0] = w[0].add(v[0]);
  x = rotate642(x.add(y).add(v[0]).add(fetch642(s, offset + 8)), 37).mul(mul3);
  y = rotate642(y.add(v[1]).add(fetch642(s, offset + 48)), 42).mul(mul3);
  x = x.xor(w[1].mul(9));
  y = y.add(v[0].mul(9).add(fetch642(s, offset + 40)));
  z = rotate642(z.add(w[0]), 33).mul(mul3);
  v = weakHashLen32WithSeedsStr2(s, offset, v[1].mul(mul3), x.add(w[0]));
  w = weakHashLen32WithSeedsStr2(s, offset + 32, z.add(w[1]), y.add(fetch642(s, offset + 16)));
  [z, x] = [x, z];
  return hashLen162(hashLen162(v[0], w[0], mul3).add(shiftMix2(y).mul(k02)).add(z), hashLen162(v[1], w[1], mul3).add(x), mul3);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/util.js
function createScalarValue2(value, dtype) {
  if (dtype === "string") {
    return encodeString2(value);
  }
  return toTypedArray2([value], dtype);
}
function noConversionNeeded2(a, dtype) {
  return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
}
function toTypedArray2(a, dtype) {
  if (dtype === "string") {
    throw new Error("Cannot convert a string[] to a TypedArray");
  }
  if (Array.isArray(a)) {
    a = flatten2(a);
  }
  if (env2().getBool("DEBUG")) {
    checkConversionForErrors2(a, dtype);
  }
  if (noConversionNeeded2(a, dtype)) {
    return a;
  }
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(a);
  } else if (dtype === "int32") {
    return new Int32Array(a);
  } else if (dtype === "bool") {
    const bool = new Uint8Array(a.length);
    for (let i = 0; i < bool.length; ++i) {
      if (Math.round(a[i]) !== 0) {
        bool[i] = 1;
      }
    }
    return bool;
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function now2() {
  return env2().platform.now();
}
function fetch5(path, requestInits) {
  return env2().platform.fetch(path, requestInits);
}
function encodeString2(s, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env2().platform.encode(s, encoding);
}
function decodeString2(bytes, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env2().platform.decode(bytes, encoding);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/profiler.js
var Profiler2 = class {
  constructor(backendTimer, logger) {
    this.backendTimer = backendTimer;
    this.logger = logger;
    if (logger == null) {
      this.logger = new Logger2();
    }
  }
  profileKernel(kernelName, inputs, f) {
    let outputs;
    const holdResultWrapperFn = () => {
      outputs = f();
    };
    let timer;
    const start = now2();
    if (this.backendTimer.timerAvailable()) {
      timer = this.backendTimer.time(holdResultWrapperFn);
    } else {
      holdResultWrapperFn();
      for (const output of outputs) {
        output.dataSync();
      }
      timer = Promise.resolve({ kernelMs: now2() - start });
    }
    if (env2().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
      for (let i = 0; i < outputs.length; i++) {
        const output = outputs[i];
        output.data().then((tensorVals) => {
          checkComputationForErrors2(tensorVals, output.dtype, kernelName);
        });
      }
    }
    const kernelProfile = {
      kernelName,
      outputs,
      inputs,
      timeMs: timer.then((timing) => timing.kernelMs),
      extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
    };
    return kernelProfile;
  }
  logKernelProfile(kernelProfile) {
    const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;
    outputs.forEach((result) => {
      Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
        this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
      });
    });
  }
};
function checkComputationForErrors2(vals, dtype, kernelName) {
  if (dtype !== "float32") {
    return false;
  }
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      console.warn(`Found ${num} in the result of '${kernelName}'`);
      return true;
    }
  }
  return false;
}
var Logger2 = class {
  logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
    const time2 = typeof timeMs === "number" ? rightPad2(`${timeMs}ms`, 9) : timeMs["error"];
    const paddedName = rightPad2(name, 25);
    const rank = result.rank;
    const size = result.size;
    const shape = rightPad2(result.shape.toString(), 14);
    let inputShapesDescription = "";
    for (const name2 in inputs) {
      const input2 = inputs[name2];
      if (input2 != null) {
        const inputShape = input2.shape || result.shape;
        const inputRank = inputShape.length;
        inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
      }
    }
    console.log(`%c${paddedName}	%c${time2}	%c${rank}D ${shape}	%c${size}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tape.js
function getFilteredNodesXToY2(tape, xs, y) {
  const tensorsFromX = {};
  const nodesFromX = {};
  for (let i = 0; i < xs.length; i++) {
    tensorsFromX[xs[i].id] = true;
  }
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (const inputName in nodeInputs) {
      const input2 = nodeInputs[inputName];
      let anyInputFromX = false;
      for (let j = 0; j < xs.length; j++) {
        if (tensorsFromX[input2.id]) {
          node.outputs.forEach((output) => tensorsFromX[output.id] = true);
          anyInputFromX = true;
          nodesFromX[node.id] = true;
          break;
        }
      }
      if (anyInputFromX) {
        break;
      }
    }
  }
  const tensorsLeadToY = {};
  tensorsLeadToY[y.id] = true;
  const nodesToY = {};
  for (let i = tape.length - 1; i >= 0; i--) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (let j = 0; j < node.outputs.length; j++) {
      if (tensorsLeadToY[node.outputs[j].id]) {
        for (const inputName in nodeInputs) {
          tensorsLeadToY[nodeInputs[inputName].id] = true;
          nodesToY[node.id] = true;
        }
        break;
      }
    }
  }
  const filteredTape = [];
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    if (nodesFromX[node.id] && nodesToY[node.id]) {
      const prunedInputs = {};
      for (const inputName in node.inputs) {
        const nodeInput = node.inputs[inputName];
        if (tensorsFromX[nodeInput.id]) {
          prunedInputs[inputName] = nodeInput;
        }
      }
      const prunedNode = Object.assign({}, node);
      prunedNode.inputs = prunedInputs;
      prunedNode.outputs = node.outputs;
      filteredTape.push(prunedNode);
    }
  }
  return filteredTape;
}
function backpropagateGradients2(tensorAccumulatedGradientMap, filteredTape, tidy3, add8) {
  for (let i = filteredTape.length - 1; i >= 0; i--) {
    const node = filteredTape[i];
    const dys = [];
    node.outputs.forEach((o) => {
      const gradTensor = tensorAccumulatedGradientMap[o.id];
      if (gradTensor != null) {
        dys.push(gradTensor);
      } else {
        dys.push(null);
      }
    });
    if (node.gradient == null) {
      throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
    }
    const inputGradients = node.gradient(dys);
    for (const inputName in node.inputs) {
      if (!(inputName in inputGradients)) {
        throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
      }
      const dx = tidy3(() => inputGradients[inputName]());
      if (dx.dtype !== "float32") {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
      }
      const x = node.inputs[inputName];
      if (!arraysEqual2(dx.shape, x.shape)) {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
      }
      if (tensorAccumulatedGradientMap[x.id] == null) {
        tensorAccumulatedGradientMap[x.id] = dx;
      } else {
        const curGradient = tensorAccumulatedGradientMap[x.id];
        tensorAccumulatedGradientMap[x.id] = add8(curGradient, dx);
        curGradient.dispose();
      }
    }
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tensor_format.js
var FORMAT_LIMIT_NUM_VALS2 = 20;
var FORMAT_NUM_FIRST_LAST_VALS2 = 3;
var FORMAT_NUM_SIG_DIGITS2 = 7;
function tensorToString2(vals, shape, dtype, verbose) {
  const strides = computeStrides2(shape);
  const padPerCol = computeMaxSizePerColumn2(vals, shape, dtype, strides);
  const rank = shape.length;
  const valsLines = subTensorToString2(vals, shape, dtype, strides, padPerCol);
  const lines = ["Tensor"];
  if (verbose) {
    lines.push(`  dtype: ${dtype}`);
    lines.push(`  rank: ${rank}`);
    lines.push(`  shape: [${shape}]`);
    lines.push(`  values:`);
  }
  lines.push(valsLines.map((l) => "    " + l).join("\n"));
  return lines.join("\n");
}
function computeMaxSizePerColumn2(vals, shape, dtype, strides) {
  const n = sizeFromShape2(shape);
  const numCols = strides[strides.length - 1];
  const padPerCol = new Array(numCols).fill(0);
  const rank = shape.length;
  const valuesOrTuples = dtype === "complex64" ? createComplexTuples2(vals) : vals;
  if (rank > 1) {
    for (let row = 0; row < n / numCols; row++) {
      const offset = row * numCols;
      for (let j = 0; j < numCols; j++) {
        padPerCol[j] = Math.max(padPerCol[j], valToString2(valuesOrTuples[offset + j], 0, dtype).length);
      }
    }
  }
  return padPerCol;
}
function valToString2(val, pad4, dtype) {
  let valStr;
  if (Array.isArray(val)) {
    valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS2))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS2))}j`;
  } else if (isString2(val)) {
    valStr = `'${val}'`;
  } else if (dtype === "bool") {
    valStr = boolNumToString2(val);
  } else {
    valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS2)).toString();
  }
  return rightPad2(valStr, pad4);
}
function boolNumToString2(v) {
  return v === 0 ? "false" : "true";
}
function subTensorToString2(vals, shape, dtype, strides, padPerCol, isLast = true) {
  const storagePerElement = dtype === "complex64" ? 2 : 1;
  const size = shape[0];
  const rank = shape.length;
  if (rank === 0) {
    if (dtype === "complex64") {
      const complexTuple = createComplexTuples2(vals);
      return [valToString2(complexTuple[0], 0, dtype)];
    }
    if (dtype === "bool") {
      return [boolNumToString2(vals[0])];
    }
    return [vals[0].toString()];
  }
  if (rank === 1) {
    if (size > FORMAT_LIMIT_NUM_VALS2) {
      const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS2 * storagePerElement;
      let firstVals = Array.from(vals.slice(0, firstValsSize));
      let lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS2) * storagePerElement, size * storagePerElement));
      if (dtype === "complex64") {
        firstVals = createComplexTuples2(firstVals);
        lastVals = createComplexTuples2(lastVals);
      }
      return [
        "[" + firstVals.map((x, i) => valToString2(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString2(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS2 + i], dtype)).join(", ") + "]"
      ];
    }
    const displayVals = dtype === "complex64" ? createComplexTuples2(vals) : Array.from(vals);
    return [
      "[" + displayVals.map((x, i) => valToString2(x, padPerCol[i], dtype)).join(", ") + "]"
    ];
  }
  const subshape = shape.slice(1);
  const substrides = strides.slice(1);
  const stride = strides[0] * storagePerElement;
  const lines = [];
  if (size > FORMAT_LIMIT_NUM_VALS2) {
    for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS2; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString2(vals.slice(start, end), subshape, dtype, substrides, padPerCol, false));
    }
    lines.push("...");
    for (let i = size - FORMAT_NUM_FIRST_LAST_VALS2; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString2(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1));
    }
  } else {
    for (let i = 0; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString2(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1));
    }
  }
  const sep = rank === 2 ? "," : "";
  lines[0] = "[" + lines[0] + sep;
  for (let i = 1; i < lines.length - 1; i++) {
    lines[i] = " " + lines[i] + sep;
  }
  let newLineSep = ",\n";
  for (let i = 2; i < rank; i++) {
    newLineSep += "\n";
  }
  lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
  return lines;
}
function createComplexTuples2(vals) {
  const complexTuples = [];
  for (let i = 0; i < vals.length; i += 2) {
    complexTuples.push([vals[i], vals[i + 1]]);
  }
  return complexTuples;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tensor.js
var TensorBuffer2 = class {
  constructor(shape, dtype, values) {
    this.dtype = dtype;
    this.shape = shape.slice();
    this.size = sizeFromShape2(shape);
    if (values != null) {
      const n = values.length;
      assert2(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
    }
    if (dtype === "complex64") {
      throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
    }
    this.values = values || getArrayFromDType2(dtype, this.size);
    this.strides = computeStrides2(shape);
  }
  set(value, ...locs) {
    if (locs.length === 0) {
      locs = [0];
    }
    assert2(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
    const index = this.locToIndex(locs);
    this.values[index] = value;
  }
  get(...locs) {
    if (locs.length === 0) {
      locs = [0];
    }
    let i = 0;
    for (const loc of locs) {
      if (loc < 0 || loc >= this.shape[i]) {
        const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
        throw new Error(msg);
      }
      i++;
    }
    let index = locs[locs.length - 1];
    for (let i2 = 0; i2 < locs.length - 1; ++i2) {
      index += this.strides[i2] * locs[i2];
    }
    return this.values[index];
  }
  locToIndex(locs) {
    if (this.rank === 0) {
      return 0;
    } else if (this.rank === 1) {
      return locs[0];
    }
    let index = locs[locs.length - 1];
    for (let i = 0; i < locs.length - 1; ++i) {
      index += this.strides[i] * locs[i];
    }
    return index;
  }
  indexToLoc(index) {
    if (this.rank === 0) {
      return [];
    } else if (this.rank === 1) {
      return [index];
    }
    const locs = new Array(this.shape.length);
    for (let i = 0; i < locs.length - 1; ++i) {
      locs[i] = Math.floor(index / this.strides[i]);
      index -= locs[i] * this.strides[i];
    }
    locs[locs.length - 1] = index;
    return locs;
  }
  get rank() {
    return this.shape.length;
  }
  toTensor() {
    return trackerFn2().makeTensor(this.values, this.shape, this.dtype);
  }
};
var trackerFn2 = null;
var opHandler3 = null;
var deprecationWarningFn2 = null;
function setTensorTracker2(fn) {
  trackerFn2 = fn;
}
function setOpHandler2(handler) {
  opHandler3 = handler;
}
function setDeprecationWarningFn2(fn) {
  deprecationWarningFn2 = fn;
}
var Tensor4 = class {
  constructor(shape, dtype, dataId, id) {
    this.kept = false;
    this.isDisposedInternal = false;
    this.shape = shape.slice();
    this.dtype = dtype || "float32";
    this.size = sizeFromShape2(shape);
    this.strides = computeStrides2(shape);
    this.dataId = dataId;
    this.id = id;
    this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }
  get rank() {
    return this.shape.length;
  }
  async buffer() {
    const vals = await this.data();
    return opHandler3.buffer(this.shape, this.dtype, vals);
  }
  bufferSync() {
    return opHandler3.buffer(this.shape, this.dtype, this.dataSync());
  }
  async array() {
    const vals = await this.data();
    return toNestedArray2(this.shape, vals, this.dtype === "complex64");
  }
  arraySync() {
    return toNestedArray2(this.shape, this.dataSync(), this.dtype === "complex64");
  }
  async data() {
    this.throwIfDisposed();
    const data = trackerFn2().read(this.dataId);
    if (this.dtype === "string") {
      const bytes = await data;
      try {
        return bytes.map((b) => decodeString2(b));
      } catch (_a) {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return data;
  }
  dataSync() {
    this.throwIfDisposed();
    const data = trackerFn2().readSync(this.dataId);
    if (this.dtype === "string") {
      try {
        return data.map((b) => decodeString2(b));
      } catch (_a) {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return data;
  }
  async bytes() {
    this.throwIfDisposed();
    const data = await trackerFn2().read(this.dataId);
    if (this.dtype === "string") {
      return data;
    } else {
      return new Uint8Array(data.buffer);
    }
  }
  dispose() {
    if (this.isDisposed) {
      return;
    }
    trackerFn2().disposeTensor(this);
    this.isDisposedInternal = true;
  }
  get isDisposed() {
    return this.isDisposedInternal;
  }
  throwIfDisposed() {
    if (this.isDisposed) {
      throw new Error(`Tensor is disposed.`);
    }
  }
  print(verbose = false) {
    return opHandler3.print(this, verbose);
  }
  clone() {
    this.throwIfDisposed();
    return opHandler3.clone(this);
  }
  toString(verbose = false) {
    const vals = this.dataSync();
    return tensorToString2(vals, this.shape, this.dtype, verbose);
  }
  cast(dtype) {
    this.throwIfDisposed();
    return opHandler3.cast(this, dtype);
  }
  variable(trainable = true, name, dtype) {
    this.throwIfDisposed();
    return trackerFn2().makeVariable(this, trainable, name, dtype);
  }
};
Object.defineProperty(Tensor4, Symbol.hasInstance, {
  value: (instance) => {
    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
  }
});
function getGlobalTensorClass2() {
  return getGlobal2("Tensor", () => {
    return Tensor4;
  });
}
getGlobalTensorClass2();
var Variable2 = class extends Tensor4 {
  constructor(initialValue, trainable, name, tensorId) {
    super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
    this.trainable = trainable;
    this.name = name;
  }
  assign(newValue) {
    if (newValue.dtype !== this.dtype) {
      throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
    }
    if (!arraysEqual2(newValue.shape, this.shape)) {
      throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
    }
    trackerFn2().disposeTensor(this);
    this.dataId = newValue.dataId;
    trackerFn2().incRef(this, null);
  }
  dispose() {
    trackerFn2().disposeVariable(this);
    this.isDisposedInternal = true;
  }
};
Object.defineProperty(Variable2, Symbol.hasInstance, {
  value: (instance) => {
    return instance instanceof Tensor4 && instance.assign != null && instance.assign instanceof Function;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
var tensor_util_exports2 = {};
__export(tensor_util_exports2, {
  assertTypesMatch: () => assertTypesMatch2,
  getTensorsInContainer: () => getTensorsInContainer2,
  isTensorInList: () => isTensorInList2,
  makeTypesMatch: () => makeTypesMatch2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/types.js
var Rank2;
(function(Rank16) {
  Rank16["R0"] = "R0";
  Rank16["R1"] = "R1";
  Rank16["R2"] = "R2";
  Rank16["R3"] = "R3";
  Rank16["R4"] = "R4";
  Rank16["R5"] = "R5";
  Rank16["R6"] = "R6";
})(Rank2 || (Rank2 = {}));
var UpcastInt32AndMap2;
(function(UpcastInt32AndMap3) {
  UpcastInt32AndMap3["float32"] = "float32";
  UpcastInt32AndMap3["int32"] = "int32";
  UpcastInt32AndMap3["bool"] = "int32";
  UpcastInt32AndMap3["complex64"] = "complex64";
})(UpcastInt32AndMap2 || (UpcastInt32AndMap2 = {}));
var UpcastBoolAndMap2;
(function(UpcastBoolAndMap3) {
  UpcastBoolAndMap3["float32"] = "float32";
  UpcastBoolAndMap3["int32"] = "int32";
  UpcastBoolAndMap3["bool"] = "bool";
  UpcastBoolAndMap3["complex64"] = "complex64";
})(UpcastBoolAndMap2 || (UpcastBoolAndMap2 = {}));
var UpcastFloat32AndMap2;
(function(UpcastFloat32AndMap3) {
  UpcastFloat32AndMap3["float32"] = "float32";
  UpcastFloat32AndMap3["int32"] = "float32";
  UpcastFloat32AndMap3["bool"] = "float32";
  UpcastFloat32AndMap3["complex64"] = "complex64";
})(UpcastFloat32AndMap2 || (UpcastFloat32AndMap2 = {}));
var UpcastComplex64AndMap2;
(function(UpcastComplex64AndMap3) {
  UpcastComplex64AndMap3["float32"] = "complex64";
  UpcastComplex64AndMap3["int32"] = "complex64";
  UpcastComplex64AndMap3["bool"] = "complex64";
  UpcastComplex64AndMap3["complex64"] = "complex64";
})(UpcastComplex64AndMap2 || (UpcastComplex64AndMap2 = {}));
var upcastTypeMap2 = {
  "float32": UpcastFloat32AndMap2,
  "int32": UpcastInt32AndMap2,
  "bool": UpcastBoolAndMap2,
  "complex64": UpcastComplex64AndMap2
};
function upcastType2(typeA, typeB) {
  if (typeA === "string" || typeB === "string") {
    if (typeA === "string" && typeB === "string") {
      return "string";
    }
    throw new Error(`Can not upcast ${typeA} with ${typeB}`);
  }
  return upcastTypeMap2[typeA][typeB];
}
function sumOutType2(type) {
  return upcastType2(type, "int32");
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tensor_util.js
function makeTypesMatch2(a, b) {
  if (a.dtype === b.dtype) {
    return [a, b];
  }
  const dtype = upcastType2(a.dtype, b.dtype);
  return [a.cast(dtype), b.cast(dtype)];
}
function assertTypesMatch2(a, b) {
  assert2(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
}
function isTensorInList2(tensor3, tensorList) {
  return tensorList.some((x) => x.id === tensor3.id);
}
function getTensorsInContainer2(result) {
  const list = [];
  const seen = new Set();
  walkTensorContainer2(result, list, seen);
  return list;
}
function walkTensorContainer2(container, list, seen) {
  if (container == null) {
    return;
  }
  if (container instanceof Tensor4) {
    list.push(container);
    return;
  }
  if (!isIterable2(container)) {
    return;
  }
  const iterable = container;
  for (const k in iterable) {
    const val = iterable[k];
    if (!seen.has(val)) {
      seen.add(val);
      walkTensorContainer2(val, list, seen);
    }
  }
}
function isIterable2(obj) {
  return Array.isArray(obj) || typeof obj === "object";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/engine.js
function isRegisteredKernelInvocation2(kernelInvocation) {
  return kernelInvocation.kernelName != null;
}
var EngineState2 = class {
  constructor() {
    this.registeredVariables = {};
    this.nextTapeNodeId = 0;
    this.numBytes = 0;
    this.numTensors = 0;
    this.numStringTensors = 0;
    this.numDataBuffers = 0;
    this.gradientDepth = 0;
    this.kernelDepth = 0;
    this.scopeStack = [];
    this.numDataMovesStack = [];
    this.nextScopeId = 0;
    this.tensorInfo = new WeakMap();
    this.profiling = false;
    this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,
      get kernelNames() {
        return Array.from(new Set(this.kernels.map((k) => k.name)));
      }
    };
  }
  dispose() {
    for (const variableName in this.registeredVariables) {
      this.registeredVariables[variableName].dispose();
    }
  }
};
var Engine3 = class {
  constructor(ENV7) {
    this.ENV = ENV7;
    this.registry = {};
    this.registryFactory = {};
    this.pendingBackendInitId = 0;
    this.state = new EngineState2();
  }
  async ready() {
    if (this.pendingBackendInit != null) {
      return this.pendingBackendInit.then(() => {
      });
    }
    if (this.backendInstance != null) {
      return;
    }
    const sortedBackends = this.getSortedBackends();
    for (let i = 0; i < sortedBackends.length; i++) {
      const backendName = sortedBackends[i];
      const success = await this.initializeBackend(backendName).success;
      if (success) {
        await this.setBackend(backendName);
        return;
      }
    }
    throw new Error(`Could not initialize any backends, all backend initializations failed.`);
  }
  get backend() {
    if (this.pendingBackendInit != null) {
      throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
    }
    if (this.backendInstance == null) {
      const { name, asyncInit } = this.initializeBackendsAndReturnBest();
      if (asyncInit) {
        throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      }
      this.setBackend(name);
    }
    return this.backendInstance;
  }
  backendNames() {
    return Object.keys(this.registryFactory);
  }
  findBackend(backendName) {
    if (!(backendName in this.registry)) {
      if (backendName in this.registryFactory) {
        const { asyncInit } = this.initializeBackend(backendName);
        if (asyncInit) {
          return null;
        }
      } else {
        return null;
      }
    }
    return this.registry[backendName];
  }
  findBackendFactory(backendName) {
    if (!(backendName in this.registryFactory)) {
      return null;
    }
    return this.registryFactory[backendName].factory;
  }
  registerBackend(backendName, factory, priority = 1) {
    if (backendName in this.registryFactory) {
      console.warn(`${backendName} backend was already registered. Reusing existing backend factory.`);
      return false;
    }
    this.registryFactory[backendName] = { factory, priority };
    return true;
  }
  async setBackend(backendName) {
    if (this.registryFactory[backendName] == null) {
      throw new Error(`Backend name '${backendName}' not found in registry`);
    }
    this.backendName = backendName;
    if (this.registry[backendName] == null) {
      this.backendInstance = null;
      const { success, asyncInit } = this.initializeBackend(backendName);
      const result = asyncInit ? await success : success;
      if (!result) {
        return false;
      }
    }
    this.backendInstance = this.registry[backendName];
    this.setupRegisteredKernels();
    this.profiler = new Profiler2(this.backendInstance);
    return true;
  }
  setupRegisteredKernels() {
    const kernels = getKernelsForBackend2(this.backendName);
    kernels.forEach((kernel) => {
      if (kernel.setupFunc != null) {
        kernel.setupFunc(this.backendInstance);
      }
    });
  }
  disposeRegisteredKernels(backendName) {
    const kernels = getKernelsForBackend2(backendName);
    kernels.forEach((kernel) => {
      if (kernel.disposeFunc != null) {
        kernel.disposeFunc(this.registry[backendName]);
      }
    });
  }
  initializeBackend(backendName) {
    const registryFactoryEntry = this.registryFactory[backendName];
    if (registryFactoryEntry == null) {
      throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
    }
    try {
      const backend3 = registryFactoryEntry.factory();
      if (backend3 && !(backend3 instanceof KernelBackend2) && typeof backend3.then === "function") {
        const promiseId = ++this.pendingBackendInitId;
        const success = backend3.then((backendInstance) => {
          if (promiseId < this.pendingBackendInitId) {
            return false;
          }
          this.registry[backendName] = backendInstance;
          this.pendingBackendInit = null;
          return true;
        }).catch((err) => {
          if (promiseId < this.pendingBackendInitId) {
            return false;
          }
          this.pendingBackendInit = null;
          console.warn(`Initialization of backend ${backendName} failed`);
          console.warn(err.stack || err.message);
          return false;
        });
        this.pendingBackendInit = success;
        return { success, asyncInit: true };
      } else {
        this.registry[backendName] = backend3;
        return { success: true, asyncInit: false };
      }
    } catch (err) {
      console.warn(`Initialization of backend ${backendName} failed`);
      console.warn(err.stack || err.message);
      return { success: false, asyncInit: false };
    }
  }
  removeBackend(backendName) {
    if (!(backendName in this.registryFactory)) {
      throw new Error(`${backendName} backend not found in registry`);
    }
    if (this.backendName === backendName && this.pendingBackendInit != null) {
      this.pendingBackendInitId++;
    }
    if (backendName in this.registry) {
      this.disposeRegisteredKernels(backendName);
      this.registry[backendName].dispose();
      delete this.registry[backendName];
    }
    delete this.registryFactory[backendName];
    if (this.backendName === backendName) {
      this.pendingBackendInit = null;
      this.backendName = null;
      this.backendInstance = null;
    }
  }
  getSortedBackends() {
    if (Object.keys(this.registryFactory).length === 0) {
      throw new Error("No backend found in registry.");
    }
    return Object.keys(this.registryFactory).sort((a, b) => {
      return this.registryFactory[b].priority - this.registryFactory[a].priority;
    });
  }
  initializeBackendsAndReturnBest() {
    const sortedBackends = this.getSortedBackends();
    for (let i = 0; i < sortedBackends.length; i++) {
      const backendName = sortedBackends[i];
      const { success, asyncInit } = this.initializeBackend(backendName);
      if (asyncInit || success) {
        return { name: backendName, asyncInit };
      }
    }
    throw new Error(`Could not initialize any backends, all backend initializations failed.`);
  }
  moveData(backend3, dataId) {
    const info = this.state.tensorInfo.get(dataId);
    const srcBackend = info.backend;
    const values = this.readSync(dataId);
    const refCount = srcBackend.refCount(dataId);
    srcBackend.disposeData(dataId, true);
    info.backend = backend3;
    backend3.move(dataId, values, info.shape, info.dtype, refCount);
    if (this.shouldCheckForMemLeaks()) {
      this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
    }
  }
  tidy(nameOrFn, fn) {
    let name = null;
    if (fn == null) {
      if (typeof nameOrFn !== "function") {
        throw new Error("Please provide a function to tidy()");
      }
      fn = nameOrFn;
    } else {
      if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
        throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      }
      if (typeof fn !== "function") {
        throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      }
      name = nameOrFn;
    }
    let result;
    return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
      result = fn();
      if (result instanceof Promise) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      return result;
    });
  }
  scopedRun(start, end, f) {
    start();
    try {
      const res = f();
      end();
      return res;
    } catch (ex) {
      end();
      throw ex;
    }
  }
  nextTensorId() {
    return Engine3.nextTensorId++;
  }
  nextVariableId() {
    return Engine3.nextVariableId++;
  }
  clone(x) {
    const y = ENGINE2.runKernel(Identity2, { x });
    const inputs = { x };
    const grad3 = (dy) => ({
      x: () => {
        const dtype = "float32";
        const gradInputs = { x: dy };
        const attrs = { dtype };
        return ENGINE2.runKernel(Cast2, gradInputs, attrs);
      }
    });
    const saved = [];
    this.addTapeNode(this.state.activeScope.name, inputs, [y], grad3, saved, {});
    return y;
  }
  runKernel(kernelName, inputs, attrs) {
    const hasKernel = getKernel2(kernelName, this.backendName) != null;
    if (!hasKernel) {
      throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
    }
    return this.runKernelFunc({ kernelName, inputs, attrs });
  }
  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }
  checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
    const numDataIdsAfter = this.backend.numDataIds();
    let numOutputDataIds = 0;
    outInfos.forEach((info) => {
      numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
    });
    const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
    const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
    if (dataIdsLeaked > 0) {
      throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
    }
  }
  runKernelFunc(kernelParams) {
    let outputs;
    let saved = [];
    const isTapeOn = this.isTapeOn();
    const startingBytecount = this.state.numBytes;
    const startingNumTensors = this.state.numTensors;
    if (this.shouldCheckForMemLeaks()) {
      this.state.numDataMovesStack.push(0);
    }
    let kernelFunc3;
    if (this.backendName == null) {
      this.backend;
    }
    let out;
    const kernelOrScopeName = isRegisteredKernelInvocation2(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
    if (isRegisteredKernelInvocation2(kernelParams)) {
      const { kernelName, inputs: inputs2, attrs: attrs2 } = kernelParams;
      if (this.backendName == null) {
        this.backend;
      }
      const kernel = getKernel2(kernelName, this.backendName);
      assert2(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
      kernelFunc3 = () => {
        const numDataIdsBefore = this.backend.numDataIds();
        out = kernel.kernelFunc({ inputs: inputs2, attrs: attrs2, backend: this.backend });
        const outInfos = Array.isArray(out) ? out : [out];
        if (this.shouldCheckForMemLeaks()) {
          this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
        }
        const outTensors = outInfos.map((outInfo) => {
          if (outInfo.rank != null) {
            return outInfo;
          }
          const { dataId, shape, dtype } = outInfo;
          return this.makeTensorFromDataId(dataId, shape, dtype);
        });
        if (isTapeOn) {
          const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
          saved = this.saveTensorsForBackwardMode(tensorsToSave);
        }
        return outTensors;
      };
    } else {
      const { forwardFunc } = kernelParams;
      const saveFunc = (tensors) => {
        if (!isTapeOn) {
          return;
        }
        saved = tensors.map((tensor3) => this.keep(this.clone(tensor3)));
      };
      kernelFunc3 = () => {
        const numDataIdsBefore = this.backend.numDataIds();
        out = this.tidy(() => forwardFunc(this.backend, saveFunc));
        const outs = Array.isArray(out) ? out : [out];
        if (this.shouldCheckForMemLeaks()) {
          this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
        }
        return outs;
      };
    }
    const { inputs, attrs } = kernelParams;
    const backwardsFunc = isRegisteredKernelInvocation2(kernelParams) ? null : kernelParams.backwardsFunc;
    let kernelProfile;
    this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
      if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
        outputs = kernelFunc3();
      } else {
        kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc3());
        if (this.ENV.getBool("DEBUG")) {
          this.profiler.logKernelProfile(kernelProfile);
        }
        outputs = kernelProfile.outputs;
      }
    });
    if (isTapeOn) {
      this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
    }
    if (this.state.profiling) {
      this.state.activeProfile.kernels.push({
        name: kernelOrScopeName,
        bytesAdded: this.state.numBytes - startingBytecount,
        totalBytesSnapshot: this.state.numBytes,
        tensorsAdded: this.state.numTensors - startingNumTensors,
        totalTensorsSnapshot: this.state.numTensors,
        inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
        outputShapes: outputs.map((item) => item.shape),
        kernelTimeMs: kernelProfile.timeMs,
        extraInfo: kernelProfile.extraInfo
      });
    }
    return Array.isArray(out) ? outputs : outputs[0];
  }
  saveTensorsForBackwardMode(tensors) {
    const saved = tensors.map((tensor3) => this.keep(this.clone(tensor3)));
    return saved;
  }
  getTensorsForGradient(kernelName, inputs, outputs) {
    const gradConfig = getGradient2(kernelName);
    if (gradConfig != null) {
      const inputsToSave = gradConfig.inputsToSave || [];
      const outputsToSave = gradConfig.outputsToSave || [];
      let inputTensorsToSave;
      if (gradConfig.saveAllInputs) {
        assert2(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
        inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
      } else {
        inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
      }
      const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);
      return inputTensorsToSave.concat(outputTensorsToSave);
    }
    return [];
  }
  makeTensor(values, shape, dtype, backend3) {
    if (values == null) {
      throw new Error("Values passed to engine.makeTensor() are null");
    }
    dtype = dtype || "float32";
    backend3 = backend3 || this.backend;
    let backendVals = values;
    if (dtype === "string" && isString2(values[0])) {
      backendVals = values.map((d) => encodeString2(d));
    }
    const dataId = backend3.write(backendVals, shape, dtype);
    const t = new Tensor4(shape, dtype, dataId, this.nextTensorId());
    this.trackTensor(t, backend3);
    if (dtype === "string") {
      const info = this.state.tensorInfo.get(dataId);
      const newBytes = bytesFromStringArray2(backendVals);
      this.state.numBytes += newBytes - info.bytes;
      info.bytes = newBytes;
    }
    return t;
  }
  makeTensorFromDataId(dataId, shape, dtype, backend3) {
    dtype = dtype || "float32";
    const t = new Tensor4(shape, dtype, dataId, this.nextTensorId());
    this.trackTensor(t, backend3);
    return t;
  }
  makeVariable(initialValue, trainable = true, name, dtype) {
    name = name || this.nextVariableId().toString();
    if (dtype != null && dtype !== initialValue.dtype) {
      initialValue = initialValue.cast(dtype);
    }
    const v = new Variable2(initialValue, trainable, name, this.nextTensorId());
    if (this.state.registeredVariables[v.name] != null) {
      throw new Error(`Variable with name ${v.name} was already registered`);
    }
    this.state.registeredVariables[v.name] = v;
    this.incRef(v, this.backend);
    return v;
  }
  trackTensor(a, backend3) {
    this.state.numTensors++;
    if (a.dtype === "string") {
      this.state.numStringTensors++;
    }
    let bytes = 0;
    if (a.dtype !== "complex64" && a.dtype !== "string") {
      bytes = a.size * bytesPerElement2(a.dtype);
    }
    this.state.numBytes += bytes;
    if (!this.state.tensorInfo.has(a.dataId)) {
      this.state.numDataBuffers++;
      this.state.tensorInfo.set(a.dataId, {
        backend: backend3 || this.backend,
        dtype: a.dtype,
        shape: a.shape,
        bytes
      });
    }
    if (!(a instanceof Variable2)) {
      this.track(a);
    }
  }
  incRef(a, backend3) {
    this.trackTensor(a, backend3);
    this.backend.incRef(a.dataId);
  }
  removeDataId(dataId, backend3) {
    if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend3) {
      this.state.tensorInfo.delete(dataId);
      this.state.numDataBuffers--;
    }
  }
  disposeTensor(a) {
    if (!this.state.tensorInfo.has(a.dataId)) {
      return;
    }
    const info = this.state.tensorInfo.get(a.dataId);
    this.state.numTensors--;
    if (a.dtype === "string") {
      this.state.numStringTensors--;
      this.state.numBytes -= info.bytes;
    }
    if (a.dtype !== "complex64" && a.dtype !== "string") {
      const bytes = a.size * bytesPerElement2(a.dtype);
      this.state.numBytes -= bytes;
    }
    if (info.backend.disposeData(a.dataId)) {
      this.removeDataId(a.dataId, info.backend);
    }
  }
  disposeVariables() {
    for (const varName in this.state.registeredVariables) {
      const v = this.state.registeredVariables[varName];
      this.disposeVariable(v);
    }
  }
  disposeVariable(v) {
    this.disposeTensor(v);
    if (this.state.registeredVariables[v.name] != null) {
      delete this.state.registeredVariables[v.name];
    }
  }
  memory() {
    const info = this.backend.memory();
    info.numTensors = this.state.numTensors;
    info.numDataBuffers = this.state.numDataBuffers;
    info.numBytes = this.state.numBytes;
    if (this.state.numStringTensors > 0) {
      info.unreliable = true;
      if (info.reasons == null) {
        info.reasons = [];
      }
      info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
    }
    return info;
  }
  async profile(query) {
    this.state.profiling = true;
    const startBytes = this.state.numBytes;
    const startNumTensors = this.state.numTensors;
    this.state.activeProfile.kernels = [];
    this.state.activeProfile.result = await query();
    this.state.profiling = false;
    this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
    this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
    this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
    for (const kernel of this.state.activeProfile.kernels) {
      kernel.kernelTimeMs = await kernel.kernelTimeMs;
      kernel.extraInfo = await kernel.extraInfo;
    }
    return this.state.activeProfile;
  }
  isTapeOn() {
    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
  }
  addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
    const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
    const gradConfig = getGradient2(kernelName);
    if (gradConfig != null) {
      gradientsFunc = gradConfig.gradFunc;
    }
    if (gradientsFunc != null) {
      tapeNode.gradient = (dys) => {
        dys = dys.map((dy, i) => {
          if (dy == null) {
            const output = outputs[i];
            const vals = makeZerosTypedArray2(output.size, output.dtype);
            return this.makeTensor(vals, output.shape, output.dtype);
          }
          return dy;
        });
        return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
      };
    }
    this.state.activeTape.push(tapeNode);
  }
  keep(result) {
    result.kept = true;
    return result;
  }
  startTape() {
    if (this.state.gradientDepth === 0) {
      this.state.activeTape = [];
    }
    this.state.gradientDepth++;
  }
  endTape() {
    this.state.gradientDepth--;
  }
  startScope(name) {
    const scopeInfo = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    if (name) {
      scopeInfo.name = name;
    }
    this.state.scopeStack.push(scopeInfo);
    this.state.activeScope = scopeInfo;
  }
  endScope(result) {
    const tensorsToTrackInParent = getTensorsInContainer2(result);
    const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t) => t.id));
    for (let i = 0; i < this.state.activeScope.track.length; i++) {
      const tensor3 = this.state.activeScope.track[i];
      if (!tensor3.kept && !tensorsToTrackInParentSet.has(tensor3.id)) {
        tensor3.dispose();
      }
    }
    const oldScope = this.state.scopeStack.pop();
    this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
    tensorsToTrackInParent.forEach((tensor3) => {
      if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
        this.track(tensor3);
      }
    });
  }
  gradients(f, xs, dy, allowNoGradients = false) {
    assert2(xs.length > 0, () => "gradients() received an empty list of xs.");
    if (dy != null && dy.dtype !== "float32") {
      throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
    }
    const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
    assert2(y instanceof Tensor4, () => "The result y returned by f() must be a tensor.");
    const filteredTape = getFilteredNodesXToY2(this.state.activeTape, xs, y);
    if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
      throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    }
    return this.tidy("backward", () => {
      const accumulatedGradientMap = {};
      accumulatedGradientMap[y.id] = dy == null ? ones3(y.shape) : dy;
      backpropagateGradients2(accumulatedGradientMap, filteredTape, (f2) => this.tidy(f2), add3);
      const grads3 = xs.map((x) => accumulatedGradientMap[x.id]);
      if (this.state.gradientDepth === 0) {
        this.state.activeTape.forEach((node) => {
          for (const tensor3 of node.saved) {
            tensor3.dispose();
          }
        });
        this.state.activeTape = null;
      }
      return { value: y, grads: grads3 };
    });
  }
  customGrad(f) {
    assert2(isFunction2(f), () => "The f passed in customGrad(f) must be a function.");
    return (...inputs) => {
      assert2(inputs.every((t) => t instanceof Tensor4), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      let res;
      const inputMap = {};
      inputs.forEach((input2, i) => {
        inputMap[i] = input2;
      });
      const forwardFunc = (_, save) => {
        res = f(...[...inputs, save]);
        assert2(res.value instanceof Tensor4, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
        assert2(isFunction2(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
        return res.value;
      };
      const backwardsFunc = (dy, saved) => {
        const gradRes = res.gradFunc(dy, saved);
        const grads3 = Array.isArray(gradRes) ? gradRes : [gradRes];
        assert2(grads3.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
        assert2(grads3.every((t) => t instanceof Tensor4), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
        const gradMap = {};
        grads3.forEach((grad3, i) => {
          gradMap[i] = () => grad3;
        });
        return gradMap;
      };
      return this.runKernelFunc({
        forwardFunc,
        backwardsFunc,
        inputs: inputMap
      });
    };
  }
  readSync(dataId) {
    const info = this.state.tensorInfo.get(dataId);
    return info.backend.readSync(dataId);
  }
  read(dataId) {
    const info = this.state.tensorInfo.get(dataId);
    return info.backend.read(dataId);
  }
  async time(query) {
    const start = now2();
    const timingInfo = await this.backend.time(query);
    timingInfo.wallMs = now2() - start;
    return timingInfo;
  }
  track(result) {
    if (this.state.activeScope != null) {
      result.scopeId = this.state.activeScope.id;
      this.state.activeScope.track.push(result);
    }
    return result;
  }
  get registeredVariables() {
    return this.state.registeredVariables;
  }
  reset() {
    this.pendingBackendInitId++;
    this.state.dispose();
    this.ENV.reset();
    this.state = new EngineState2();
    for (const backendName in this.registry) {
      this.disposeRegisteredKernels(backendName);
      this.registry[backendName].dispose();
      delete this.registry[backendName];
    }
    this.backendName = null;
    this.backendInstance = null;
    this.pendingBackendInit = null;
  }
};
Engine3.nextTensorId = 0;
Engine3.nextVariableId = 0;
function ones3(shape) {
  const values = makeOnesTypedArray2(sizeFromShape2(shape), "float32");
  return ENGINE2.makeTensor(values, shape, "float32");
}
function getOrMakeEngine2() {
  const ns = getGlobalNamespace2();
  if (ns._tfengine == null) {
    const environment = new Environment2(ns);
    ns._tfengine = new Engine3(environment);
  }
  setEnvironmentGlobal2(ns._tfengine.ENV);
  setTensorTracker2(() => ns._tfengine);
  return ns._tfengine;
}
var ENGINE2 = getOrMakeEngine2();
function add3(a, b) {
  const inputs = { a, b };
  return ENGINE2.runKernel(Add2, inputs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/device_util.js
var device_util_exports2 = {};
__export(device_util_exports2, {
  isBrowser: () => isBrowser2,
  isMobile: () => isMobile2
});
function _isNavigatorDefined2() {
  return typeof navigator !== "undefined" && navigator != null;
}
function isMobile2(nav) {
  if (nav || _isNavigatorDefined2()) {
    if (!nav) {
      nav = navigator;
    }
    if (nav.product === "ReactNative") {
      return true;
    }
    const a = nav.userAgent || nav.vendor || window.opera;
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
  }
  return false;
}
function isBrowser2() {
  return typeof window !== "undefined" && window.document != null || typeof WorkerGlobalScope !== "undefined";
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/flags.js
var ENV4 = env2();
ENV4.registerFlag("DEBUG", () => false, (debugValue) => {
  if (debugValue) {
    console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
  }
});
ENV4.registerFlag("IS_BROWSER", () => isBrowser2());
ENV4.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
ENV4.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
ENV4.registerFlag("PROD", () => false);
ENV4.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV4.getBool("DEBUG"));
ENV4.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
ENV4.registerFlag("IS_TEST", () => false);
ENV4.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
ENV4.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js
function inferShape2(val, dtype) {
  let firstElem = val;
  if (isTypedArray2(val)) {
    return dtype === "string" ? [] : [val.length];
  }
  if (!Array.isArray(val)) {
    return [];
  }
  const shape = [];
  while (Array.isArray(firstElem) || isTypedArray2(firstElem) && dtype !== "string") {
    shape.push(firstElem.length);
    firstElem = firstElem[0];
  }
  if (Array.isArray(val) && env2().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
    deepAssertShapeConsistency2(val, shape, []);
  }
  return shape;
}
function deepAssertShapeConsistency2(val, shape, indices) {
  indices = indices || [];
  if (!Array.isArray(val) && !isTypedArray2(val)) {
    assert2(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
    return;
  }
  assert2(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
  assert2(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
  const subShape = shape.slice(1);
  for (let i = 0; i < val.length; ++i) {
    deepAssertShapeConsistency2(val[i], subShape, indices.concat(i));
  }
}
function assertDtype2(expectedDtype, actualDType, argName, functionName) {
  if (expectedDtype === "string_or_numeric") {
    return;
  }
  if (expectedDtype == null) {
    throw new Error(`Expected dtype cannot be null.`);
  }
  if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
  }
}
function convertToTensor2(x, argName, functionName, parseAsDtype = "numeric") {
  if (x instanceof Tensor4) {
    assertDtype2(parseAsDtype, x.dtype, argName, functionName);
    return x;
  }
  let inferredDtype = inferDtype2(x);
  if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
    inferredDtype = parseAsDtype;
  }
  assertDtype2(parseAsDtype, inferredDtype, argName, functionName);
  if (x == null || !isTypedArray2(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
    const type = x == null ? "null" : x.constructor.name;
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
  }
  const inferredShape = inferShape2(x, inferredDtype);
  if (!isTypedArray2(x) && !Array.isArray(x)) {
    x = [x];
  }
  const skipTypedArray = true;
  const values = inferredDtype !== "string" ? toTypedArray2(x, inferredDtype) : flatten2(x, [], skipTypedArray);
  return ENGINE2.makeTensor(values, inferredShape, inferredDtype);
}
function convertToTensorArray2(arg, argName, functionName, parseAsDtype = "numeric") {
  if (!Array.isArray(arg)) {
    throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
  }
  const tensors = arg;
  return tensors.map((t, i) => convertToTensor2(t, `${argName}[${i}]`, functionName, parseAsDtype));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/operation.js
var OP_SCOPE_SUFFIX2 = "__op";
function op2(f) {
  const keys = Object.keys(f);
  if (keys.length !== 1) {
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
  }
  let opName = keys[0];
  const fn = f[opName];
  if (opName.endsWith("_")) {
    opName = opName.substring(0, opName.length - 1);
  }
  opName = opName + OP_SCOPE_SUFFIX2;
  const f2 = (...args) => {
    ENGINE2.startScope(opName);
    try {
      const result = fn(...args);
      if (isPromise2(result)) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      ENGINE2.endScope(result);
      return result;
    } catch (ex) {
      ENGINE2.endScope(null);
      throw ex;
    }
  };
  Object.defineProperty(f2, "name", { value: opName, configurable: true });
  return f2;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/complex.js
function complex_2(real6, imag5) {
  const $real = convertToTensor2(real6, "real", "complex");
  const $imag = convertToTensor2(imag5, "imag", "complex");
  assertShapesMatch2($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
  const inputs = { real: $real, imag: $imag };
  return ENGINE2.runKernel(Complex2, inputs);
}
var complex2 = op2({ complex_: complex_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js
function makeTensor2(values, shape, inferredShape, dtype) {
  if (dtype == null) {
    dtype = inferDtype2(values);
  }
  if (dtype === "complex64") {
    throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
  }
  if (!isTypedArray2(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  }
  if (shape != null) {
    assertNonNegativeIntegerDimensions2(shape);
    const providedSize = sizeFromShape2(shape);
    const inferredSize = sizeFromShape2(inferredShape);
    assert2(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
    for (let i = 0; i < inferredShape.length; ++i) {
      const inferred = inferredShape[i];
      const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape2(shape.slice(i)) : true;
      assert2(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
    }
  }
  if (!isTypedArray2(values) && !Array.isArray(values)) {
    values = [values];
  }
  shape = shape || inferredShape;
  values = dtype !== "string" ? toTypedArray2(values, dtype) : flatten2(values, [], true);
  return ENGINE2.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js
function tensor2(values, shape, dtype) {
  const inferredShape = inferShape2(values, dtype);
  return makeTensor2(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/types.js
var DTYPE_VALUE_SIZE_MAP2 = {
  "float32": 4,
  "float16": 2,
  "int32": 4,
  "uint16": 2,
  "uint8": 1,
  "bool": 1,
  "complex64": 8
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js
var NUM_BYTES_STRING_LENGTH2 = 4;
async function encodeWeights2(tensors, group) {
  const specs = [];
  const dataPromises = [];
  const names = Array.isArray(tensors) ? tensors.map((tensor3) => tensor3.name) : Object.keys(tensors);
  for (let i = 0; i < names.length; ++i) {
    const name = names[i];
    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
    if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);
    }
    const spec = { name, shape: t.shape, dtype: t.dtype };
    if (t.dtype === "string") {
      const utf8bytes = new Promise(async (resolve) => {
        const vals = await t.bytes();
        const totalNumBytes = vals.reduce((p2, c) => p2 + c.length, 0) + NUM_BYTES_STRING_LENGTH2 * vals.length;
        const bytes = new Uint8Array(totalNumBytes);
        let offset = 0;
        for (let i2 = 0; i2 < vals.length; i2++) {
          const val = vals[i2];
          const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
          bytes.set(bytesOfLength, offset);
          offset += NUM_BYTES_STRING_LENGTH2;
          bytes.set(val, offset);
          offset += val.length;
        }
        resolve(bytes);
      });
      dataPromises.push(utf8bytes);
    } else {
      dataPromises.push(t.data());
    }
    if (group != null) {
      spec.group = group;
    }
    specs.push(spec);
  }
  const tensorValues = await Promise.all(dataPromises);
  return { data: concatenateTypedArrays2(tensorValues), specs };
}
function decodeWeights2(buffer3, specs) {
  const out = {};
  let float16Decode;
  let offset = 0;
  for (const spec of specs) {
    const name = spec.name;
    const dtype = spec.dtype;
    const shape = spec.shape;
    const size = sizeFromShape2(shape);
    let values;
    if ("quantization" in spec) {
      const quantization = spec.quantization;
      if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
        if (!("min" in quantization && "scale" in quantization)) {
          throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
        }
      } else if (quantization.dtype === "float16") {
        if (dtype !== "float32") {
          throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
        }
      } else {
        throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
      }
      const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP2[quantization.dtype];
      const byteBuffer = buffer3.slice(offset, offset + size * quantizationSizeFactor);
      const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
      if (dtype === "float32") {
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          values = new Float32Array(quantizedArray.length);
          for (let i = 0; i < quantizedArray.length; i++) {
            const v = quantizedArray[i];
            values[i] = v * quantization.scale + quantization.min;
          }
        } else if (quantization.dtype === "float16") {
          if (float16Decode === void 0) {
            float16Decode = getFloat16Decoder2();
          }
          values = float16Decode(quantizedArray);
        } else {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
        }
      } else if (dtype === "int32") {
        if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
        }
        values = new Int32Array(quantizedArray.length);
        for (let i = 0; i < quantizedArray.length; i++) {
          const v = quantizedArray[i];
          values[i] = Math.round(v * quantization.scale + quantization.min);
        }
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * quantizationSizeFactor;
    } else if (dtype === "string") {
      const size2 = sizeFromShape2(spec.shape);
      values = [];
      for (let i = 0; i < size2; i++) {
        const byteLength = new Uint32Array(buffer3.slice(offset, offset + NUM_BYTES_STRING_LENGTH2))[0];
        offset += NUM_BYTES_STRING_LENGTH2;
        const bytes = new Uint8Array(buffer3.slice(offset, offset + byteLength));
        values.push(bytes);
        offset += byteLength;
      }
    } else {
      const dtypeFactor = DTYPE_VALUE_SIZE_MAP2[dtype];
      const byteBuffer = buffer3.slice(offset, offset + size * dtypeFactor);
      if (dtype === "float32") {
        values = new Float32Array(byteBuffer);
      } else if (dtype === "int32") {
        values = new Int32Array(byteBuffer);
      } else if (dtype === "bool") {
        values = new Uint8Array(byteBuffer);
      } else if (dtype === "complex64") {
        values = new Float32Array(byteBuffer);
        const real6 = new Float32Array(values.length / 2);
        const image4 = new Float32Array(values.length / 2);
        for (let i = 0; i < real6.length; i++) {
          real6[i] = values[i * 2];
          image4[i] = values[i * 2 + 1];
        }
        const realTensor = tensor2(real6, shape, "float32");
        const imageTensor = tensor2(image4, shape, "float32");
        out[name] = complex2(realTensor, imageTensor);
        realTensor.dispose();
        imageTensor.dispose();
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * dtypeFactor;
    }
    if (dtype !== "complex64") {
      out[name] = tensor2(values, shape, dtype);
    }
  }
  return out;
}
function concatenateTypedArrays2(xs) {
  if (xs === null) {
    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
  }
  let totalByteLength = 0;
  const normalizedXs = [];
  xs.forEach((x) => {
    totalByteLength += x.byteLength;
    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
    }
  });
  const y = new Uint8Array(totalByteLength);
  let offset = 0;
  normalizedXs.forEach((x) => {
    y.set(new Uint8Array(x.buffer), offset);
    offset += x.byteLength;
  });
  return y.buffer;
}
var useNodeBuffer2 = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
function stringByteLength2(str) {
  if (useNodeBuffer2) {
    return Buffer.byteLength(str);
  }
  return new Blob([str]).size;
}
function arrayBufferToBase64String2(buffer3) {
  if (useNodeBuffer2) {
    return Buffer.from(buffer3).toString("base64");
  }
  const buf = new Uint8Array(buffer3);
  let s = "";
  for (let i = 0, l = buf.length; i < l; i++) {
    s += String.fromCharCode(buf[i]);
  }
  return btoa(s);
}
function base64StringToArrayBuffer2(str) {
  if (useNodeBuffer2) {
    const buf = Buffer.from(str, "base64");
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
  }
  const s = atob(str);
  const buffer3 = new Uint8Array(s.length);
  for (let i = 0; i < s.length; ++i) {
    buffer3.set([s.charCodeAt(i)], i);
  }
  return buffer3.buffer;
}
function concatenateArrayBuffers2(buffers) {
  if (buffers.length === 1) {
    return buffers[0];
  }
  let totalByteLength = 0;
  buffers.forEach((buffer3) => {
    totalByteLength += buffer3.byteLength;
  });
  const temp = new Uint8Array(totalByteLength);
  let offset = 0;
  buffers.forEach((buffer3) => {
    temp.set(new Uint8Array(buffer3), offset);
    offset += buffer3.byteLength;
  });
  return temp.buffer;
}
function basename2(path) {
  const SEPARATOR = "/";
  path = path.trim();
  while (path.endsWith(SEPARATOR)) {
    path = path.slice(0, path.length - 1);
  }
  const items = path.split(SEPARATOR);
  return items[items.length - 1];
}
function getModelArtifactsInfoForJSON2(modelArtifacts) {
  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  }
  return {
    dateSaved: new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength2(JSON.stringify(modelArtifacts.modelTopology)),
    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength2(JSON.stringify(modelArtifacts.weightSpecs)),
    weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
  };
}
function computeFloat16MantisaTable2() {
  const convertMantissa = (i) => {
    let m = i << 13;
    let e = 0;
    while ((m & 8388608) === 0) {
      e -= 8388608;
      m <<= 1;
    }
    m &= ~8388608;
    e += 947912704;
    return m | e;
  };
  const mantisaTable = new Uint32Array(2048);
  mantisaTable[0] = 0;
  for (let i = 1; i < 1024; i++) {
    mantisaTable[i] = convertMantissa(i);
  }
  for (let i = 1024; i < 2048; i++) {
    mantisaTable[i] = 939524096 + (i - 1024 << 13);
  }
  return mantisaTable;
}
function computeFloat16ExponentTable2() {
  const exponentTable = new Uint32Array(64);
  exponentTable[0] = 0;
  exponentTable[31] = 1199570944;
  exponentTable[32] = 2147483648;
  exponentTable[63] = 3347054592;
  for (let i = 1; i < 31; i++) {
    exponentTable[i] = i << 23;
  }
  for (let i = 33; i < 63; i++) {
    exponentTable[i] = 2147483648 + (i - 32 << 23);
  }
  return exponentTable;
}
function computeFloat16OffsetTable2() {
  const offsetTable = new Uint32Array(64);
  for (let i = 0; i < 64; i++) {
    offsetTable[i] = 1024;
  }
  offsetTable[0] = offsetTable[32] = 0;
  return offsetTable;
}
function getFloat16Decoder2() {
  const mantisaTable = computeFloat16MantisaTable2();
  const exponentTable = computeFloat16ExponentTable2();
  const offsetTable = computeFloat16OffsetTable2();
  return (quantizedArray) => {
    const buffer3 = new ArrayBuffer(4 * quantizedArray.length);
    const bufferUint32View = new Uint32Array(buffer3);
    for (let index = 0; index < quantizedArray.length; index++) {
      const float16Bits = quantizedArray[index];
      const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
      bufferUint32View[index] = float32Bits;
    }
    return new Float32Array(buffer3);
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js
var IORouterRegistry2 = class {
  constructor() {
    this.saveRouters = [];
    this.loadRouters = [];
  }
  static getInstance() {
    if (IORouterRegistry2.instance == null) {
      IORouterRegistry2.instance = new IORouterRegistry2();
    }
    return IORouterRegistry2.instance;
  }
  static registerSaveRouter(saveRouter) {
    IORouterRegistry2.getInstance().saveRouters.push(saveRouter);
  }
  static registerLoadRouter(loadRouter) {
    IORouterRegistry2.getInstance().loadRouters.push(loadRouter);
  }
  static getSaveHandlers(url) {
    return IORouterRegistry2.getHandlers(url, "save");
  }
  static getLoadHandlers(url, loadOptions) {
    return IORouterRegistry2.getHandlers(url, "load", loadOptions);
  }
  static getHandlers(url, handlerType, loadOptions) {
    const validHandlers = [];
    const routers = handlerType === "load" ? IORouterRegistry2.getInstance().loadRouters : IORouterRegistry2.getInstance().saveRouters;
    routers.forEach((router) => {
      const handler = router(url, loadOptions);
      if (handler !== null) {
        validHandlers.push(handler);
      }
    });
    return validHandlers;
  }
};
var registerSaveRouter2 = (loudRouter) => IORouterRegistry2.registerSaveRouter(loudRouter);
var registerLoadRouter2 = (loudRouter) => IORouterRegistry2.registerLoadRouter(loudRouter);
var getSaveHandlers2 = (url) => IORouterRegistry2.getSaveHandlers(url);
var getLoadHandlers2 = (url, loadOptions) => IORouterRegistry2.getLoadHandlers(url, loadOptions);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js
var DATABASE_NAME2 = "tensorflowjs";
var DATABASE_VERSION2 = 1;
var MODEL_STORE_NAME2 = "models_store";
var INFO_STORE_NAME2 = "model_info_store";
function getIndexedDBFactory2() {
  if (!env2().getBool("IS_BROWSER")) {
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  }
  const theWindow = typeof window === "undefined" ? self : window;
  const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
  if (factory == null) {
    throw new Error("The current browser does not appear to support IndexedDB.");
  }
  return factory;
}
function setUpDatabase2(openRequest) {
  const db = openRequest.result;
  db.createObjectStore(MODEL_STORE_NAME2, { keyPath: "modelPath" });
  db.createObjectStore(INFO_STORE_NAME2, { keyPath: "modelPath" });
}
var BrowserIndexedDB2 = class {
  constructor(modelPath) {
    this.indexedDB = getIndexedDBFactory2();
    if (modelPath == null || !modelPath) {
      throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    }
    this.modelPath = modelPath;
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    }
    return this.databaseAction(this.modelPath, modelArtifacts);
  }
  async load() {
    return this.databaseAction(this.modelPath);
  }
  databaseAction(modelPath, modelArtifacts) {
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME2, DATABASE_VERSION2);
      openRequest.onupgradeneeded = () => setUpDatabase2(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        if (modelArtifacts == null) {
          const modelTx = db.transaction(MODEL_STORE_NAME2, "readonly");
          const modelStore = modelTx.objectStore(MODEL_STORE_NAME2);
          const getRequest = modelStore.get(this.modelPath);
          getRequest.onsuccess = () => {
            if (getRequest.result == null) {
              db.close();
              return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
            } else {
              resolve(getRequest.result.modelArtifacts);
            }
          };
          getRequest.onerror = (error) => {
            db.close();
            return reject(getRequest.error);
          };
          modelTx.oncomplete = () => db.close();
        } else {
          const modelArtifactsInfo = getModelArtifactsInfoForJSON2(modelArtifacts);
          const infoTx = db.transaction(INFO_STORE_NAME2, "readwrite");
          let infoStore = infoTx.objectStore(INFO_STORE_NAME2);
          const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });
          let modelTx;
          putInfoRequest.onsuccess = () => {
            modelTx = db.transaction(MODEL_STORE_NAME2, "readwrite");
            const modelStore = modelTx.objectStore(MODEL_STORE_NAME2);
            const putModelRequest = modelStore.put({
              modelPath: this.modelPath,
              modelArtifacts,
              modelArtifactsInfo
            });
            putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });
            putModelRequest.onerror = (error) => {
              infoStore = infoTx.objectStore(INFO_STORE_NAME2);
              const deleteInfoRequest = infoStore.delete(this.modelPath);
              deleteInfoRequest.onsuccess = () => {
                db.close();
                return reject(putModelRequest.error);
              };
              deleteInfoRequest.onerror = (error2) => {
                db.close();
                return reject(putModelRequest.error);
              };
            };
          };
          putInfoRequest.onerror = (error) => {
            db.close();
            return reject(putInfoRequest.error);
          };
          infoTx.oncomplete = () => {
            if (modelTx == null) {
              db.close();
            } else {
              modelTx.oncomplete = () => db.close();
            }
          };
        }
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
};
BrowserIndexedDB2.URL_SCHEME = "indexeddb://";
var indexedDBRouter2 = (url) => {
  if (!env2().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB2.URL_SCHEME)) {
      return browserIndexedDB2(url.slice(BrowserIndexedDB2.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry2.registerSaveRouter(indexedDBRouter2);
IORouterRegistry2.registerLoadRouter(indexedDBRouter2);
function browserIndexedDB2(modelPath) {
  return new BrowserIndexedDB2(modelPath);
}
function maybeStripScheme3(key) {
  return key.startsWith(BrowserIndexedDB2.URL_SCHEME) ? key.slice(BrowserIndexedDB2.URL_SCHEME.length) : key;
}
var BrowserIndexedDBManager2 = class {
  constructor() {
    this.indexedDB = getIndexedDBFactory2();
  }
  async listModels() {
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME2, DATABASE_VERSION2);
      openRequest.onupgradeneeded = () => setUpDatabase2(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        const tx = db.transaction(INFO_STORE_NAME2, "readonly");
        const store = tx.objectStore(INFO_STORE_NAME2);
        const getAllInfoRequest = store.getAll();
        getAllInfoRequest.onsuccess = () => {
          const out = {};
          for (const item of getAllInfoRequest.result) {
            out[item.modelPath] = item.modelArtifactsInfo;
          }
          resolve(out);
        };
        getAllInfoRequest.onerror = (error) => {
          db.close();
          return reject(getAllInfoRequest.error);
        };
        tx.oncomplete = () => db.close();
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
  async removeModel(path) {
    path = maybeStripScheme3(path);
    return new Promise((resolve, reject) => {
      const openRequest = this.indexedDB.open(DATABASE_NAME2, DATABASE_VERSION2);
      openRequest.onupgradeneeded = () => setUpDatabase2(openRequest);
      openRequest.onsuccess = () => {
        const db = openRequest.result;
        const infoTx = db.transaction(INFO_STORE_NAME2, "readwrite");
        const infoStore = infoTx.objectStore(INFO_STORE_NAME2);
        const getInfoRequest = infoStore.get(path);
        let modelTx;
        getInfoRequest.onsuccess = () => {
          if (getInfoRequest.result == null) {
            db.close();
            return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
          } else {
            const deleteInfoRequest = infoStore.delete(path);
            const deleteModelData = () => {
              modelTx = db.transaction(MODEL_STORE_NAME2, "readwrite");
              const modelStore = modelTx.objectStore(MODEL_STORE_NAME2);
              const deleteModelRequest = modelStore.delete(path);
              deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
              deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
            };
            deleteInfoRequest.onsuccess = deleteModelData;
            deleteInfoRequest.onerror = (error) => {
              deleteModelData();
              db.close();
              return reject(getInfoRequest.error);
            };
          }
        };
        getInfoRequest.onerror = (error) => {
          db.close();
          return reject(getInfoRequest.error);
        };
        infoTx.oncomplete = () => {
          if (modelTx == null) {
            db.close();
          } else {
            modelTx.oncomplete = () => db.close();
          }
        };
      };
      openRequest.onerror = (error) => reject(openRequest.error);
    });
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js
var PATH_SEPARATOR2 = "/";
var PATH_PREFIX2 = "tensorflowjs_models";
var INFO_SUFFIX2 = "info";
var MODEL_TOPOLOGY_SUFFIX2 = "model_topology";
var WEIGHT_SPECS_SUFFIX2 = "weight_specs";
var WEIGHT_DATA_SUFFIX2 = "weight_data";
var MODEL_METADATA_SUFFIX2 = "model_metadata";
function getModelKeys2(path) {
  return {
    info: [PATH_PREFIX2, path, INFO_SUFFIX2].join(PATH_SEPARATOR2),
    topology: [PATH_PREFIX2, path, MODEL_TOPOLOGY_SUFFIX2].join(PATH_SEPARATOR2),
    weightSpecs: [PATH_PREFIX2, path, WEIGHT_SPECS_SUFFIX2].join(PATH_SEPARATOR2),
    weightData: [PATH_PREFIX2, path, WEIGHT_DATA_SUFFIX2].join(PATH_SEPARATOR2),
    modelMetadata: [PATH_PREFIX2, path, MODEL_METADATA_SUFFIX2].join(PATH_SEPARATOR2)
  };
}
function getModelPathFromKey2(key) {
  const items = key.split(PATH_SEPARATOR2);
  if (items.length < 3) {
    throw new Error(`Invalid key format: ${key}`);
  }
  return items.slice(1, items.length - 1).join(PATH_SEPARATOR2);
}
function maybeStripScheme4(key) {
  return key.startsWith(BrowserLocalStorage2.URL_SCHEME) ? key.slice(BrowserLocalStorage2.URL_SCHEME.length) : key;
}
var BrowserLocalStorage2 = class {
  constructor(modelPath) {
    if (!env2().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
      throw new Error("The current environment does not support local storage.");
    }
    this.LS = window.localStorage;
    if (modelPath == null || !modelPath) {
      throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    }
    this.modelPath = modelPath;
    this.keys = getModelKeys2(this.modelPath);
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    } else {
      const topology = JSON.stringify(modelArtifacts.modelTopology);
      const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
      const modelArtifactsInfo = getModelArtifactsInfoForJSON2(modelArtifacts);
      try {
        this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
        this.LS.setItem(this.keys.topology, topology);
        this.LS.setItem(this.keys.weightSpecs, weightSpecs);
        this.LS.setItem(this.keys.weightData, arrayBufferToBase64String2(modelArtifacts.weightData));
        const result = {
          format: modelArtifacts.format,
          generatedBy: modelArtifacts.generatedBy,
          convertedBy: modelArtifacts.convertedBy
        };
        if (modelArtifacts.signature != null) {
          result.signature = modelArtifacts.signature;
        }
        if (modelArtifacts.userDefinedMetadata != null) {
          result.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
        }
        if (modelArtifacts.modelInitializer != null) {
          result.modelInitializer = modelArtifacts.modelInitializer;
        }
        this.LS.setItem(this.keys.modelMetadata, JSON.stringify(result));
        return { modelArtifactsInfo };
      } catch (err) {
        this.LS.removeItem(this.keys.info);
        this.LS.removeItem(this.keys.topology);
        this.LS.removeItem(this.keys.weightSpecs);
        this.LS.removeItem(this.keys.weightData);
        this.LS.removeItem(this.keys.modelMetadata);
        throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
      }
    }
  }
  async load() {
    const info = JSON.parse(this.LS.getItem(this.keys.info));
    if (info == null) {
      throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
    }
    if (info.modelTopologyType !== "JSON") {
      throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
    }
    const out = {};
    const topology = JSON.parse(this.LS.getItem(this.keys.topology));
    if (topology == null) {
      throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
    }
    out.modelTopology = topology;
    const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
    if (weightSpecs == null) {
      throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
    }
    out.weightSpecs = weightSpecs;
    const metadataString = this.LS.getItem(this.keys.modelMetadata);
    if (metadataString != null) {
      const metadata = JSON.parse(metadataString);
      out.format = metadata["format"];
      out.generatedBy = metadata["generatedBy"];
      out.convertedBy = metadata["convertedBy"];
      if (metadata["signature"] != null) {
        out.signature = metadata["signature"];
      }
      if (metadata["userDefinedMetadata"] != null) {
        out.userDefinedMetadata = metadata["userDefinedMetadata"];
      }
      if (metadata["modelInitializer"] != null) {
        out.modelInitializer = metadata["modelInitializer"];
      }
    }
    const weightDataBase64 = this.LS.getItem(this.keys.weightData);
    if (weightDataBase64 == null) {
      throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
    }
    out.weightData = base64StringToArrayBuffer2(weightDataBase64);
    return out;
  }
};
BrowserLocalStorage2.URL_SCHEME = "localstorage://";
var localStorageRouter2 = (url) => {
  if (!env2().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage2.URL_SCHEME)) {
      return browserLocalStorage2(url.slice(BrowserLocalStorage2.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry2.registerSaveRouter(localStorageRouter2);
IORouterRegistry2.registerLoadRouter(localStorageRouter2);
function browserLocalStorage2(modelPath) {
  return new BrowserLocalStorage2(modelPath);
}
var BrowserLocalStorageManager2 = class {
  constructor() {
    assert2(env2().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
    assert2(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
    this.LS = window.localStorage;
  }
  async listModels() {
    const out = {};
    const prefix = PATH_PREFIX2 + PATH_SEPARATOR2;
    const suffix = PATH_SEPARATOR2 + INFO_SUFFIX2;
    for (let i = 0; i < this.LS.length; ++i) {
      const key = this.LS.key(i);
      if (key.startsWith(prefix) && key.endsWith(suffix)) {
        const modelPath = getModelPathFromKey2(key);
        out[modelPath] = JSON.parse(this.LS.getItem(key));
      }
    }
    return out;
  }
  async removeModel(path) {
    path = maybeStripScheme4(path);
    const keys = getModelKeys2(path);
    if (this.LS.getItem(keys.info) == null) {
      throw new Error(`Cannot find model at path '${path}'`);
    }
    const info = JSON.parse(this.LS.getItem(keys.info));
    this.LS.removeItem(keys.info);
    this.LS.removeItem(keys.topology);
    this.LS.removeItem(keys.weightSpecs);
    this.LS.removeItem(keys.weightData);
    return info;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/model_management.js
var URL_SCHEME_SUFFIX2 = "://";
var ModelStoreManagerRegistry2 = class {
  constructor() {
    this.managers = {};
  }
  static getInstance() {
    if (ModelStoreManagerRegistry2.instance == null) {
      ModelStoreManagerRegistry2.instance = new ModelStoreManagerRegistry2();
    }
    return ModelStoreManagerRegistry2.instance;
  }
  static registerManager(scheme, manager) {
    assert2(scheme != null, () => "scheme must not be undefined or null.");
    if (scheme.endsWith(URL_SCHEME_SUFFIX2)) {
      scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX2));
    }
    assert2(scheme.length > 0, () => "scheme must not be an empty string.");
    const registry = ModelStoreManagerRegistry2.getInstance();
    assert2(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
    registry.managers[scheme] = manager;
  }
  static getManager(scheme) {
    const manager = this.getInstance().managers[scheme];
    if (manager == null) {
      throw new Error(`Cannot find model manager for scheme '${scheme}'`);
    }
    return manager;
  }
  static getSchemes() {
    return Object.keys(this.getInstance().managers);
  }
};
function parseURL2(url) {
  if (url.indexOf(URL_SCHEME_SUFFIX2) === -1) {
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry2.getSchemes().join(",")}`);
  }
  return {
    scheme: url.split(URL_SCHEME_SUFFIX2)[0],
    path: url.split(URL_SCHEME_SUFFIX2)[1]
  };
}
async function cloneModelInternal2(sourceURL, destURL, deleteSource = false) {
  assert2(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
  const loadHandlers = IORouterRegistry2.getLoadHandlers(sourceURL);
  assert2(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
  assert2(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
  const loadHandler = loadHandlers[0];
  const saveHandlers = IORouterRegistry2.getSaveHandlers(destURL);
  assert2(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
  assert2(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
  const saveHandler = saveHandlers[0];
  const sourceScheme = parseURL2(sourceURL).scheme;
  const sourcePath = parseURL2(sourceURL).path;
  const sameMedium = sourceScheme === parseURL2(sourceURL).scheme;
  const modelArtifacts = await loadHandler.load();
  if (deleteSource && sameMedium) {
    await ModelStoreManagerRegistry2.getManager(sourceScheme).removeModel(sourcePath);
  }
  const saveResult = await saveHandler.save(modelArtifacts);
  if (deleteSource && !sameMedium) {
    await ModelStoreManagerRegistry2.getManager(sourceScheme).removeModel(sourcePath);
  }
  return saveResult.modelArtifactsInfo;
}
async function listModels2() {
  const schemes = ModelStoreManagerRegistry2.getSchemes();
  const out = {};
  for (const scheme of schemes) {
    const schemeOut = await ModelStoreManagerRegistry2.getManager(scheme).listModels();
    for (const path in schemeOut) {
      const url = scheme + URL_SCHEME_SUFFIX2 + path;
      out[url] = schemeOut[path];
    }
  }
  return out;
}
async function removeModel2(url) {
  const schemeAndPath = parseURL2(url);
  const manager = ModelStoreManagerRegistry2.getManager(schemeAndPath.scheme);
  return manager.removeModel(schemeAndPath.path);
}
async function copyModel2(sourceURL, destURL) {
  const deleteSource = false;
  return cloneModelInternal2(sourceURL, destURL, deleteSource);
}
async function moveModel2(sourceURL, destURL) {
  const deleteSource = true;
  return cloneModelInternal2(sourceURL, destURL, deleteSource);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js
var PlatformBrowser2 = class {
  fetch(path, init2) {
    return fetch(path, init2);
  }
  now() {
    return performance.now();
  }
  encode(text, encoding) {
    if (encoding !== "utf-8" && encoding !== "utf8") {
      throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
    }
    if (this.textEncoder == null) {
      this.textEncoder = new TextEncoder();
    }
    return this.textEncoder.encode(text);
  }
  decode(bytes, encoding) {
    return new TextDecoder(encoding).decode(bytes);
  }
};
if (env2().get("IS_BROWSER")) {
  env2().setPlatform("browser", new PlatformBrowser2());
  try {
    ModelStoreManagerRegistry2.registerManager(BrowserLocalStorage2.URL_SCHEME, new BrowserLocalStorageManager2());
  } catch (err) {
  }
  try {
    ModelStoreManagerRegistry2.registerManager(BrowserIndexedDB2.URL_SCHEME, new BrowserIndexedDBManager2());
  } catch (err) {
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js
var getNodeFetch2 = {
  importFetch: () => require_browser()
};
var systemFetch2;
var PlatformNode2 = class {
  constructor() {
    this.util = __require("util");
    this.textEncoder = new this.util.TextEncoder();
  }
  fetch(path, requestInits) {
    if (env2().global.fetch != null) {
      return env2().global.fetch(path, requestInits);
    }
    if (systemFetch2 == null) {
      systemFetch2 = getNodeFetch2.importFetch();
    }
    return systemFetch2(path, requestInits);
  }
  now() {
    const time2 = process.hrtime();
    return time2[0] * 1e3 + time2[1] / 1e6;
  }
  encode(text, encoding) {
    if (encoding !== "utf-8" && encoding !== "utf8") {
      throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
    }
    return this.textEncoder.encode(text);
  }
  decode(bytes, encoding) {
    if (bytes.length === 0) {
      return "";
    }
    return new this.util.TextDecoder(encoding).decode(bytes);
  }
};
if (env2().get("IS_NODE")) {
  env2().setPlatform("node", new PlatformNode2());
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js
function buffer2(shape, dtype = "float32", values) {
  dtype = dtype || "float32";
  assertNonNegativeIntegerDimensions2(shape);
  return new TensorBuffer2(shape, dtype, values);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/cast.js
function cast_2(x, dtype) {
  const $x = convertToTensor2(x, "x", "cast");
  if (!isValidDtype2(dtype)) {
    throw new Error(`Failed to cast to unknown dtype ${dtype}`);
  }
  if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
    throw new Error("Only strings can be casted to strings");
  }
  const inputs = { x: $x };
  const attrs = { dtype };
  return ENGINE2.runKernel(Cast2, inputs, attrs);
}
var cast2 = op2({ cast_: cast_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/clone.js
function clone_2(x) {
  const $x = convertToTensor2(x, "x", "clone", "string_or_numeric");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Identity2, inputs);
}
var clone2 = op2({ clone_: clone_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/print.js
function print3(x, verbose = false) {
  console.log(x.toString(verbose));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js
getOrMakeEngine2();
var opHandler4 = {
  buffer: buffer2,
  cast: cast2,
  clone: clone2,
  print: print3
};
setOpHandler2(opHandler4);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/io.js
var io_exports2 = {};
__export(io_exports2, {
  browserFiles: () => browserFiles2,
  browserHTTPRequest: () => browserHTTPRequest2,
  concatenateArrayBuffers: () => concatenateArrayBuffers2,
  copyModel: () => copyModel2,
  decodeWeights: () => decodeWeights2,
  encodeWeights: () => encodeWeights2,
  fromMemory: () => fromMemory2,
  getLoadHandlers: () => getLoadHandlers2,
  getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON2,
  getSaveHandlers: () => getSaveHandlers2,
  http: () => http2,
  isHTTPScheme: () => isHTTPScheme2,
  listModels: () => listModels2,
  loadWeights: () => loadWeights2,
  moveModel: () => moveModel2,
  registerLoadRouter: () => registerLoadRouter2,
  registerSaveRouter: () => registerSaveRouter2,
  removeModel: () => removeModel2,
  weightsLoaderFactory: () => weightsLoaderFactory2,
  withSaveHandler: () => withSaveHandler2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js
var DEFAULT_FILE_NAME_PREFIX2 = "model";
var DEFAULT_JSON_EXTENSION_NAME2 = ".json";
var DEFAULT_WEIGHT_DATA_EXTENSION_NAME2 = ".weights.bin";
function defer2(f) {
  return new Promise((resolve) => setTimeout(resolve)).then(f);
}
var BrowserDownloads2 = class {
  constructor(fileNamePrefix) {
    if (!env2().getBool("IS_BROWSER")) {
      throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    }
    if (fileNamePrefix.startsWith(BrowserDownloads2.URL_SCHEME)) {
      fileNamePrefix = fileNamePrefix.slice(BrowserDownloads2.URL_SCHEME.length);
    }
    if (fileNamePrefix == null || fileNamePrefix.length === 0) {
      fileNamePrefix = DEFAULT_FILE_NAME_PREFIX2;
    }
    this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME2;
    this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME2;
  }
  async save(modelArtifacts) {
    if (typeof document === "undefined") {
      throw new Error("Browser downloads are not supported in this environment since `document` is not present");
    }
    const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
    } else {
      const weightsManifest = [{
        paths: ["./" + this.weightDataFileName],
        weights: modelArtifacts.weightSpecs
      }];
      const modelTopologyAndWeightManifest = {
        modelTopology: modelArtifacts.modelTopology,
        format: modelArtifacts.format,
        generatedBy: modelArtifacts.generatedBy,
        convertedBy: modelArtifacts.convertedBy,
        weightsManifest
      };
      if (modelArtifacts.signature != null) {
        modelTopologyAndWeightManifest.signature = modelArtifacts.signature;
      }
      if (modelArtifacts.userDefinedMetadata != null) {
        modelTopologyAndWeightManifest.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
      }
      if (modelArtifacts.modelInitializer != null) {
        modelTopologyAndWeightManifest.modelInitializer = modelArtifacts.modelInitializer;
      }
      const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: "application/json" }));
      const jsonAnchor = this.jsonAnchor == null ? document.createElement("a") : this.jsonAnchor;
      jsonAnchor.download = this.modelTopologyFileName;
      jsonAnchor.href = modelTopologyAndWeightManifestURL;
      await defer2(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
      if (modelArtifacts.weightData != null) {
        const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
        weightDataAnchor.download = this.weightDataFileName;
        weightDataAnchor.href = weightsURL;
        await defer2(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
      }
      return { modelArtifactsInfo: getModelArtifactsInfoForJSON2(modelArtifacts) };
    }
  }
};
BrowserDownloads2.URL_SCHEME = "downloads://";
var BrowserFiles2 = class {
  constructor(files) {
    if (files == null || files.length < 1) {
      throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
    }
    this.files = files;
  }
  async load() {
    const jsonFile = this.files[0];
    const weightFiles = this.files.slice(1);
    return new Promise((resolve, reject) => {
      const jsonReader = new FileReader();
      jsonReader.onload = (event) => {
        const modelJSON = JSON.parse(event.target.result);
        const modelTopology = modelJSON.modelTopology;
        if (modelTopology == null) {
          reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));
          return;
        }
        if (weightFiles.length === 0) {
          resolve({ modelTopology });
        }
        const weightsManifest = modelJSON.weightsManifest;
        if (weightsManifest == null) {
          reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));
          return;
        }
        let pathToFile;
        try {
          pathToFile = this.checkManifestAndWeightFiles(weightsManifest, weightFiles);
        } catch (err) {
          reject(err);
          return;
        }
        const weightSpecs = [];
        const paths = [];
        const perFileBuffers = [];
        weightsManifest.forEach((weightsGroup) => {
          weightsGroup.paths.forEach((path) => {
            paths.push(path);
            perFileBuffers.push(null);
          });
          weightSpecs.push(...weightsGroup.weights);
        });
        weightsManifest.forEach((weightsGroup) => {
          weightsGroup.paths.forEach((path) => {
            const weightFileReader = new FileReader();
            weightFileReader.onload = (event2) => {
              const weightData = event2.target.result;
              const index = paths.indexOf(path);
              perFileBuffers[index] = weightData;
              if (perFileBuffers.indexOf(null) === -1) {
                const result = {
                  modelTopology,
                  weightSpecs,
                  weightData: concatenateArrayBuffers2(perFileBuffers),
                  format: modelJSON.format,
                  generatedBy: modelJSON.generatedBy,
                  convertedBy: modelJSON.convertedBy
                };
                if (modelJSON.signature != null) {
                  result.signature = modelJSON.signature;
                }
                if (modelJSON.userDefinedMetadata != null) {
                  result.userDefinedMetadata = modelJSON.userDefinedMetadata;
                }
                if (modelJSON.modelInitializer != null) {
                  result.modelInitializer = modelJSON.modelInitializer;
                }
                resolve(result);
              }
            };
            weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
            weightFileReader.readAsArrayBuffer(pathToFile[path]);
          });
        });
      };
      jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
      jsonReader.readAsText(jsonFile);
    });
  }
  checkManifestAndWeightFiles(manifest, files) {
    const basenames = [];
    const fileNames = files.map((file) => basename2(file.name));
    const pathToFile = {};
    for (const group of manifest) {
      group.paths.forEach((path) => {
        const pathBasename = basename2(path);
        if (basenames.indexOf(pathBasename) !== -1) {
          throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
        }
        basenames.push(pathBasename);
        if (fileNames.indexOf(pathBasename) === -1) {
          throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
        } else {
          pathToFile[path] = files[fileNames.indexOf(pathBasename)];
        }
      });
    }
    if (basenames.length !== files.length) {
      throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${files.length}).`);
    }
    return pathToFile;
  }
};
var browserDownloadsRouter2 = (url) => {
  if (!env2().getBool("IS_BROWSER")) {
    return null;
  } else {
    if (!Array.isArray(url) && url.startsWith(BrowserDownloads2.URL_SCHEME)) {
      return browserDownloads2(url.slice(BrowserDownloads2.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
IORouterRegistry2.registerSaveRouter(browserDownloadsRouter2);
function browserDownloads2(fileNamePrefix = "model") {
  return new BrowserDownloads2(fileNamePrefix);
}
function browserFiles2(files) {
  return new BrowserFiles2(files);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/progress.js
function monitorPromisesProgress2(promises, onProgress, startFraction, endFraction) {
  checkPromises(promises);
  startFraction = startFraction == null ? 0 : startFraction;
  endFraction = endFraction == null ? 1 : endFraction;
  checkFraction(startFraction, endFraction);
  let resolvedPromise = 0;
  const registerMonitor = (promise) => {
    promise.then((value) => {
      const fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
      onProgress(fraction);
      return value;
    });
    return promise;
  };
  function checkPromises(promises2) {
    assert2(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
  }
  function checkFraction(startFraction2, endFraction2) {
    assert2(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
    assert2(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
    assert2(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
  }
  return Promise.all(promises.map(registerMonitor));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js
async function loadWeightsAsArrayBuffer2(fetchURLs, loadOptions) {
  if (loadOptions == null) {
    loadOptions = {};
  }
  const fetchFunc = loadOptions.fetchFunc == null ? env2().platform.fetch : loadOptions.fetchFunc;
  const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));
  const fetchStartFraction = 0;
  const fetchEndFraction = 0.5;
  const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress2(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
  const bufferPromises = responses.map((response) => response.arrayBuffer());
  const bufferStartFraction = 0.5;
  const bufferEndFraction = 1;
  const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress2(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
  return buffers;
}
async function loadWeights2(manifest, filePathPrefix = "", weightNames, requestInit) {
  const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer2(fetchUrls, { requestInit });
  const loadWeights3 = weightsLoaderFactory2(fetchWeights);
  return loadWeights3(manifest, filePathPrefix, weightNames);
}
function weightsLoaderFactory2(fetchWeightsFunction) {
  return async (manifest, filePathPrefix = "", weightNames) => {
    const groupIndicesToFetchMap = manifest.map(() => false);
    const groupWeightsToFetch = {};
    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
    const allManifestWeightNames = [];
    manifest.forEach((manifestGroupConfig, groupIndex) => {
      let groupOffset = 0;
      manifestGroupConfig.weights.forEach((weightsEntry) => {
        const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
        const weightsBytes = DTYPE_VALUE_SIZE_MAP2[rawDtype] * sizeFromShape2(weightsEntry.shape);
        const enqueueWeightsForFetchingFn = () => {
          groupIndicesToFetchMap[groupIndex] = true;
          if (groupWeightsToFetch[groupIndex] == null) {
            groupWeightsToFetch[groupIndex] = [];
          }
          groupWeightsToFetch[groupIndex].push({
            manifestEntry: weightsEntry,
            groupOffset,
            sizeBytes: weightsBytes
          });
        };
        if (weightNames != null) {
          weightNames.forEach((weightName, weightIndex) => {
            if (weightName === weightsEntry.name) {
              enqueueWeightsForFetchingFn();
              weightsFound[weightIndex] = true;
            }
          });
        } else {
          enqueueWeightsForFetchingFn();
        }
        allManifestWeightNames.push(weightsEntry.name);
        groupOffset += weightsBytes;
      });
    });
    if (!weightsFound.every((found) => found)) {
      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);
      throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
    }
    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
      if (shouldFetch) {
        accumulator.push(i);
      }
      return accumulator;
    }, []);
    const fetchUrls = [];
    groupIndicesToFetch.forEach((i) => {
      manifest[i].paths.forEach((filepath) => {
        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
        fetchUrls.push(fetchUrl);
      });
    });
    const buffers = await fetchWeightsFunction(fetchUrls);
    const weightsTensorMap = {};
    let bufferIndexOffset = 0;
    groupIndicesToFetch.forEach((i) => {
      const numBuffers = manifest[i].paths.length;
      let groupBytes = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        groupBytes += buffers[bufferIndexOffset + i2].byteLength;
      }
      const groupBuffer = new ArrayBuffer(groupBytes);
      const groupByteBuffer = new Uint8Array(groupBuffer);
      let groupBufferOffset = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        const buffer3 = new Uint8Array(buffers[bufferIndexOffset + i2]);
        groupByteBuffer.set(buffer3, groupBufferOffset);
        groupBufferOffset += buffer3.byteLength;
      }
      const weightsEntries = groupWeightsToFetch[i];
      weightsEntries.forEach((weightsEntry) => {
        const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
        const nameToTensorMap = decodeWeights2(byteBuffer, [weightsEntry.manifestEntry]);
        for (const name in nameToTensorMap) {
          weightsTensorMap[name] = nameToTensorMap[name];
        }
      });
      bufferIndexOffset += numBuffers;
    });
    return weightsTensorMap;
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/http.js
var OCTET_STREAM_MIME_TYPE2 = "application/octet-stream";
var JSON_TYPE2 = "application/json";
var HTTPRequest2 = class {
  constructor(path, loadOptions) {
    this.DEFAULT_METHOD = "POST";
    if (loadOptions == null) {
      loadOptions = {};
    }
    this.weightPathPrefix = loadOptions.weightPathPrefix;
    this.onProgress = loadOptions.onProgress;
    this.weightUrlConverter = loadOptions.weightUrlConverter;
    if (loadOptions.fetchFunc != null) {
      assert2(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
      this.fetch = loadOptions.fetchFunc;
    } else {
      this.fetch = env2().platform.fetch;
    }
    assert2(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
    if (Array.isArray(path)) {
      assert2(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
    }
    this.path = path;
    if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
      throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    }
    this.requestInit = loadOptions.requestInit || {};
  }
  async save(modelArtifacts) {
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
    }
    const init2 = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
    init2.body = new FormData();
    const weightsManifest = [{
      paths: ["./model.weights.bin"],
      weights: modelArtifacts.weightSpecs
    }];
    const modelTopologyAndWeightManifest = {
      modelTopology: modelArtifacts.modelTopology,
      format: modelArtifacts.format,
      generatedBy: modelArtifacts.generatedBy,
      convertedBy: modelArtifacts.convertedBy,
      weightsManifest
    };
    if (modelArtifacts.signature != null) {
      modelTopologyAndWeightManifest.signature = modelArtifacts.signature;
    }
    if (modelArtifacts.userDefinedMetadata != null) {
      modelTopologyAndWeightManifest.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
    }
    if (modelArtifacts.modelInitializer != null) {
      modelTopologyAndWeightManifest.modelInitializer = modelArtifacts.modelInitializer;
    }
    init2.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE2 }), "model.json");
    if (modelArtifacts.weightData != null) {
      init2.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE2 }), "model.weights.bin");
    }
    const response = await this.fetch(this.path, init2);
    if (response.ok) {
      return {
        modelArtifactsInfo: getModelArtifactsInfoForJSON2(modelArtifacts),
        responses: [response]
      };
    } else {
      throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
    }
  }
  async load() {
    const modelConfigRequest = await this.fetch(this.path, this.requestInit);
    if (!modelConfigRequest.ok) {
      throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
    }
    let modelConfig;
    try {
      modelConfig = await modelConfigRequest.json();
    } catch (e) {
      let message = `Failed to parse model JSON of response from ${this.path}.`;
      if (this.path.endsWith(".pb")) {
        message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
      } else {
        message += " Please make sure the server is serving valid JSON for this request.";
      }
      throw new Error(message);
    }
    const modelTopology = modelConfig.modelTopology;
    const weightsManifest = modelConfig.weightsManifest;
    const generatedBy = modelConfig.generatedBy;
    const convertedBy = modelConfig.convertedBy;
    const format = modelConfig.format;
    const signature = modelConfig.signature;
    const userDefinedMetadata = modelConfig.userDefinedMetadata;
    if (modelTopology == null && weightsManifest == null) {
      throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
    }
    let weightSpecs;
    let weightData;
    if (weightsManifest != null) {
      const results = await this.loadWeights(weightsManifest);
      [weightSpecs, weightData] = results;
    }
    const artifacts = {
      modelTopology,
      weightSpecs,
      weightData,
      generatedBy,
      convertedBy,
      format
    };
    if (signature != null) {
      artifacts.signature = signature;
    }
    if (userDefinedMetadata != null) {
      artifacts.userDefinedMetadata = userDefinedMetadata;
    }
    const initializer = modelConfig.modelInitializer;
    if (initializer) {
      artifacts.modelInitializer = initializer;
    }
    return artifacts;
  }
  async loadWeights(weightsManifest) {
    const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
    const [prefix, suffix] = parseUrl2(weightPath);
    const pathPrefix = this.weightPathPrefix || prefix;
    const weightSpecs = [];
    for (const entry of weightsManifest) {
      weightSpecs.push(...entry.weights);
    }
    const fetchURLs = [];
    const urlPromises = [];
    for (const weightsGroup of weightsManifest) {
      for (const path of weightsGroup.paths) {
        if (this.weightUrlConverter != null) {
          urlPromises.push(this.weightUrlConverter(path));
        } else {
          fetchURLs.push(pathPrefix + path + suffix);
        }
      }
    }
    if (this.weightUrlConverter) {
      fetchURLs.push(...await Promise.all(urlPromises));
    }
    const buffers = await loadWeightsAsArrayBuffer2(fetchURLs, {
      requestInit: this.requestInit,
      fetchFunc: this.fetch,
      onProgress: this.onProgress
    });
    return [weightSpecs, concatenateArrayBuffers2(buffers)];
  }
};
HTTPRequest2.URL_SCHEME_REGEX = /^https?:\/\//;
function parseUrl2(url) {
  const lastSlash = url.lastIndexOf("/");
  const lastSearchParam = url.lastIndexOf("?");
  const prefix = url.substring(0, lastSlash);
  const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
  return [prefix + "/", suffix];
}
function isHTTPScheme2(url) {
  return url.match(HTTPRequest2.URL_SCHEME_REGEX) != null;
}
var httpRouter2 = (url, loadOptions) => {
  if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
    return null;
  } else {
    let isHTTP = true;
    if (Array.isArray(url)) {
      isHTTP = url.every((urlItem) => isHTTPScheme2(urlItem));
    } else {
      isHTTP = isHTTPScheme2(url);
    }
    if (isHTTP) {
      return http2(url, loadOptions);
    }
  }
  return null;
};
IORouterRegistry2.registerSaveRouter(httpRouter2);
IORouterRegistry2.registerLoadRouter(httpRouter2);
function http2(path, loadOptions) {
  return new HTTPRequest2(path, loadOptions);
}
function browserHTTPRequest2(path, loadOptions) {
  return http2(path, loadOptions);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js
var PassthroughLoader2 = class {
  constructor(modelArtifacts) {
    this.modelArtifacts = modelArtifacts;
  }
  async load() {
    return this.modelArtifacts;
  }
};
var PassthroughSaver2 = class {
  constructor(saveHandler) {
    this.saveHandler = saveHandler;
  }
  async save(modelArtifacts) {
    return this.saveHandler(modelArtifacts);
  }
};
function fromMemory2(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  if (arguments.length === 1) {
    const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
    if (isModelArtifacts) {
      return new PassthroughLoader2(modelArtifacts);
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader2({ modelTopology: modelArtifacts });
    }
  } else {
    console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
    return new PassthroughLoader2({
      modelTopology: modelArtifacts,
      weightSpecs,
      weightData,
      trainingConfig
    });
  }
}
function withSaveHandler2(saveHandler) {
  return new PassthroughSaver2(saveHandler);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js
function matMul_2(a, b, transposeA = false, transposeB = false) {
  let $a = convertToTensor2(a, "a", "matMul");
  let $b = convertToTensor2(b, "b", "matMul");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  const attrs = { transposeA, transposeB };
  return ENGINE2.runKernel(BatchMatMul2, inputs, attrs);
}
var matMul3 = op2({ matMul_: matMul_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js
function oneHot_2(indices, depth, onValue = 1, offValue = 0) {
  if (depth < 2) {
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
  }
  const $indices = convertToTensor2(indices, "indices", "oneHot", "int32");
  const inputs = { indices: $indices };
  const attrs = { depth, onValue, offValue };
  return ENGINE2.runKernel(OneHot2, inputs, attrs);
}
var oneHot2 = op2({ oneHot_: oneHot_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js
function transpose_2(x, perm) {
  const $x = convertToTensor2(x, "x", "transpose");
  if (perm == null) {
    perm = $x.shape.map((s, i) => i).reverse();
  }
  assert2($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
  perm.forEach((axis) => {
    assert2(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
  });
  if ($x.rank <= 1) {
    return $x.clone();
  }
  const inputs = { x: $x };
  const attrs = { perm };
  return ENGINE2.runKernel(Transpose2, inputs, attrs);
}
var transpose2 = op2({ transpose_: transpose_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js
function confusionMatrix_2(labels, predictions, numClasses) {
  const $labels = convertToTensor2(labels, "labels", "confusionMatrix");
  const $predictions = convertToTensor2(predictions, "predictions", "confusionMatrix");
  assert2(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), () => `If provided, numClasses must be a positive integer, but got ${numClasses}`);
  assert2($labels.rank === 1, () => `Expected the rank of labels to be 1, but got ${$labels.rank}`);
  assert2($predictions.rank === 1, () => `Expected the rank of predictions to be 1, but got ${$predictions.rank}`);
  assert2($labels.shape[0] === $predictions.shape[0], () => `Mismatch in the number of examples: ${$labels.shape[0]} vs. ${$predictions.shape[0]}. Labels and predictions should have the same number of elements.`);
  assert2(numClasses > 0 && Number.isInteger(numClasses), () => `numClasses is required to be a positive integer, but got ${numClasses}`);
  const oneHotLabels = oneHot2(cast2($labels, "int32"), numClasses);
  const oneHotPredictions = oneHot2(cast2($predictions, "int32"), numClasses);
  const oneHotLabelsT = transpose2(oneHotLabels);
  const product = matMul3(oneHotLabelsT, oneHotPredictions);
  return cast2(product, "int32");
}
var confusionMatrix2 = op2({ confusionMatrix_: confusionMatrix_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/browser.js
var browser_exports2 = {};
__export(browser_exports2, {
  fromPixels: () => fromPixels2,
  fromPixelsAsync: () => fromPixelsAsync2,
  toPixels: () => toPixels2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js
function tensor3d2(values, shape, dtype) {
  assertNonNull2(values);
  if (shape != null && shape.length !== 3) {
    throw new Error("tensor3d() requires shape to have three numbers");
  }
  const inferredShape = inferShape2(values, dtype);
  if (inferredShape.length !== 3 && inferredShape.length !== 1) {
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor2(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/browser.js
var fromPixels2DContext2;
function fromPixels_2(pixels, numChannels = 3) {
  if (numChannels > 4) {
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  }
  if (pixels == null) {
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  }
  let isPixelData3 = false;
  let isImageData = false;
  let isVideo = false;
  let isImage = false;
  let isCanvasLike = false;
  let isImageBitmap = false;
  if (pixels.data instanceof Uint8Array) {
    isPixelData3 = true;
  } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
    isImageData = true;
  } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
    isVideo = true;
  } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
    isImage = true;
  } else if (pixels.getContext != null) {
    isCanvasLike = true;
  } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
    isImageBitmap = true;
  } else {
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${pixels.constructor.name}`);
  }
  if (isVideo) {
    const HAVE_CURRENT_DATA_READY_STATE = 2;
    if (isVideo && pixels.readyState < HAVE_CURRENT_DATA_READY_STATE) {
      throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.");
    }
  }
  const kernel = getKernel2(FromPixels2, ENGINE2.backendName);
  if (kernel != null) {
    const inputs = { pixels };
    const attrs = { numChannels };
    return ENGINE2.runKernel(FromPixels2, inputs, attrs);
  }
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  let vals;
  if (isCanvasLike) {
    vals = pixels.getContext("2d").getImageData(0, 0, width, height).data;
  } else if (isImageData || isPixelData3) {
    vals = pixels.data;
  } else if (isImage || isVideo || isImageBitmap) {
    if (fromPixels2DContext2 == null) {
      fromPixels2DContext2 = document.createElement("canvas").getContext("2d");
    }
    fromPixels2DContext2.canvas.width = width;
    fromPixels2DContext2.canvas.height = height;
    fromPixels2DContext2.drawImage(pixels, 0, 0, width, height);
    vals = fromPixels2DContext2.getImageData(0, 0, width, height).data;
  }
  let values;
  if (numChannels === 4) {
    values = new Int32Array(vals);
  } else {
    const numPixels = width * height;
    values = new Int32Array(numPixels * numChannels);
    for (let i = 0; i < numPixels; i++) {
      for (let channel = 0; channel < numChannels; ++channel) {
        values[i * numChannels + channel] = vals[i * 4 + channel];
      }
    }
  }
  const outShape = [height, width, numChannels];
  return tensor3d2(values, outShape, "int32");
}
function isPixelData2(pixels) {
  return pixels != null && pixels.data instanceof Uint8Array;
}
function isImageBitmapFullySupported2() {
  return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
}
function isNonEmptyPixels2(pixels) {
  return pixels != null && pixels.width !== 0 && pixels.height !== 0;
}
function canWrapPixelsToImageBitmap2(pixels) {
  return isImageBitmapFullySupported2() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels2(pixels) && !isPixelData2(pixels);
}
async function fromPixelsAsync2(pixels, numChannels = 3) {
  let inputs = null;
  if (env2().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap2(pixels)) {
    let imageBitmap;
    try {
      imageBitmap = await createImageBitmap(pixels, { premultiplyAlpha: "none" });
    } catch (e) {
      imageBitmap = null;
    }
    if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
      inputs = imageBitmap;
    } else {
      inputs = pixels;
    }
  } else {
    inputs = pixels;
  }
  return fromPixels_2(inputs, numChannels);
}
async function toPixels2(img, canvas) {
  let $img = convertToTensor2(img, "img", "toPixels");
  if (!(img instanceof Tensor4)) {
    const originalImgTensor = $img;
    $img = cast2(originalImgTensor, "int32");
    originalImgTensor.dispose();
  }
  if ($img.rank !== 2 && $img.rank !== 3) {
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);
  }
  const [height, width] = $img.shape.slice(0, 2);
  const depth = $img.rank === 2 ? 1 : $img.shape[2];
  if (depth > 4 || depth === 2) {
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${depth}`);
  }
  if ($img.dtype !== "float32" && $img.dtype !== "int32") {
    throw new Error(`Unsupported type for toPixels: ${$img.dtype}. Please use float32 or int32 tensors.`);
  }
  const data = await $img.data();
  const multiplier = $img.dtype === "float32" ? 255 : 1;
  const bytes = new Uint8ClampedArray(width * height * 4);
  for (let i = 0; i < height * width; ++i) {
    const rgba = [0, 0, 0, 255];
    for (let d = 0; d < depth; d++) {
      const value = data[i * depth + d];
      if ($img.dtype === "float32") {
        if (value < 0 || value > 1) {
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`);
        }
      } else if ($img.dtype === "int32") {
        if (value < 0 || value > 255) {
          throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);
        }
      }
      if (depth === 1) {
        rgba[0] = value * multiplier;
        rgba[1] = value * multiplier;
        rgba[2] = value * multiplier;
      } else {
        rgba[d] = value * multiplier;
      }
    }
    const j = i * 4;
    bytes[j + 0] = Math.round(rgba[0]);
    bytes[j + 1] = Math.round(rgba[1]);
    bytes[j + 2] = Math.round(rgba[2]);
    bytes[j + 3] = Math.round(rgba[3]);
  }
  if (canvas != null) {
    canvas.width = width;
    canvas.height = height;
    const ctx = canvas.getContext("2d");
    const imageData = new ImageData(bytes, width, height);
    ctx.putImageData(imageData, 0, 0);
  }
  if ($img !== img) {
    $img.dispose();
  }
  return bytes;
}
var fromPixels2 = op2({ fromPixels_: fromPixels_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js
var gather_nd_util_exports2 = {};
__export(gather_nd_util_exports2, {
  prepareAndValidate: () => prepareAndValidate2
});
function prepareAndValidate2(tensor3, indices) {
  const tensorRank = tensor3.shape.length;
  const indicesRank = indices.shape.length;
  if (tensorRank < 1) {
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
  }
  if (indicesRank < 1) {
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
  }
  if (indices.shape[indicesRank - 1] > tensorRank) {
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
  }
  if (sizeFromShape2(tensor3.shape) === 0) {
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor3.shape}.`);
  }
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  let nResult = 1;
  for (let i = 0; i < indicesShape.length - 1; ++i) {
    nResult *= indicesShape[i];
  }
  const inputShape = tensor3.shape;
  const resultShape = indicesShape.slice();
  resultShape.pop();
  let sliceSize = 1;
  for (let i = sliceRank; i < tensorRank; ++i) {
    sliceSize *= inputShape[i];
    resultShape.push(inputShape[i]);
  }
  const strides = [
    ...computeStrides2(tensor3.shape).map((stride) => stride / sliceSize),
    1
  ].slice(0, sliceRank);
  return [resultShape, nResult, sliceSize, strides];
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js
var scatter_nd_util_exports2 = {};
__export(scatter_nd_util_exports2, {
  calculateShapes: () => calculateShapes2,
  validateInput: () => validateInput3,
  validateUpdateShape: () => validateUpdateShape2
});
function validateUpdateShape2(shape, indices, updates) {
  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
  const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
  if (updates.rank < batchDim) {
    throw new Error(shapeError + ` update.rank < ${batchDim}. `);
  }
  if (shape.length < sliceDim + (updates.rank - batchDim)) {
    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
  }
  if (updates.rank !== batchDim + shape.length - sliceDim) {
    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
  }
  for (let d = 0; d < batchDim; ++d) {
    if (updates.shape[d] !== indices.shape[d]) {
      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
    }
  }
  for (let d = 0; d < updates.rank - batchDim; ++d) {
    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
    }
  }
}
function validateInput3(updates, indices, shape) {
  if (indices.rank < 1) {
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
  }
  if (updates.rank < 1) {
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
  }
  if (shape.length < 1) {
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
  }
  if (shape.length === 0) {
    if (indices.size === 0) {
      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
    }
    if (updates.size === 0) {
      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
    }
  }
  validateUpdateShape2(shape, indices, updates);
}
function calculateShapes2(updates, indices, shape) {
  const indicesRank = indices.shape.length;
  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
  const totalNd = shape.length;
  let sliceSize = 1;
  for (let i = sliceRank; i < totalNd; ++i) {
    sliceSize *= shape[i];
  }
  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
  const numUpdates = sizeFromShape2(indices.shape) / safeSliceDim;
  const strides = [...computeStrides2(shape.slice(0, sliceRank)), 1];
  const outputSize = sizeFromShape2(shape);
  return { sliceRank, numUpdates, sliceSize, strides, outputSize };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js
var slice_util_exports2 = {};
__export(slice_util_exports2, {
  assertParamsValid: () => assertParamsValid2,
  computeFlatOffset: () => computeFlatOffset2,
  computeOutShape: () => computeOutShape4,
  getNormalizedAxes: () => getNormalizedAxes2,
  isSliceContinous: () => isSliceContinous2,
  maskToAxes: () => maskToAxes2,
  parseSliceParams: () => parseSliceParams2,
  sliceInfo: () => sliceInfo2,
  startForAxis: () => startForAxis2,
  startIndicesWithElidedDims: () => startIndicesWithElidedDims2,
  stopForAxis: () => stopForAxis2,
  stopIndicesWithElidedDims: () => stopIndicesWithElidedDims2,
  stridesForAxis: () => stridesForAxis2,
  stridesWithElidedDims: () => stridesWithElidedDims2
});
function assertParamsValid2(input2, begin, size) {
  const inputRank = input2.shape.length;
  assert2(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
  assert2(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must match the rank of the array (${inputRank}).`);
  for (let i = 0; i < inputRank; ++i) {
    assert2(begin[i] + size[i] <= input2.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size[i]}) would overflow input.shape[${i}] (${input2.shape[i]})`);
  }
}
function maskToAxes2(mask) {
  const axes = [];
  let axis = 0;
  while (mask > 0) {
    if (mask & 1) {
      axes.push(axis);
    }
    mask /= 2;
    axis++;
  }
  return axes;
}
function computeOutShape4(begin, end, strides) {
  const size = [];
  for (let axis = 0; axis < begin.length; axis++) {
    size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
  }
  return size;
}
function stridesWithElidedDims2(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
  const newStrides = [...strides];
  for (let i = newStrides.length; i < inputShape.length; i++) {
    newStrides.push(1);
  }
  for (let i = 0; i < numElidedAxes; i++) {
    if (i === 0) {
      newStrides[ellipsisInsertionIndex] = 1;
    } else {
      newStrides.splice(ellipsisInsertionIndex, 0, 1);
      newStrides.pop();
    }
  }
  return newStrides;
}
function unnormalizeAxis2(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
  if (normalizedAxis <= ellipsisInsertionIndex) {
    return normalizedAxis;
  }
  return normalizedAxis - (numElidedAxes - 1);
}
function getElidedAxes2(numElidedAxes, ellipsisInsertionIndex) {
  const elidedAxes = [];
  for (let i = 0; i < numElidedAxes; i++) {
    elidedAxes.push(ellipsisInsertionIndex + i);
  }
  return elidedAxes;
}
function getNormalizedAxes2(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
  const inputRank = inputShape.length;
  let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
  if (ellipsisAxes.length && numInterpolatedAxes > 0) {
    const fullIndex = ellipsisAxes[0];
    const numElidedAxes = numInterpolatedAxes + 1;
    normalizedBegin = startIndicesWithElidedDims2(beginMask, fullIndex, numElidedAxes, begin, inputShape);
    normalizedEnd = stopIndicesWithElidedDims2(endMask, fullIndex, numElidedAxes, end, inputShape);
    normalizedStrides = stridesWithElidedDims2(strides, fullIndex, numElidedAxes, inputShape);
  } else {
    for (let axis = 0; axis < inputRank; axis++) {
      normalizedBegin[axis] = startForAxis2(beginMask, begin, strides, inputShape, axis, ellipsisMask);
      normalizedEnd[axis] = stopForAxis2(endMask, end, strides, inputShape, axis, ellipsisMask);
      normalizedStrides[axis] = stridesForAxis2(strides, axis, ellipsisMask);
    }
  }
  return {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  };
}
function startIndicesWithElidedDims2(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes2(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = 0;
    } else {
      const originalAxis = unnormalizeAxis2(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalBegin[originalAxis];
      if (beginMask & 1 << originalAxis) {
        originalValue = 0;
      }
      newIndices[axis] = originalValue;
    }
  }
  return newIndices;
}
function stopIndicesWithElidedDims2(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes2(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = Number.MAX_SAFE_INTEGER;
    } else {
      const originalAxis = unnormalizeAxis2(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalEnd[originalAxis];
      if (endMask & 1 << originalAxis) {
        originalValue = Number.MAX_SAFE_INTEGER;
      }
      newIndices[axis] = originalValue;
    }
  }
  for (let i = 0; i < newIndices.length; i++) {
    const axisSize = inputShape[i];
    if (newIndices[i] < 0) {
      newIndices[i] += axisSize;
    }
    newIndices[i] = clamp2(0, newIndices[i], inputShape[i]);
  }
  return newIndices;
}
function stridesForAxis2(strides, axis, ellipsisMask) {
  let stride = strides[axis];
  if (ellipsisMask & 1 << axis || stride == null) {
    stride = 1;
  }
  return stride;
}
function startForAxis2(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
  let start = startIndices[axis];
  const stride = strides[axis] || 1;
  if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
    if (stride > 0) {
      start = Number.MIN_SAFE_INTEGER;
    } else {
      start = Number.MAX_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (start < 0) {
    start += axisSize;
  }
  start = clamp2(0, start, axisSize - 1);
  return start;
}
function stopForAxis2(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
  let stop = stopIndices[axis];
  const stride = strides[axis] || 1;
  if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
    if (stride > 0) {
      stop = Number.MAX_SAFE_INTEGER;
    } else {
      stop = Number.MIN_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (stop < 0) {
    stop += axisSize;
  }
  if (stride > 0) {
    stop = clamp2(0, stop, axisSize);
  } else {
    stop = clamp2(-1, stop, axisSize - 1);
  }
  return stop;
}
function isSliceContinous2(shape, begin, size) {
  let firstNonOneAxis = size.length;
  for (let i = 0; i < size.length; i++) {
    if (size[i] > 1) {
      firstNonOneAxis = i;
      break;
    }
  }
  for (let i = firstNonOneAxis + 1; i < size.length; i++) {
    if (begin[i] > 0 || size[i] !== shape[i]) {
      return false;
    }
  }
  return true;
}
function computeFlatOffset2(begin, strides) {
  let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
  for (let i = 0; i < begin.length - 1; i++) {
    flatOffset += begin[i] * strides[i];
  }
  return flatOffset;
}
function parseSliceParams2(x, begin, size) {
  let begin_;
  const xRank = x.shape.length;
  if (typeof begin === "number") {
    begin_ = [begin, ...new Array(xRank - 1).fill(0)];
  } else if (begin.length < xRank) {
    begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
  } else {
    begin_ = begin.slice();
  }
  begin_.forEach((d) => {
    assert2(d !== -1, () => "slice() does not support negative begin indexing.");
  });
  let size_;
  if (size == null) {
    size_ = new Array(xRank).fill(-1);
  } else if (typeof size === "number") {
    size_ = [size, ...new Array(xRank - 1).fill(-1)];
  } else if (size.length < xRank) {
    size_ = size.concat(new Array(xRank - size.length).fill(-1));
  } else {
    size_ = size;
  }
  size_ = size_.map((d, i) => {
    if (d >= 0) {
      return d;
    } else {
      assert2(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
      return x.shape[i] - begin_[i];
    }
  });
  return [begin_, size_];
}
function sliceInfo2(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
  let $begin = begin.slice();
  let $end = end.slice();
  let $strides = strides;
  if (strides == null) {
    $strides = new Array($begin.length);
  }
  const ellipsisAxes = maskToAxes2(ellipsisMask);
  if (ellipsisAxes.length > 1) {
    throw new Error("Multiple ellipses in slice is not allowed.");
  }
  if (ellipsisMask !== 0 && newAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");
  }
  if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");
  }
  const numInterpolatedAxes = xShape.length - $begin.length;
  const expandAxes = maskToAxes2(newAxisMask);
  const newShape = xShape.slice();
  expandAxes.forEach((axis) => {
    $begin[axis] = 0;
    $end[axis] = 1;
    newShape.splice(axis, 0, 1);
  });
  const { begin: normalizedBegin, end: normalizedEnd, strides: normalizedStrides } = getNormalizedAxes2(newShape, ellipsisAxes, numInterpolatedAxes, $begin, $end, $strides, beginMask, endMask, ellipsisMask);
  $begin = normalizedBegin;
  $end = normalizedEnd;
  $strides = normalizedStrides;
  const shrinkAxes = maskToAxes2(shrinkAxisMask);
  shrinkAxes.forEach((axis) => {
    $end[axis] = $begin[axis] + 1;
    $strides[axis] = 1;
  });
  const size = computeOutShape4($begin, $end, $strides);
  const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);
  const nonStrided = $strides.every((v) => v === 1);
  return { nonStrided, $begin, $end, $strides, size, newShape, outShape };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/serialization.js
var serialization_exports2 = {};
__export(serialization_exports2, {
  Serializable: () => Serializable9,
  SerializationMap: () => SerializationMap2,
  registerClass: () => registerClass2
});
var Serializable9 = class {
  getClassName() {
    return this.constructor.className;
  }
  static fromConfig(cls, config) {
    return new cls(config);
  }
};
var SerializationMap2 = class {
  constructor() {
    this.classNameMap = {};
  }
  static getMap() {
    if (SerializationMap2.instance == null) {
      SerializationMap2.instance = new SerializationMap2();
    }
    return SerializationMap2.instance;
  }
  static register(cls) {
    SerializationMap2.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
  }
};
function registerClass2(cls) {
  assert2(cls.className != null, () => `Class being registered does not have the static className property defined.`);
  assert2(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
  assert2(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
  SerializationMap2.register(cls);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/globals.js
function deprecationWarn2(msg) {
  if (env2().getBool("DEPRECATION_WARNINGS_ENABLED")) {
    console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
  }
}
setDeprecationWarningFn2(deprecationWarn2);
function engine2() {
  return ENGINE2;
}
function memory2() {
  return ENGINE2.memory();
}
function tidy2(nameOrFn, fn) {
  return ENGINE2.tidy(nameOrFn, fn);
}
function dispose2(container) {
  const tensors = getTensorsInContainer2(container);
  tensors.forEach((tensor3) => tensor3.dispose());
}
function keep2(result) {
  return ENGINE2.keep(result);
}
function registerBackend2(name, factory, priority = 1) {
  return ENGINE2.registerBackend(name, factory, priority);
}
function backend2() {
  return ENGINE2.backend;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/add.js
function add_2(a, b) {
  let $a = convertToTensor2(a, "a", "add");
  let $b = convertToTensor2(b, "b", "add");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Add2, inputs);
}
var add4 = op2({ add_: add_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js
function floorDiv_2(a, b) {
  let $a = convertToTensor2(a, "a", "floorDiv");
  let $b = convertToTensor2(b, "b", "floorDiv");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(FloorDiv2, inputs);
}
var floorDiv2 = op2({ floorDiv_: floorDiv_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/div.js
function div_2(a, b) {
  let $a = convertToTensor2(a, "a", "div");
  let $b = convertToTensor2(b, "b", "div");
  [$a, $b] = makeTypesMatch2($a, $b);
  if ($a.dtype === "int32" && $b.dtype === "int32") {
    return floorDiv2($a, $b);
  }
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE2.runKernel(RealDiv2, inputs, attrs);
}
var div2 = op2({ div_: div_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/mul.js
function mul_2(a, b) {
  let $a = convertToTensor2(a, "a", "mul");
  let $b = convertToTensor2(b, "b", "mul");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Multiply2, inputs);
}
var mul2 = op2({ mul_: mul_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/abs.js
function abs_2(x) {
  const $x = convertToTensor2(x, "x", "abs");
  if ($x.dtype === "complex64") {
    const inputs = { x: $x };
    return ENGINE2.runKernel(ComplexAbs2, inputs);
  } else {
    const inputs = { x: $x };
    return ENGINE2.runKernel(Abs2, inputs);
  }
}
var abs2 = op2({ abs_: abs_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/acos.js
function acos_2(x) {
  const $x = convertToTensor2(x, "x", "acos");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Acos2, inputs);
}
var acos2 = op2({ acos_: acos_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js
function acosh_2(x) {
  const $x = convertToTensor2(x, "x", "acosh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Acosh2, inputs);
}
var acosh2 = op2({ acosh_: acosh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js
function addN_2(tensors) {
  assert2(Array.isArray(tensors), () => "The argument passed to tf.addN() must be a list of tensors");
  assert2(tensors.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${tensors.length}`);
  const $tensors = tensors.map((t, i) => convertToTensor2(t, `tensors${i}`, "addN"));
  const firstTensor = $tensors[0];
  $tensors.forEach((t) => {
    if (t.dtype !== firstTensor.dtype) {
      throw new Error("All tensors passed to tf.addN() must have the same dtype");
    }
  });
  $tensors.forEach((t) => {
    if (!arraysEqual2(t.shape, firstTensor.shape)) {
      throw new Error("All tensors passed to tf.addN() must have the same shape");
    }
  });
  const inputs = $tensors;
  return ENGINE2.runKernel(AddN2, inputs);
}
var addN2 = op2({ addN_: addN_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/all.js
function all_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "all", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(All2, inputs, attrs);
}
var all2 = op2({ all_: all_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/any.js
function any_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "any", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(Any2, inputs, attrs);
}
var any2 = op2({ any_: any_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js
function argMax_2(x, axis = 0) {
  const $x = convertToTensor2(x, "x", "argMax");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE2.runKernel(ArgMax2, inputs, attrs);
}
var argMax2 = op2({ argMax_: argMax_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js
function argMin_2(x, axis = 0) {
  const $x = convertToTensor2(x, "x", "argMin");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE2.runKernel(ArgMin2, inputs, attrs);
}
var argMin2 = op2({ argMin_: argMin_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/asin.js
function asin_2(x) {
  const $x = convertToTensor2(x, "x", "asin");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Asin2, inputs);
}
var asin2 = op2({ asin_: asin_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js
function asinh_2(x) {
  const $x = convertToTensor2(x, "x", "asinh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Asinh2, inputs);
}
var asinh2 = op2({ asinh_: asinh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/atan.js
function atan_2(x) {
  const $x = convertToTensor2(x, "x", "atan");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Atan3, inputs);
}
var atan3 = op2({ atan_: atan_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js
function atan2_2(a, b) {
  let $a = convertToTensor2(a, "a", "atan2");
  let $b = convertToTensor2(b, "b", "atan2");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Atan22, inputs);
}
var atan22 = op2({ atan2_: atan2_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js
function atanh_2(x) {
  const $x = convertToTensor2(x, "x", "atanh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Atanh2, inputs);
}
var atanh2 = op2({ atanh_: atanh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js
function computeDilation2DInfo2(inputShape, filterShape, strides, pad4, dataFormat = "NHWC", dilations) {
  const inputChannels = inputShape[3];
  const $filterShape = [...filterShape, inputChannels];
  const $dataFormat = convertConv2DDataFormat2(dataFormat);
  return computeConv2DInfo2(inputShape, $filterShape, strides, dilations, pad4, null, null, $dataFormat);
}
function computePool2DInfo2(inShape, filterSize, strides, dilations, pad4, roundingMode, dataFormat = "channelsLast") {
  const [filterHeight, filterWidth] = parseTupleParam2(filterSize);
  let filterShape;
  if (dataFormat === "channelsLast") {
    filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
  } else if (dataFormat === "channelsFirst") {
    filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv2DInfo2(inShape, filterShape, strides, dilations, pad4, roundingMode, false, dataFormat);
}
function computePool3DInfo2(inShape, filterSize, strides, dilations, pad4, roundingMode, dataFormat = "NDHWC") {
  const [filterDepth, filterHeight, filterWidth] = parse3TupleParam2(filterSize);
  let filterShape;
  let $dataFormat;
  if (dataFormat === "NDHWC") {
    $dataFormat = "channelsLast";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
  } else if (dataFormat === "NCDHW") {
    $dataFormat = "channelsFirst";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv3DInfo2(inShape, filterShape, strides, dilations, pad4, false, $dataFormat, roundingMode);
}
function computeConv2DInfo2(inShape, filterShape, strides, dilations, pad4, roundingMode, depthwise = false, dataFormat = "channelsLast") {
  let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideHeight, strideWidth] = parseTupleParam2(strides);
  const [dilationHeight, dilationWidth] = parseTupleParam2(dilations);
  const effectiveFilterHeight = getEffectiveFilterSize2(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize2(filterWidth, dilationWidth);
  const { padInfo, outHeight, outWidth } = getPadAndOutInfo2(pad4, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inHeight,
    inWidth,
    inChannels,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideHeight,
    strideWidth,
    filterHeight,
    filterWidth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeConv3DInfo2(inShape, filterShape, strides, dilations, pad4, depthwise = false, dataFormat = "channelsLast", roundingMode) {
  let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam2(strides);
  const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam2(dilations);
  const effectiveFilterDepth = getEffectiveFilterSize2(filterDepth, dilationDepth);
  const effectiveFilterHeight = getEffectiveFilterSize2(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize2(filterWidth, dilationWidth);
  const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo2(pad4, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inDepth,
    inHeight,
    inWidth,
    inChannels,
    outDepth,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideDepth,
    strideHeight,
    strideWidth,
    filterDepth,
    filterHeight,
    filterWidth,
    effectiveFilterDepth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationDepth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeOutputShape2D2(inShape, fieldSize, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad2(inShape, fieldSize, stride);
  }
  const inputRows = inShape[0];
  const inputCols = inShape[1];
  const outputRows = round3((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round3((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputRows, outputCols];
}
function computeOutputShape4D2(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad2(inShape, fieldSize, stride);
  }
  const inputDepth = inShape[0];
  const inputRows = inShape[1];
  const inputCols = inShape[2];
  const outputDepths = round3((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputRows = round3((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round3((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputDepths, outputRows, outputCols, outChannels];
}
function computeDefaultPad2(inputShape, fieldSize, stride, dilation = 1) {
  const effectiveFieldSize = getEffectiveFilterSize2(fieldSize, dilation);
  return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
}
function parseTupleParam2(param) {
  if (typeof param === "number") {
    return [param, param, param];
  }
  if (param.length === 2) {
    return [param[0], param[1], 1];
  }
  return param;
}
function parse3TupleParam2(param) {
  return typeof param === "number" ? [param, param, param] : param;
}
function getEffectiveFilterSize2(filterSize, dilation) {
  if (dilation <= 1) {
    return filterSize;
  }
  return filterSize + (filterSize - 1) * (dilation - 1);
}
function getPadAndOutInfo2(pad4, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
  let padInfo;
  let outHeight;
  let outWidth;
  if (typeof pad4 === "number") {
    const padType = pad4 === 0 ? "VALID" : "NUMBER";
    padInfo = { top: pad4, bottom: pad4, left: pad4, right: pad4, type: padType };
    const outShape = computeOutputShape2D2([inHeight, inWidth], filterHeight, strideHeight, pad4, roundingMode);
    outHeight = outShape[0];
    outWidth = outShape[1];
  } else if (pad4 === "same") {
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
    const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, type: "SAME" };
  } else if (pad4 === "valid") {
    padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else if (typeof pad4 === "object") {
    const top = dataFormat === "channelsLast" ? pad4[1][0] : pad4[2][0];
    const bottom = dataFormat === "channelsLast" ? pad4[1][1] : pad4[2][1];
    const left = dataFormat === "channelsLast" ? pad4[2][0] : pad4[3][0];
    const right = dataFormat === "channelsLast" ? pad4[2][1] : pad4[3][1];
    const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
    padInfo = { top, bottom, left, right, type: padType };
    outHeight = round3((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
    outWidth = round3((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
  } else {
    throw Error(`Unknown padding parameter: ${pad4}`);
  }
  return { padInfo, outHeight, outWidth };
}
function get3DPadAndOutInfo2(pad4, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
  let padInfo;
  let outDepth;
  let outHeight;
  let outWidth;
  if (typeof pad4 === "number") {
    const padType = pad4 === 0 ? "VALID" : "NUMBER";
    padInfo = {
      top: pad4,
      bottom: pad4,
      left: pad4,
      right: pad4,
      front: pad4,
      back: pad4,
      type: padType
    };
    const outShape = computeOutputShape4D2([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad4, roundingMode);
    outDepth = outShape[0];
    outHeight = outShape[1];
    outWidth = outShape[2];
  } else if (pad4 === "same") {
    outDepth = Math.ceil(inDepth / strideDepth);
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
    const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
    const front = Math.floor(padAlongDepth / 2);
    const back = padAlongDepth - front;
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, front, back, type: "SAME" };
  } else if (pad4 === "valid") {
    padInfo = {
      top: 0,
      bottom: 0,
      left: 0,
      right: 0,
      front: 0,
      back: 0,
      type: "VALID"
    };
    outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else {
    throw Error(`Unknown padding parameter: ${pad4}`);
  }
  return { padInfo, outDepth, outHeight, outWidth };
}
function round3(value, roundingMode) {
  if (!roundingMode) {
    return Math.trunc(value);
  }
  switch (roundingMode) {
    case "round":
      return Math.round(value);
    case "ceil":
      return Math.ceil(value);
    case "floor":
      return Math.floor(value);
    default:
      throw new Error(`Unknown roundingMode ${roundingMode}`);
  }
}
function tupleValuesAreOne2(param) {
  const [dimA, dimB, dimC] = parseTupleParam2(param);
  return dimA === 1 && dimB === 1 && dimC === 1;
}
function eitherStridesOrDilationsAreOne2(strides, dilations) {
  return tupleValuesAreOne2(strides) || tupleValuesAreOne2(dilations);
}
function convertConv2DDataFormat2(dataFormat) {
  if (dataFormat === "NHWC") {
    return "channelsLast";
  } else if (dataFormat === "NCHW") {
    return "channelsFirst";
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js
function reshape_2(x, shape) {
  const $x = convertToTensor2(x, "x", "reshape", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = { shape };
  return ENGINE2.runKernel(Reshape2, inputs, attrs);
}
var reshape2 = op2({ reshape_: reshape_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js
function avgPool_2(x, filterSize, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "avgPool", "float32");
  const dilations = 1;
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in avgPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  let res = ENGINE2.runKernel(AvgPool2, inputs, attrs);
  res = cast2(res, $x.dtype);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPool2 = op2({ avgPool_: avgPool_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js
function avgPool3d_2(x, filterSize, strides, pad4, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor2(x, "x", "avgPool3d", "float32");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert2(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert2(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat };
  let res = ENGINE2.runKernel(AvgPool3D2, inputs, attrs);
  res = cast2(res, x5D.dtype);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3d2 = op2({ avgPool3d_: avgPool3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat.js
function concat_2(tensors, axis = 0) {
  assert2(tensors.length >= 1, () => "Pass at least one tensor to concat");
  const $tensors = convertToTensorArray2(tensors, "tensors", "concat", "string_or_numeric");
  if ($tensors[0].dtype === "complex64") {
    $tensors.forEach((tensor3) => {
      if (tensor3.dtype !== "complex64") {
        throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor3.dtype}. `);
      }
    });
  }
  if ($tensors.length === 1) {
    return clone2($tensors[0]);
  }
  const inputs = $tensors;
  const attr = { axis };
  return ENGINE2.runKernel(Concat2, inputs, attr);
}
var concat2 = op2({ concat_: concat_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js
function sigmoid_2(x) {
  const $x = convertToTensor2(x, "x", "sigmoid");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Sigmoid2, inputs);
}
var sigmoid2 = op2({ sigmoid_: sigmoid_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice.js
function slice_2(x, begin, size) {
  const $x = convertToTensor2(x, "x", "slice", "string_or_numeric");
  if ($x.rank === 0) {
    throw new Error("Slicing scalar is not possible");
  }
  const inputs = { x: $x };
  const attrs = { begin, size };
  return ENGINE2.runKernel(Slice2, inputs, attrs);
}
var slice2 = op2({ slice_: slice_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js
function tanh_2(x) {
  const $x = convertToTensor2(x, "x", "tanh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Tanh2, inputs);
}
var tanh4 = op2({ tanh_: tanh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js
function basicLSTMCell_2(forgetBias, lstmKernel, lstmBias, data, c, h) {
  const $forgetBias = convertToTensor2(forgetBias, "forgetBias", "basicLSTMCell");
  const $lstmKernel = convertToTensor2(lstmKernel, "lstmKernel", "basicLSTMCell");
  const $lstmBias = convertToTensor2(lstmBias, "lstmBias", "basicLSTMCell");
  const $data = convertToTensor2(data, "data", "basicLSTMCell");
  const $c = convertToTensor2(c, "c", "basicLSTMCell");
  const $h = convertToTensor2(h, "h", "basicLSTMCell");
  const combined = concat2([$data, $h], 1);
  const weighted = matMul3(combined, $lstmKernel);
  const res = add4(weighted, $lstmBias);
  const batchSize = res.shape[0];
  const sliceCols = res.shape[1] / 4;
  const sliceSize = [batchSize, sliceCols];
  const i = slice2(res, [0, 0], sliceSize);
  const j = slice2(res, [0, sliceCols], sliceSize);
  const f = slice2(res, [0, sliceCols * 2], sliceSize);
  const o = slice2(res, [0, sliceCols * 3], sliceSize);
  const newC = add4(mul2(sigmoid2(i), tanh4(j)), mul2($c, sigmoid2(add4($forgetBias, f))));
  const newH = mul2(tanh4(newC), sigmoid2(o));
  return [newC, newH];
}
var basicLSTMCell2 = op2({ basicLSTMCell_: basicLSTMCell_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js
function batchToSpaceND_2(x, blockShape, crops) {
  const $x = convertToTensor2(x, "x", "batchToSpaceND");
  const prod6 = blockShape.reduce((a, b) => a * b);
  assert2($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
  assert2(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
  assert2($x.shape[0] % prod6 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod6}`);
  const inputs = { x: $x };
  const attrs = { blockShape, crops };
  return ENGINE2.runKernel(BatchToSpaceND2, inputs, attrs);
}
var batchToSpaceND2 = op2({ batchToSpaceND_: batchToSpaceND_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js
function xAs4D2(x) {
  let x4D;
  if (x.rank === 0 || x.rank === 1) {
    x4D = reshape2(x, [1, 1, 1, x.size]);
  } else if (x.rank === 2) {
    x4D = reshape2(x, [1, 1, x.shape[0], x.shape[1]]);
  } else if (x.rank === 3) {
    x4D = reshape2(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  } else {
    x4D = x;
  }
  return x4D;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js
function batchNorm_2(x, mean5, variance, offset, scale2, varianceEpsilon) {
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const $x = convertToTensor2(x, "x", "batchNorm");
  const $mean = convertToTensor2(mean5, "mean", "batchNorm");
  const $variance = convertToTensor2(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor2(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor2(offset, "offset", "batchNorm");
  }
  assert2($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  assert2($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  assert2($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const x4D = xAs4D2($x);
  const inputs = {
    x: x4D,
    scale: $scale,
    offset: $offset,
    mean: $mean,
    variance: $variance
  };
  const attrs = { varianceEpsilon };
  const res = ENGINE2.runKernel(FusedBatchNorm2, inputs, attrs);
  return reshape2(res, $x.shape);
}
var batchNorm2 = op2({ batchNorm_: batchNorm_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js
function batchNorm2d_2(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor2(x, "x", "batchNorm");
  const $mean = convertToTensor2(mean5, "mean", "batchNorm");
  const $variance = convertToTensor2(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor2(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor2(offset, "offset", "batchNorm");
  }
  assert2($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
  assert2($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
  assert2($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert2($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert2($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm2($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm2d2 = op2({ batchNorm2d_: batchNorm2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js
function batchNorm3d_2(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor2(x, "x", "batchNorm");
  const $mean = convertToTensor2(mean5, "mean", "batchNorm");
  const $variance = convertToTensor2(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor2(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor2(offset, "offset", "batchNorm");
  }
  assert2($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
  assert2($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
  assert2($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert2($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert2($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm2($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm3d2 = op2({ batchNorm3d_: batchNorm3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js
function batchNorm4d_2(x, mean5, variance, offset, scale2, varianceEpsilon) {
  const $x = convertToTensor2(x, "x", "batchNorm");
  const $mean = convertToTensor2(mean5, "mean", "batchNorm");
  const $variance = convertToTensor2(variance, "variance", "batchNorm");
  let $scale;
  if (scale2 != null) {
    $scale = convertToTensor2(scale2, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor2(offset, "offset", "batchNorm");
  }
  assert2($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
  assert2($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
  assert2($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert2($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert2($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm2($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm4d2 = op2({ batchNorm4d_: batchNorm4d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js
function bincount_2(x, weights, size) {
  const $x = convertToTensor2(x, "x", "bincount");
  const $weights = convertToTensor2(weights, "weights", "bincount");
  assert2($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
  assert2(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert2($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size };
  return ENGINE2.runKernel(Bincount2, inputs, attrs);
}
var bincount2 = op2({ bincount_: bincount_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js
function broadcastTo_2(x, shape) {
  let input2 = convertToTensor2(x, "broadcastTo", "x");
  const xShape = input2.shape;
  if (shape.some((d) => !(d > 0) || d % 1 !== 0)) {
    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);
  }
  if (shape.length < input2.rank) {
    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input2.rank}.`);
  }
  if (shape.length > input2.rank) {
    const newShape = input2.shape.slice();
    while (newShape.length < shape.length) {
      newShape.unshift(1);
    }
    input2 = reshape2(input2, newShape);
  }
  const inputShape = input2.shape;
  const reps = Array.from(shape);
  for (let i = shape.length - 1; i >= 0; i--) {
    if (inputShape[i] === shape[i]) {
      reps[i] = 1;
    } else if (input2.shape[i] !== 1) {
      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
    }
  }
  const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
  if (axes.length === 0) {
    return clone2(input2);
  }
  const inputs = { x: input2 };
  const attrs = { reps };
  return ENGINE2.runKernel(Tile2, inputs, attrs);
}
var broadcastTo2 = op2({ broadcastTo_: broadcastTo_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js
function ceil_2(x) {
  const $x = convertToTensor2(x, "x", "ceil");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Ceil2, inputs);
}
var ceil2 = op2({ ceil_: ceil_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js
function clipByValue_2(x, clipValueMin, clipValueMax) {
  const $x = convertToTensor2(x, "x", "clipByValue");
  assert2(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
  const inputs = { x: $x };
  const attrs = { clipValueMin, clipValueMax };
  return ENGINE2.runKernel(ClipByValue2, inputs, attrs);
}
var clipByValue2 = op2({ clipByValue_: clipByValue_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js
function concat1d_2(tensors) {
  return concat2(tensors, 0);
}
var concat1d2 = op2({ concat1d_: concat1d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js
function concat2d_2(tensors, axis) {
  return concat2(tensors, axis);
}
var concat2d2 = op2({ concat2d_: concat2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js
function concat3d_2(tensors, axis) {
  return concat2(tensors, axis);
}
var concat3d2 = op2({ concat3d_: concat3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js
function concat4d_2(tensors, axis) {
  return concat2(tensors, axis);
}
var concat4d2 = op2({ concat4d_: concat4d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js
function conv2d_2(x, filter, strides, pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "conv2d");
  const $filter = convertToTensor2(filter, "filter", "conv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert2($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert2(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE2.runKernel(Conv2D2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2d3 = op2({ conv2d_: conv2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js
function conv1d_2(x, filter, stride, pad4, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "conv1d");
  const $filter = convertToTensor2(filter, "filter", "conv1d");
  let x3D = $x;
  let reshapedTo3D = false;
  if ($x.rank === 2) {
    reshapedTo3D = true;
    x3D = reshape2($x, [1, $x.shape[0], $x.shape[1]]);
  }
  assert2(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
  assert2($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in conv1d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  assert2(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
  assert2(eitherStridesOrDilationsAreOne2(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
  assert2(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
  const filter4D = reshape2($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
  const input4D = reshape2(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
  const strides = [1, stride];
  const dilations = [1, dilation];
  const conv2dDataFormat = "NHWC";
  const res = conv2d3(input4D, filter4D, strides, pad4, conv2dDataFormat, dilations, dimRoundingMode);
  if (reshapedTo3D) {
    return reshape2(res, [res.shape[2], res.shape[3]]);
  }
  return reshape2(res, [res.shape[0], res.shape[2], res.shape[3]]);
}
var conv1d2 = op2({ conv1d_: conv1d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js
function conv2DBackpropInput_2(xShape, dy, filter, strides, pad4, dataFormat = "NHWC", dimRoundingMode) {
  assert2(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape4D = xShape;
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    xShape4D = [1, xShape[0], xShape[1], xShape[2]];
  }
  assert2(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
  assert2(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
  assert2(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
  const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert2(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
  assert2(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad4, dataFormat, dimRoundingMode, inputShape: xShape4D };
  const res = ENGINE2.runKernel(Conv2DBackpropInput2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2DBackpropInput2 = op2({ conv2DBackpropInput_: conv2DBackpropInput_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js
function conv2dTranspose_2(x, filter, outputShape, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "conv2dTranspose");
  const $filter = convertToTensor2(filter, "filter", "conv2dTranspose");
  return conv2DBackpropInput2(outputShape, $x, $filter, strides, pad4, "NHWC", dimRoundingMode);
}
var conv2dTranspose2 = op2({ conv2dTranspose_: conv2dTranspose_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js
function conv3d_2(x, filter, strides, pad4, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
  const $x = convertToTensor2(x, "x", "conv3d");
  const $filter = convertToTensor2(filter, "filter", "conv3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert2(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
  assert2($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
  assert2(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert2(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
  const inputs = { x: x5D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations };
  const res = ENGINE2.runKernel(Conv3D2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3d2 = op2({ conv3d_: conv3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js
function conv3DBackpropInput_2(xShape, dy, filter, strides, pad4) {
  assert2(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape5D = xShape;
  let dy5D = dy;
  let reshapedTo5D = false;
  if (dy.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
  }
  const inDepth = xShape5D[4];
  const outDepth = dy5D.shape[4];
  assert2(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
  assert2(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
  assert2(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
  assert2(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
  assert2(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
  const inputs = { dy: dy5D, filter };
  const attrs = { pad: pad4, strides, inputShape: xShape5D };
  const res = ENGINE2.runKernel(Conv3DBackpropInputV22, inputs, attrs);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3DBackpropInput2 = op2({ conv3DBackpropInput_: conv3DBackpropInput_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js
function conv3dTranspose_2(x, filter, outputShape, strides, pad4) {
  const $x = convertToTensor2(x, "x", "conv3dTranspose");
  const $filter = convertToTensor2(filter, "filter", "conv3dTranspose");
  return conv3DBackpropInput2(outputShape, $x, $filter, strides, pad4);
}
var conv3dTranspose2 = op2({ conv3dTranspose_: conv3dTranspose_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/cos.js
function cos_2(x) {
  const $x = convertToTensor2(x, "x", "cos");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Cos2, inputs);
}
var cos2 = op2({ cos_: cos_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js
function cosh_2(x) {
  const $x = convertToTensor2(x, "x", "cosh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Cosh2, inputs);
}
var cosh2 = op2({ cosh_: cosh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js
function cumsum_2(x, axis = 0, exclusive = false, reverse6 = false) {
  const $x = convertToTensor2(x, "x", "cumsum");
  const inputs = { x: $x };
  const attrs = { axis, exclusive, reverse: reverse6 };
  return ENGINE2.runKernel(Cumsum2, inputs, attrs);
}
var cumsum2 = op2({ cumsum_: cumsum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js
function denseBincount_2(x, weights, size, binaryOutput = false) {
  const $x = convertToTensor2(x, "x", "denseBincount");
  const $weights = convertToTensor2(weights, "weights", "denseBincount");
  assert2($x.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${$x.dtype}`);
  assert2($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${$x.rank}.`);
  assert2(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert2($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size, binaryOutput };
  return ENGINE2.runKernel(DenseBincount2, inputs, attrs);
}
var denseBincount2 = op2({ denseBincount_: denseBincount_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js
function depthToSpace_2(x, blockSize, dataFormat = "NHWC") {
  const $x = convertToTensor2(x, "x", "depthToSpace");
  const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
  assert2(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
  assert2(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
  assert2(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
  const inputs = { x: $x };
  const attrs = { blockSize, dataFormat };
  return ENGINE2.runKernel(DepthToSpace2, inputs, attrs);
}
var depthToSpace2 = op2({ depthToSpace_: depthToSpace_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js
function depthwiseConv2d_2(x, filter, strides, pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "depthwiseConv2d");
  const $filter = convertToTensor2(filter, "filter", "depthwiseConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert2($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert2(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE2.runKernel(DepthwiseConv2dNative2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2d3 = op2({ depthwiseConv2d_: depthwiseConv2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/diag.js
function diag_2(x) {
  const $x = convertToTensor2(x, "x", "diag");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Diag2, inputs);
}
var diag2 = op2({ diag_: diag_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js
function dilation2d_2(x, filter, strides, pad4, dilations = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor2(x, "x", "dilation2d");
  const $filter = convertToTensor2(filter, "filter", "dilation2d");
  assert2($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
  assert2($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
  assert2(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    reshapedTo4D = true;
  }
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad4, dilations };
  const res = ENGINE2.runKernel(Dilation2D2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var dilation2d2 = op2({ dilation2d_: dilation2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js
function getBroadcastDims2(inShape, outShape) {
  const inRank = inShape.length;
  const dims = [];
  for (let i = 0; i < inRank; i++) {
    const dim = inRank - 1 - i;
    const a = inShape[dim] || 1;
    const b = outShape[outShape.length - 1 - i] || 1;
    if (b > 1 && a === 1) {
      dims.unshift(dim);
    }
  }
  return dims;
}
function getReductionAxes2(inShape, outShape) {
  const result = [];
  for (let i = 0; i < outShape.length; i++) {
    const inDim = inShape[inShape.length - i - 1];
    const outAxis = outShape.length - i - 1;
    const outDim = outShape[outAxis];
    if (inDim == null || inDim === 1 && outDim > 1) {
      result.unshift(outAxis);
    }
  }
  return result;
}
function assertAndGetBroadcastShape2(shapeA, shapeB) {
  const result = [];
  const l = Math.max(shapeA.length, shapeB.length);
  for (let i = 0; i < l; i++) {
    let a = shapeA[shapeA.length - i - 1];
    if (a == null) {
      a = 1;
    }
    let b = shapeB[shapeB.length - i - 1];
    if (b == null) {
      b = 1;
    }
    if (a === 1) {
      result.unshift(b);
    } else if (b === 1) {
      result.unshift(a);
    } else if (a !== b) {
      const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
      throw Error(errMsg);
    } else {
      result.unshift(a);
    }
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/equal.js
function equal_2(a, b) {
  let $a = convertToTensor2(a, "a", "equal", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "equal", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Equal2, inputs);
}
var equal2 = op2({ equal_: equal_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/where.js
function where_2(condition, a, b) {
  const $a = convertToTensor2(a, "a", "where");
  const $b = convertToTensor2(b, "b", "where");
  const $condition = convertToTensor2(condition, "condition", "where", "bool");
  const broadcastShape = assertAndGetBroadcastShape2(assertAndGetBroadcastShape2($condition.shape, $a.shape), $b.shape);
  const $broadcastedCondition = broadcastTo2($condition, broadcastShape);
  const $broadcastedA = broadcastTo2($a, broadcastShape);
  const $broadcastedB = broadcastTo2($b, broadcastShape);
  const inputs = {
    condition: $broadcastedCondition,
    t: $broadcastedA,
    e: $broadcastedB
  };
  return ENGINE2.runKernel(Select2, inputs);
}
var where2 = op2({ where_: where_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js
function zerosLike_2(x) {
  const $x = convertToTensor2(x, "x", "zerosLike");
  const inputs = { x: $x };
  return ENGINE2.runKernel(ZerosLike2, inputs);
}
var zerosLike2 = op2({ zerosLike_: zerosLike_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js
function divNoNan_2(a, b) {
  let $a = convertToTensor2(a, "a", "div");
  let $b = convertToTensor2(b, "b", "div");
  [$a, $b] = makeTypesMatch2($a, $b);
  const divResult = div2($a, $b);
  const zeros6 = zerosLike2(divResult);
  const bEqualsZero = equal2($b, zeros6);
  return where2(bEqualsZero, zeros6, divResult);
}
var divNoNan2 = op2({ divNoNan_: divNoNan_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/dot.js
function dot_2(t1, t2) {
  const $t1 = convertToTensor2(t1, "t1", "dot");
  const $t2 = convertToTensor2(t2, "t2", "dot");
  assert2(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
  const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
  const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
  assert2(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
  if ($t1.rank === 1 && $t2.rank === 1) {
    const t12D = reshape2($t1, [1, -1]);
    const t22D = reshape2($t2, [-1, 1]);
    const t1t2 = matMul3(t12D, t22D);
    return reshape2(t1t2, []);
  } else if ($t1.rank === 1 && $t2.rank === 2) {
    const t12D = reshape2($t1, [1, -1]);
    const t22D = reshape2($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul3(t12D, t22D);
    return reshape2(t1t2, [t1t2.size]);
  } else if ($t1.rank === 2 && $t2.rank === 1) {
    const t22D = reshape2($t2, [-1, 1]);
    const t1t2 = matMul3($t1, t22D);
    return reshape2(t1t2, [t1t2.size]);
  } else {
    const t22D = reshape2($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul3($t1, t22D);
    return t1t2;
  }
}
var dot2 = op2({ dot_: dot_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js
function einsum_2(equation, ...tensors) {
  const $tensors = tensors.map((t, i) => convertToTensor2(t, `tensors${i}`, "einsum"));
  const attrs = { equation };
  return ENGINE2.runKernel(Einsum2, $tensors, attrs);
}
var einsum2 = op2({ einsum_: einsum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/elu.js
function elu_2(x) {
  const $x = convertToTensor2(x, "x", "elu");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Elu2, inputs);
}
var elu2 = op2({ elu_: elu_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/erf.js
function erf_2(x) {
  let $x = convertToTensor2(x, "x", "erf");
  assert2($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
  if ($x.dtype === "int32") {
    $x = cast2($x, "float32");
  }
  const inputs = { x: $x };
  return ENGINE2.runKernel(Erf2, inputs);
}
var erf2 = op2({ erf_: erf_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/exp.js
function exp_2(x) {
  const $x = convertToTensor2(x, "x", "exp");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Exp2, inputs);
}
var exp2 = op2({ exp_: exp_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js
function expandDims_2(x, axis = 0) {
  const $x = convertToTensor2(x, "x", "expandDims", "string_or_numeric");
  assert2(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
  const inputs = { input: $x };
  const attrs = { dim: axis };
  return ENGINE2.runKernel(ExpandDims2, inputs, attrs);
}
var expandDims2 = op2({ expandDims_: expandDims_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js
function expm1_2(x) {
  const $x = convertToTensor2(x, "x", "expm1");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Expm12, inputs);
}
var expm12 = op2({ expm1_: expm1_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tile.js
function tile_2(x, reps) {
  const $x = convertToTensor2(x, "x", "tile", "string_or_numeric");
  assert2($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
  const inputs = { x: $x };
  const attrs = { reps };
  return ENGINE2.runKernel(Tile2, inputs, attrs);
}
var tile2 = op2({ tile_: tile_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/eye.js
function eye_2(numRows, numColumns, batchShape, dtype = "float32") {
  if (numColumns == null) {
    numColumns = numRows;
  }
  const buff = buffer2([numRows, numColumns], dtype);
  const n = numRows <= numColumns ? numRows : numColumns;
  for (let i = 0; i < n; ++i) {
    buff.set(1, i, i);
  }
  const out = reshape2(buff.toTensor(), [numRows, numColumns]);
  if (batchShape == null) {
    return out;
  } else {
    if (batchShape.length === 1) {
      return tile2(expandDims2(out, 0), [batchShape[0], 1, 1]);
    } else if (batchShape.length === 2) {
      return tile2(expandDims2(expandDims2(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
    } else if (batchShape.length === 3) {
      return tile2(expandDims2(expandDims2(expandDims2(out, 0), 0), 0), [
        batchShape[0],
        batchShape[1],
        batchShape[2],
        1,
        1
      ]);
    } else {
      throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
    }
  }
}
var eye2 = op2({ eye_: eye_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fill.js
function fill2(shape, value, dtype) {
  const attrs = { shape, value, dtype };
  return ENGINE2.runKernel(Fill2, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/floor.js
function floor_2(x) {
  const $x = convertToTensor2(x, "x", "floor");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Floor2, inputs);
}
var floor2 = op2({ floor_: floor_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/gather.js
function gather_2(x, indices, axis = 0, batchDims = 0) {
  const $x = convertToTensor2(x, "x", "gather");
  const $indices = convertToTensor2(indices, "indices", "gather", "int32");
  const inputs = { x: $x, indices: $indices };
  const attrs = { axis, batchDims };
  return ENGINE2.runKernel(GatherV22, inputs, attrs);
}
var gather2 = op2({ gather_: gather_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/greater.js
function greater_2(a, b) {
  let $a = convertToTensor2(a, "a", "greater", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "greater", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Greater2, inputs);
}
var greater2 = op2({ greater_: greater_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js
function greaterEqual_2(a, b) {
  let $a = convertToTensor2(a, "a", "greaterEqual", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "greaterEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(GreaterEqual2, inputs);
}
var greaterEqual2 = op2({ greaterEqual_: greaterEqual_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/imag.js
function imag_2(input2) {
  const $input = convertToTensor2(input2, "input", "imag");
  const inputs = { input: $input };
  return ENGINE2.runKernel(Imag2, inputs);
}
var imag2 = op2({ imag_: imag_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js
function isFinite_2(x) {
  const $x = convertToTensor2(x, "x", "isFinite");
  const inputs = { x: $x };
  return ENGINE2.runKernel(IsFinite2, inputs);
}
var isFinite3 = op2({ isFinite_: isFinite_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js
function isInf_2(x) {
  const $x = convertToTensor2(x, "x", "isInf");
  const inputs = { x: $x };
  return ENGINE2.runKernel(IsInf2, inputs);
}
var isInf2 = op2({ isInf_: isInf_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js
function isNaN_2(x) {
  const $x = convertToTensor2(x, "x", "isNaN");
  const inputs = { x: $x };
  return ENGINE2.runKernel(IsNan2, inputs);
}
var isNaN3 = op2({ isNaN_: isNaN_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js
function leakyRelu_2(x, alpha = 0.2) {
  const $x = convertToTensor2(x, "x", "leakyRelu");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE2.runKernel(LeakyRelu2, inputs, attrs);
}
var leakyRelu2 = op2({ leakyRelu_: leakyRelu_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/less.js
function less_2(a, b) {
  let $a = convertToTensor2(a, "a", "less", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "less", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Less2, inputs);
}
var less2 = op2({ less_: less_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js
function lessEqual_2(a, b) {
  let $a = convertToTensor2(a, "a", "lessEqual", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "lessEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(LessEqual2, inputs);
}
var lessEqual2 = op2({ lessEqual_: lessEqual_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/linspace.js
function linspace2(start, stop, num) {
  if (num <= 0) {
    throw new Error("The number of values should be positive.");
  }
  const attrs = { start, stop, num };
  return ENGINE2.runKernel(LinSpace2, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js
function localResponseNormalization_2(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const $x = convertToTensor2(x, "x", "localResponseNormalization");
  assert2($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
  assert2(isInt2(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  const inputs = { x: x4D };
  const attrs = { depthRadius, bias, alpha, beta };
  const res = ENGINE2.runKernel(LRN2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  } else {
    return res;
  }
}
var localResponseNormalization2 = op2({ localResponseNormalization_: localResponseNormalization_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/log.js
function log_2(x) {
  const $x = convertToTensor2(x, "x", "log");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Log2, inputs);
}
var log3 = op2({ log_: log_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js
function log1p_2(x) {
  const $x = convertToTensor2(x, "x", "log1p");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Log1p2, inputs);
}
var log1p2 = op2({ log1p_: log1p_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients.js
function variableGrads2(f, varList) {
  assert2(isFunction2(f), () => "The f passed in variableGrads(f) must be a function");
  assert2(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable2), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const specifiedVarList = varList != null;
  if (!specifiedVarList) {
    varList = [];
    for (const varName in ENGINE2.registeredVariables) {
      varList.push(ENGINE2.registeredVariables[varName]);
    }
  }
  const specifiedNonTrainable = specifiedVarList ? varList.filter((variable3) => !variable3.trainable) : null;
  const originalVarCount = varList.length;
  varList = varList.filter((variable3) => variable3.trainable);
  assert2(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
  const allowNoGradients = true;
  const { value, grads: grads3 } = ENGINE2.gradients(f, varList, null, allowNoGradients);
  assert2(grads3.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
  assert2(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
  const namedGrads = {};
  varList.forEach((v, i) => {
    if (grads3[i] != null) {
      namedGrads[v.name] = grads3[i];
    }
  });
  if (specifiedNonTrainable != null) {
    specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
  }
  return { value, grads: namedGrads };
}
function customGrad2(f) {
  return ENGINE2.customGrad(f);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/neg.js
function neg_2(x) {
  const $x = convertToTensor2(x, "x", "neg");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Neg2, inputs);
}
var neg2 = op2({ neg_: neg_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js
function softplus_2(x) {
  const $x = convertToTensor2(x, "x", "softplus");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Softplus2, inputs);
}
var softplus2 = op2({ softplus_: softplus_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js
function logSigmoid_2(x) {
  const $x = convertToTensor2(x, "x", "logSigmoid");
  const customOp = customGrad2((x2) => {
    const value = neg2(softplus2(neg2(x2)));
    const gradFunc = (dy) => {
      const derX = mul2(dy, sigmoid2(neg2(x2)));
      return derX;
    };
    return { value, gradFunc };
  });
  return customOp($x);
}
var logSigmoid2 = op2({ logSigmoid_: logSigmoid_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max.js
function max_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "max");
  const inputs = { x: $x };
  const attrs = { reductionIndices: axis, keepDims };
  return ENGINE2.runKernel(Max2, inputs, attrs);
}
var max2 = op2({ max_: max_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sub.js
function sub_2(a, b) {
  let $a = convertToTensor2(a, "a", "sub");
  let $b = convertToTensor2(b, "b", "sub");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Sub2, inputs);
}
var sub2 = op2({ sub_: sub_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sum.js
function sum_2(x, axis = null, keepDims = false) {
  let $x = convertToTensor2(x, "x", "sum");
  if ($x.dtype === "bool") {
    $x = cast2($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(Sum2, inputs, attrs);
}
var sum4 = op2({ sum_: sum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js
function logSoftmax_2(logits, axis = -1) {
  const $logits = convertToTensor2(logits, "logits", "logSoftmax");
  if (axis === -1) {
    axis = $logits.rank - 1;
  }
  if (axis !== $logits.rank - 1) {
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
  }
  const customOp = customGrad2((logits2, save) => {
    const keepDims = true;
    const xMax = max2(logits2, axis, true);
    const shifted = sub2(logits2, xMax);
    const value = sub2(cast2(shifted, "float32"), log3(sum4(exp2(shifted), axis, keepDims)));
    save([value]);
    const gradFunc = (dy, saved) => {
      const [value2] = saved;
      const keepDims2 = true;
      const softmax7 = exp2(value2);
      return sub2(dy, mul2(sum4(dy, axis, keepDims2), softmax7));
    };
    return { value, gradFunc };
  });
  return customOp($logits);
}
var logSoftmax2 = op2({ logSoftmax_: logSoftmax_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js
function axesAreInnerMostDims2(axes, rank) {
  for (let i = 0; i < axes.length; ++i) {
    if (axes[axes.length - i - 1] !== rank - 1 - i) {
      return false;
    }
  }
  return true;
}
function combineLocations2(outputLoc, reduceLoc, axes) {
  const rank = outputLoc.length + reduceLoc.length;
  const loc = [];
  let outIdx = 0;
  let reduceIdx = 0;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      loc.push(outputLoc[outIdx++]);
    } else {
      loc.push(reduceLoc[reduceIdx++]);
    }
  }
  return loc;
}
function computeOutAndReduceShapes2(aShape, axes) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      outShape.push(aShape[dim]);
    }
  }
  const reduceShape = axes.map((dim) => aShape[dim]);
  return [outShape, reduceShape];
}
function expandShapeToKeepDim2(shape, axes) {
  const reduceSubShape = axes.map((x) => 1);
  return combineLocations2(shape, reduceSubShape, axes);
}
function assertAxesAreInnerMostDims2(msg, axes, rank) {
  assert2(axesAreInnerMostDims2(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
}
function getAxesPermutation2(axes, rank) {
  if (axesAreInnerMostDims2(axes, rank)) {
    return null;
  }
  const result = [];
  for (let i = 0; i < rank; ++i) {
    if (axes.indexOf(i) === -1) {
      result.push(i);
    }
  }
  axes.forEach((axis) => result.push(axis));
  return result;
}
function getUndoAxesPermutation2(axes) {
  return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
}
function getInnerMostAxes2(numAxes, rank) {
  const res = [];
  for (let i = rank - numAxes; i < rank; ++i) {
    res.push(i);
  }
  return res;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js
function logSumExp_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "logSumExp");
  const axes = parseAxisParam2(axis, $x.shape);
  const xMax = max2($x, axes, true);
  const a = sub2($x, xMax);
  const b = exp2(a);
  const c = sum4(b, axes);
  const d = log3(c);
  const res = add4(reshape2(xMax, d.shape), d);
  if (keepDims) {
    const newShape = expandShapeToKeepDim2(res.shape, axes);
    return reshape2(res, newShape);
  }
  return res;
}
var logSumExp2 = op2({ logSumExp_: logSumExp_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js
function logicalAnd_2(a, b) {
  const $a = convertToTensor2(a, "a", "logicalAnd", "bool");
  const $b = convertToTensor2(b, "b", "logicalAnd", "bool");
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(LogicalAnd2, inputs);
}
var logicalAnd2 = op2({ logicalAnd_: logicalAnd_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js
function logicalNot_2(x) {
  const $x = convertToTensor2(x, "x", "logicalNot", "bool");
  const inputs = { x: $x };
  return ENGINE2.runKernel(LogicalNot2, inputs);
}
var logicalNot2 = op2({ logicalNot_: logicalNot_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js
function logicalOr_2(a, b) {
  const $a = convertToTensor2(a, "a", "logicalOr", "bool");
  const $b = convertToTensor2(b, "b", "logicalOr", "bool");
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(LogicalOr2, inputs);
}
var logicalOr2 = op2({ logicalOr_: logicalOr_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js
function logicalXor_2(a, b) {
  const $a = convertToTensor2(a, "a", "logicalXor", "bool");
  const $b = convertToTensor2(b, "b", "logicalXor", "bool");
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  return logicalAnd2(logicalOr2(a, b), logicalNot2(logicalAnd2(a, b)));
}
var logicalXor2 = op2({ logicalXor_: logicalXor_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js
function maxPool_2(x, filterSize, strides, pad4, dimRoundingMode) {
  const $x = convertToTensor2(x, "x", "maxPool");
  const dilations = 1;
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in maxPool: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  const res = ENGINE2.runKernel(MaxPool2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var maxPool2 = op2({ maxPool_: maxPool_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js
function maxPool3d_2(x, filterSize = [1, 1, 1], strides, pad4, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor2(x, "x", "maxPool3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert2(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert2(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat };
  const res = ENGINE2.runKernel(MaxPool3D2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3d2 = op2({ maxPool3d_: maxPool3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js
function maxPoolWithArgmax_2(x, filterSize, strides, pad4, includeBatchInIndex = false) {
  const $x = convertToTensor2(x, "x", "maxPoolWithArgmax");
  const inputs = { x: $x };
  const attrs = { filterSize, strides, pad: pad4, includeBatchInIndex };
  const result = ENGINE2.runKernel(MaxPoolWithArgmax2, inputs, attrs);
  return { result: result[0], indexes: result[1] };
}
var maxPoolWithArgmax2 = op2({ maxPoolWithArgmax_: maxPoolWithArgmax_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js
function maximum_2(a, b) {
  let $a = convertToTensor2(a, "a", "maximum");
  let $b = convertToTensor2(b, "b", "maximum");
  [$a, $b] = makeTypesMatch2($a, $b);
  if ($a.dtype === "bool") {
    $a = cast2($a, "int32");
    $b = cast2($b, "int32");
  }
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Maximum2, inputs);
}
var maximum2 = op2({ maximum_: maximum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/mean.js
function mean_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "mean");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(Mean2, inputs, attrs);
}
var mean2 = op2({ mean_: mean_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js
function zeros2(shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = zeros2(shape, "float32");
    const imag5 = zeros2(shape, "float32");
    return complex2(real6, imag5);
  }
  const values = makeZerosTypedArray2(sizeFromShape2(shape), dtype);
  return ENGINE2.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/ones.js
function ones4(shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = ones4(shape, "float32");
    const imag5 = zeros2(shape, "float32");
    return complex2(real6, imag5);
  }
  const values = makeOnesTypedArray2(sizeFromShape2(shape), dtype);
  return ENGINE2.makeTensor(values, shape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/min.js
function min_2(x, axis = null, keepDims = false) {
  const $x = convertToTensor2(x, "x", "min");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(Min2, inputs, attrs);
}
var min2 = op2({ min_: min_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js
function minimum_2(a, b) {
  let $a = convertToTensor2(a, "a", "minimum");
  let $b = convertToTensor2(b, "b", "minimum");
  [$a, $b] = makeTypesMatch2($a, $b);
  if ($a.dtype === "bool") {
    $a = cast2($a, "int32");
    $b = cast2($b, "int32");
  }
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Minimum2, inputs);
}
var minimum2 = op2({ minimum_: minimum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js
function mirrorPad_2(x, paddings, mode) {
  assert2(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
  const $x = convertToTensor2(x, "x", "mirrorPad");
  if ($x.rank === 0) {
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  }
  assert2(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
  const shapeOffset = mode === "reflect" ? 1 : 0;
  for (let i = 0; i < $x.rank; i++) {
    assert2(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
    assert2(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
  }
  const attrs = { paddings, mode };
  const inputs = { x: $x };
  return ENGINE2.runKernel(MirrorPad2, inputs, attrs);
}
var mirrorPad2 = op2({ mirrorPad_: mirrorPad_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/mod.js
function mod_2(a, b) {
  let $a = convertToTensor2(a, "a", "mod");
  let $b = convertToTensor2(b, "b", "mod");
  [$a, $b] = makeTypesMatch2($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(Mod2, inputs);
}
var mod2 = op2({ mod_: mod_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/square.js
function square_2(x) {
  const $x = convertToTensor2(x, "x", "square");
  const attrs = {};
  return ENGINE2.runKernel("Square", { x: $x }, attrs);
}
var square2 = op2({ square_: square_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/moments.js
function moments_2(x, axis = null, keepDims = false) {
  x = convertToTensor2(x, "x", "moments");
  const axes = parseAxisParam2(axis, x.shape);
  const xMean = mean2(x, axes, keepDims);
  let keepDimsShape = xMean.shape;
  if (!keepDims) {
    keepDimsShape = expandShapeToKeepDim2(xMean.shape, axes);
  }
  const devSquared = square2(sub2(cast2(x, "float32"), reshape2(xMean, keepDimsShape)));
  const variance = mean2(devSquared, axes, keepDims);
  return { mean: xMean, variance };
}
var moments2 = op2({ moments_: moments_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/multi_rnn_cell.js
function multiRNNCell_2(lstmCells, data, c, h) {
  const $data = convertToTensor2(data, "data", "multiRNNCell");
  const $c = convertToTensorArray2(c, "c", "multiRNNCell");
  const $h = convertToTensorArray2(h, "h", "multiRNNCell");
  let input2 = $data;
  const newStates = [];
  for (let i = 0; i < lstmCells.length; i++) {
    const output = lstmCells[i](input2, $c[i], $h[i]);
    newStates.push(output[0]);
    newStates.push(output[1]);
    input2 = output[1];
  }
  const newC = [];
  const newH = [];
  for (let i = 0; i < newStates.length; i += 2) {
    newC.push(newStates[i]);
    newH.push(newStates[i + 1]);
  }
  return [newC, newH];
}
var multiRNNCell2 = op2({ multiRNNCell_: multiRNNCell_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/multinomial.js
function multinomial_2(logits, numSamples, seed, normalized = false) {
  const $logits = convertToTensor2(logits, "logits", "multinomial");
  const numOutcomes = $logits.size;
  const origRank = $logits.rank;
  if (numOutcomes < 2) {
    throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${numOutcomes}.`);
  }
  if (origRank > 2) {
    throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`);
  }
  seed = seed || Math.random();
  const logits2D = origRank === 1 ? reshape2($logits, [1, -1]) : $logits;
  const inputs = { logits: logits2D };
  const attrs = { numSamples, seed, normalized };
  const res = ENGINE2.runKernel(Multinomial2, inputs, attrs);
  return origRank === 1 ? reshape2(res, [res.size]) : res;
}
var multinomial2 = op2({ multinomial_: multinomial_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js
function notEqual_2(a, b) {
  let $a = convertToTensor2(a, "a", "notEqual", "string_or_numeric");
  let $b = convertToTensor2(b, "b", "notEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE2.runKernel(NotEqual2, inputs);
}
var notEqual2 = op2({ notEqual_: notEqual_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js
function onesLike_2(x) {
  const $x = convertToTensor2(x, "x", "onesLike");
  const inputs = { x: $x };
  return ENGINE2.runKernel(OnesLike2, inputs);
}
var onesLike2 = op2({ onesLike_: onesLike_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js
function outerProduct_2(v1, v2) {
  const $v1 = convertToTensor2(v1, "v1", "outerProduct");
  const $v2 = convertToTensor2(v2, "v2", "outerProduct");
  assert2($v1.rank === 1 && $v2.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${$v1.rank} and ${$v2.rank}.`);
  const v12D = reshape2($v1, [-1, 1]);
  const v22D = reshape2($v2, [1, -1]);
  return matMul3(v12D, v22D);
}
var outerProduct2 = op2({ outerProduct_: outerProduct_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pad.js
function pad_2(x, paddings, constantValue = 0) {
  const $x = convertToTensor2(x, "x", "pad");
  if ($x.rank === 0) {
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  }
  const attrs = { paddings, constantValue };
  const inputs = { x: $x };
  return ENGINE2.runKernel(PadV22, inputs, attrs);
}
var pad2 = op2({ pad_: pad_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js
function pad1d_2(x, paddings, constantValue = 0) {
  assert2(paddings.length === 2, () => "Invalid number of paddings. Must be length of 2.");
  return pad2(x, [paddings], constantValue);
}
var pad1d2 = op2({ pad1d_: pad1d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js
function pad2d_2(x, paddings, constantValue = 0) {
  assert2(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad2(x, paddings, constantValue);
}
var pad2d2 = op2({ pad2d_: pad2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js
function pad3d_2(x, paddings, constantValue = 0) {
  assert2(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad2(x, paddings, constantValue);
}
var pad3d2 = op2({ pad3d_: pad3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js
function pad4d_2(x, paddings, constantValue = 0) {
  assert2(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each.");
  return pad2(x, paddings, constantValue);
}
var pad4d2 = op2({ pad4d_: pad4d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js
function spaceToBatchND_2(x, blockShape, paddings) {
  const $x = convertToTensor2(x, "x", "spaceToBatchND");
  assert2($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
  assert2(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
  assert2($x.shape.reduce((a, b, i) => {
    if (i > 0 && i <= blockShape.length) {
      return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
    }
    return a;
  }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
  const inputs = { x: $x };
  const attrs = { blockShape, paddings };
  return ENGINE2.runKernel(SpaceToBatchND2, inputs, attrs);
}
var spaceToBatchND2 = op2({ spaceToBatchND_: spaceToBatchND_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pool.js
function pool_2(input2, windowShape, poolingType, pad4, dilations, strides) {
  if (dilations == null) {
    dilations = [1, 1];
  }
  if (strides == null) {
    strides = 1;
  }
  if (pad4 === 0) {
    pad4 = "valid";
  }
  const $x = convertToTensor2(input2, "x", "maxPool");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computePool2DInfo2(x4D.shape, windowShape, strides, dilations, pad4);
  const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
  let basePadding;
  if (pad4 === "same") {
    basePadding = withSpaceToBatchBasePaddings2([convInfo.filterHeight, convInfo.filterWidth], dilation);
  } else {
    basePadding = [[0, 0], [0, 0]];
  }
  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings2([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
  const convertedPad = isDilationOne ? pad4 : "valid";
  const convertedX = isDilationOne ? x4D : spaceToBatchND2(x4D, dilation, adjustedPadding);
  const forwardOp = poolingType === "avg" ? () => avgPool2(convertedX, windowShape, strides, convertedPad) : () => maxPool2(convertedX, windowShape, strides, convertedPad);
  const y = forwardOp();
  const res = isDilationOne ? y : batchToSpaceND2(y, dilation, adjustedCrops);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
function requiredSpaceToBatchPaddings2(inputShape, blockShape, basePadding) {
  const padStart = basePadding.map((b) => b[0]);
  const origPadEnd = basePadding.map((b) => b[1]);
  const fullInputShape = inputShape.concat(padStart, origPadEnd);
  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);
  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);
  return [paddings, crops];
}
function withSpaceToBatchBasePaddings2(filterShape, dilation) {
  const dilatedFilterShape = filterShape.map((s, i) => {
    return s + (s - 1) * (dilation[i] - 1);
  });
  const padExtraShape = dilatedFilterShape.map((s) => s - 1);
  const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
  return padExtraShape.map((_, i) => {
    return [padExtraStart[i], padExtraEnd[i]];
  });
}
var pool2 = op2({ pool_: pool_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/pow.js
function pow_2(base3, exp6) {
  let $base = convertToTensor2(base3, "base", "pow");
  let $exp = convertToTensor2(exp6, "exp", "pow");
  [$base, $exp] = makeTypesMatch2($base, $exp);
  const inputs = { a: $base, b: $exp };
  return ENGINE2.runKernel(Pow2, inputs);
}
var pow2 = op2({ pow_: pow_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js
function prelu_2(x, alpha) {
  const $x = convertToTensor2(x, "x", "prelu");
  const $alpha = convertToTensor2(alpha, "alpha", "prelu");
  const inputs = { x: $x, alpha: $alpha };
  return ENGINE2.runKernel(Prelu2, inputs);
}
var prelu2 = op2({ prelu_: prelu_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/prod.js
function prod_2(x, axis = null, keepDims = false) {
  let $x = convertToTensor2(x, "x", "prod");
  if ($x.dtype === "bool") {
    $x = cast2($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE2.runKernel(Prod2, inputs, attrs);
}
var prod2 = op2({ prod_: prod_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/rand.js
function rand_2(shape, randFunction, dtype) {
  const size = sizeFromShape2(shape);
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  for (let i = 0; i < size; i++) {
    values[i] = randFunction();
  }
  return ENGINE2.makeTensor(values, shape, dtype);
}
var rand2 = op2({ rand_: rand_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js
var seedrandom2 = __toModule(require_seedrandom2());
var MPRandGauss2 = class {
  constructor(mean5, stdDeviation, dtype, truncated, seed) {
    this.mean = mean5;
    this.stdDev = stdDeviation;
    this.dtype = dtype;
    this.nextVal = NaN;
    this.truncated = truncated;
    if (this.truncated) {
      this.upper = this.mean + this.stdDev * 2;
      this.lower = this.mean - this.stdDev * 2;
    }
    const seedValue = seed ? seed : Math.random();
    this.random = seedrandom2.alea(seedValue.toString());
  }
  nextValue() {
    if (!isNaN(this.nextVal)) {
      const value = this.nextVal;
      this.nextVal = NaN;
      return value;
    }
    let resultX, resultY;
    let isValid = false;
    while (!isValid) {
      let v1, v2, s;
      do {
        v1 = 2 * this.random() - 1;
        v2 = 2 * this.random() - 1;
        s = v1 * v1 + v2 * v2;
      } while (s >= 1 || s === 0);
      const mul3 = Math.sqrt(-2 * Math.log(s) / s);
      resultX = this.mean + this.stdDev * v1 * mul3;
      resultY = this.mean + this.stdDev * v2 * mul3;
      if (!this.truncated || this.isValidTruncated(resultX)) {
        isValid = true;
      }
    }
    if (!this.truncated || this.isValidTruncated(resultY)) {
      this.nextVal = this.convertValue(resultY);
    }
    return this.convertValue(resultX);
  }
  convertValue(value) {
    if (this.dtype == null || this.dtype === "float32") {
      return value;
    }
    return Math.round(value);
  }
  isValidTruncated(value) {
    return value <= this.upper && value >= this.lower;
  }
};
var RandGamma2 = class {
  constructor(alpha, beta, dtype, seed) {
    this.alpha = alpha;
    this.beta = 1 / beta;
    this.dtype = dtype;
    const seedValue = seed ? seed : Math.random();
    this.randu = seedrandom2.alea(seedValue.toString());
    this.randn = new MPRandGauss2(0, 1, dtype, false, this.randu());
    if (alpha < 1) {
      this.d = alpha + 2 / 3;
    } else {
      this.d = alpha - 1 / 3;
    }
    this.c = 1 / Math.sqrt(9 * this.d);
  }
  nextValue() {
    let x2, v0, v1, x, u, v;
    while (true) {
      do {
        x = this.randn.nextValue();
        v = 1 + this.c * x;
      } while (v <= 0);
      v *= v * v;
      x2 = x * x;
      v0 = 1 - 0.331 * x2 * x2;
      v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
      u = this.randu();
      if (u < v0 || Math.log(u) < v1) {
        break;
      }
    }
    v = 1 / this.beta * this.d * v;
    if (this.alpha < 1) {
      v *= Math.pow(this.randu(), 1 / this.alpha);
    }
    return this.convertValue(v);
  }
  convertValue(value) {
    if (this.dtype === "float32") {
      return value;
    }
    return Math.round(value);
  }
};
var UniformRandom2 = class {
  constructor(min7 = 0, max7 = 1, dtype, seed) {
    this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
    this.min = min7;
    this.range = max7 - min7;
    this.dtype = dtype;
    if (seed == null) {
      seed = Math.random();
    }
    if (typeof seed === "number") {
      seed = seed.toString();
    }
    if (!this.canReturnFloat() && this.range <= 1) {
      throw new Error(`The difference between ${min7} - ${max7} <= 1 and dtype is not float`);
    }
    this.random = seedrandom2.alea(seed);
  }
  convertValue(value) {
    if (this.canReturnFloat()) {
      return value;
    }
    return Math.round(value);
  }
  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/random_gamma.js
function randomGamma_2(shape, alpha, beta = 1, dtype = "float32", seed) {
  if (beta == null) {
    beta = 1;
  }
  if (dtype == null) {
    dtype = "float32";
  }
  if (dtype !== "float32" && dtype !== "int32") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const rgamma = new RandGamma2(alpha, beta, dtype, seed);
  const res = buffer2(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = rgamma.nextValue();
  }
  return res.toTensor();
}
var randomGamma2 = op2({ randomGamma_: randomGamma_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js
function randomNormal_2(shape, mean5 = 0, stdDev = 1, dtype, seed) {
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const randGauss = new MPRandGauss2(mean5, stdDev, dtype, false, seed);
  const res = buffer2(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var randomNormal2 = op2({ randomNormal_: randomNormal_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js
function randomUniform_2(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
  const res = buffer2(shape, dtype);
  const random = new UniformRandom2(minval, maxval, null, seed);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = random.nextValue();
  }
  return res.toTensor();
}
var randomUniform2 = op2({ randomUniform_: randomUniform_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/range.js
function range2(start, stop, step6 = 1, dtype = "float32") {
  if (step6 === 0) {
    throw new Error("Cannot have a step of zero");
  }
  const attrs = { start, stop, step: step6, dtype };
  return ENGINE2.runKernel(Range2, {}, attrs);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/real.js
function real_2(input2) {
  const $input = convertToTensor2(input2, "input", "real");
  const inputs = { input: $input };
  return ENGINE2.runKernel(Real2, inputs);
}
var real2 = op2({ real_: real_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js
function reciprocal_2(x) {
  const $x = convertToTensor2(x, "x", "reciprocal");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Reciprocal2, inputs);
}
var reciprocal2 = op2({ reciprocal_: reciprocal_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/relu.js
function relu_2(x) {
  const $x = convertToTensor2(x, "x", "relu");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Relu2, inputs);
}
var relu2 = op2({ relu_: relu_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js
function relu6_2(x) {
  const $x = convertToTensor2(x, "x", "relu6");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Relu62, inputs);
}
var relu62 = op2({ relu6_: relu6_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js
function reverse_2(x, axis) {
  const $x = convertToTensor2(x, "x", "reverse");
  const inputs = { x: $x };
  const attrs = { dims: axis };
  return ENGINE2.runKernel(Reverse2, inputs, attrs);
}
var reverse2 = op2({ reverse_: reverse_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reverse_1d.js
function reverse1d_2(x) {
  const $x = convertToTensor2(x, "x", "reverse");
  assert2($x.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`);
  return reverse2($x, 0);
}
var reverse1d2 = op2({ reverse1d_: reverse1d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reverse_2d.js
function reverse2d_2(x, axis) {
  const $x = convertToTensor2(x, "x", "reverse");
  assert2($x.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`);
  return reverse2($x, axis);
}
var reverse2d2 = op2({ reverse2d_: reverse2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reverse_3d.js
function reverse3d_2(x, axis) {
  const $x = convertToTensor2(x, "x", "reverse");
  assert2($x.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`);
  return reverse2($x, axis);
}
var reverse3d2 = op2({ reverse3d_: reverse3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reverse_4d.js
function reverse4d_2(x, axis) {
  const $x = convertToTensor2(x, "x", "reverse");
  assert2($x.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`);
  return reverse2($x, axis);
}
var reverse4d2 = op2({ reverse4d_: reverse4d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/round.js
function round_2(x) {
  const $x = convertToTensor2(x, "x", "round");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Round2, inputs);
}
var round4 = op2({ round_: round_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js
function rsqrt_2(x) {
  const $x = convertToTensor2(x, "x", "rsqrt");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Rsqrt2, inputs);
}
var rsqrt2 = op2({ rsqrt_: rsqrt_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js
function scalar2(value, dtype) {
  if ((isTypedArray2(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  }
  if (dtype === "string" && isTypedArray2(value) && !(value instanceof Uint8Array)) {
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  }
  const shape = [];
  const inferredShape = [];
  return makeTensor2(value, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/selu.js
function selu_2(x) {
  const $x = convertToTensor2(x, "x", "selu");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Selu2, inputs);
}
var selu2 = op2({ selu_: selu_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js
function separableConv2d_2(x, depthwiseFilter, pointwiseFilter, strides, pad4, dilation = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor2(x, "x", "separableConv2d");
  const $depthwiseFilter = convertToTensor2(depthwiseFilter, "depthwiseFilter", "separableConv2d");
  const $pointwiseFilter = convertToTensor2(pointwiseFilter, "pointwiseFilter", "separableConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  if (dataFormat === "NCHW") {
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  }
  assert2(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert2($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert2($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert2($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
  assert2($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
  const inChannels = $depthwiseFilter.shape[2];
  const channelMultiplier = $depthwiseFilter.shape[3];
  assert2($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
  const depthwise = depthwiseConv2d3(x4D, $depthwiseFilter, strides, pad4, dataFormat, dilation);
  const pointwiseStride = 1;
  const res = conv2d3(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var separableConv2d2 = op2({ separableConv2d_: separableConv2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js
async function setdiff1dAsync_2(x, y) {
  const $x = convertToTensor2(x, "x", "setdiff1d");
  const $y = convertToTensor2(y, "y", "setdiff1d");
  assert2($x.dtype === $y.dtype, () => `x and y should have the same dtype, but got x (${$x.dtype}) and y (${$y.dtype}).`);
  assert2($x.rank === 1, () => `x should be 1D tensor, but got x (${$x.shape}).`);
  assert2($y.rank === 1, () => `y should be 1D tensor, but got y (${$y.shape}).`);
  const xVals = await $x.data();
  const yVals = await $y.data();
  const ySet = new Set(yVals);
  let outputSize = 0;
  for (let i = 0; i < xVals.length; i++) {
    if (!ySet.has(xVals[i])) {
      outputSize++;
    }
  }
  const buffer3 = new TensorBuffer2([outputSize], $x.dtype);
  const indices = new TensorBuffer2([outputSize], "int32");
  for (let i = 0, p2 = 0; i < xVals.length; i++) {
    if (!ySet.has(xVals[i])) {
      buffer3.values[p2] = xVals[i];
      indices.values[p2] = i;
      p2++;
    }
  }
  return [buffer3.toTensor(), indices.toTensor()];
}
var setdiff1dAsync2 = setdiff1dAsync_2;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sign.js
function sign_2(x) {
  const $x = convertToTensor2(x, "x", "sign");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Sign2, inputs);
}
var sign2 = op2({ sign_: sign_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sin.js
function sin_2(x) {
  const $x = convertToTensor2(x, "x", "sin");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Sin2, inputs);
}
var sin2 = op2({ sin_: sin_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js
function sinh_2(x) {
  const $x = convertToTensor2(x, "x", "sinh");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Sinh2, inputs);
}
var sinh2 = op2({ sinh_: sinh_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js
function slice1d_2(x, begin, size) {
  const $x = convertToTensor2(x, "x", "slice1d");
  assert2($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
  return slice2($x, [begin], [size]);
}
var slice1d2 = op2({ slice1d_: slice1d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js
function slice2d_2(x, begin, size) {
  const $x = convertToTensor2(x, "x", "slice2d");
  assert2($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
  return slice2($x, begin, size);
}
var slice2d2 = op2({ slice2d_: slice2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js
function slice3d_2(x, begin, size) {
  const $x = convertToTensor2(x, "x", "slice3d");
  assert2($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
  return slice2($x, begin, size);
}
var slice3d2 = op2({ slice3d_: slice3d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js
function slice4d_2(x, begin, size) {
  const $x = convertToTensor2(x, "x", "slice4d");
  assert2($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
  return slice2($x, begin, size);
}
var slice4d2 = op2({ slice4d_: slice4d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js
function softmax_2(logits, dim = -1) {
  const $logits = convertToTensor2(logits, "logits", "softmax", "float32");
  if (dim === -1) {
    dim = $logits.rank - 1;
  }
  if (dim !== $logits.rank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
  }
  const inputs = { logits: $logits };
  const attrs = { dim };
  return ENGINE2.runKernel(Softmax2, inputs, attrs);
}
var softmax2 = op2({ softmax_: softmax_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js
function fft_2(input2) {
  assert2(input2.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE2.runKernel(FFT2, inputs);
}
var fft2 = op2({ fft_: fft_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js
function ifft_2(input2) {
  assert2(input2.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE2.runKernel(IFFT2, inputs);
}
var ifft2 = op2({ ifft_: ifft_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js
function irfft_2(input2) {
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let ret;
  if (innerDimensionSize <= 2) {
    const complexInput = reshape2(input2, [batch, innerDimensionSize]);
    ret = ifft2(complexInput);
  } else {
    const outputShape = [batch, 2 * (innerDimensionSize - 1)];
    const realInput = reshape2(real2(input2), [batch, innerDimensionSize]);
    const imagInput = reshape2(imag2(input2), [batch, innerDimensionSize]);
    const realConjugate = reverse2(slice2(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
    const imagConjugate = mul2(reverse2(slice2(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar2(-1));
    const r = concat2([realInput, realConjugate], 1);
    const i = concat2([imagInput, imagConjugate], 1);
    const complexInput = reshape2(complex2(r, i), [outputShape[0], outputShape[1]]);
    ret = ifft2(complexInput);
  }
  ret = real2(ret);
  if (input2.rank === 3 && input2.shape[0] !== 0) {
    const temp = ret;
    const batch2 = input2.shape[0];
    ret = reshape2(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
    temp.dispose();
  }
  return ret;
}
var irfft2 = op2({ irfft_: irfft_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/split.js
function split_2(x, numOrSizeSplits, axis = 0) {
  const $x = convertToTensor2(x, "x", "split");
  const inputs = { x: $x };
  const attr = { numOrSizeSplits, axis };
  return ENGINE2.runKernel(SplitV2, inputs, attr);
}
var split2 = op2({ split_: split_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js
function rfft_2(input2, fftLength) {
  assert2(input2.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input2.dtype}`);
  let innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let adjustedInput;
  if (fftLength != null && fftLength < innerDimensionSize) {
    const begin = input2.shape.map((v) => 0);
    const size = input2.shape.map((v) => v);
    size[input2.shape.length - 1] = fftLength;
    adjustedInput = slice2(input2, begin, size);
    innerDimensionSize = fftLength;
  } else if (fftLength != null && fftLength > innerDimensionSize) {
    const zerosShape = input2.shape.map((v) => v);
    zerosShape[input2.shape.length - 1] = fftLength - innerDimensionSize;
    adjustedInput = concat2([input2, zeros2(zerosShape)], input2.shape.length - 1);
    innerDimensionSize = fftLength;
  } else {
    adjustedInput = input2;
  }
  const zerosInput = zerosLike2(adjustedInput);
  const complexInput = reshape2(complex2(adjustedInput, zerosInput), [batch, innerDimensionSize]);
  const ret = fft2(complexInput);
  const half = Math.floor(innerDimensionSize / 2) + 1;
  const realValues = real2(ret);
  const imagValues = imag2(ret);
  const realComplexConjugate = split2(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
  const imagComplexConjugate = split2(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
  const outputShape = adjustedInput.shape.slice();
  outputShape[adjustedInput.shape.length - 1] = half;
  return reshape2(complex2(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
}
var rfft2 = op2({ rfft_: rfft_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js
function sqrt_2(x) {
  const $x = convertToTensor2(x, "x", "sqrt");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Sqrt2, inputs);
}
var sqrt2 = op2({ sqrt_: sqrt_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js
function squaredDifference_2(a, b) {
  let $a = convertToTensor2(a, "a", "squaredDifference");
  let $b = convertToTensor2(b, "b", "squaredDifference");
  [$a, $b] = makeTypesMatch2($a, $b);
  assertAndGetBroadcastShape2($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE2.runKernel(SquaredDifference2, inputs, attrs);
}
var squaredDifference2 = op2({ squaredDifference_: squaredDifference_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js
function squeeze_2(x, axis) {
  const $x = convertToTensor2(x, "x", "squeeze");
  return reshape2($x, squeezeShape2($x.shape, axis).newShape);
}
var squeeze2 = op2({ squeeze_: squeeze_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/stack.js
function stack_2(tensors, axis = 0) {
  const $tensors = convertToTensorArray2(tensors, "tensors", "stack", "string_or_numeric");
  assert2($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
  if ($tensors.length > 0) {
    assert2(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
  }
  const inputs = $tensors;
  const attrs = { axis };
  return ENGINE2.runKernel(Pack2, inputs, attrs);
}
var stack2 = op2({ stack_: stack_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/step.js
function step_2(x, alpha = 0) {
  const $x = convertToTensor2(x, "x", "step");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE2.runKernel(Step2, inputs, attrs);
}
var step2 = op2({ step_: step_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js
function stridedSlice_2(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
  const $x = convertToTensor2(x, "x", "stridedSlice", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  return ENGINE2.runKernel(StridedSlice2, inputs, attrs);
}
var stridedSlice2 = op2({ stridedSlice_: stridedSlice_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tan.js
function tan_2(x) {
  const $x = convertToTensor2(x, "x", "tan");
  const inputs = { x: $x };
  return ENGINE2.runKernel(Tan2, inputs);
}
var tan2 = op2({ tan_: tan_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js
function tensor1d2(values, dtype) {
  assertNonNull2(values);
  const inferredShape = inferShape2(values, dtype);
  if (inferredShape.length !== 1) {
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  }
  const shape = null;
  return makeTensor2(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js
function tensor2d2(values, shape, dtype) {
  assertNonNull2(values);
  if (shape != null && shape.length !== 2) {
    throw new Error("tensor2d() requires shape to have two numbers");
  }
  const inferredShape = inferShape2(values, dtype);
  if (inferredShape.length !== 2 && inferredShape.length !== 1) {
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  }
  return makeTensor2(values, shape, inferredShape, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/topk.js
function topk_2(x, k = 1, sorted = true) {
  const $x = convertToTensor2(x, "x", "topk");
  if ($x.rank === 0) {
    throw new Error("topk() expects the input to be of rank 1 or higher");
  }
  const lastDim = $x.shape[$x.shape.length - 1];
  if (k > lastDim) {
    throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k}`);
  }
  const inputs = { x: $x };
  const attrs = { k, sorted };
  const [values, indices] = ENGINE2.runKernel(TopK2, inputs, attrs);
  return { values, indices };
}
var topk2 = op2({ topk_: topk_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js
function truncatedNormal_2(shape, mean5 = 0, stdDev = 1, dtype, seed) {
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type $ { dtype }`);
  }
  const randGauss = new MPRandGauss2(mean5, stdDev, dtype, true, seed);
  const res = buffer2(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var truncatedNormal2 = op2({ truncatedNormal_: truncatedNormal_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/unique.js
function unique_2(x, axis = 0) {
  const $x = convertToTensor2(x, "x", "unique", "string_or_numeric");
  assert2($x.rank > 0, () => "The input tensor must be at least 1D");
  const inputs = { x: $x };
  const attrs = { axis };
  const [values, indices] = ENGINE2.runKernel(Unique2, inputs, attrs);
  return { values, indices };
}
var unique2 = op2({ unique_: unique_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js
function unsortedSegmentSum_2(x, segmentIds, numSegments) {
  const $x = convertToTensor2(x, "x", "unsortedSegmentSum");
  const $segmentIds = convertToTensor2(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
  assert2(isInt2(numSegments), () => "numSegments must be of dtype int");
  const inputs = { x: $x, segmentIds: $segmentIds };
  const attrs = { numSegments };
  return ENGINE2.runKernel(UnsortedSegmentSum2, inputs, attrs);
}
var unsortedSegmentSum2 = op2({ unsortedSegmentSum_: unsortedSegmentSum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js
function unstack_2(x, axis = 0) {
  const $x = convertToTensor2(x, "x", "unstack", "string_or_numeric");
  assert2(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
  const inputs = { value: $x };
  const attrs = { axis };
  return ENGINE2.runKernel(Unpack2, inputs, attrs);
}
var unstack2 = op2({ unstack_: unstack_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/variable.js
function variable2(initialValue, trainable = true, name, dtype) {
  return ENGINE2.makeVariable(initialValue, trainable, name, dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js
function whereImpl2(condShape, condVals) {
  const indices = [];
  for (let i = 0; i < condVals.length; i++) {
    if (condVals[i]) {
      indices.push(i);
    }
  }
  const inBuffer = buffer2(condShape, "int32");
  const out = buffer2([indices.length, condShape.length], "int32");
  for (let i = 0; i < indices.length; i++) {
    const loc = inBuffer.indexToLoc(indices[i]);
    const offset = i * condShape.length;
    out.values.set(loc, offset);
  }
  return out.toTensor();
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/where_async.js
async function whereAsync_2(condition) {
  const $condition = convertToTensor2(condition, "condition", "whereAsync", "bool");
  const vals = await $condition.data();
  const res = whereImpl2($condition.shape, vals);
  if (condition !== $condition) {
    $condition.dispose();
  }
  return res;
}
var whereAsync2 = whereAsync_2;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/norm.js
function norm_2(x, ord = "euclidean", axis = null, keepDims = false) {
  x = convertToTensor2(x, "x", "norm");
  const norm3 = normImpl2(x, ord, axis);
  let keepDimsShape = norm3.shape;
  if (keepDims) {
    const axes = parseAxisParam2(axis, x.shape);
    keepDimsShape = expandShapeToKeepDim2(norm3.shape, axes);
  }
  return reshape2(norm3, keepDimsShape);
}
function normImpl2(x, p2, axis = null) {
  if (x.rank === 0) {
    return abs2(x);
  }
  if (x.rank !== 1 && axis === null) {
    return normImpl2(reshape2(x, [-1]), p2, axis);
  }
  if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
    if (p2 === 1) {
      return sum4(abs2(x), axis);
    }
    if (p2 === Infinity) {
      return max2(abs2(x), axis);
    }
    if (p2 === -Infinity) {
      return min2(abs2(x), axis);
    }
    if (p2 === "euclidean" || p2 === 2) {
      return sqrt2(sum4(pow2(abs2(x), scalar2(2, "int32")), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  if (Array.isArray(axis) && axis.length === 2) {
    if (p2 === 1) {
      return max2(sum4(abs2(x), axis[0]), axis[1] - 1);
    }
    if (p2 === Infinity) {
      return max2(sum4(abs2(x), axis[1]), axis[0]);
    }
    if (p2 === -Infinity) {
      return min2(sum4(abs2(x), axis[1]), axis[0]);
    }
    if (p2 === "fro" || p2 === "euclidean") {
      return sqrt2(sum4(square2(x), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  throw new Error(`Error in norm: invalid axis: ${axis}`);
}
var norm2 = op2({ norm_: norm_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js
function movingAverage_2(v, x, decay, step6, zeroDebias = true) {
  const $v = convertToTensor2(v, "v", "movingAverage");
  const $x = convertToTensor2(x, "x", "movingAverage");
  const $decay = convertToTensor2(decay, "decay", "movingAverage");
  assertTypesMatch2($v, $x);
  assert2(arraysEqual2($v.shape, $x.shape), () => "Shape mismatch in v and x");
  const one = scalar2(1);
  const oneMinusDecay = sub2(one, $decay);
  let update = mul2(sub2($x, $v), oneMinusDecay);
  if (zeroDebias) {
    assert2(step6 != null, () => "When using zeroDebias: true, step is required.");
    const $step = convertToTensor2(step6, "step", "movingAverage");
    update = div2(update, sub2(one, pow2($decay, $step)));
  }
  return add4($v, update);
}
var movingAverage2 = op2({ movingAverage_: movingAverage_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js
function scatterND_2(indices, updates, shape) {
  const $indices = convertToTensor2(indices, "indices", "scatterND", "int32");
  const $updates = convertToTensor2(updates, "updates", "scatterND");
  validateInput3($updates, $indices, shape);
  const inputs = { indices: $indices, updates: $updates };
  const attrs = { shape };
  return ENGINE2.runKernel(ScatterNd2, inputs, attrs);
}
var scatterND2 = op2({ scatterND_: scatterND_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js
function validateInput4(sparseIndices, sparseValues, outputShape, defaultValues) {
  if (sparseIndices.dtype !== "int32") {
    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${sparseIndices.dtype}.`);
  }
  if (sparseIndices.rank > 2) {
    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${sparseIndices.shape}.`);
  }
  const numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
  const numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
  if (outputShape.length !== numDims) {
    throw new Error(`outputShape has incorrect number of elements:, ${outputShape.length}, should be: ${numDims}.`);
  }
  const numValues = sparseValues.size;
  if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
    throw new Error(`sparseValues has incorrect shape ${sparseValues.shape}, should be [] or [${numElems}]`);
  }
  if (sparseValues.dtype !== defaultValues.dtype) {
    throw new Error("sparseValues.dtype must match defaultValues.dtype");
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js
function sparseToDense_2(sparseIndices, sparseValues, outputShape, defaultValue = 0) {
  const $sparseIndices = convertToTensor2(sparseIndices, "sparseIndices", "sparseToDense", "int32");
  const $sparseValues = convertToTensor2(sparseValues, "sparseValues", "sparseToDense");
  const $defaultValue = convertToTensor2(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
  validateInput4($sparseIndices, $sparseValues, outputShape, $defaultValue);
  const inputs = {
    sparseIndices: $sparseIndices,
    sparseValues: $sparseValues,
    defaultValue: $defaultValue
  };
  const attrs = { outputShape };
  return ENGINE2.runKernel(SparseToDense2, inputs, attrs);
}
var sparseToDense2 = op2({ sparseToDense_: sparseToDense_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js
function gatherND_2(x, indices) {
  const $indices = convertToTensor2(indices, "indices", "gatherND", "int32");
  const $x = convertToTensor2(x, "x", "gatherND", "string_or_numeric");
  const inputs = { params: $x, indices: $indices };
  return ENGINE2.runKernel(GatherNd2, inputs);
}
var gatherND2 = op2({ gatherND_: gatherND_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js
function getNoiseShape2(x, noiseShape) {
  if (noiseShape == null) {
    return x.shape.slice();
  }
  if (arraysEqual2(x.shape, noiseShape)) {
    return noiseShape;
  }
  if (x.shape.length === noiseShape.length) {
    const newDimension = [];
    for (let i = 0; i < x.shape.length; i++) {
      if (noiseShape[i] == null && x.shape[i] != null) {
        newDimension.push(x.shape[i]);
      } else {
        newDimension.push(noiseShape[i]);
      }
    }
    return newDimension;
  }
  return noiseShape;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js
function dropout_2(x, rate, noiseShape, seed) {
  const $x = convertToTensor2(x, "x", "dropout");
  assert2($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
  assert2(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
  if (rate === 0) {
    return x instanceof Tensor4 ? $x.clone() : $x;
  }
  const $noiseShape = getNoiseShape2($x, noiseShape);
  const keepProb = 1 - rate;
  const multiplier = div2(floor2(add4(randomUniform2($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
  return mul2($x, multiplier);
}
var dropout2 = op2({ dropout_: dropout_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js
function enclosingPowerOfTwo2(value) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
}
function cosineWindow2(windowLength, a, b) {
  const even = 1 - windowLength % 2;
  const newValues = new Float32Array(windowLength);
  for (let i = 0; i < windowLength; ++i) {
    const cosArg = 2 * Math.PI * i / (windowLength + even - 1);
    newValues[i] = a - b * Math.cos(cosArg);
  }
  return tensor1d2(newValues, "float32");
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js
var fused_ops_exports2 = {};
__export(fused_ops_exports2, {
  conv2d: () => conv2d4,
  depthwiseConv2d: () => depthwiseConv2d4,
  matMul: () => matMul4
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js
function conv2DBackpropFilter_2(x, dy, filterShape, strides, pad4, dataFormat = "NHWC", dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape2(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
  assert2(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
  assert2(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert2(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
  assert2(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad4, dataFormat, dimRoundingMode, filterShape };
  return ENGINE2.runKernel(Conv2DBackpropFilter2, inputs, attrs);
}
var conv2DBackpropFilter2 = op2({ conv2DBackpropFilter_: conv2DBackpropFilter_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js
function getFusedDyActivation2(dy, y, activation2) {
  if (activation2 == null || activation2 === "linear") {
    return dy;
  }
  if (activation2 === "relu") {
    return mul2(dy, step2(y));
  }
  throw new Error(`Cannot compute gradient for fused activation ${activation2}.`);
}
function getFusedBiasGradient2(bias, dyActivation) {
  let res = dyActivation;
  const reduceAxes = getReductionAxes2(bias.shape, dyActivation.shape);
  if (reduceAxes.length > 0) {
    res = sum4(res, reduceAxes);
  }
  return reshape2(res, bias.shape);
}
function applyActivation2(x, activation2, preluActivationWeights, leakyreluAlpha) {
  if (activation2 === "linear") {
    return x;
  } else if (activation2 === "relu") {
    return relu2(x);
  } else if (activation2 === "elu") {
    return elu2(x);
  } else if (activation2 === "relu6") {
    return relu62(x);
  } else if (activation2 === "prelu") {
    return prelu2(x, preluActivationWeights);
  } else if (activation2 === "leakyrelu") {
    return leakyRelu2(x, leakyreluAlpha);
  } else if (activation2 === "sigmoid") {
    return sigmoid2(x);
  }
  throw new Error(`Unknown fused activation ${activation2}.`);
}
var shouldFuse2 = (gradientDepth, activation2) => {
  const gradientMode = gradientDepth > 0;
  return !gradientMode || activation2 === "linear";
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js
function fusedConv2d_2({ x, filter, strides, pad: pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation: activation2 = "linear", preluActivationWeights, leakyreluAlpha }) {
  activation2 = activation2 || "linear";
  if (shouldFuse2(ENGINE2.state.gradientDepth, activation2) === false) {
    let result = conv2d3(x, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add4(result, bias);
    }
    return applyActivation2(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor2(x, "x", "conv2d");
  const $filter = convertToTensor2(filter, "filter", "conv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert2($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  assert2(x4D.shape[3] === $filter.shape[2], () => `Error in conv2d: depth of input (${x4D.shape[3]}) must match input depth for filter ${$filter.shape[2]}.`);
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert2(dataFormat === "NHWC", () => `Error in conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
  const convInfo = computeConv2DInfo2(x4D.shape, $filter.shape, strides, dilations, pad4, dimRoundingMode);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor2(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch2($bias, $x);
    assertAndGetBroadcastShape2(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor2(preluActivationWeights, "prelu weights", "fused conv2d");
  }
  const grad3 = (dy, saved) => {
    const [$filter2, x4D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation2(dy, y, activation2);
    assert2(tupleValuesAreOne2(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    const xDer = conv2DBackpropInput2(x4D2.shape, dyActivation, $filter2, strides, pad4);
    const filterDer = conv2DBackpropFilter2(x4D2, dyActivation, $filter2.shape, strides, pad4);
    const der = [xDer, filterDer];
    if ($bias2 != null) {
      const biasDer = getFusedBiasGradient2($bias2, dyActivation);
      der.push(biasDer);
    }
    return der;
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad2((x4D2, filter2, save) => {
      let res = ENGINE2.runKernel(FusedConv2D2, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad2((x4D2, filter2, bias2, save) => {
      let res = ENGINE2.runKernel(FusedConv2D2, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var conv2d4 = op2({ fusedConv2d_: fusedConv2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js
function depthwiseConv2dNativeBackpropFilter_2(x, dy, filterShape, strides, pad4, dilations = [1, 1], dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape2(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad4, dimRoundingMode, dilations, filterShape };
  return ENGINE2.runKernel(DepthwiseConv2dNativeBackpropFilter2, inputs, attrs);
}
var depthwiseConv2dNativeBackpropFilter2 = op2({ depthwiseConv2dNativeBackpropFilter_: depthwiseConv2dNativeBackpropFilter_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js
function depthwiseConv2dNativeBackpropInput_2(xShape, dy, filter, strides, pad4, dilations = [1, 1], dimRoundingMode) {
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad4, dimRoundingMode, dilations, inputShape: xShape };
  const res = ENGINE2.runKernel(DepthwiseConv2dNativeBackpropInput2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2dNativeBackpropInput2 = op2({ depthwiseConv2dNativeBackpropInput_: depthwiseConv2dNativeBackpropInput_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js
function fusedDepthwiseConv2d_2({ x, filter, strides, pad: pad4, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation: activation2 = "linear", preluActivationWeights, leakyreluAlpha }) {
  if (shouldFuse2(ENGINE2.state.gradientDepth, activation2) === false) {
    let result = depthwiseConv2d3(x, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add4(result, bias);
    }
    return applyActivation2(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor2(x, "x", "depthwiseConv2d");
  const $filter = convertToTensor2(filter, "filter", "depthwiseConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape2($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert2(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert2($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert2(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dilations == null) {
    dilations = [1, 1];
  }
  assert2(eitherStridesOrDilationsAreOne2(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const convInfo = computeConv2DInfo2(x4D.shape, $filter.shape, strides, dilations, pad4, dimRoundingMode, true);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor2(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch2($bias, $x);
    assertAndGetBroadcastShape2(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor2(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
  }
  const grad3 = (dy, saved) => {
    assert2(tupleValuesAreOne2(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
    const [$filter2, x4D2, y, bias2] = saved;
    const dyActivation = getFusedDyActivation2(dy, y, activation2);
    const xDer = depthwiseConv2dNativeBackpropInput2(x4D2.shape, dyActivation, $filter2, strides, pad4, dilations, dimRoundingMode);
    const filterDer = depthwiseConv2dNativeBackpropFilter2(x4D2, dyActivation, $filter2.shape, strides, pad4, dilations, dimRoundingMode);
    if (bias2 != null) {
      const biasDer = getFusedBiasGradient2($bias, dyActivation);
      return [xDer, filterDer, biasDer];
    }
    return [xDer, filterDer];
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad2((x4D2, filter2, save) => {
      let res = ENGINE2.runKernel(FusedDepthwiseConv2D2, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad2((x4D2, filter2, bias2, save) => {
      let res = ENGINE2.runKernel(FusedDepthwiseConv2D2, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad3 };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var depthwiseConv2d4 = op2({ fusedDepthwiseConv2d_: fusedDepthwiseConv2d_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js
function fusedMatMul_2({ a, b, transposeA = false, transposeB = false, bias, activation: activation2 = "linear", preluActivationWeights, leakyreluAlpha }) {
  if (shouldFuse2(ENGINE2.state.gradientDepth, activation2) === false) {
    let result = matMul3(a, b, transposeA, transposeB);
    if (bias != null) {
      result = add4(result, bias);
    }
    return applyActivation2(result, activation2, preluActivationWeights, leakyreluAlpha);
  }
  let $a = convertToTensor2(a, "a", "fused matMul");
  let $b = convertToTensor2(b, "b", "fused matMul");
  [$a, $b] = makeTypesMatch2($a, $b);
  const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
  const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
  const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
  const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
  const outerDimsA = $a.shape.slice(0, -2);
  const outerDimsB = $b.shape.slice(0, -2);
  const batchDimA = sizeFromShape2(outerDimsA);
  const batchDimB = sizeFromShape2(outerDimsB);
  assert2($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, () => `Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${$a.rank} and ${$b.rank}.`);
  assert2(arraysEqual2(outerDimsA, outerDimsB), () => `Error in fused matMul: outer dimensions (${outerDimsA}) and (${outerDimsB}) of Tensors with shapes ${$a.shape} and ${$b.shape} must match.`);
  assert2(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);
  const a3D = transposeA ? reshape2($a, [batchDimA, innerShapeA, outerShapeA]) : reshape2($a, [batchDimA, outerShapeA, innerShapeA]);
  const b3D = transposeB ? reshape2($b, [batchDimB, outerShapeB, innerShapeB]) : reshape2($b, [batchDimB, innerShapeB, outerShapeB]);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor2(bias, "bias", "fused matMul");
    [$bias] = makeTypesMatch2($bias, $a);
    assertAndGetBroadcastShape2(outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor2(preluActivationWeights, "prelu weights", "fused matMul");
  }
  const grad3 = (dy, saved) => {
    const [a3D2, b3D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation2(reshape2(dy, y.shape), y, activation2);
    let aDer;
    let bDer;
    if (!transposeA && !transposeB) {
      aDer = matMul3(dyActivation, b3D2, false, true);
      bDer = matMul3(a3D2, dyActivation, true, false);
    } else if (!transposeA && transposeB) {
      aDer = matMul3(dyActivation, b3D2, false, false);
      bDer = matMul3(dyActivation, a3D2, true, false);
    } else if (transposeA && !transposeB) {
      aDer = matMul3(b3D2, dyActivation, false, true);
      bDer = matMul3(a3D2, dyActivation, false, false);
    } else {
      aDer = matMul3(b3D2, dyActivation, true, true);
      bDer = matMul3(dyActivation, a3D2, true, true);
    }
    if (bias != null) {
      const biasDer = getFusedBiasGradient2($bias2, dyActivation);
      return [aDer, bDer, biasDer];
    } else {
      return [aDer, bDer];
    }
  };
  const inputs = {
    a: a3D,
    b: b3D,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = { transposeA, transposeB, activation: activation2, leakyreluAlpha };
  if (bias == null) {
    const customOp = customGrad2((a3D2, b3D2, save) => {
      const res = ENGINE2.runKernel(_FusedMatMul2, inputs, attrs);
      save([a3D2, b3D2, res]);
      return { value: reshape2(res, outShape), gradFunc: grad3 };
    });
    return customOp(a3D, b3D);
  } else {
    const customOpWithBias = customGrad2((a3D2, b3D2, $bias2, save) => {
      const res = ENGINE2.runKernel(_FusedMatMul2, inputs, attrs);
      save([a3D2, b3D2, res, $bias2]);
      return { value: reshape2(res, outShape), gradFunc: grad3 };
    });
    return customOpWithBias(a3D, b3D, $bias);
  }
}
var matMul4 = op2({ fusedMatMul_: fusedMatMul_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js
function hammingWindow_2(windowLength) {
  return cosineWindow2(windowLength, 0.54, 0.46);
}
var hammingWindow2 = op2({ hammingWindow_: hammingWindow_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js
function hannWindow_2(windowLength) {
  return cosineWindow2(windowLength, 0.5, 0.5);
}
var hannWindow2 = op2({ hannWindow_: hannWindow_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js
function frame_2(signal2, frameLength, frameStep, padEnd = false, padValue = 0) {
  let start = 0;
  const output = [];
  while (start + frameLength <= signal2.size) {
    output.push(slice2(signal2, start, frameLength));
    start += frameStep;
  }
  if (padEnd) {
    while (start < signal2.size) {
      const padLen = start + frameLength - signal2.size;
      const pad4 = concat2([
        slice2(signal2, start, frameLength - padLen),
        fill2([padLen], padValue)
      ]);
      output.push(pad4);
      start += frameStep;
    }
  }
  if (output.length === 0) {
    return tensor2d2([], [0, frameLength]);
  }
  return reshape2(concat2(output), [output.length, frameLength]);
}
var frame2 = op2({ frame_: frame_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js
function stft_2(signal2, frameLength, frameStep, fftLength, windowFn = hannWindow2) {
  if (fftLength == null) {
    fftLength = enclosingPowerOfTwo2(frameLength);
  }
  const framedSignal = frame2(signal2, frameLength, frameStep);
  const windowedSignal = mul2(framedSignal, windowFn(frameLength));
  return rfft2(windowedSignal, fftLength);
}
var stft2 = op2({ stft_: stft_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js
function cropAndResize_2(image4, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
  const $image = convertToTensor2(image4, "image", "cropAndResize");
  const $boxes = convertToTensor2(boxes, "boxes", "cropAndResize", "float32");
  const $boxInd = convertToTensor2(boxInd, "boxInd", "cropAndResize", "int32");
  const numBoxes = $boxes.shape[0];
  assert2($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
  assert2($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
  assert2($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
  assert2(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
  assert2(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
  assert2(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
  const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
  const attrs = { method, extrapolationValue, cropSize };
  const res = ENGINE2.runKernel(CropAndResize2, inputs, attrs);
  return res;
}
var cropAndResize2 = op2({ cropAndResize_: cropAndResize_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js
function flipLeftRight_2(image4) {
  const $image = convertToTensor2(image4, "image", "flipLeftRight", "float32");
  assert2($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const res = ENGINE2.runKernel(FlipLeftRight2, inputs, {});
  return res;
}
var flipLeftRight2 = op2({ flipLeftRight_: flipLeftRight_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js
function rotateWithOffset_2(image4, radians, fillValue = 0, center = 0.5) {
  const $image = convertToTensor2(image4, "image", "rotateWithOffset", "float32");
  assert2($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const attrs = { radians, fillValue, center };
  const res = ENGINE2.runKernel(RotateWithOffset2, inputs, attrs);
  return res;
}
var rotateWithOffset2 = op2({ rotateWithOffset_: rotateWithOffset_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js
function nonMaxSuppSanityCheck2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  if (iouThreshold == null) {
    iouThreshold = 0.5;
  }
  if (scoreThreshold == null) {
    scoreThreshold = Number.NEGATIVE_INFINITY;
  }
  if (softNmsSigma == null) {
    softNmsSigma = 0;
  }
  const numBoxes = boxes.shape[0];
  maxOutputSize = Math.min(maxOutputSize, numBoxes);
  assert2(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
  assert2(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
  assert2(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
  assert2(scores.rank === 1, () => "scores must be a 1D tensor");
  assert2(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
  assert2(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
  return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js
function nonMaxSuppression_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppression");
  const inputs = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold };
  return ENGINE2.runKernel(NonMaxSuppressionV32, { boxes: $boxes, scores: $scores }, attrs);
}
var nonMaxSuppression2 = op2({ nonMaxSuppression_: nonMaxSuppression_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js
function binaryInsert2(arr, element, comparator) {
  const index = binarySearch2(arr, element, comparator);
  const insertionPoint = index < 0 ? -(index + 1) : index;
  arr.splice(insertionPoint, 0, element);
}
function binarySearch2(arr, target, comparator) {
  return binarySearch_2(arr, target, comparator || defaultComparator2);
}
function defaultComparator2(a, b) {
  return a > b ? 1 : a < b ? -1 : 0;
}
function binarySearch_2(arr, target, comparator) {
  let left = 0;
  let right = arr.length;
  let middle = 0;
  let found = false;
  while (left < right) {
    middle = left + (right - left >>> 1);
    const compareResult = comparator(target, arr[middle]);
    if (compareResult > 0) {
      left = middle + 1;
    } else {
      right = middle;
      found = !compareResult;
    }
  }
  return found ? left : -left - 1;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js
function nonMaxSuppressionV3Impl2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
  return nonMaxSuppressionImpl_2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0);
}
function nonMaxSuppressionV4Impl2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
  return nonMaxSuppressionImpl_2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0, false, padToMaxOutputSize, true);
}
function nonMaxSuppressionV5Impl2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  return nonMaxSuppressionImpl_2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true);
}
function nonMaxSuppressionImpl_2(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
  const candidates = [];
  for (let i = 0; i < scores.length; i++) {
    if (scores[i] > scoreThreshold) {
      candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
    }
  }
  candidates.sort(ascendingComparator2);
  const scale2 = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
  const selectedIndices = [];
  const selectedScores = [];
  while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
    const candidate = candidates.pop();
    const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;
    if (originalScore < scoreThreshold) {
      break;
    }
    let ignoreCandidate = false;
    for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
      const iou = intersectionOverUnion2(boxes, boxIndex, selectedIndices[j]);
      if (iou >= iouThreshold) {
        ignoreCandidate = true;
        break;
      }
      candidate.score = candidate.score * suppressWeight2(iouThreshold, scale2, iou);
      if (candidate.score <= scoreThreshold) {
        break;
      }
    }
    candidate.suppressBeginIndex = selectedIndices.length;
    if (!ignoreCandidate) {
      if (candidate.score === originalScore) {
        selectedIndices.push(boxIndex);
        selectedScores.push(candidate.score);
      } else if (candidate.score > scoreThreshold) {
        binaryInsert2(candidates, candidate, ascendingComparator2);
      }
    }
  }
  const validOutputs = selectedIndices.length;
  const elemsToPad = maxOutputSize - validOutputs;
  if (padToMaxOutputSize && elemsToPad > 0) {
    selectedIndices.push(...new Array(elemsToPad).fill(0));
    selectedScores.push(...new Array(elemsToPad).fill(0));
  }
  const result = { selectedIndices };
  if (returnScoresTensor) {
    result["selectedScores"] = selectedScores;
  }
  if (returnValidOutputs) {
    result["validOutputs"] = validOutputs;
  }
  return result;
}
function intersectionOverUnion2(boxes, i, j) {
  const iCoord = boxes.subarray(i * 4, i * 4 + 4);
  const jCoord = boxes.subarray(j * 4, j * 4 + 4);
  const yminI = Math.min(iCoord[0], iCoord[2]);
  const xminI = Math.min(iCoord[1], iCoord[3]);
  const ymaxI = Math.max(iCoord[0], iCoord[2]);
  const xmaxI = Math.max(iCoord[1], iCoord[3]);
  const yminJ = Math.min(jCoord[0], jCoord[2]);
  const xminJ = Math.min(jCoord[1], jCoord[3]);
  const ymaxJ = Math.max(jCoord[0], jCoord[2]);
  const xmaxJ = Math.max(jCoord[1], jCoord[3]);
  const areaI = (ymaxI - yminI) * (xmaxI - xminI);
  const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
  if (areaI <= 0 || areaJ <= 0) {
    return 0;
  }
  const intersectionYmin = Math.max(yminI, yminJ);
  const intersectionXmin = Math.max(xminI, xminJ);
  const intersectionYmax = Math.min(ymaxI, ymaxJ);
  const intersectionXmax = Math.min(xmaxI, xmaxJ);
  const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
  return intersectionArea / (areaI + areaJ - intersectionArea);
}
function suppressWeight2(iouThreshold, scale2, iou) {
  const weight = Math.exp(scale2 * iou * iou);
  return iou <= iouThreshold ? weight : 0;
}
function ascendingComparator2(c1, c2) {
  return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js
async function nonMaxSuppressionAsync_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppressionAsync");
  const inputs = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices } = nonMaxSuppressionV3Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return tensor1d2(selectedIndices, "int32");
}
var nonMaxSuppressionAsync2 = nonMaxSuppressionAsync_2;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js
function nonMaxSuppressionWithScore_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
  const result = ENGINE2.runKernel(NonMaxSuppressionV52, inputs, attrs);
  return { selectedIndices: result[0], selectedScores: result[1] };
}
var nonMaxSuppressionWithScore2 = op2({ nonMaxSuppressionWithScore_: nonMaxSuppressionWithScore_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js
async function nonMaxSuppressionWithScoreAsync_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d2(selectedIndices, "int32"),
    selectedScores: tensor1d2(selectedScores)
  };
}
var nonMaxSuppressionWithScoreAsync2 = nonMaxSuppressionWithScoreAsync_2;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js
function nonMaxSuppressionPadded_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = {
    maxOutputSize: $maxOutputSize,
    iouThreshold: $iouThreshold,
    scoreThreshold: $scoreThreshold,
    padToMaxOutputSize
  };
  const result = ENGINE2.runKernel(NonMaxSuppressionV42, inputs, attrs);
  return { selectedIndices: result[0], validOutputs: result[1] };
}
var nonMaxSuppressionPadded2 = op2({ nonMaxSuppressionPadded_: nonMaxSuppressionPadded_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js
async function nonMaxSuppressionPaddedAsync_2(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor2(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor2(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck2($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null);
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const [boxesVals, scoresVals] = await Promise.all([$boxes.data(), $scores.data()]);
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl2(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d2(selectedIndices, "int32"),
    validOutputs: scalar2(validOutputs, "int32")
  };
}
var nonMaxSuppressionPaddedAsync2 = nonMaxSuppressionPaddedAsync_2;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js
function resizeBilinear_2(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor2(images, "images", "resizeBilinear");
  assert2($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert2(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size}.`);
  assert2(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape2($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE2.runKernel(ResizeBilinear2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeBilinear2 = op2({ resizeBilinear_: resizeBilinear_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js
function resizeNearestNeighbor_2(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor2(images, "images", "resizeNearestNeighbor");
  assert2($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert2(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size}.`);
  assert2($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
  assert2(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape2($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE2.runKernel(ResizeNearestNeighbor2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeNearestNeighbor2 = op2({ resizeNearestNeighbor_: resizeNearestNeighbor_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js
function threshold_2(image4, method = "binary", inverted = false, threshValue = 0.5) {
  const $image = convertToTensor2(image4, "image", "threshold");
  const RED_INTENCITY_COEF = 0.2989;
  const GREEN_INTENCITY_COEF = 0.587;
  const BLUE_INTENCITY_COEF = 0.114;
  const totalPixelsInImage = $image.shape[0] * $image.shape[1];
  let $threshold = mul2(tensor1d2([threshValue]), 255);
  let r, g, b, grayscale;
  assert2($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
  assert2($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
  assert2($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
  assert2(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
  if ($image.shape[2] === 3) {
    [r, g, b] = split2($image, [1, 1, 1], -1);
    const $r = mul2(r, RED_INTENCITY_COEF);
    const $g = mul2(g, GREEN_INTENCITY_COEF);
    const $b = mul2(b, BLUE_INTENCITY_COEF);
    grayscale = add4(add4($r, $g), $b);
  } else {
    grayscale = image4;
  }
  if (method === "otsu") {
    const $histogram = bincount2(cast2(round4(grayscale), "int32"), tensor2([]), 256);
    $threshold = otsu2($histogram, totalPixelsInImage);
  }
  const invCondition = inverted ? lessEqual2(grayscale, $threshold) : greater2(grayscale, $threshold);
  const result = cast2(mul2(invCondition, 255), "int32");
  return result;
}
function otsu2(histogram, total) {
  let bestThresh = tensor1d2([-1]);
  let bestInBetVar = tensor1d2([0]);
  let cInBetVar = tensor1d2([0]);
  let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
  for (let index = 0; index < histogram.size - 1; index++) {
    classFirst = slice2(histogram, 0, index + 1);
    classSecond = slice2(histogram, index + 1);
    weightForeground = div2(sum4(classFirst), total);
    weightBack = div2(sum4(classSecond), total);
    const meanFirstDivA = sum4(mul2(classFirst, range2(0, classFirst.size)));
    meanFirst = div2(meanFirstDivA, sum4(classFirst));
    const meanSecFill = fill2(classSecond.shape, classFirst.size);
    const meanSecAdd = add4(range2(0, classSecond.size), meanSecFill);
    const meanSecMul = mul2(classSecond, meanSecAdd);
    meanSec = div2(sum4(meanSecMul), sum4(classSecond));
    const cInBetVarSubA = sub2(meanFirst, meanSec);
    const cInBetVarSubB = sub2(meanFirst, meanSec);
    const cInBetVarMul = mul2(weightForeground, weightBack);
    cInBetVar = mul2(mul2(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
    const condition = greater2(cInBetVar, bestInBetVar);
    bestInBetVar = where2(condition, cInBetVar, bestInBetVar);
    bestThresh = where2(condition, tensor1d2([index]), bestThresh);
  }
  return bestThresh;
}
var threshold2 = op2({ threshold_: threshold_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js
function transform_2(image4, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
  const $image = convertToTensor2(image4, "image", "transform", "float32");
  const $transforms = convertToTensor2(transforms, "transforms", "transform", "float32");
  assert2($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
  assert2($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
  assert2(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
  const inputs = { image: $image, transforms: $transforms };
  const attrs = { interpolation, fillMode, fillValue, outputShape };
  return ENGINE2.runKernel(Transform2, inputs, attrs);
}
var transform2 = op2({ transform_: transform_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js
function bandPart_2(a, numLower, numUpper) {
  assert2(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
  assert2(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
  const $a = convertToTensor2(a, "a", "bandPart");
  assert2($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
  const shape = $a.shape;
  const [M, N] = $a.shape.slice(-2);
  if (!(numLower <= M)) {
    throw new Error(`bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
  }
  if (!(numUpper <= N)) {
    throw new Error(`bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N}).`);
  }
  if (numLower < 0) {
    numLower = M;
  }
  if (numUpper < 0) {
    numUpper = N;
  }
  const i = reshape2(range2(0, M, 1, "int32"), [-1, 1]);
  const j = range2(0, N, 1, "int32");
  const ij = sub2(i, j);
  const inBand = logicalAnd2(lessEqual2(ij, scalar2(+numLower, "int32")), greaterEqual2(ij, scalar2(-numUpper, "int32")));
  const zero = zeros2([M, N], $a.dtype);
  return reshape2(stack2(unstack2(reshape2($a, [-1, M, N])).map((mat) => where2(inBand, mat, zero))), shape);
}
var bandPart2 = op2({ bandPart_: bandPart_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js
function gramSchmidt_2(xs) {
  let inputIsTensor2D;
  if (Array.isArray(xs)) {
    inputIsTensor2D = false;
    assert2(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const dim = xs[0].shape[0];
    for (let i = 1; i < xs.length; ++i) {
      assert2(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
    }
  } else {
    inputIsTensor2D = true;
    xs = split2(xs, xs.shape[0], 0).map((x) => squeeze2(x, [0]));
  }
  assert2(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
  const ys = [];
  const xs1d = xs;
  for (let i = 0; i < xs.length; ++i) {
    ys.push(ENGINE2.tidy(() => {
      let x = xs1d[i];
      if (i > 0) {
        for (let j = 0; j < i; ++j) {
          const proj = mul2(sum4(mul2(ys[j], x)), ys[j]);
          x = sub2(x, proj);
        }
      }
      return div2(x, norm2(x, "euclidean"));
    }));
  }
  if (inputIsTensor2D) {
    return stack2(ys, 0);
  } else {
    return ys;
  }
}
var gramSchmidt2 = op2({ gramSchmidt_: gramSchmidt_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js
function qr_2(x, fullMatrices = false) {
  assert2(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
  if (x.rank === 2) {
    return qr2d2(x, fullMatrices);
  } else {
    const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
    const x2ds = unstack2(reshape2(x, [
      outerDimsProd,
      x.shape[x.shape.length - 2],
      x.shape[x.shape.length - 1]
    ]), 0);
    const q2ds = [];
    const r2ds = [];
    x2ds.forEach((x2d) => {
      const [q2d, r2d] = qr2d2(x2d, fullMatrices);
      q2ds.push(q2d);
      r2ds.push(r2d);
    });
    const q = reshape2(stack2(q2ds, 0), x.shape);
    const r = reshape2(stack2(r2ds, 0), x.shape);
    return [q, r];
  }
}
function qr2d2(x, fullMatrices = false) {
  return ENGINE2.tidy(() => {
    assert2(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
    const m = x.shape[0];
    const n = x.shape[1];
    let q = eye2(m);
    let r = clone2(x);
    const one2D = tensor2d2([[1]], [1, 1]);
    let w = clone2(one2D);
    const iters = m >= n ? n : m;
    for (let j = 0; j < iters; ++j) {
      const rTemp = r;
      const wTemp = w;
      const qTemp = q;
      [w, r, q] = ENGINE2.tidy(() => {
        const rjEnd1 = slice2(r, [j, j], [m - j, 1]);
        const normX = norm2(rjEnd1);
        const rjj = slice2(r, [j, j], [1, 1]);
        const s = where2(greater2(rjj, 0), tensor2d2([[-1]]), tensor2d2([[1]]));
        const u1 = sub2(rjj, mul2(s, normX));
        const wPre = div2(rjEnd1, u1);
        if (wPre.shape[0] === 1) {
          w = clone2(one2D);
        } else {
          w = concat2([
            one2D,
            slice2(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
          ], 0);
        }
        const tau = neg2(div2(matMul3(s, u1), normX));
        const rjEndAll = slice2(r, [j, 0], [m - j, n]);
        const tauTimesW = mul2(tau, w);
        const wT = transpose2(w);
        if (j === 0) {
          r = sub2(rjEndAll, matMul3(tauTimesW, matMul3(wT, rjEndAll)));
        } else {
          const rTimesTau = sub2(rjEndAll, matMul3(tauTimesW, matMul3(wT, rjEndAll)));
          r = concat2([slice2(r, [0, 0], [j, n]), rTimesTau], 0);
        }
        const tawTimesWT = transpose2(tauTimesW);
        const qAllJEnd = slice2(q, [0, j], [m, q.shape[1] - j]);
        if (j === 0) {
          q = sub2(qAllJEnd, matMul3(matMul3(qAllJEnd, w), tawTimesWT));
        } else {
          const qTimesTau = sub2(qAllJEnd, matMul3(matMul3(qAllJEnd, w), tawTimesWT));
          q = concat2([slice2(q, [0, 0], [m, j]), qTimesTau], 1);
        }
        return [w, r, q];
      });
      dispose2([rTemp, wTemp, qTemp]);
    }
    if (!fullMatrices && m > n) {
      q = slice2(q, [0, 0], [m, n]);
      r = slice2(r, [0, 0], [n, n]);
    }
    return [q, r];
  });
}
var qr2 = op2({ qr_: qr_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js
var Reduction2;
(function(Reduction3) {
  Reduction3[Reduction3["NONE"] = 0] = "NONE";
  Reduction3[Reduction3["MEAN"] = 1] = "MEAN";
  Reduction3[Reduction3["SUM"] = 2] = "SUM";
  Reduction3[Reduction3["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(Reduction2 || (Reduction2 = {}));

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js
function computeWeightedLoss_2(losses4, weights, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $losses = convertToTensor2(losses4, "losses", "computeWeightedLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "computeWeightedLoss");
  }
  const weightedLoss = $weights == null ? $losses : mul2($losses, $weights);
  if (reduction2 === Reduction2.NONE) {
    return weightedLoss;
  }
  if (reduction2 === Reduction2.SUM) {
    return sum4(weightedLoss);
  }
  if (reduction2 === Reduction2.MEAN) {
    if ($weights == null) {
      return mean2(weightedLoss);
    } else {
      const broadcastFactor = $losses.size / $weights.size;
      const result = div2(sum4(weightedLoss), sum4($weights));
      return broadcastFactor > 1 ? div2(result, scalar2(broadcastFactor)) : result;
    }
  }
  if (reduction2 === Reduction2.SUM_BY_NONZERO_WEIGHTS) {
    if ($weights == null) {
      return div2(sum4(weightedLoss), scalar2($losses.size));
    } else {
      const broadcastedWeights = mul2($weights, ones4($losses.shape));
      const numNonZeros = cast2(sum4(notEqual2(broadcastedWeights, scalar2(0))), "float32");
      return div2(sum4(weightedLoss), numNonZeros);
    }
  }
  throw Error(`Unknown reduction: ${reduction2}`);
}
var computeWeightedLoss2 = op2({ computeWeightedLoss_: computeWeightedLoss_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js
function absoluteDifference_2(labels, predictions, weights, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor2(labels, "labels", "absoluteDifference");
  const $predictions = convertToTensor2(predictions, "predictions", "absoluteDifference");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "absoluteDifference");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
  const losses4 = abs2(sub2($labels, $predictions));
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var absoluteDifference2 = op2({ absoluteDifference_: absoluteDifference_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js
function cosineDistance_2(labels, predictions, axis, weights, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor2(labels, "labels", "cosineDistance");
  const $predictions = convertToTensor2(predictions, "predictions", "cosineDistance");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "cosineDistance");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in cosineDistance: ");
  const one = scalar2(1);
  const losses4 = sub2(one, sum4(mul2($labels, $predictions), axis, true));
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var cosineDistance2 = op2({ cosineDistance_: cosineDistance_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js
function hingeLoss_2(labels, predictions, weights, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  let $labels = convertToTensor2(labels, "labels", "hingeLoss");
  const $predictions = convertToTensor2(predictions, "predictions", "hingeLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "hingeLoss");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in hingeLoss: ");
  const one = scalar2(1);
  $labels = sub2(mul2(scalar2(2), $labels), one);
  const losses4 = relu2(sub2(one, mul2($labels, $predictions)));
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var hingeLoss2 = op2({ hingeLoss_: hingeLoss_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js
function huberLoss_2(labels, predictions, weights, delta = 1, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor2(labels, "labels", "huberLoss");
  const $predictions = convertToTensor2(predictions, "predictions", "huberLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "huberLoss");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in huberLoss: ");
  const deltaScalar = scalar2(delta);
  const error = abs2(sub2($predictions, $labels));
  const quadratic = minimum2(error, deltaScalar);
  const linear = sub2(error, quadratic);
  const losses4 = add4(mul2(scalar2(0.5), square2(quadratic)), mul2(deltaScalar, linear));
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var huberLoss2 = op2({ huberLoss_: huberLoss_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js
function logLoss_2(labels, predictions, weights, epsilon3 = 1e-7, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor2(labels, "labels", "logLoss");
  const $predictions = convertToTensor2(predictions, "predictions", "logLoss");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "logLoss");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in logLoss: ");
  const one = scalar2(1);
  const epsilonScalar = scalar2(epsilon3);
  const l13 = neg2(mul2($labels, log3(add4($predictions, epsilonScalar))));
  const l23 = mul2(sub2(one, $labels), log3(add4(sub2(one, $predictions), epsilonScalar)));
  const losses4 = sub2(l13, l23);
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var logLoss2 = op2({ logLoss_: logLoss_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js
function meanSquaredError_2(labels, predictions, weights, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  const $labels = convertToTensor2(labels, "labels", "meanSquaredError");
  const $predictions = convertToTensor2(predictions, "predictions", "meanSquaredError");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "meanSquaredError");
  }
  assertShapesMatch2($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
  const losses4 = squaredDifference2($labels, $predictions);
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var meanSquaredError2 = op2({ meanSquaredError_: meanSquaredError_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js
function sigmoidCrossEntropyWithLogits_2(labels, logits) {
  const $labels = convertToTensor2(labels, "labels", "sigmoidCrossEntropyWithLogits");
  const $logits = convertToTensor2(logits, "logits", "sigmoidCrossEntropyWithLogits");
  assertShapesMatch2($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  const maxOutput = relu2($logits);
  const outputXTarget = mul2($logits, $labels);
  const sigmoidOutput = log1p2(exp2(neg2(abs2($logits))));
  return add4(sub2(maxOutput, outputXTarget), sigmoidOutput);
}
function sigmoidCrossEntropy_2(multiClassLabels, logits, weights, labelSmoothing = 0, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  let $multiClassLabels = convertToTensor2(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
  const $logits = convertToTensor2(logits, "logits", "sigmoidCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "sigmoidCrossEntropy");
  }
  assertShapesMatch2($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar2(labelSmoothing);
    const one = scalar2(1);
    const half = scalar2(0.5);
    $multiClassLabels = add4(mul2($multiClassLabels, sub2(one, labelSmoothingScalar)), mul2(half, labelSmoothingScalar));
  }
  const losses4 = sigmoidCrossEntropyWithLogits_2($multiClassLabels, $logits);
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var sigmoidCrossEntropy2 = op2({ sigmoidCrossEntropy_: sigmoidCrossEntropy_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js
function softmaxCrossEntropyWithLogits_2(labels, logits, dim = -1) {
  if (dim === -1) {
    dim = logits.rank - 1;
  }
  if (dim !== logits.rank - 1) {
    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${logits.rank} and dim was ${dim}`);
  }
  const customOp = customGrad2((labels2, logits2, save) => {
    const keepDims = true;
    const lse = logSumExp2(logits2, [dim], keepDims);
    const logResult = sub2(cast2(logits2, "float32"), lse);
    save([labels2, logResult]);
    const costVector = neg2(mul2(logResult, labels2));
    const value = sum4(costVector, [dim]);
    const gradFunc = (dy, saved) => {
      const [labels3, logResult2] = saved;
      const dyShape = expandShapeToKeepDim2(dy.shape, [dim]);
      return [
        mul2(reshape2(dy, dyShape), sub2(cast2(labels3, "float32"), exp2(logResult2))),
        mul2(reshape2(dy, dyShape), sub2(exp2(logResult2), cast2(labels3, "float32")))
      ];
    };
    return { value, gradFunc };
  });
  return customOp(labels, logits);
}
function softmaxCrossEntropy_2(onehotLabels, logits, weights, labelSmoothing = 0, reduction2 = Reduction2.SUM_BY_NONZERO_WEIGHTS) {
  let $onehotLabels = convertToTensor2(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
  const $logits = convertToTensor2(logits, "logits", "softmaxCrossEntropy");
  let $weights = null;
  if (weights != null) {
    $weights = convertToTensor2(weights, "weights", "softmaxCrossEntropy");
  }
  assertShapesMatch2($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
  if (labelSmoothing > 0) {
    const labelSmoothingScalar = scalar2(labelSmoothing);
    const one = scalar2(1);
    const numClasses = scalar2($onehotLabels.shape[1]);
    $onehotLabels = add4(mul2($onehotLabels, sub2(one, labelSmoothingScalar)), div2(labelSmoothingScalar, numClasses));
  }
  const losses4 = softmaxCrossEntropyWithLogits_2($onehotLabels, $logits);
  return computeWeightedLoss2(losses4, $weights, reduction2);
}
var softmaxCrossEntropy2 = op2({ softmaxCrossEntropy_: softmaxCrossEntropy_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js
function sparseFillEmptyRows_2(indices, values, denseShape, defaultValue) {
  const $indices = convertToTensor2(indices, "indices", "sparseFillEmptyRows");
  const $values = convertToTensor2(values, "values", "sparseFillEmptyRows");
  const $denseShape = convertToTensor2(denseShape, "denseShape", "sparseFillEmptyRows");
  const $defaultValue = convertToTensor2(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
  if ($indices.rank !== 2) {
    throw new Error(`Indices should be Tensor2D but received shape
        ${$indices.shape}`);
  }
  if ($values.rank !== 1) {
    throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);
  }
  if ($denseShape.rank !== 1) {
    throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);
  }
  if ($defaultValue.rank !== 0) {
    throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);
  }
  const inputs = {
    indices: $indices,
    values: $values,
    denseShape: $denseShape,
    defaultValue: $defaultValue
  };
  const result = ENGINE2.runKernel(SparseFillEmptyRows2, inputs);
  return {
    outputIndices: result[0],
    outputValues: result[1],
    emptyRowIndicator: result[2],
    reverseIndexMap: result[3]
  };
}
var sparseFillEmptyRows2 = op2({ sparseFillEmptyRows_: sparseFillEmptyRows_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js
function sparseReshape_2(inputIndices, inputShape, newShape) {
  const $inputIndices = convertToTensor2(inputIndices, "inputIndices", "sparseReshape");
  const $inputShape = convertToTensor2(inputShape, "inputShape", "sparseReshape");
  const $newShape = convertToTensor2(newShape, "newShape", "sparseReshape");
  if ($inputIndices.rank !== 2) {
    throw new Error(`Input indices should be Tensor2D but received shape
        ${$inputIndices.shape}`);
  }
  if ($inputShape.rank !== 1) {
    throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);
  }
  if ($newShape.rank !== 1) {
    throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);
  }
  const inputs = {
    inputIndices: $inputIndices,
    inputShape: $inputShape,
    newShape: $newShape
  };
  const result = ENGINE2.runKernel(SparseReshape2, inputs);
  return { outputIndices: result[0], outputShape: result[1] };
}
var sparseReshape2 = op2({ sparseReshape_: sparseReshape_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js
function sparseSegmentMean_2(data, indices, segmentIds) {
  const $data = convertToTensor2(data, "data", "sparseSegmentMean");
  const $indices = convertToTensor2(indices, "indices", "sparseSegmentMean");
  const $segmentIds = convertToTensor2(segmentIds, "segmentIds", "sparseSegmentMean");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
          ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
          ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE2.runKernel(SparseSegmentMean2, inputs);
}
var sparseSegmentMean2 = op2({ sparseSegmentMean_: sparseSegmentMean_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js
function sparseSegmentSum_2(data, indices, segmentIds) {
  const $data = convertToTensor2(data, "data", "sparseSegmentSum");
  const $indices = convertToTensor2(indices, "indices", "sparseSegmentSum");
  const $segmentIds = convertToTensor2(segmentIds, "segmentIds", "sparseSegmentSum");
  if ($data.rank < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if ($indices.rank !== 1) {
    throw new Error(`Indices should be Tensor1D but received shape
         ${$indices.shape}`);
  }
  if ($segmentIds.rank !== 1) {
    throw new Error(`Segment ids should be Tensor1D but received shape
         ${$segmentIds.shape}`);
  }
  const inputs = {
    data: $data,
    indices: $indices,
    segmentIds: $segmentIds
  };
  return ENGINE2.runKernel(SparseSegmentSum2, inputs);
}
var sparseSegmentSum2 = op2({ sparseSegmentSum_: sparseSegmentSum_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js
function stringNGrams_2(data, dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
  const $data = convertToTensor2(data, "data", "stringNGrams", "string");
  if ($data.dtype !== "string") {
    throw new Error("Data must be of datatype string");
  }
  if ($data.shape.length !== 1) {
    throw new Error(`Data must be a vector, saw: ${$data.shape}`);
  }
  const $dataSplits = convertToTensor2(dataSplits, "dataSplits", "stringNGrams");
  if ($dataSplits.dtype !== "int32") {
    throw new Error("Data splits must be of datatype int32");
  }
  const attrs = {
    separator,
    nGramWidths,
    leftPad,
    rightPad: rightPad3,
    padWidth,
    preserveShortSequences
  };
  const inputs = { data: $data, dataSplits: $dataSplits };
  const result = ENGINE2.runKernel(StringNGrams2, inputs, attrs);
  return { nGrams: result[0], nGramsSplits: result[1] };
}
var stringNGrams2 = op2({ stringNGrams_: stringNGrams_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js
function stringSplit_2(input2, delimiter, skipEmpty = true) {
  const $input = convertToTensor2(input2, "input", "stringSplit", "string");
  const $delimiter = convertToTensor2(delimiter, "delimiter", "stringSplit", "string");
  if ($input.rank !== 1) {
    throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);
  }
  if ($delimiter.rank !== 0) {
    throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);
  }
  const attrs = { skipEmpty };
  const inputs = { input: $input, delimiter: $delimiter };
  const result = ENGINE2.runKernel(StringSplit2, inputs, attrs);
  return { indices: result[0], values: result[1], shape: result[2] };
}
var stringSplit2 = op2({ stringSplit_: stringSplit_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js
function stringToHashBucketFast_2(input2, numBuckets) {
  const $input = convertToTensor2(input2, "input", "stringToHashBucketFast", "string");
  const attrs = { numBuckets };
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const inputs = { input: $input };
  return ENGINE2.runKernel(StringToHashBucketFast2, inputs, attrs);
}
var stringToHashBucketFast2 = op2({ stringToHashBucketFast_: stringToHashBucketFast_2 });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/ops.js
var image2 = {
  flipLeftRight: flipLeftRight2,
  resizeNearestNeighbor: resizeNearestNeighbor2,
  resizeBilinear: resizeBilinear2,
  rotateWithOffset: rotateWithOffset2,
  cropAndResize: cropAndResize2,
  nonMaxSuppression: nonMaxSuppression2,
  nonMaxSuppressionAsync: nonMaxSuppressionAsync2,
  nonMaxSuppressionWithScore: nonMaxSuppressionWithScore2,
  nonMaxSuppressionWithScoreAsync: nonMaxSuppressionWithScoreAsync2,
  nonMaxSuppressionPadded: nonMaxSuppressionPadded2,
  nonMaxSuppressionPaddedAsync: nonMaxSuppressionPaddedAsync2,
  threshold: threshold2,
  transform: transform2
};
var linalg2 = {
  bandPart: bandPart2,
  gramSchmidt: gramSchmidt2,
  qr: qr2
};
var sparse2 = {
  sparseFillEmptyRows: sparseFillEmptyRows2,
  sparseReshape: sparseReshape2,
  sparseSegmentMean: sparseSegmentMean2,
  sparseSegmentSum: sparseSegmentSum2
};
var string2 = {
  stringNGrams: stringNGrams2,
  stringSplit: stringSplit2,
  stringToHashBucketFast: stringToHashBucketFast2
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js
var Optimizer2 = class extends Serializable9 {
  minimize(f, returnCost = false, varList) {
    const { value, grads: grads3 } = this.computeGradients(f, varList);
    if (varList != null) {
      const gradArray = varList.map((v) => ({ name: v.name, tensor: grads3[v.name] }));
      this.applyGradients(gradArray);
    } else {
      this.applyGradients(grads3);
    }
    dispose2(grads3);
    if (returnCost) {
      return value;
    } else {
      value.dispose();
      return null;
    }
  }
  get iterations() {
    if (this.iterations_ == null) {
      this.iterations_ = 0;
    }
    return this.iterations_;
  }
  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }
  computeGradients(f, varList) {
    return variableGrads2(f, varList);
  }
  dispose() {
    if (this.iterations_ != null) {
      dispose2(this.iterations_);
    }
  }
  async saveIterations() {
    if (this.iterations_ == null) {
      this.iterations_ = 0;
    }
    return {
      name: "iter",
      tensor: scalar2(this.iterations_, "int32")
    };
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for this optimizer yet.");
  }
  async setWeights(weightValues) {
    throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
  }
  async extractIterations(weightValues) {
    this.iterations_ = (await weightValues[0].tensor.data())[0];
    return weightValues.slice(1);
  }
};
Object.defineProperty(Optimizer2, Symbol.hasInstance, {
  value: (instance) => {
    return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js
var AdadeltaOptimizer2 = class extends Optimizer2 {
  constructor(learningRate, rho, epsilon3 = null) {
    super();
    this.learningRate = learningRate;
    this.rho = rho;
    this.epsilon = epsilon3;
    this.accumulatedGrads = [];
    this.accumulatedUpdates = [];
    if (epsilon3 == null) {
      this.epsilon = ENGINE2.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE2.registeredVariables[name];
      const trainable = false;
      if (this.accumulatedGrads[i] == null) {
        this.accumulatedGrads[i] = {
          originalName: `${name}/accum_grad`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      if (this.accumulatedUpdates[i] == null) {
        this.accumulatedUpdates[i] = {
          originalName: `${name}/accum_var`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedGrad = this.accumulatedGrads[i].variable;
      const accumulatedUpdate = this.accumulatedUpdates[i].variable;
      tidy2(() => {
        const newAccumulatedGrad = add4(mul2(accumulatedGrad, this.rho), mul2(square2(gradient), 1 - this.rho));
        const updates = mul2(div2(sqrt2(add4(accumulatedUpdate, this.epsilon)), sqrt2(add4(accumulatedGrad, this.epsilon))), gradient);
        const newAccumulatedUpdate = add4(mul2(accumulatedUpdate, this.rho), mul2(square2(updates), 1 - this.rho));
        accumulatedGrad.assign(newAccumulatedGrad);
        accumulatedUpdate.assign(newAccumulatedUpdate);
        const newValue = add4(mul2(updates, -this.learningRate), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedUpdates != null) {
      dispose2(this.accumulatedGrads.map((v) => v.variable));
      dispose2(this.accumulatedUpdates.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const variableCount = weightValues.length / 2;
    const trainable = false;
    this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "rho": this.rho,
      "epsilon": this.epsilon
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["rho"], config["epsilon"]);
  }
};
AdadeltaOptimizer2.className = "Adadelta";
registerClass2(AdadeltaOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js
var AdagradOptimizer2 = class extends Optimizer2 {
  constructor(learningRate, initialAccumulatorValue = 0.1) {
    super();
    this.learningRate = learningRate;
    this.initialAccumulatorValue = initialAccumulatorValue;
    this.accumulatedGrads = [];
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE2.registeredVariables[name];
      if (this.accumulatedGrads[i] == null) {
        const trainable = false;
        this.accumulatedGrads[i] = {
          originalName: `${name}/accumulator`,
          variable: tidy2(() => fill2(value.shape, this.initialAccumulatorValue).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedGrad = this.accumulatedGrads[i].variable;
      tidy2(() => {
        const newAccumulatedGrad = add4(accumulatedGrad, square2(gradient));
        accumulatedGrad.assign(newAccumulatedGrad);
        const newValue = add4(mul2(div2(gradient, sqrt2(add4(newAccumulatedGrad, ENGINE2.backend.epsilon()))), -this.learningRate), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedGrads != null) {
      dispose2(this.accumulatedGrads.map((v) => v.variable));
    }
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const trainable = false;
    this.accumulatedGrads = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "initialAccumulatorValue": this.initialAccumulatorValue
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["initialAccumulatorValue"]);
  }
};
AdagradOptimizer2.className = "Adagrad";
registerClass2(AdagradOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js
var AdamOptimizer2 = class extends Optimizer2 {
  constructor(learningRate, beta1, beta2, epsilon3 = null) {
    super();
    this.learningRate = learningRate;
    this.beta1 = beta1;
    this.beta2 = beta2;
    this.epsilon = epsilon3;
    this.accumulatedFirstMoment = [];
    this.accumulatedSecondMoment = [];
    tidy2(() => {
      this.accBeta1 = scalar2(beta1).variable();
      this.accBeta2 = scalar2(beta2).variable();
    });
    if (epsilon3 == null) {
      this.epsilon = ENGINE2.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
    tidy2(() => {
      const oneMinusAccBeta1 = sub2(1, this.accBeta1);
      const oneMinusAccBeta2 = sub2(1, this.accBeta2);
      varNames.forEach((name, i) => {
        const value = ENGINE2.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedFirstMoment[i] == null) {
          this.accumulatedFirstMoment[i] = {
            originalName: `${name}/m`,
            variable: tidy2(() => zerosLike2(value).variable(trainable))
          };
        }
        if (this.accumulatedSecondMoment[i] == null) {
          this.accumulatedSecondMoment[i] = {
            originalName: `${name}/v`,
            variable: tidy2(() => zerosLike2(value).variable(trainable))
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const firstMoment = this.accumulatedFirstMoment[i].variable;
        const secondMoment = this.accumulatedSecondMoment[i].variable;
        const newFirstMoment = add4(mul2(firstMoment, this.beta1), mul2(gradient, 1 - this.beta1));
        const newSecondMoment = add4(mul2(secondMoment, this.beta2), mul2(square2(gradient), 1 - this.beta2));
        const biasCorrectedFirstMoment = div2(newFirstMoment, oneMinusAccBeta1);
        const biasCorrectedSecondMoment = div2(newSecondMoment, oneMinusAccBeta2);
        firstMoment.assign(newFirstMoment);
        secondMoment.assign(newSecondMoment);
        const newValue = add4(mul2(div2(biasCorrectedFirstMoment, add4(sqrt2(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
        value.assign(newValue);
      });
      this.accBeta1.assign(mul2(this.accBeta1, this.beta1));
      this.accBeta2.assign(mul2(this.accBeta2, this.beta2));
    });
    this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose();
    this.accBeta2.dispose();
    if (this.accumulatedFirstMoment != null) {
      dispose2(this.accumulatedFirstMoment.map((v) => v.variable));
    }
    if (this.accumulatedSecondMoment != null) {
      dispose2(this.accumulatedSecondMoment.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    tidy2(() => {
      this.accBeta1.assign(pow2(this.beta1, this.iterations_ + 1));
      this.accBeta2.assign(pow2(this.beta2, this.iterations_ + 1));
    });
    const variableCount = weightValues.length / 2;
    const trainable = false;
    this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "beta1": this.beta1,
      "beta2": this.beta2,
      "epsilon": this.epsilon
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
  }
};
AdamOptimizer2.className = "Adam";
registerClass2(AdamOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js
var AdamaxOptimizer2 = class extends Optimizer2 {
  constructor(learningRate, beta1, beta2, epsilon3 = null, decay = 0) {
    super();
    this.learningRate = learningRate;
    this.beta1 = beta1;
    this.beta2 = beta2;
    this.epsilon = epsilon3;
    this.decay = decay;
    this.accumulatedFirstMoment = [];
    this.accumulatedWeightedInfNorm = [];
    tidy2(() => {
      this.iteration = scalar2(0).variable();
      this.accBeta1 = scalar2(beta1).variable();
    });
    if (epsilon3 == null) {
      this.epsilon = ENGINE2.backend.epsilon();
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    tidy2(() => {
      const oneMinusAccBeta1 = sub2(1, this.accBeta1);
      const lr = div2(-this.learningRate, add4(mul2(this.iteration, this.decay), 1));
      variableNames.forEach((name, i) => {
        const value = ENGINE2.registeredVariables[name];
        const trainable = false;
        if (this.accumulatedFirstMoment[i] == null) {
          this.accumulatedFirstMoment[i] = {
            originalName: `${name}/m`,
            variable: zerosLike2(value).variable(trainable)
          };
        }
        if (this.accumulatedWeightedInfNorm[i] == null) {
          this.accumulatedWeightedInfNorm[i] = {
            originalName: `${name}/v`,
            variable: zerosLike2(value).variable(trainable)
          };
        }
        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
        if (gradient == null) {
          return;
        }
        const firstMoment = this.accumulatedFirstMoment[i].variable;
        const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
        const newFirstMoment = add4(mul2(firstMoment, this.beta1), mul2(gradient, 1 - this.beta1));
        const ut0 = mul2(weightedInfNorm, this.beta2);
        const ut1 = abs2(gradient);
        const newWeightedInfNorm = maximum2(ut0, ut1);
        firstMoment.assign(newFirstMoment);
        weightedInfNorm.assign(newWeightedInfNorm);
        const newValue = add4(mul2(div2(lr, oneMinusAccBeta1), div2(newFirstMoment, add4(newWeightedInfNorm, this.epsilon))), value);
        value.assign(newValue);
      });
      this.iteration.assign(add4(this.iteration, 1));
      this.accBeta1.assign(mul2(this.accBeta1, this.beta1));
    });
    this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose();
    this.iteration.dispose();
    if (this.accumulatedFirstMoment != null) {
      dispose2(this.accumulatedFirstMoment.map((v) => v.variable));
    }
    if (this.accumulatedWeightedInfNorm != null) {
      dispose2(this.accumulatedWeightedInfNorm.map((v) => v.variable));
    }
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for Adamax yet.");
  }
  async setWeights(weightValues) {
    throw new Error("setWeights() is not implemented for Adamax yet.");
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "beta1": this.beta1,
      "beta2": this.beta2,
      "epsilon": this.epsilon,
      "decay": this.decay
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
  }
};
AdamaxOptimizer2.className = "Adamax";
registerClass2(AdamaxOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js
var SGDOptimizer2 = class extends Optimizer2 {
  constructor(learningRate) {
    super();
    this.learningRate = learningRate;
    this.setLearningRate(learningRate);
  }
  applyGradients(variableGradients) {
    const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
    varNames.forEach((name, i) => {
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const value = ENGINE2.registeredVariables[name];
      tidy2(() => {
        const newValue = add4(mul2(this.c, gradient), value);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  setLearningRate(learningRate) {
    this.learningRate = learningRate;
    if (this.c != null) {
      this.c.dispose();
    }
    this.c = keep2(scalar2(-learningRate));
  }
  dispose() {
    this.c.dispose();
  }
  async getWeights() {
    return [await this.saveIterations()];
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    if (weightValues.length !== 0) {
      throw new Error("SGD optimizer does not have settable weights.");
    }
  }
  getConfig() {
    return { "learningRate": this.learningRate };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"]);
  }
};
SGDOptimizer2.className = "SGD";
registerClass2(SGDOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js
var MomentumOptimizer2 = class extends SGDOptimizer2 {
  constructor(learningRate, momentum, useNesterov = false) {
    super(learningRate);
    this.learningRate = learningRate;
    this.momentum = momentum;
    this.useNesterov = useNesterov;
    this.accumulations = [];
    this.m = scalar2(this.momentum);
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE2.registeredVariables[name];
      if (this.accumulations[i] == null) {
        const trainable = false;
        this.accumulations[i] = {
          originalName: `${name}/momentum`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      const accumulation = this.accumulations[i].variable;
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      tidy2(() => {
        let newValue;
        const newAccumulation = add4(mul2(this.m, accumulation), gradient);
        if (this.useNesterov) {
          newValue = add4(mul2(this.c, add4(gradient, mul2(newAccumulation, this.m))), value);
        } else {
          newValue = add4(mul2(this.c, newAccumulation), value);
        }
        accumulation.assign(newAccumulation);
        value.assign(newValue);
      });
    });
    this.incrementIterations();
  }
  dispose() {
    this.m.dispose();
    if (this.accumulations != null) {
      dispose2(this.accumulations.map((v) => v.variable));
    }
  }
  setMomentum(momentum) {
    this.momentum = momentum;
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulations.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const trainable = false;
    this.accumulations = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "momentum": this.momentum,
      "useNesterov": this.useNesterov
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
  }
};
MomentumOptimizer2.className = "Momentum";
registerClass2(MomentumOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js
var RMSPropOptimizer2 = class extends Optimizer2 {
  constructor(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
    super();
    this.learningRate = learningRate;
    this.decay = decay;
    this.momentum = momentum;
    this.epsilon = epsilon3;
    this.accumulatedMeanSquares = [];
    this.accumulatedMoments = [];
    this.accumulatedMeanGrads = [];
    this.centered = centered;
    if (epsilon3 == null) {
      this.epsilon = ENGINE2.backend.epsilon();
    }
    if (learningRate == null) {
      throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
    }
  }
  applyGradients(variableGradients) {
    const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
    variableNames.forEach((name, i) => {
      const value = ENGINE2.registeredVariables[name];
      const trainable = false;
      if (this.accumulatedMeanSquares[i] == null) {
        this.accumulatedMeanSquares[i] = {
          originalName: `${name}/rms`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      if (this.accumulatedMoments[i] == null) {
        this.accumulatedMoments[i] = {
          originalName: `${name}/momentum`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      if (this.accumulatedMeanGrads[i] == null && this.centered) {
        this.accumulatedMeanGrads[i] = {
          originalName: `${name}/mg`,
          variable: tidy2(() => zerosLike2(value).variable(trainable))
        };
      }
      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
      if (gradient == null) {
        return;
      }
      const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
      const accumulatedMoments = this.accumulatedMoments[i].variable;
      tidy2(() => {
        const newAccumulatedMeanSquare = add4(mul2(accumulatedMeanSquare, this.decay), mul2(square2(gradient), 1 - this.decay));
        if (this.centered) {
          const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
          const newAccumulatedMeanGrad = add4(mul2(accumulatedMeanGrad, this.decay), mul2(gradient, 1 - this.decay));
          const gradContribution = div2(mul2(gradient, this.learningRate), sqrt2(sub2(newAccumulatedMeanSquare, add4(square2(newAccumulatedMeanGrad), this.epsilon))));
          const newAccumulatedMoments = add4(mul2(accumulatedMoments, this.momentum), gradContribution);
          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
          accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
          accumulatedMoments.assign(newAccumulatedMoments);
          const newValue = sub2(value, newAccumulatedMoments);
          value.assign(newValue);
        } else {
          const newAccumulatedMeanSquare2 = add4(mul2(accumulatedMeanSquare, this.decay), mul2(square2(gradient), 1 - this.decay));
          const newAccumulatedMoments = add4(mul2(accumulatedMoments, this.momentum), div2(mul2(gradient, this.learningRate), sqrt2(add4(newAccumulatedMeanSquare2, this.epsilon))));
          accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
          accumulatedMoments.assign(newAccumulatedMoments);
          const newValue = sub2(value, newAccumulatedMoments);
          value.assign(newValue);
        }
      });
    });
    this.incrementIterations();
  }
  dispose() {
    if (this.accumulatedMeanSquares != null) {
      dispose2(this.accumulatedMeanSquares.map((v) => v.variable));
    }
    if (this.accumulatedMeanGrads != null && this.centered) {
      dispose2(this.accumulatedMeanGrads.map((v) => v.variable));
    }
    if (this.accumulatedMoments != null) {
      dispose2(this.accumulatedMoments.map((v) => v.variable));
    }
  }
  async getWeights() {
    const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
    if (this.centered) {
      variables.push(...this.accumulatedMeanGrads);
    }
    return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
  }
  async setWeights(weightValues) {
    weightValues = await this.extractIterations(weightValues);
    const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
    const trainable = false;
    this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
      originalName: v.name,
      variable: v.tensor.variable(trainable)
    }));
    if (this.centered) {
      this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
        originalName: v.name,
        variable: v.tensor.variable(trainable)
      }));
    }
  }
  getConfig() {
    return {
      "learningRate": this.learningRate,
      "decay": this.decay,
      "momentum": this.momentum,
      "epsilon": this.epsilon,
      "centered": this.centered
    };
  }
  static fromConfig(cls, config) {
    return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
  }
};
RMSPropOptimizer2.className = "RMSProp";
registerClass2(RMSPropOptimizer2);

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js
var OptimizerConstructors2 = class {
  static sgd(learningRate) {
    return new SGDOptimizer2(learningRate);
  }
  static momentum(learningRate, momentum, useNesterov = false) {
    return new MomentumOptimizer2(learningRate, momentum, useNesterov);
  }
  static rmsprop(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
    return new RMSPropOptimizer2(learningRate, decay, momentum, epsilon3, centered);
  }
  static adam(learningRate = 1e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null) {
    return new AdamOptimizer2(learningRate, beta1, beta2, epsilon3);
  }
  static adadelta(learningRate = 1e-3, rho = 0.95, epsilon3 = null) {
    return new AdadeltaOptimizer2(learningRate, rho, epsilon3);
  }
  static adamax(learningRate = 2e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null, decay = 0) {
    return new AdamaxOptimizer2(learningRate, beta1, beta2, epsilon3, decay);
  }
  static adagrad(learningRate, initialAccumulatorValue = 0.1) {
    return new AdagradOptimizer2(learningRate, initialAccumulatorValue);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/train.js
var train2 = {
  sgd: OptimizerConstructors2.sgd,
  momentum: OptimizerConstructors2.momentum,
  adadelta: OptimizerConstructors2.adadelta,
  adagrad: OptimizerConstructors2.adagrad,
  rmsprop: OptimizerConstructors2.rmsprop,
  adamax: OptimizerConstructors2.adamax,
  adam: OptimizerConstructors2.adam
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/browser_util.js
var delayCallback2 = (() => {
  if (typeof requestAnimationFrame !== "undefined") {
    return requestAnimationFrame;
  } else if (typeof setImmediate !== "undefined") {
    return setImmediate;
  }
  return (f) => f();
})();
function nextFrame2() {
  return new Promise((resolve) => delayCallback2(() => resolve()));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
var backend_util_exports2 = {};
__export(backend_util_exports2, {
  ERF_A1: () => ERF_A12,
  ERF_A2: () => ERF_A22,
  ERF_A3: () => ERF_A32,
  ERF_A4: () => ERF_A42,
  ERF_A5: () => ERF_A52,
  ERF_P: () => ERF_P2,
  PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD2,
  SELU_SCALE: () => SELU_SCALE2,
  SELU_SCALEALPHA: () => SELU_SCALEALPHA2,
  applyActivation: () => applyActivation2,
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape2,
  assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims2,
  assertParamsConsistent: () => assertParamsConsistent2,
  assignToTypedArray: () => assignToTypedArray2,
  axesAreInnerMostDims: () => axesAreInnerMostDims2,
  calculateShapes: () => calculateShapes2,
  checkEinsumDimSizes: () => checkEinsumDimSizes2,
  combineLocations: () => combineLocations2,
  complexWithEvenIndex: () => complexWithEvenIndex2,
  complexWithOddIndex: () => complexWithOddIndex2,
  computeConv2DInfo: () => computeConv2DInfo2,
  computeConv3DInfo: () => computeConv3DInfo2,
  computeDefaultPad: () => computeDefaultPad2,
  computeDilation2DInfo: () => computeDilation2DInfo2,
  computeOptimalWindowSize: () => computeOptimalWindowSize2,
  computeOutAndReduceShapes: () => computeOutAndReduceShapes2,
  computeOutShape: () => computeOutShape5,
  computePool2DInfo: () => computePool2DInfo2,
  computePool3DInfo: () => computePool3DInfo2,
  convertConv2DDataFormat: () => convertConv2DDataFormat2,
  decodeEinsumEquation: () => decodeEinsumEquation2,
  eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne2,
  expandShapeToKeepDim: () => expandShapeToKeepDim2,
  exponent: () => exponent2,
  exponents: () => exponents2,
  fromStringArrayToUint8: () => fromStringArrayToUint82,
  fromUint8ToStringArray: () => fromUint8ToStringArray2,
  getAxesPermutation: () => getAxesPermutation2,
  getBroadcastDims: () => getBroadcastDims2,
  getComplexWithIndex: () => getComplexWithIndex2,
  getEinsumComputePath: () => getEinsumComputePath2,
  getEinsumPermutation: () => getEinsumPermutation2,
  getFusedBiasGradient: () => getFusedBiasGradient2,
  getFusedDyActivation: () => getFusedDyActivation2,
  getImageCenter: () => getImageCenter2,
  getInnerMostAxes: () => getInnerMostAxes2,
  getPermuted: () => getPermuted2,
  getReductionAxes: () => getReductionAxes2,
  getReshaped: () => getReshaped2,
  getReshapedPermuted: () => getReshapedPermuted2,
  getSliceBeginCoords: () => getSliceBeginCoords2,
  getSliceSize: () => getSliceSize2,
  getUndoAxesPermutation: () => getUndoAxesPermutation2,
  isIdentityPermutation: () => isIdentityPermutation2,
  log: () => log4,
  mergeRealAndImagArrays: () => mergeRealAndImagArrays2,
  prepareAndValidate: () => prepareAndValidate2,
  prepareSplitSize: () => prepareSplitSize2,
  segment_util: () => segment_util_exports2,
  shouldFuse: () => shouldFuse2,
  slice_util: () => slice_util_exports2,
  splitRealAndImagArrays: () => splitRealAndImagArrays2,
  tupleValuesAreOne: () => tupleValuesAreOne2,
  upcastType: () => upcastType2,
  validateInput: () => validateInput3,
  validateUpdateShape: () => validateUpdateShape2,
  warn: () => warn2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js
function assertParamsConsistent2(shapes, axis) {
  const rank = shapes[0].length;
  shapes.forEach((shape, i) => {
    assert2(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
  });
  assert2(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
  const firstShape = shapes[0];
  shapes.forEach((shape, i) => {
    for (let r = 0; r < rank; r++) {
      assert2(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
    }
  });
}
function computeOutShape5(shapes, axis) {
  const outputShape = shapes[0].slice();
  for (let i = 1; i < shapes.length; i++) {
    outputShape[axis] += shapes[i][axis];
  }
  return outputShape;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js
var PARALLELIZE_THRESHOLD2 = 30;
function computeOptimalWindowSize2(inSize) {
  if (inSize <= PARALLELIZE_THRESHOLD2) {
    return inSize;
  }
  return nearestDivisor2(inSize, Math.floor(Math.sqrt(inSize)));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js
function getImageCenter2(center, imageHeight, imageWidth) {
  const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
  const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
  return [centerX, centerY];
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js
function getReshaped2(inputShape, blockShape, prod6, batchToSpace = true) {
  let reshaped = [];
  if (batchToSpace) {
    reshaped = reshaped.concat(blockShape.slice(0));
    reshaped.push(inputShape[0] / prod6);
    reshaped = reshaped.concat(inputShape.slice(1));
  } else {
    reshaped = reshaped.concat(inputShape[0]);
    const spatialLength = blockShape.length;
    for (let i = 0; i < spatialLength; ++i) {
      reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
    }
    reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
  }
  return reshaped;
}
function getPermuted2(reshapedRank, blockShapeRank, batchToSpace = true) {
  const permuted = [];
  if (batchToSpace) {
    permuted.push(blockShapeRank);
    for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
      if (i <= 2 * blockShapeRank) {
        permuted.push(i);
        permuted.push(i - (blockShapeRank + 1));
      } else {
        permuted.push(i);
      }
    }
  } else {
    const permutedBeforeBatch = [];
    const permutedAfterBatch = [];
    for (let i = 1; i < reshapedRank; ++i) {
      if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
        permutedAfterBatch.push(i);
      } else {
        permutedBeforeBatch.push(i);
      }
    }
    permuted.push(...permutedBeforeBatch);
    permuted.push(0);
    permuted.push(...permutedAfterBatch);
  }
  return permuted;
}
function getReshapedPermuted2(inputShape, blockShape, prod6, batchToSpace = true) {
  const reshapedPermuted = [];
  if (batchToSpace) {
    reshapedPermuted.push(inputShape[0] / prod6);
  } else {
    reshapedPermuted.push(inputShape[0] * prod6);
  }
  for (let i = 1; i < inputShape.length; ++i) {
    if (i <= blockShape.length) {
      if (batchToSpace) {
        reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
      } else {
        reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
      }
    } else {
      reshapedPermuted.push(inputShape[i]);
    }
  }
  return reshapedPermuted;
}
function getSliceBeginCoords2(crops, blockShape) {
  const sliceBeginCoords = [0];
  for (let i = 0; i < blockShape; ++i) {
    sliceBeginCoords.push(crops[i][0]);
  }
  return sliceBeginCoords;
}
function getSliceSize2(uncroppedShape, crops, blockShape) {
  const sliceSize = uncroppedShape.slice(0, 1);
  for (let i = 0; i < blockShape; ++i) {
    sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
  }
  return sliceSize;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js
var SELU_SCALEALPHA2 = 1.7580993408473768;
var SELU_SCALE2 = 1.0507009873554805;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js
var ERF_P2 = 0.3275911;
var ERF_A12 = 0.254829592;
var ERF_A22 = -0.284496736;
var ERF_A32 = 1.421413741;
var ERF_A42 = -1.453152027;
var ERF_A52 = 1.061405429;

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/log.js
function warn2(...msg) {
  if (!env2().getBool("IS_TEST")) {
    console.warn(...msg);
  }
}
function log4(...msg) {
  if (!env2().getBool("IS_TEST")) {
    console.log(...msg);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js
function mergeRealAndImagArrays2(real6, imag5) {
  if (real6.length !== imag5.length) {
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real6.length}, imag: ${imag5.length}.`);
  }
  const result = new Float32Array(real6.length * 2);
  for (let i = 0; i < result.length; i += 2) {
    result[i] = real6[i / 2];
    result[i + 1] = imag5[i / 2];
  }
  return result;
}
function splitRealAndImagArrays2(complex6) {
  const real6 = new Float32Array(complex6.length / 2);
  const imag5 = new Float32Array(complex6.length / 2);
  for (let i = 0; i < complex6.length; i += 2) {
    real6[i / 2] = complex6[i];
    imag5[i / 2] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function complexWithEvenIndex2(complex6) {
  const len = Math.ceil(complex6.length / 4);
  const real6 = new Float32Array(len);
  const imag5 = new Float32Array(len);
  for (let i = 0; i < complex6.length; i += 4) {
    real6[Math.floor(i / 4)] = complex6[i];
    imag5[Math.floor(i / 4)] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function complexWithOddIndex2(complex6) {
  const len = Math.floor(complex6.length / 4);
  const real6 = new Float32Array(len);
  const imag5 = new Float32Array(len);
  for (let i = 2; i < complex6.length; i += 4) {
    real6[Math.floor(i / 4)] = complex6[i];
    imag5[Math.floor(i / 4)] = complex6[i + 1];
  }
  return { real: real6, imag: imag5 };
}
function getComplexWithIndex2(complex6, index) {
  const real6 = complex6[index * 2];
  const imag5 = complex6[index * 2 + 1];
  return { real: real6, imag: imag5 };
}
function assignToTypedArray2(data, real6, imag5, index) {
  data[index * 2] = real6;
  data[index * 2 + 1] = imag5;
}
function exponents2(n, inverse) {
  const real6 = new Float32Array(n / 2);
  const imag5 = new Float32Array(n / 2);
  for (let i = 0; i < Math.ceil(n / 2); i++) {
    const x = (inverse ? 2 : -2) * Math.PI * (i / n);
    real6[i] = Math.cos(x);
    imag5[i] = Math.sin(x);
  }
  return { real: real6, imag: imag5 };
}
function exponent2(k, n, inverse) {
  const x = (inverse ? 2 : -2) * Math.PI * (k / n);
  const real6 = Math.cos(x);
  const imag5 = Math.sin(x);
  return { real: real6, imag: imag5 };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js
var ARROW2 = "->";
var ARROW_REGEX2 = /->/g;
var COMMA2 = ",";
var ELLIPSIS2 = "...";
function decodeEinsumEquation2(equation, numTensors) {
  equation = equation.replace(/\s/g, "");
  const numArrows = (equation.length - equation.replace(ARROW_REGEX2, "").length) / ARROW2.length;
  if (numArrows < 1) {
    throw new Error("Equations without an arrow are not supported.");
  } else if (numArrows > 1) {
    throw new Error(`Equation must contain exactly one arrow ("${ARROW2}").`);
  }
  const [inputString, outputString] = equation.split(ARROW2);
  assert2(inputString.indexOf(ELLIPSIS2) === -1, () => `The ellipsis notation ("${ELLIPSIS2}") is not supported yet.`);
  const inputTerms = inputString.split(COMMA2);
  const numInputs = inputTerms.length;
  if (numTensors !== numInputs) {
    throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
  }
  if (numInputs > 2) {
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  }
  const allDims = [];
  for (let i = 0; i < outputString.length; ++i) {
    const dimName = outputString[i];
    if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
      throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
    }
    if (allDims.indexOf(dimName) === -1) {
      allDims.push(dimName);
    }
  }
  for (let i = 0; i < inputString.length; ++i) {
    const dimName = inputString[i];
    if (allDims.indexOf(dimName) === -1 && dimName !== COMMA2) {
      allDims.push(dimName);
    }
  }
  const idDims = new Array(inputTerms.length);
  for (let i = 0; i < numInputs; ++i) {
    if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
      throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
    }
    idDims[i] = [];
    for (let j = 0; j < inputTerms[i].length; ++j) {
      idDims[i].push(allDims.indexOf(inputTerms[i][j]));
    }
  }
  const numDims = allDims.length;
  const numOutDims = outputString.length;
  const summedDims = [];
  for (let i = numOutDims; i < numDims; ++i) {
    summedDims.push(i);
  }
  return { allDims, summedDims, idDims };
}
function getEinsumPermutation2(nDims, idDims) {
  let permutationIndices = new Array(nDims);
  permutationIndices.fill(-1);
  for (let i = 0; i < idDims.length; ++i) {
    permutationIndices[idDims[i]] = i;
  }
  const expandDims7 = [];
  for (let i = 0; i < nDims; ++i) {
    if (permutationIndices[i] === -1) {
      expandDims7.push(i);
    }
  }
  permutationIndices = permutationIndices.filter((d) => d !== -1);
  return { permutationIndices, expandDims: expandDims7 };
}
function checkEinsumDimSizes2(nDims, idDims, tensors) {
  const dimSizes = new Array(nDims);
  for (let i = 0; i < tensors.length; ++i) {
    const shape = tensors[i].shape;
    for (let j = 0; j < idDims[i].length; ++j) {
      if (dimSizes[idDims[i][j]] === void 0) {
        dimSizes[idDims[i][j]] = shape[j];
      } else {
        assert2(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j]}`);
      }
    }
  }
}
function getEinsumComputePath2(summedDims, idDims) {
  const path = summedDims;
  const steps = [];
  let nSteps = 0;
  if (summedDims.length === 0) {
    path.push(-1);
  }
  nSteps = summedDims.length + 1;
  for (let i = 0; i < nSteps; ++i) {
    steps.push([]);
  }
  const computedTermIndices = [];
  for (let i = 0; i < path.length; ++i) {
    const summedDim = path[i];
    const termIndices = findTermsWithDim2(idDims, summedDim);
    for (const termIndex of termIndices) {
      if (computedTermIndices.indexOf(termIndex) === -1) {
        steps[i].push(termIndex);
        computedTermIndices.push(termIndex);
      }
    }
  }
  return { path, steps };
}
function isIdentityPermutation2(perm) {
  return perm.every((dim, index) => dim === index);
}
function findTermsWithDim2(idDims, dim) {
  const termIndices = [];
  for (let i = 0; i < idDims.length; ++i) {
    if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
      termIndices.push(i);
    }
  }
  return termIndices;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js
function prepareSplitSize2(x, numOrSizeSplits, axis = 0) {
  let splitSizes = [];
  if (typeof numOrSizeSplits === "number") {
    assert2(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
    splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
  } else {
    const numOfNegs = numOrSizeSplits.reduce((count2, value) => {
      if (value === -1) {
        count2 += 1;
      }
      return count2;
    }, 0);
    assert2(numOfNegs <= 1, () => "There should be only one negative value in split array.");
    const negIndex = numOrSizeSplits.indexOf(-1);
    if (negIndex !== -1) {
      const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
      numOrSizeSplits[negIndex] = x.shape[axis] - total;
    }
    assert2(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
    splitSizes = numOrSizeSplits;
  }
  return splitSizes;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js
var segment_util_exports2 = {};
__export(segment_util_exports2, {
  collectGatherOpShapeInfo: () => collectGatherOpShapeInfo2,
  computeOutShape: () => computeOutShape6,
  segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize2
});
function segOpComputeOptimalWindowSize2(inSize, numSegments) {
  let done = false;
  let res;
  if (inSize <= PARALLELIZE_THRESHOLD2) {
    res = inSize;
    done = true;
  } else {
    res = nearestDivisor2(inSize, Math.floor(Math.sqrt(inSize)));
  }
  while (!done) {
    if (res > numSegments || res === inSize) {
      done = true;
    } else {
      res = nearestDivisor2(inSize, res + 1);
    }
  }
  return res;
}
function computeOutShape6(aShape, axis, numSegments) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (dim !== axis) {
      outShape.push(aShape[dim]);
    } else {
      outShape.push(numSegments);
    }
  }
  return outShape;
}
function collectGatherOpShapeInfo2(x, indices, axis, batchDims) {
  const indicesRank = indices.shape.length;
  const xRank = x.shape.length;
  if (batchDims !== 0) {
    if (batchDims < -indicesRank || batchDims > indicesRank) {
      throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
    }
  }
  if (batchDims < 0) {
    batchDims += indicesRank;
  }
  if (batchDims > xRank) {
    throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
  }
  if (axis < batchDims) {
    throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
  }
  for (let i = 0; i < batchDims; ++i) {
    if (x.shape[i] !== indices.shape[i]) {
      throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
    }
  }
  const dimSize = x.shape[axis];
  const outputShape = [];
  let batchSize = 1;
  let outerSize = 1;
  let sliceSize = 1;
  for (let i = 0; i < batchDims; ++i) {
    outputShape.push(x.shape[i]);
    batchSize *= x.shape[i];
  }
  for (let i = batchDims; i < axis; i++) {
    outputShape.push(x.shape[i]);
    outerSize *= x.shape[i];
  }
  for (let i = batchDims; i < indicesRank; i++) {
    outputShape.push(indices.shape[i]);
  }
  for (let i = axis + 1; i < xRank; i++) {
    outputShape.push(x.shape[i]);
    sliceSize *= x.shape[i];
  }
  return { batchSize, sliceSize, outerSize, dimSize, outputShape };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js
function fromUint8ToStringArray2(vals) {
  try {
    return vals.map((val) => decodeString2(val));
  } catch (err) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
  }
}
function fromStringArrayToUint82(strings) {
  return strings.map((s) => encodeString2(s));
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js
var kernel_impls_exports2 = {};
__export(kernel_impls_exports2, {
  nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl2,
  nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl2,
  nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl2,
  whereImpl: () => whereImpl2
});

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/abs.js
getGlobalTensorClass2().prototype.abs = function() {
  this.throwIfDisposed();
  return abs2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acos.js
getGlobalTensorClass2().prototype.acos = function() {
  this.throwIfDisposed();
  return acos2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acosh.js
getGlobalTensorClass2().prototype.acosh = function() {
  this.throwIfDisposed();
  return acosh2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/add.js
getGlobalTensorClass2().prototype.add = function(b) {
  this.throwIfDisposed();
  return add4(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/all.js
getGlobalTensorClass2().prototype.all = function(axis, keepDims) {
  this.throwIfDisposed();
  return all2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/any.js
getGlobalTensorClass2().prototype.any = function(axis, keepDims) {
  this.throwIfDisposed();
  return any2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_max.js
getGlobalTensorClass2().prototype.argMax = function(axis) {
  this.throwIfDisposed();
  return argMax2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_min.js
getGlobalTensorClass2().prototype.argMin = function(axis) {
  this.throwIfDisposed();
  return argMin2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_scalar.js
getGlobalTensorClass2().prototype.asScalar = function() {
  this.throwIfDisposed();
  assert2(this.size === 1, () => "The array must have only 1 element.");
  return reshape2(this, []);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_type.js
getGlobalTensorClass2().prototype.asType = function(dtype) {
  this.throwIfDisposed();
  return cast2(this, dtype);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as1d.js
getGlobalTensorClass2().prototype.as1D = function() {
  this.throwIfDisposed();
  return reshape2(this, [this.size]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as2d.js
getGlobalTensorClass2().prototype.as2D = function(rows, columns) {
  this.throwIfDisposed();
  return reshape2(this, [rows, columns]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as3d.js
getGlobalTensorClass2().prototype.as3D = function(rows, columns, depth) {
  this.throwIfDisposed();
  return reshape2(this, [rows, columns, depth]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as4d.js
getGlobalTensorClass2().prototype.as4D = function(rows, columns, depth, depth2) {
  this.throwIfDisposed();
  return reshape2(this, [rows, columns, depth, depth2]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as5d.js
getGlobalTensorClass2().prototype.as5D = function(rows, columns, depth, depth2, depth3) {
  this.throwIfDisposed();
  return reshape2(this, [rows, columns, depth, depth2, depth3]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asin.js
getGlobalTensorClass2().prototype.asin = function() {
  this.throwIfDisposed();
  return asin2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asinh.js
getGlobalTensorClass2().prototype.asinh = function() {
  this.throwIfDisposed();
  return asinh2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan.js
getGlobalTensorClass2().prototype.atan = function() {
  this.throwIfDisposed();
  return atan3(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan2.js
getGlobalTensorClass2().prototype.atan2 = function(b) {
  this.throwIfDisposed();
  return atan22(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atanh.js
getGlobalTensorClass2().prototype.atanh = function() {
  this.throwIfDisposed();
  return atanh2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/avg_pool.js
getGlobalTensorClass2().prototype.avgPool = function(filterSize, strides, pad4, dimRoundingMode) {
  this.throwIfDisposed();
  return avgPool2(this, filterSize, strides, pad4, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batch_to_space_nd.js
getGlobalTensorClass2().prototype.batchToSpaceND = function(blockShape, crops) {
  this.throwIfDisposed();
  return batchToSpaceND2(this, blockShape, crops);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batchnorm.js
getGlobalTensorClass2().prototype.batchNorm = function(mean5, variance, offset, scale2, varianceEpsilon) {
  this.throwIfDisposed();
  return batchNorm2(this, mean5, variance, offset, scale2, varianceEpsilon);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/broadcast_to.js
getGlobalTensorClass2().prototype.broadcastTo = function(shape) {
  this.throwIfDisposed();
  return broadcastTo2(this, shape);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cast.js
getGlobalTensorClass2().prototype.cast = function(dtype) {
  this.throwIfDisposed();
  return cast2(this, dtype);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ceil.js
getGlobalTensorClass2().prototype.ceil = function() {
  this.throwIfDisposed();
  return ceil2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/clip_by_value.js
getGlobalTensorClass2().prototype.clipByValue = function(min7, max7) {
  this.throwIfDisposed();
  return clipByValue2(this, min7, max7);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/concat.js
getGlobalTensorClass2().prototype.concat = function(x, axis) {
  this.throwIfDisposed();
  if (x instanceof Tensor4) {
    x = [x];
  }
  return concat2([this, ...x], axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv1d.js
getGlobalTensorClass2().prototype.conv1d = function(filter, stride, pad4, dataFormat, dilation, dimRoundingMode) {
  this.throwIfDisposed();
  return conv1d2(this, filter, stride, pad4, dataFormat, dilation, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d_transpose.js
getGlobalTensorClass2().prototype.conv2dTranspose = function(filter, outputShape, strides, pad4, dimRoundingMode) {
  this.throwIfDisposed();
  return conv2dTranspose2(this, filter, outputShape, strides, pad4, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d.js
getGlobalTensorClass2().prototype.conv2d = function(filter, strides, pad4, dataFormat, dilations, dimRoundingMode) {
  this.throwIfDisposed();
  return conv2d3(this, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cos.js
getGlobalTensorClass2().prototype.cos = function() {
  this.throwIfDisposed();
  return cos2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cosh.js
getGlobalTensorClass2().prototype.cosh = function() {
  this.throwIfDisposed();
  return cosh2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cumsum.js
getGlobalTensorClass2().prototype.cumsum = function(axis, exclusive, reverse6) {
  this.throwIfDisposed();
  return cumsum2(this, axis, exclusive, reverse6);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depth_to_space.js
getGlobalTensorClass2().prototype.depthToSpace = function(blockSize, dataFormat) {
  this.throwIfDisposed();
  return depthToSpace2(this, blockSize, dataFormat);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depthwise_conv2d.js
getGlobalTensorClass2().prototype.depthwiseConv2d = function(filter, strides, pad4, dataFormat, dilations, dimRoundingMode) {
  this.throwIfDisposed();
  return depthwiseConv2d3(this, filter, strides, pad4, dataFormat, dilations, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dilation2d.js
getGlobalTensorClass2().prototype.dilation2d = function(filter, strides, pad4, dilations, dataFormat) {
  this.throwIfDisposed();
  return dilation2d2(this, filter, strides, pad4, dilations, dataFormat);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div_no_nan.js
getGlobalTensorClass2().prototype.divNoNan = function(b) {
  this.throwIfDisposed();
  return divNoNan2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div.js
getGlobalTensorClass2().prototype.div = function(b) {
  this.throwIfDisposed();
  return div2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dot.js
getGlobalTensorClass2().prototype.dot = function(b) {
  this.throwIfDisposed();
  return dot2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/elu.js
getGlobalTensorClass2().prototype.elu = function() {
  this.throwIfDisposed();
  return elu2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/equal.js
getGlobalTensorClass2().prototype.equal = function(b) {
  this.throwIfDisposed();
  return equal2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/erf.js
getGlobalTensorClass2().prototype.erf = function() {
  this.throwIfDisposed();
  return erf2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/exp.js
getGlobalTensorClass2().prototype.exp = function() {
  this.throwIfDisposed();
  return exp2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expand_dims.js
getGlobalTensorClass2().prototype.expandDims = function(axis) {
  this.throwIfDisposed();
  return expandDims2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expm1.js
getGlobalTensorClass2().prototype.expm1 = function() {
  this.throwIfDisposed();
  return expm12(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/fft.js
getGlobalTensorClass2().prototype.fft = function() {
  this.throwIfDisposed();
  return fft2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/flatten.js
getGlobalTensorClass2().prototype.flatten = function() {
  this.throwIfDisposed();
  return reshape2(this, [this.size]);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floor.js
getGlobalTensorClass2().prototype.floor = function() {
  this.throwIfDisposed();
  return floor2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floorDiv.js
getGlobalTensorClass2().prototype.floorDiv = function(b) {
  this.throwIfDisposed();
  return floorDiv2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/gather.js
getGlobalTensorClass2().prototype.gather = function(indices, axis) {
  this.throwIfDisposed();
  return gather2(this, indices, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater_equal.js
getGlobalTensorClass2().prototype.greaterEqual = function(b) {
  this.throwIfDisposed();
  return greaterEqual2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater.js
getGlobalTensorClass2().prototype.greater = function(b) {
  this.throwIfDisposed();
  return greater2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ifft.js
getGlobalTensorClass2().prototype.ifft = function() {
  this.throwIfDisposed();
  return ifft2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/irfft.js
getGlobalTensorClass2().prototype.irfft = function() {
  this.throwIfDisposed();
  return irfft2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_finite.js
getGlobalTensorClass2().prototype.isFinite = function() {
  this.throwIfDisposed();
  return isFinite3(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_inf.js
getGlobalTensorClass2().prototype.isInf = function() {
  this.throwIfDisposed();
  return isInf2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_nan.js
getGlobalTensorClass2().prototype.isNaN = function() {
  this.throwIfDisposed();
  return isNaN3(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/leaky_relu.js
getGlobalTensorClass2().prototype.leakyRelu = function(alpha) {
  this.throwIfDisposed();
  return leakyRelu2(this, alpha);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less_equal.js
getGlobalTensorClass2().prototype.lessEqual = function(b) {
  this.throwIfDisposed();
  return lessEqual2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less.js
getGlobalTensorClass2().prototype.less = function(b) {
  this.throwIfDisposed();
  return less2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/local_response_normalization.js
getGlobalTensorClass2().prototype.localResponseNormalization = function(depthRadius, bias, alpha, beta) {
  this.throwIfDisposed();
  return localResponseNormalization2(this, depthRadius, bias, alpha, beta);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sigmoid.js
getGlobalTensorClass2().prototype.logSigmoid = function() {
  this.throwIfDisposed();
  return logSigmoid2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_softmax.js
getGlobalTensorClass2().prototype.logSoftmax = function(axis) {
  this.throwIfDisposed();
  return logSoftmax2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sum_exp.js
getGlobalTensorClass2().prototype.logSumExp = function(axis, keepDims) {
  this.throwIfDisposed();
  return logSumExp2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log.js
getGlobalTensorClass2().prototype.log = function() {
  this.throwIfDisposed();
  return log3(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log1p.js
getGlobalTensorClass2().prototype.log1p = function() {
  this.throwIfDisposed();
  return log1p2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_and.js
getGlobalTensorClass2().prototype.logicalAnd = function(b) {
  this.throwIfDisposed();
  return logicalAnd2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_not.js
getGlobalTensorClass2().prototype.logicalNot = function() {
  this.throwIfDisposed();
  return logicalNot2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_or.js
getGlobalTensorClass2().prototype.logicalOr = function(b) {
  this.throwIfDisposed();
  return logicalOr2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_xor.js
getGlobalTensorClass2().prototype.logicalXor = function(b) {
  this.throwIfDisposed();
  return logicalXor2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mat_mul.js
getGlobalTensorClass2().prototype.matMul = function(b, transposeA, transposeB) {
  this.throwIfDisposed();
  return matMul3(this, b, transposeA, transposeB);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max_pool.js
getGlobalTensorClass2().prototype.maxPool = function(filterSize, strides, pad4, dimRoundingMode) {
  this.throwIfDisposed();
  return maxPool2(this, filterSize, strides, pad4, dimRoundingMode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max.js
getGlobalTensorClass2().prototype.max = function(axis, keepDims) {
  this.throwIfDisposed();
  return max2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/maximum.js
getGlobalTensorClass2().prototype.maximum = function(b) {
  this.throwIfDisposed();
  return maximum2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mean.js
getGlobalTensorClass2().prototype.mean = function(axis, keepDims) {
  this.throwIfDisposed();
  return mean2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/min.js
getGlobalTensorClass2().prototype.min = function(axis, keepDims) {
  this.throwIfDisposed();
  return min2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/minimum.js
getGlobalTensorClass2().prototype.minimum = function(b) {
  this.throwIfDisposed();
  return minimum2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mirror_pad.js
getGlobalTensorClass2().prototype.mirrorPad = function(paddings, mode) {
  this.throwIfDisposed();
  return mirrorPad2(this, paddings, mode);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mod.js
getGlobalTensorClass2().prototype.mod = function(b) {
  this.throwIfDisposed();
  return mod2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mul.js
getGlobalTensorClass2().prototype.mul = function(b) {
  this.throwIfDisposed();
  return mul2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/neg.js
getGlobalTensorClass2().prototype.neg = function() {
  this.throwIfDisposed();
  return neg2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/norm.js
getGlobalTensorClass2().prototype.norm = function(ord, axis, keepDims) {
  this.throwIfDisposed();
  return norm2(this, ord, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/not_equal.js
getGlobalTensorClass2().prototype.notEqual = function(b) {
  this.throwIfDisposed();
  return notEqual2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/one_hot.js
getGlobalTensorClass2().prototype.oneHot = function(depth, onValue = 1, offValue = 0) {
  this.throwIfDisposed();
  return oneHot2(this, depth, onValue, offValue);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ones_like.js
getGlobalTensorClass2().prototype.onesLike = function() {
  this.throwIfDisposed();
  return onesLike2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pad.js
getGlobalTensorClass2().prototype.pad = function(paddings, constantValue) {
  this.throwIfDisposed();
  return pad2(this, paddings, constantValue);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pool.js
getGlobalTensorClass2().prototype.pool = function(windowShape, poolingType, padding, dilationRate, strides) {
  this.throwIfDisposed();
  return pool2(this, windowShape, poolingType, padding, dilationRate, strides);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pow.js
getGlobalTensorClass2().prototype.pow = function(exp6) {
  this.throwIfDisposed();
  return pow2(this, exp6);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prelu.js
getGlobalTensorClass2().prototype.prelu = function(alpha) {
  this.throwIfDisposed();
  return prelu2(this, alpha);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prod.js
getGlobalTensorClass2().prototype.prod = function(axis, keepDims) {
  this.throwIfDisposed();
  return prod2(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reciprocal.js
getGlobalTensorClass2().prototype.reciprocal = function() {
  this.throwIfDisposed();
  return reciprocal2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu.js
getGlobalTensorClass2().prototype.relu = function() {
  this.throwIfDisposed();
  return relu2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu6.js
getGlobalTensorClass2().prototype.relu6 = function() {
  this.throwIfDisposed();
  return relu62(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape_as.js
getGlobalTensorClass2().prototype.reshapeAs = function(x) {
  this.throwIfDisposed();
  return reshape2(this, x.shape);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape.js
getGlobalTensorClass2().prototype.reshape = function(shape) {
  this.throwIfDisposed();
  return reshape2(this, shape);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_bilinear.js
getGlobalTensorClass2().prototype.resizeBilinear = function(newShape2D, alignCorners, halfPixelCenters) {
  this.throwIfDisposed();
  return resizeBilinear2(this, newShape2D, alignCorners, halfPixelCenters);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_nearest_neighbor.js
getGlobalTensorClass2().prototype.resizeNearestNeighbor = function(newShape2D, alignCorners, halfFloatCenters) {
  this.throwIfDisposed();
  return resizeNearestNeighbor2(this, newShape2D, alignCorners, halfFloatCenters);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reverse.js
getGlobalTensorClass2().prototype.reverse = function(axis) {
  this.throwIfDisposed();
  return reverse2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rfft.js
getGlobalTensorClass2().prototype.rfft = function() {
  this.throwIfDisposed();
  return rfft2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/round.js
getGlobalTensorClass2().prototype.round = function() {
  this.throwIfDisposed();
  return round4(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rsqrt.js
getGlobalTensorClass2().prototype.rsqrt = function() {
  this.throwIfDisposed();
  return rsqrt2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/selu.js
getGlobalTensorClass2().prototype.selu = function() {
  this.throwIfDisposed();
  return selu2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/separable_conv2d.js
getGlobalTensorClass2().prototype.separableConv2d = function(depthwiseFilter, pointwiseFilter, strides, pad4, dilation, dataFormat) {
  this.throwIfDisposed();
  return separableConv2d2(this, depthwiseFilter, pointwiseFilter, strides, pad4, dilation, dataFormat);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sigmoid.js
getGlobalTensorClass2().prototype.sigmoid = function() {
  this.throwIfDisposed();
  return sigmoid2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sign.js
getGlobalTensorClass2().prototype.sign = function() {
  this.throwIfDisposed();
  return sign2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sin.js
getGlobalTensorClass2().prototype.sin = function() {
  this.throwIfDisposed();
  return sin2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sinh.js
getGlobalTensorClass2().prototype.sinh = function() {
  this.throwIfDisposed();
  return sinh2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/slice.js
getGlobalTensorClass2().prototype.slice = function(begin, size) {
  this.throwIfDisposed();
  return slice2(this, begin, size);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softmax.js
getGlobalTensorClass2().prototype.softmax = function(dim) {
  this.throwIfDisposed();
  return softmax2(this, dim);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softplus.js
getGlobalTensorClass2().prototype.softplus = function() {
  this.throwIfDisposed();
  return softplus2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/space_to_batch_nd.js
getGlobalTensorClass2().prototype.spaceToBatchND = function(blockShape, paddings) {
  this.throwIfDisposed();
  return spaceToBatchND2(this, blockShape, paddings);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/split.js
getGlobalTensorClass2().prototype.split = function(numOrSizeSplits, axis) {
  this.throwIfDisposed();
  return split2(this, numOrSizeSplits, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sqrt.js
getGlobalTensorClass2().prototype.sqrt = function() {
  this.throwIfDisposed();
  return sqrt2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/square.js
getGlobalTensorClass2().prototype.square = function() {
  this.throwIfDisposed();
  return square2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js
getGlobalTensorClass2().prototype.squaredDifference = function(b) {
  this.throwIfDisposed();
  return squaredDifference2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squeeze.js
getGlobalTensorClass2().prototype.squeeze = function(axis) {
  this.throwIfDisposed();
  return squeeze2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/stack.js
getGlobalTensorClass2().prototype.stack = function(x, axis) {
  this.throwIfDisposed();
  const tensorsToBeStacked = x instanceof Tensor4 ? [this, x] : [this, ...x];
  return stack2(tensorsToBeStacked, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/step.js
getGlobalTensorClass2().prototype.step = function(alpha) {
  this.throwIfDisposed();
  return step2(this, alpha);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/strided_slice.js
getGlobalTensorClass2().prototype.stridedSlice = function(begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
  this.throwIfDisposed();
  return stridedSlice2(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sub.js
getGlobalTensorClass2().prototype.sub = function(b) {
  this.throwIfDisposed();
  return sub2(this, b);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sum.js
getGlobalTensorClass2().prototype.sum = function(axis, keepDims) {
  this.throwIfDisposed();
  return sum4(this, axis, keepDims);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tan.js
getGlobalTensorClass2().prototype.tan = function() {
  this.throwIfDisposed();
  return tan2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tanh.js
getGlobalTensorClass2().prototype.tanh = function() {
  this.throwIfDisposed();
  return tanh4(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tile.js
getGlobalTensorClass2().prototype.tile = function(reps) {
  this.throwIfDisposed();
  return tile2(this, reps);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_bool.js
getGlobalTensorClass2().prototype.toBool = function() {
  this.throwIfDisposed();
  return cast2(this, "bool");
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_float.js
getGlobalTensorClass2().prototype.toFloat = function() {
  this.throwIfDisposed();
  return cast2(this, "float32");
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_int.js
getGlobalTensorClass2().prototype.toInt = function() {
  this.throwIfDisposed();
  return cast2(this, "int32");
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/topk.js
getGlobalTensorClass2().prototype.topk = function(k, sorted) {
  this.throwIfDisposed();
  return topk2(this, k, sorted);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/transpose.js
getGlobalTensorClass2().prototype.transpose = function(perm) {
  this.throwIfDisposed();
  return transpose2(this, perm);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unique.js
getGlobalTensorClass2().prototype.unique = function(axis) {
  this.throwIfDisposed();
  return unique2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unsorted_segment_sum.js
getGlobalTensorClass2().prototype.unsortedSegmentSum = function(segmentIds, numSegments) {
  this.throwIfDisposed();
  return unsortedSegmentSum2(this, segmentIds, numSegments);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unstack.js
getGlobalTensorClass2().prototype.unstack = function(axis) {
  this.throwIfDisposed();
  return unstack2(this, axis);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/where.js
getGlobalTensorClass2().prototype.where = function(condition, x) {
  this.throwIfDisposed();
  return where2(condition, this, x);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/zeros_like.js
getGlobalTensorClass2().prototype.zerosLike = function() {
  this.throwIfDisposed();
  return zerosLike2(this);
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Abs_grad.js
var absGradConfig = {
  kernelName: Abs2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(dy, step2(cast2(x, "float32"), -1)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Acos_grad.js
var acosGradConfig = {
  kernelName: Acos2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return {
      x: () => {
        const a = square2(cast2(x, "float32"));
        const b = sqrt2(sub2(scalar2(1), a));
        return neg2(div2(dy, b));
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Acosh_grad.js
var acoshGradConfig = {
  kernelName: Acosh2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return {
      x: () => {
        const a = sqrt2(sub2(square2(cast2(x, "float32")), 1));
        return div2(dy, a);
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Add_grad.js
var addGradConfig = {
  kernelName: Add2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      let res = dy;
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, a.shape);
    };
    const derB = () => {
      let res = dy;
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, b.shape);
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/AddN_grad.js
var addNGradConfig = {
  kernelName: AddN2,
  saveAllInputs: true,
  gradFunc: (dy, saved) => {
    const ders = {};
    saved.forEach((_, i) => {
      ders[i] = () => dy.clone();
    });
    return ders;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMax_grad.js
var argMaxGradConfig = {
  kernelName: ArgMax2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => zerosLike2(x) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMin_grad.js
var argMinGradConfig = {
  kernelName: ArgMin2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => zerosLike2(x) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Asin_grad.js
var asinGradConfig = {
  kernelName: Asin2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, sqrt2(sub2(scalar2(1), square2(cast2(x, "float32"))))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Asinh_grad.js
var asinhGradConfig = {
  kernelName: Asinh2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return {
      x: () => {
        const a = sqrt2(add4(scalar2(1), square2(cast2(x, "float32"))));
        return div2(dy, a);
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Atan2_grad.js
var atan2GradConfig = {
  kernelName: Atan22,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      const d = add4(square2(a), square2(b));
      let res = mul2(dy, div2(b, d));
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, a.shape);
    };
    const derB = () => {
      const d = add4(square2(a), square2(b));
      let res = neg2(mul2(dy, div2(a, d)));
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, b.shape);
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Atan_grad.js
var atanGradConfig = {
  kernelName: Atan3,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, add4(square2(cast2(x, "float32")), 1)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Atanh_grad.js
var atanhGradConfig = {
  kernelName: Atanh2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, sub2(scalar2(1), square2(cast2(x, "float32")))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js
function avgPool3dGrad_(dy, input2, filterSize, strides, pad4, dimRoundingMode) {
  const $dy = convertToTensor2(dy, "dy", "avgPool3dGrad");
  const $input = convertToTensor2(input2, "input", "avgPool3dGrad");
  let dy5D = $dy;
  let input5D = $input;
  let reshapedTo5D = false;
  if ($input.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape2($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
    input5D = reshape2($input, [
      1,
      $input.shape[0],
      $input.shape[1],
      $input.shape[2],
      $input.shape[3]
    ]);
  }
  assert2(dy5D.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
  assert2(input5D.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { dy: dy5D, input: input5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  const res = ENGINE2.runKernel(AvgPool3DGrad2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3dGrad = op2({ avgPool3dGrad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool3D_grad.js
var avgPool3DGradConfig = {
  kernelName: AvgPool3D2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
    return {
      x: () => avgPool3dGrad(dy, x, filterSize, strides, pad4, dimRoundingMode)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js
function avgPoolGrad_(dy, input2, filterSize, strides, pad4) {
  const $dy = convertToTensor2(dy, "dy", "avgPoolGrad");
  const $input = convertToTensor2(input2, "input", "avgPoolGrad");
  assert2($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
  let input4D = $input;
  let dy4D = $dy;
  let reshapedTo4D = false;
  if ($input.rank === 3) {
    reshapedTo4D = true;
    input4D = reshape2($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);
    dy4D = reshape2($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);
  }
  assert2(dy4D.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${dy4D.rank}.`);
  assert2(input4D.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${input4D.rank}.`);
  const inputs = { dy: dy4D, input: input4D };
  const attrs = { filterSize, strides, pad: pad4 };
  const res = ENGINE2.runKernel(AvgPoolGrad2, inputs, attrs);
  if (reshapedTo4D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPoolGrad = op2({ avgPoolGrad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool_grad.js
var avgPoolGradConfig = {
  kernelName: AvgPool2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { filterSize, strides, pad: pad4 } = attrs;
    return { x: () => avgPoolGrad(dy, x, filterSize, strides, pad4) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/BatchMatMul_grad.js
var batchMatMulGradConfig = {
  kernelName: BatchMatMul2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved, attrs) => {
    const [a, b] = saved;
    const { transposeA, transposeB } = attrs;
    if (!transposeA && !transposeB) {
      return {
        a: () => matMul3(dy, b, false, true),
        b: () => matMul3(a, dy, true, false)
      };
    } else if (!transposeA && transposeB) {
      return {
        a: () => matMul3(dy, b, false, false),
        b: () => matMul3(dy, a, true, false)
      };
    } else if (transposeA && !transposeB) {
      return {
        a: () => matMul3(b, dy, false, true),
        b: () => matMul3(a, dy, false, false)
      };
    } else {
      return {
        a: () => matMul3(b, dy, true, true),
        b: () => matMul3(dy, a, true, true)
      };
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/BatchToSpaceND_grad.js
var batchToSpaceNDGradConfig = {
  kernelName: BatchToSpaceND2,
  gradFunc: (dy, saved, attrs) => {
    const { blockShape, crops } = attrs;
    return { x: () => spaceToBatchND2(dy, blockShape, crops) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/BroadcastTo_grad.js
var broadcastToGradConfig = {
  kernelName: BroadcastTo2,
  gradFunc: (dy, saved, attrs) => {
    const broadCastToAttrs = attrs;
    const inputShape = broadCastToAttrs.inputShape;
    const outputShape = broadCastToAttrs.shape;
    const reps = Array.from(outputShape);
    for (let i = inputShape.length - 1; i >= 0; i--) {
      if (inputShape[i] === outputShape[i]) {
        reps[i] = 1;
      } else if (inputShape[i] !== 1) {
        throw new Error(`broadcastTo(): [${inputShape}] cannot be broadcast to [${outputShape}].`);
      }
    }
    const axes = [];
    for (let i = 0; i < reps.length; i++) {
      if (reps[i] > 1) {
        axes.push(i);
      }
    }
    return { x: () => sum4(dy, axes, true) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Cast_grad.js
var castGradConfig = {
  kernelName: Cast2,
  gradFunc: (dy) => {
    return { x: () => dy.clone() };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Ceil_grad.js
var ceilGradConfig = {
  kernelName: Ceil2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ClipByValue_grad.js
var clipByValueGradConfig = {
  kernelName: ClipByValue2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { clipValueMin, clipValueMax } = attrs;
    return {
      x: () => where2(logicalAnd2(greaterEqual2(x, clipValueMin), lessEqual2(x, clipValueMax)), dy, zerosLike2(dy))
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ComplexAbs_grad.js
var complexAbsGradConfig = {
  kernelName: ComplexAbs2,
  inputsToSave: ["x"],
  gradFunc: absGradConfig.gradFunc
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Concat_grad.js
var concatGradConfig = {
  kernelName: Concat2,
  saveAllInputs: true,
  gradFunc: (dy, saved, attrs) => {
    const shapes = saved.map((t) => t.shape);
    const { axis } = attrs;
    const $axis = parseAxisParam2(axis, saved[0].shape)[0];
    const sizeSplits = shapes.map((s) => s[$axis]);
    const derTensors = split2(dy, sizeSplits, $axis);
    return derTensors.map((t) => () => t);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2D_grad.js
var conv2DGradConfig = {
  kernelName: Conv2D2,
  inputsToSave: ["x", "filter"],
  gradFunc: (dy, saved, attrs) => {
    const [x4D, $filter] = saved;
    const { dilations, strides, pad: pad4, dataFormat } = attrs;
    assert2(tupleValuesAreOne2(dilations), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    return {
      x: () => conv2DBackpropInput2(x4D.shape, dy, $filter, strides, pad4, dataFormat),
      filter: () => conv2DBackpropFilter2(x4D, dy, $filter.shape, strides, pad4, dataFormat)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2DBackpropInput_grad.js
var conv2DBackpropInputGradConfig = {
  kernelName: Conv2DBackpropInput2,
  inputsToSave: ["dy", "filter"],
  gradFunc: (ddx, saved, attrs) => {
    const [dy, filter] = saved;
    const { strides, pad: pad4, dataFormat, dimRoundingMode } = attrs;
    return {
      dy: () => conv2d3(ddx, filter, strides, pad4, dataFormat, 1, dimRoundingMode),
      filter: () => conv2DBackpropFilter2(ddx, dy, filter.shape, strides, pad4, dataFormat, dimRoundingMode)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js
function conv3DBackpropFilter_(x, dy, filterShape, strides, pad4) {
  let x5D = x;
  if (x.rank === 4) {
    x5D = reshape2(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);
  }
  let dy5D = dy;
  if (dy5D.rank === 4) {
    dy5D = reshape2(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
  }
  assert2(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${x5D.shape}.`);
  assert2(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${dy5D.shape}.`);
  assert2(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${filterShape}.`);
  assert2(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must match input depth in filter (${filterShape[3]}.`);
  assert2(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must match output depth for filter (${filterShape[4]}).`);
  const inputs = { x: x5D, dy: dy5D };
  const attrs = { strides, pad: pad4, filterShape };
  return ENGINE2.runKernel(Conv3DBackpropFilterV22, inputs, attrs);
}
var conv3DBackpropFilter = op2({ conv3DBackpropFilter_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Conv3D_grad.js
var conv3DGradConfig = {
  kernelName: Conv3D2,
  inputsToSave: ["x", "filter"],
  gradFunc: (dy, saved, attrs) => {
    const { dilations, strides, pad: pad4 } = attrs;
    assert2(tupleValuesAreOne2(dilations), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    const [x5D, $filter] = saved;
    return {
      x: () => conv3DBackpropInput2(x5D.shape, dy, $filter, strides, pad4),
      filter: () => conv3DBackpropFilter(x5D, dy, $filter.shape, strides, pad4)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Cos_grad.js
var cosGradConfig = {
  kernelName: Cos2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(neg2(sin2(cast2(x, "float32"))), dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Cosh_grad.js
var coshGradConfig = {
  kernelName: Cosh2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(sinh2(cast2(x, "float32")), dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Cumsum_grad.js
var cumsumGradConfig = {
  kernelName: Cumsum2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { axis, exclusive, reverse: reverse6 } = attrs;
    return {
      x: () => {
        const permutation = getAxesPermutation2([axis], x.rank);
        let out = cumsum2(dy, axis, exclusive, !reverse6);
        if (permutation != null) {
          out = transpose2(out, permutation);
        }
        return out;
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/DepthwiseConv2dNative_grad.js
var depthwiseConv2dNativeGradConfig = {
  kernelName: DepthwiseConv2dNative2,
  inputsToSave: ["x", "filter"],
  gradFunc: (dy, saved, attrs) => {
    const { dilations, strides, pad: pad4, dimRoundingMode } = attrs;
    const $dilations = dilations == null ? [1, 1] : dilations;
    assert2(tupleValuesAreOne2($dilations), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${$dilations}'`);
    const [x, filter] = saved;
    assert2(x.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${x.rank}.`);
    assert2(filter.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${filter.rank}.`);
    assert2(x.shape[3] === filter.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${x.shape[3]}) must match the inChannels dimension in filter ${filter.shape[2]}.`);
    assert2(eitherStridesOrDilationsAreOne2(strides, $dilations), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${strides} and dilations '${$dilations}'.`);
    if (dimRoundingMode != null) {
      assert2(isInt2(pad4), () => `Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
    }
    return {
      x: () => depthwiseConv2dNativeBackpropInput2(x.shape, dy, filter, strides, pad4, dilations, dimRoundingMode),
      filter: () => depthwiseConv2dNativeBackpropFilter2(x, dy, filter.shape, strides, pad4, dilations, dimRoundingMode)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Dilation2D_grad.js
var dilation2dGradConfig = {
  kernelName: Dilation2D2,
  inputsToSave: ["x", "filter"],
  gradFunc: (dy, saved, attrs) => {
    const [x, filter] = saved;
    const inputInputs = { x, filter, dy };
    const filterInputs = { x, filter, dy };
    return {
      x: () => ENGINE2.runKernel(Dilation2DBackpropInput2, inputInputs, attrs),
      filter: () => ENGINE2.runKernel(Dilation2DBackpropFilter2, filterInputs, attrs)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Elu_grad.js
var eluGradConfig = {
  kernelName: Elu2,
  outputsToSave: [true],
  gradFunc: (dy, saved) => {
    const [y] = saved;
    const inputs = { dy, y };
    return { x: () => ENGINE2.runKernel(EluGrad2, inputs) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Erf_grad.js
var erfGradConfig = {
  kernelName: Erf2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    const a = mul2(exp2(neg2(square2(x))), 2 / Math.sqrt(Math.PI));
    return { x: () => mul2(dy, a) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Exp_grad.js
var expGradConfig = {
  kernelName: Exp2,
  outputsToSave: [true],
  gradFunc: (dy, saved) => {
    const [y] = saved;
    return { x: () => mul2(dy, y) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ExpandDims_grad.js
var expandDimsGradConfig = {
  kernelName: ExpandDims2,
  inputsToSave: ["input"],
  gradFunc: (dy, saved) => {
    const [input2] = saved;
    return { input: () => reshape2(dy, input2.shape) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Expm1_grad.js
var expm1GradConfig = {
  kernelName: Expm12,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(dy, exp2(x)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Floor_grad.js
var floorGradConfig = {
  kernelName: Floor2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/FloorDiv_grad.js
var floorDivGradConfig = {
  kernelName: FloorDiv2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      const res = div2(dy, cast2(b, "float32"));
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(res, reduceAxes), a.shape);
      }
      return res;
    };
    const derB = () => {
      let res = mul2(dy, cast2(a, "float32"));
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        res = reshape2(sum4(res, reduceAxes), b.shape);
      }
      const tmp = square2(b);
      return neg2(div2(res, cast2(tmp, "float32")));
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/FusedBatchNorm_grad.js
var fusedBatchNormGradConfig = {
  kernelName: FusedBatchNorm2,
  inputsToSave: ["x", "mean", "variance", "scale"],
  gradFunc: (dy, saved, attrs) => {
    const { varianceEpsilon } = attrs;
    const [x, mean5, variance, scale2] = saved;
    const scaleValue = scale2 == null ? scalar2(1) : scale2;
    const reductionAxes = getReductionAxes2(mean5.shape, x.shape);
    const tileShape = [];
    if (mean5.rank === 1) {
      for (let i = 0; i < x.shape.length - 1; ++i) {
        tileShape.push(x.shape[i]);
      }
      tileShape.push(1);
    }
    const xMinusMean = sub2(x, mean5);
    const dyTimesScaleValue = mul2(dy, scaleValue);
    const oneOverSqrtVariance = rsqrt2(add4(variance, scalar2(varianceEpsilon)));
    const minusHalfRCube = mul2(mul2(mul2(oneOverSqrtVariance, oneOverSqrtVariance), oneOverSqrtVariance), scalar2(-0.5));
    const derX = () => {
      if (mean5.rank === 1) {
        return reshape2(mul2(mul2(dy, tile2(reshape2(oneOverSqrtVariance, [1, 1, 1, mean5.shape[0]]), tileShape)), scaleValue), x.shape);
      } else {
        return reshape2(mul2(mul2(dy, oneOverSqrtVariance), scaleValue), x.shape);
      }
    };
    const derMean = () => {
      let meanDer = mul2(mul2(oneOverSqrtVariance, scalar2(-1)), dyTimesScaleValue);
      if (mean5.rank === 1) {
        meanDer = sum4(meanDer, reductionAxes);
      }
      return reshape2(meanDer, mean5.shape);
    };
    const derVariance = () => {
      let varianceDer = mul2(mul2(minusHalfRCube, xMinusMean), dyTimesScaleValue);
      if (mean5.rank === 1) {
        varianceDer = sum4(varianceDer, reductionAxes);
      }
      return reshape2(varianceDer, mean5.shape);
    };
    const derScale = () => {
      const xMinusMean2TimesRsqrt = mul2(xMinusMean, oneOverSqrtVariance);
      let scaleDer = mul2(dy, xMinusMean2TimesRsqrt);
      if (mean5.rank === 1) {
        scaleDer = sum4(scaleDer, reductionAxes);
      }
      return reshape2(scaleDer, mean5.shape);
    };
    const derOffset = () => {
      let offsetDer = dy;
      if (mean5.rank === 1) {
        offsetDer = sum4(offsetDer, reductionAxes);
      }
      return reshape2(offsetDer, mean5.shape);
    };
    return {
      x: derX,
      mean: derMean,
      variance: derVariance,
      scale: derScale,
      offset: derOffset
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/GatherV2_grad.js
var gatherGradConfig = {
  kernelName: GatherV22,
  inputsToSave: ["x", "indices"],
  gradFunc: (dy, saved, attrs) => {
    const [x, indices] = saved;
    const { axis } = attrs;
    const parsedAxis = parseAxisParam2(axis, x.shape)[0];
    const derX = () => {
      const paramsShape = x.shape;
      const indicesSize = indices.size;
      const outerShape = paramsShape.slice(0, parsedAxis);
      const outerDims = outerShape.length;
      const innerShape = paramsShape.slice(axis, paramsShape.length).slice(1);
      const innerDims = innerShape.length;
      const outerAxesIndices = arrayRange(0, outerDims);
      const innerAxesIndices = arrayRange(outerDims + 1, outerDims + 1 + innerDims);
      const valuesShape = arrayConcat([outerShape, [indicesSize], innerShape]);
      const values = reshape2(dy, valuesShape);
      const reshapedIndices = reshape2(indices, [indicesSize]);
      const transposeDims = arrayConcat([[outerDims], outerAxesIndices, innerAxesIndices]);
      const valuesTranspose = transpose2(values, transposeDims);
      let paramsGrad = unsortedSegmentSum2(valuesTranspose, reshapedIndices, x.shape[parsedAxis]);
      const invertTransposeDims = getUndoAxesPermutation2(transposeDims);
      paramsGrad = transpose2(paramsGrad, invertTransposeDims);
      return paramsGrad;
    };
    return { x: derX, indices: () => indices };
  }
};
function arrayRange(start, stop) {
  const result = [];
  for (let i = start; i < stop; ++i) {
    result.push(i);
  }
  return result;
}
function arrayConcat(arrays) {
  const result = [];
  for (let i = 0; i < arrays.length; ++i) {
    for (let j = 0; j < arrays[i].length; ++j) {
      result.push(arrays[i][j]);
    }
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/GreaterEqual_grad.js
var greaterEqualGradConfig = {
  kernelName: GreaterEqual2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    return { a: () => zerosLike2(a), b: () => zerosLike2(b) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Identity_grad.js
var identityGradConfig = {
  kernelName: Identity2,
  gradFunc: (dy) => {
    return { x: () => cast2(dy, "float32") };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/IsFinite_grad.js
var isFiniteGradConfig = {
  kernelName: IsFinite2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/IsInf_grad.js
var isInfGradConfig = {
  kernelName: IsInf2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/IsNan_grad.js
var isNanGradConfig = {
  kernelName: IsNan2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/LeakyRelu_grad.js
var leakyReluGradConfig = {
  kernelName: LeakyRelu2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { alpha } = attrs;
    const mask = greater2(x, 0);
    return { x: () => where2(mask, dy, mul2(dy, alpha)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Log1p_grad.js
var log1pGradConfig = {
  kernelName: Log1p2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, add4(x, 1)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Log_grad.js
var logGradConfig = {
  kernelName: Log2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, cast2(x, "float32")) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/LogSoftmax_grad.js
var logSoftmaxGradConfig = {
  kernelName: LogSoftmax2,
  inputsToSave: [],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const [value] = saved;
    const { axis } = attrs;
    return {
      logits: () => {
        const keepDims = true;
        const softmax7 = exp2(value);
        return sub2(dy, mul2(sum4(dy, axis, keepDims), softmax7));
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization_backprop.js
function localResponseNormalizationBackprop_(x, y, dy, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const inputs = { x, y, dy };
  const attrs = { depthRadius, bias, alpha, beta };
  return ENGINE2.runKernel(LRNGrad2, inputs, attrs);
}
var localResponseNormalizationBackprop = op2({ localResponseNormalizationBackprop_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/LRN_grad.js
var lrnGradConfig = {
  kernelName: LRN2,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const [x, y] = saved;
    const { depthRadius, bias, alpha, beta } = attrs;
    return {
      x: () => localResponseNormalizationBackprop(x, y, dy, depthRadius, bias, alpha, beta)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/min_max_grad_util.js
function gradForMinAndMax(dy, y, xOrig, origAxes) {
  if (y.rank < xOrig.rank) {
    y = reshape2(y, expandShapeToKeepDim2(y.shape, origAxes));
  }
  if (dy.rank < xOrig.rank) {
    dy = reshape2(dy, expandShapeToKeepDim2(dy.shape, origAxes));
  }
  return {
    x: () => {
      const dx = mul2(dy, cast2(equal2(xOrig, y), dy.dtype));
      return dx;
    }
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Max_grad.js
var maxGradConfig = {
  kernelName: Max2,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const maxAttrs = attrs;
    const { reductionIndices } = maxAttrs;
    const x = saved[0];
    const y = saved[1];
    const origAxes = parseAxisParam2(reductionIndices, x.shape);
    const maxGrad = gradForMinAndMax(dy, y, x, origAxes);
    return {
      x: () => {
        return maxGrad["x"]();
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Maximum_grad.js
var maximumGradConfig = {
  kernelName: Maximum2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const derA = () => mul2(dy, cast2(greaterEqual2(a, b), "float32"));
    const derB = () => mul2(dy, cast2(less2(a, b), "float32"));
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d_grad.js
function maxPool3dGrad_(dy, input2, output, filterSize, strides, pad4, dimRoundingMode) {
  const $dy = convertToTensor2(dy, "dy", "maxPool3dGrad");
  const $input = convertToTensor2(input2, "input", "maxPool3dGrad");
  const $output = convertToTensor2(output, "output", "maxPool3dGrad");
  let dy5D = $dy;
  let input5D = $input;
  let output5D = $output;
  let reshapedTo5D = false;
  if ($input.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape2($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
    input5D = reshape2($input, [
      1,
      $input.shape[0],
      $input.shape[1],
      $input.shape[2],
      $input.shape[3]
    ]);
    output5D = reshape2($output, [
      1,
      $output.shape[0],
      $output.shape[1],
      $output.shape[2],
      $output.shape[3]
    ]);
  }
  assert2(dy5D.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
  assert2(input5D.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
  assert2(output5D.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${output5D.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { dy: dy5D, input: input5D, output: output5D };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  const res = ENGINE2.runKernel(MaxPool3DGrad2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape2(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3dGrad = op2({ maxPool3dGrad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool3D_grad.js
var maxPool3DGradConfig = {
  kernelName: MaxPool3D2,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const [x, y] = saved;
    const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
    return {
      x: () => maxPool3dGrad(dy, x, y, filterSize, strides, pad4, dimRoundingMode)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_grad.js
function maxPoolGrad_(dy, input2, output, filterSize, strides, pad4, dimRoundingMode) {
  const $dy = convertToTensor2(dy, "dy", "maxPoolGrad");
  const $input = convertToTensor2(input2, "input", "maxPoolGrad");
  const $output = convertToTensor2(output, "output", "maxPoolGrad");
  assert2($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
  assert2($dy.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${$dy.rank}.`);
  assert2($input.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${$input.rank}.`);
  if (dimRoundingMode != null) {
    assert2(isInt2(pad4), () => `Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ${dimRoundingMode} but got pad ${pad4}.`);
  }
  const inputs = { dy: $dy, input: $input, output: $output };
  const attrs = { filterSize, strides, pad: pad4, dimRoundingMode };
  return ENGINE2.runKernel(MaxPoolGrad2, inputs, attrs);
}
var maxPoolGrad = op2({ maxPoolGrad_ });

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool_grad.js
var maxPoolGradConfig = {
  kernelName: MaxPool2,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const [x, y] = saved;
    const { filterSize, strides, pad: pad4 } = attrs;
    return {
      x: () => maxPoolGrad(dy, x, y, filterSize, strides, pad4)
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Mean_grad.js
var meanGradConfig = {
  kernelName: Mean2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { axis } = attrs;
    const axes = parseAxisParam2(axis, x.shape);
    const shapes = computeOutAndReduceShapes2(x.shape, axes);
    const reduceShape = shapes[1];
    const reduceSize = sizeFromShape2(reduceShape);
    const derX = () => {
      const expandedDyShape = x.shape.slice();
      axes.forEach((axis2) => {
        expandedDyShape[axis2] = 1;
      });
      const expandedDy = reshape2(dy, expandedDyShape);
      const res = div2(mul2(expandedDy, ones4(x.shape, "float32")), reduceSize);
      return res;
    };
    return { x: derX };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Min_grad.js
var minGradConfig = {
  kernelName: Min2,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const minAttrs = attrs;
    const { axis } = minAttrs;
    const [x, y] = saved;
    const origAxes = parseAxisParam2(axis, x.shape);
    const minGrad = gradForMinAndMax(dy, y, x, origAxes);
    return {
      x: () => {
        return minGrad["x"]();
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Minimum_grad.js
var minimumGradConfig = {
  kernelName: Minimum2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const derA = () => mul2(dy, cast2(lessEqual2(a, b), "float32"));
    const derB = () => mul2(dy, cast2(greater2(a, b), "float32"));
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/MirrorPad_grad.js
var mirrorPadGradConfig = {
  kernelName: MirrorPad2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const x = saved[0];
    const { paddings } = attrs;
    const begin = paddings.map((p2) => p2[0]);
    return { x: () => slice2(dy, begin, x.shape) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Mod_grad.js
var modGradConfig = {
  kernelName: Mod2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(dy, reduceAxes), a.shape);
      }
      return dy;
    };
    const derB = () => {
      const res = mul2(dy, neg2(floor2(div2(a, b))));
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(res, reduceAxes), b.shape);
      }
      return res;
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Multiply_grad.js
var multiplyGradConfig = {
  kernelName: Multiply2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      const res = mul2(dy, cast2(b, "float32"));
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(res, reduceAxes), a.shape);
      }
      return res;
    };
    const derB = () => {
      const res = mul2(dy, cast2(a, "float32"));
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(res, reduceAxes), b.shape);
      }
      return res;
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Neg_grad.js
var negGradConfig = {
  kernelName: Neg2,
  gradFunc: (dy) => {
    return { x: () => neg2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/OneHot_grad.js
var oneHotGradConfig = {
  kernelName: OneHot2,
  inputsToSave: ["indices"],
  gradFunc: (dy, saved) => {
    const indices = saved[0];
    return { indices: () => zeros2(indices.shape, "float32") };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/OnesLike_grad.js
var onesLikeGradConfig = {
  kernelName: OnesLike2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Pack_grad.js
var packGradConfig = {
  kernelName: Pack2,
  saveAllInputs: true,
  gradFunc: (dy, saved, attrs) => {
    const { axis } = attrs;
    const derTensors = unstack2(dy, axis);
    return derTensors.map((t) => () => t);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/PadV2_grad.js
var padV2GradConfig = {
  kernelName: PadV22,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const x = saved[0];
    const { paddings } = attrs;
    const begin = paddings.map((p2) => p2[0]);
    return { x: () => slice2(dy, begin, x.shape) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Pow_grad.js
var powGradConfig = {
  kernelName: Pow2,
  inputsToSave: ["a", "b"],
  outputsToSave: [true],
  gradFunc: (dy, saved) => {
    const [a, b, y] = saved;
    const base3 = a;
    const exp6 = b;
    const outShape = assertAndGetBroadcastShape2(base3.shape, exp6.shape);
    const derBase = () => {
      const expFloat = cast2(exp6, "float32");
      let res = mul2(dy, mul2(expFloat, pow2(base3, sub2(expFloat, scalar2(1)))));
      const reduceAxes = getReductionAxes2(base3.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, base3.shape);
    };
    const derExp = () => {
      const condition = greater2(base3, 0);
      const logBase = where2(condition, log3(base3), zerosLike2(base3));
      let res = mul2(dy, mul2(y, logBase));
      const reduceAxes = getReductionAxes2(exp6.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, exp6.shape);
    };
    return { a: derBase, b: derExp };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Prelu_grad.js
var preluGradConfig = {
  kernelName: Prelu2,
  inputsToSave: ["x", "alpha"],
  gradFunc: (dy, saved) => {
    const [x, alpha] = saved;
    const mask = greater2(x, 0);
    return {
      x: () => where2(mask, dy, mul2(dy, alpha)),
      alpha: () => {
        let res = where2(mask, zerosLike2(dy), mul2(dy, x));
        const reduceAxes = getReductionAxes2(alpha.shape, dy.shape);
        if (reduceAxes.length > 0) {
          res = sum4(res, reduceAxes);
        }
        return reshape2(res, alpha.shape);
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/RealDiv_grad.js
var divGradConfig = {
  kernelName: RealDiv2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      const res = div2(dy, cast2(b, "float32"));
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        return reshape2(sum4(res, reduceAxes), a.shape);
      }
      return res;
    };
    const derB = () => {
      let res = mul2(dy, cast2(a, "float32"));
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        res = reshape2(sum4(res, reduceAxes), b.shape);
      }
      const tmp = square2(b);
      return neg2(div2(res, cast2(tmp, "float32")));
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Reciprocal_grad.js
var reciprocalGradConfig = {
  kernelName: Reciprocal2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, neg2(square2(x))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Relu6_grad.js
var relu6GradConfig = {
  kernelName: Relu62,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    const mask = mul2(lessEqual2(x, 6), step2(x));
    return { x: () => mul2(dy, cast2(mask, "float32")) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Relu_grad.js
var reluGradConfig = {
  kernelName: Relu2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(dy, cast2(step2(x), "float32")) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Reshape_grad.js
var reshapeGradConfig = {
  kernelName: Reshape2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => reshape2(dy, x.shape) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeBilinear_grad.js
var resizeBilinearGradConfig = {
  kernelName: ResizeBilinear2,
  inputsToSave: ["images"],
  gradFunc: (dy, saved, attrs) => {
    const [images] = saved;
    const inputs = { dy, images };
    const imagesDer = () => ENGINE2.runKernel(ResizeBilinearGrad2, inputs, attrs);
    return { images: imagesDer };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeNearestNeighbor_grad.js
var resizeNearestNeighborGradConfig = {
  kernelName: ResizeNearestNeighbor2,
  inputsToSave: ["images"],
  gradFunc: (dy, saved, attrs) => {
    const [images] = saved;
    const inputs = { dy, images };
    const imagesDer = () => ENGINE2.runKernel(ResizeNearestNeighborGrad2, inputs, attrs);
    return { images: imagesDer };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Reverse_grad.js
var reverseGradConfig = {
  kernelName: Reverse2,
  gradFunc: (dy, saved, attrs) => {
    const { dims } = attrs;
    const axes = parseAxisParam2(dims, dy.shape);
    return { x: () => reverse2(dy, axes) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Round_grad.js
var roundGradConfig = {
  kernelName: Round2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Rsqrt_grad.js
var rsqrtGradConfig = {
  kernelName: Rsqrt2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => neg2(div2(dy, mul2(pow2(x, 1.5), 2))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Select_grad.js
var selectGradConfig = {
  kernelName: Select2,
  inputsToSave: ["condition"],
  gradFunc: (dy, saved) => {
    const [condition] = saved;
    return {
      condition: () => cast2(zerosLike2(condition), "float32"),
      t: () => mul2(dy, cast2(condition, dy.dtype)),
      e: () => mul2(dy, cast2(logicalNot2(condition), dy.dtype))
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Selu_grad.js
var seluGradConfig = {
  kernelName: Selu2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return {
      x: () => {
        const mask = greater2(x, scalar2(0));
        const scaleAlpha2 = scalar2(SELU_SCALEALPHA2);
        const scale2 = scalar2(SELU_SCALE2);
        const greaterThanZeroDer = mul2(dy, scale2);
        const lessEqualZeroDer = mul2(mul2(dy, scaleAlpha2), exp2(cast2(x, "float32")));
        return where2(mask, greaterThanZeroDer, lessEqualZeroDer);
      }
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sigmoid_grad.js
var sigmoidGradConfig = {
  kernelName: Sigmoid2,
  outputsToSave: [true],
  gradFunc: (dy, saved) => {
    const [y] = saved;
    return { x: () => mul2(dy, mul2(y, sub2(scalar2(1), y))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sign_grad.js
var signGradConfig = {
  kernelName: Sign2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sin_grad.js
var sinGradConfig = {
  kernelName: Sin2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(cos2(cast2(x, "float32")), dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sinh_grad.js
var sinhGradConfig = {
  kernelName: Sinh2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(cosh2(cast2(x, "float32")), dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Slice_grad.js
var sliceGradConfig = {
  kernelName: Slice2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { begin, size } = attrs;
    const inputShape = x.shape;
    const [begin_, size_] = parseSliceParams2(x, begin, size);
    const paddings = [];
    for (let i = 0; i < dy.rank; i++) {
      paddings.push([begin_[i], inputShape[i] - begin_[i] - size_[i]]);
    }
    return { x: () => pad2(dy, paddings) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Softmax_grad.js
var softmaxGradConfig = {
  kernelName: Softmax2,
  outputsToSave: [true],
  gradFunc: (dy, saved, attrs) => {
    const [y] = saved;
    const { dim } = attrs;
    const keepDims = true;
    const dyTimesY = mul2(dy, y);
    return {
      logits: () => sub2(dyTimesY, mul2(sum4(dyTimesY, [dim], keepDims), y))
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Softplus_grad.js
var softplusGradConfig = {
  kernelName: Softplus2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(dy, sigmoid2(x)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/SpaceToBatchND_grad.js
var spaceToBatchNDGradConfig = {
  kernelName: SpaceToBatchND2,
  gradFunc: (dy, saved, attrs) => {
    const { blockShape, paddings } = attrs;
    return { x: () => batchToSpaceND2(dy, blockShape, paddings) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/SplitV_grad.js
var splitVGradConfig = {
  kernelName: SplitV2,
  gradFunc: (dy, saved, attrs) => {
    const { axis } = attrs;
    return { x: () => concat2(dy, axis) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sqrt_grad.js
var sqrtGradConfig = {
  kernelName: Sqrt2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, mul2(sqrt2(cast2(x, "float32")), 2)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js
var squareGradConfig = {
  kernelName: Square2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => mul2(dy, mul2(cast2(x, "float32"), 2)) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js
var squaredDifferenceGradConfig = {
  kernelName: SquaredDifference2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const two = scalar2(2);
    const derA = () => mul2(dy, mul2(two, sub2(a, b)));
    const derB = () => mul2(dy, mul2(two, sub2(b, a)));
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Step_grad.js
var stepGradConfig = {
  kernelName: Step2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sub_grad.js
var subGradConfig = {
  kernelName: Sub2,
  inputsToSave: ["a", "b"],
  gradFunc: (dy, saved) => {
    const [a, b] = saved;
    const outShape = assertAndGetBroadcastShape2(a.shape, b.shape);
    const derA = () => {
      let res = dy;
      const reduceAxes = getReductionAxes2(a.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(res, a.shape);
    };
    const derB = () => {
      let res = dy;
      const reduceAxes = getReductionAxes2(b.shape, outShape);
      if (reduceAxes.length > 0) {
        res = sum4(res, reduceAxes);
      }
      return reshape2(neg2(res), b.shape);
    };
    return { a: derA, b: derB };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Sum_grad.js
var sumGradConfig = {
  kernelName: Sum2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const expandedDyShape = x.shape.slice();
    const { axis } = attrs;
    const axes = parseAxisParam2(axis, x.shape);
    axes.forEach((axis2) => {
      expandedDyShape[axis2] = 1;
    });
    const expandedDy = reshape2(dy, expandedDyShape);
    const derX = mul2(expandedDy, ones4(x.shape, "float32"));
    return { x: () => derX };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Tan_grad.js
var tanGradConfig = {
  kernelName: Tan2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved) => {
    const [x] = saved;
    return { x: () => div2(dy, square2(cos2(x))) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Tanh_grad.js
var tanhGradConfig = {
  kernelName: Tanh2,
  outputsToSave: [true],
  gradFunc: (dy, saved) => {
    const [y] = saved;
    return { x: () => mul2(sub2(scalar2(1), square2(y)), dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Tile_grad.js
var tileGradConfig = {
  kernelName: Tile2,
  inputsToSave: ["x"],
  gradFunc: (dy, saved, attrs) => {
    const [x] = saved;
    const { reps } = attrs;
    const derX = () => {
      let xGrad = zerosLike2(x);
      if (x.rank === 1) {
        for (let i = 0; i < reps[0]; ++i) {
          xGrad = add4(xGrad, slice2(dy, [i * x.shape[0]], [x.shape[0]]));
        }
      } else if (x.rank === 2) {
        for (let i = 0; i < reps[0]; ++i) {
          for (let j = 0; j < reps[1]; ++j) {
            xGrad = add4(xGrad, slice2(dy, [i * x.shape[0], j * x.shape[1]], [
              x.shape[0],
              x.shape[1]
            ]));
          }
        }
      } else if (x.rank === 3) {
        for (let i = 0; i < reps[0]; ++i) {
          for (let j = 0; j < reps[1]; ++j) {
            for (let k = 0; k < reps[2]; ++k) {
              xGrad = add4(xGrad, slice2(dy, [i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));
            }
          }
        }
      } else if (x.rank === 4) {
        for (let i = 0; i < reps[0]; ++i) {
          for (let j = 0; j < reps[1]; ++j) {
            for (let k = 0; k < reps[2]; ++k) {
              for (let l = 0; l < reps[3]; ++l) {
                xGrad = add4(xGrad, slice2(dy, [
                  i * x.shape[0],
                  j * x.shape[1],
                  k * x.shape[2],
                  l * x.shape[3]
                ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));
              }
            }
          }
        }
      } else {
        throw new Error(`Gradient for tile operation is not implemented for rank-${x.rank} tensors yet.`);
      }
      return xGrad;
    };
    return { x: derX };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Transpose_grad.js
var transposeGradConfig = {
  kernelName: Transpose2,
  gradFunc: (dy, saved, attrs) => {
    const transposeAttrs = attrs;
    const { perm } = transposeAttrs;
    const undoPerm = getUndoAxesPermutation2(perm);
    return { x: () => transpose2(dy, undoPerm) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/Unpack_grad.js
var unpackGradConfig = {
  kernelName: Unpack2,
  gradFunc: (dy, saved, attrs) => {
    const unpackAttrs = attrs;
    const { axis } = unpackAttrs;
    return { value: () => stack2(dy, axis) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/UnsortedSegmentSum_grad.js
var unsortedSegmentSumGradConfig = {
  kernelName: UnsortedSegmentSum2,
  inputsToSave: ["segmentIds"],
  gradFunc: (dy, saved) => {
    const [segmentIds] = saved;
    const derX = () => {
      return gatherDropNegatives(dy, segmentIds);
    };
    return { x: derX };
  }
};
function gatherDropNegatives(x, indices) {
  const zeroClippedIndices = maximum2(indices, zerosLike2(indices));
  const gathered = gather2(x, zeroClippedIndices);
  let isPositive = greaterEqual2(indices, scalar2(0, "int32"));
  const numIters = gathered.rank - isPositive.rank;
  for (let i = 0; i < numIters; ++i) {
    isPositive = expandDims2(isPositive, i + 1);
  }
  isPositive = logicalAnd2(isPositive, ones4(gathered.shape, "bool"));
  const zeroSlice = zerosLike2(gathered);
  return where2(isPositive, gathered, zeroSlice);
}

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/gradients/ZerosLike_grad.js
var zerosLikeGradConfig = {
  kernelName: ZerosLike2,
  gradFunc: (dy) => {
    return { x: () => zerosLike2(dy) };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js
var gradConfigs = [
  absGradConfig,
  acosGradConfig,
  acoshGradConfig,
  addGradConfig,
  addNGradConfig,
  argMaxGradConfig,
  argMinGradConfig,
  asinGradConfig,
  asinhGradConfig,
  atan2GradConfig,
  atanGradConfig,
  atanhGradConfig,
  avgPool3DGradConfig,
  avgPoolGradConfig,
  batchMatMulGradConfig,
  batchToSpaceNDGradConfig,
  broadcastToGradConfig,
  castGradConfig,
  ceilGradConfig,
  clipByValueGradConfig,
  complexAbsGradConfig,
  concatGradConfig,
  conv2DBackpropInputGradConfig,
  conv2DGradConfig,
  conv3DGradConfig,
  cosGradConfig,
  coshGradConfig,
  cumsumGradConfig,
  depthwiseConv2dNativeGradConfig,
  dilation2dGradConfig,
  divGradConfig,
  eluGradConfig,
  erfGradConfig,
  expGradConfig,
  expandDimsGradConfig,
  expm1GradConfig,
  floorDivGradConfig,
  floorGradConfig,
  fusedBatchNormGradConfig,
  gatherGradConfig,
  greaterEqualGradConfig,
  identityGradConfig,
  isFiniteGradConfig,
  isInfGradConfig,
  isNanGradConfig,
  leakyReluGradConfig,
  log1pGradConfig,
  logGradConfig,
  logSoftmaxGradConfig,
  lrnGradConfig,
  maxGradConfig,
  maxGradConfig,
  maximumGradConfig,
  maxPool3DGradConfig,
  maxPoolGradConfig,
  meanGradConfig,
  minGradConfig,
  minimumGradConfig,
  mirrorPadGradConfig,
  modGradConfig,
  multiplyGradConfig,
  negGradConfig,
  oneHotGradConfig,
  onesLikeGradConfig,
  packGradConfig,
  padV2GradConfig,
  padV2GradConfig,
  powGradConfig,
  preluGradConfig,
  reciprocalGradConfig,
  relu6GradConfig,
  reluGradConfig,
  reshapeGradConfig,
  resizeBilinearGradConfig,
  resizeNearestNeighborGradConfig,
  reverseGradConfig,
  roundGradConfig,
  rsqrtGradConfig,
  selectGradConfig,
  seluGradConfig,
  sigmoidGradConfig,
  signGradConfig,
  sinGradConfig,
  sinhGradConfig,
  sliceGradConfig,
  softmaxGradConfig,
  softplusGradConfig,
  spaceToBatchNDGradConfig,
  spaceToBatchNDGradConfig,
  splitVGradConfig,
  splitVGradConfig,
  sqrtGradConfig,
  squaredDifferenceGradConfig,
  squareGradConfig,
  stepGradConfig,
  subGradConfig,
  sumGradConfig,
  tanGradConfig,
  tanhGradConfig,
  tileGradConfig,
  transposeGradConfig,
  unpackGradConfig,
  unsortedSegmentSumGradConfig,
  zerosLikeGradConfig
];
for (const gradientConfig of gradConfigs) {
  registerGradient2(gradientConfig);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_constraints.ts
var exports_constraints_exports = {};
__export(exports_constraints_exports, {
  maxNorm: () => maxNorm,
  minMaxNorm: () => minMaxNorm,
  nonNeg: () => nonNeg,
  unitNorm: () => unitNorm
});

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/backend/common.ts
var _epsilon;
function epsilon() {
  if (_epsilon == null) {
    _epsilon = backend2().epsilon();
  }
  return _epsilon;
}
function imageDataFormat() {
  return "channelsLast";
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/errors.ts
var AttributeError = class extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, AttributeError.prototype);
  }
};
var RuntimeError = class extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, RuntimeError.prototype);
  }
};
var ValueError = class extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, ValueError.prototype);
  }
};
var NotImplementedError = class extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, NotImplementedError.prototype);
  }
};
var AssertionError = class extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, AssertionError.prototype);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/generic_utils.ts
function pyListRepeat(value, numValues) {
  if (Array.isArray(value)) {
    let newArray = [];
    for (let i = 0; i < numValues; i++) {
      newArray = newArray.concat(value);
    }
    return newArray;
  } else {
    const newArray = new Array(numValues);
    newArray.fill(value);
    return newArray;
  }
}
function assert3(val, message) {
  if (!val) {
    throw new AssertionError(message);
  }
}
function count(array2, refernce) {
  let counter = 0;
  for (const item of array2) {
    if (item === refernce) {
      counter++;
    }
  }
  return counter;
}
function singletonOrArray(xs) {
  if (xs.length === 1) {
    return xs[0];
  }
  return xs;
}
function toList(x) {
  if (Array.isArray(x)) {
    return x;
  }
  return [x];
}
function toSnakeCase(name) {
  const intermediate = name.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2");
  const insecure = intermediate.replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  if (insecure[0] !== "_") {
    return insecure;
  }
  return "private" + insecure;
}
function toCamelCase(identifier) {
  if (identifier.length <= 1) {
    return identifier;
  }
  if (identifier.indexOf("_") === -1) {
    return identifier;
  }
  return identifier.replace(/[_]+(\w|$)/g, (m, p1) => p1.toUpperCase());
}
var _GLOBAL_CUSTOM_OBJECTS = {};
function serializeKerasObject(instance) {
  if (instance === null || instance === void 0) {
    return null;
  }
  const dict = {};
  dict["className"] = instance.getClassName();
  dict["config"] = instance.getConfig();
  return dict;
}
function convertNDArrayScalarsInConfig(config) {
  if (config == null || typeof config !== "object") {
    return;
  } else if (Array.isArray(config)) {
    config.forEach((configItem) => convertNDArrayScalarsInConfig(configItem));
  } else {
    const fields = Object.keys(config);
    for (const field of fields) {
      const value = config[field];
      if (value != null && typeof value === "object") {
        if (!Array.isArray(value) && value["type"] === "ndarray" && typeof value["value"] === "number") {
          config[field] = value["value"];
        } else {
          convertNDArrayScalarsInConfig(value);
        }
      }
    }
  }
}
function deserializeKerasObject(identifier, moduleObjects = {}, customObjects = {}, printableModuleName = "object", fastWeightInit = false) {
  if (typeof identifier === "string") {
    const functionName = identifier;
    let fn;
    if (functionName in customObjects) {
      fn = customObjects[functionName];
    } else if (functionName in _GLOBAL_CUSTOM_OBJECTS) {
      fn = _GLOBAL_CUSTOM_OBJECTS[functionName];
    } else {
      fn = moduleObjects[functionName];
      if (fn == null) {
        throw new ValueError(`Unknown ${printableModuleName}: ${identifier}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
      }
    }
    return fn;
  } else {
    const config = identifier;
    if (config["className"] == null || config["config"] == null) {
      throw new ValueError(`${printableModuleName}: Improper config format: ${JSON.stringify(config)}.
'className' and 'config' must set.`);
    }
    const className = config["className"];
    let cls, fromConfig;
    if (className in customObjects) {
      [cls, fromConfig] = customObjects[className];
    } else if (className in _GLOBAL_CUSTOM_OBJECTS) {
      [cls, fromConfig] = _GLOBAL_CUSTOM_OBJECTS["className"];
    } else if (className in moduleObjects) {
      [cls, fromConfig] = moduleObjects[className];
    }
    if (cls == null) {
      throw new ValueError(`Unknown ${printableModuleName}: ${className}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    }
    if (fromConfig != null) {
      const customObjectsCombined = {};
      for (const key of Object.keys(_GLOBAL_CUSTOM_OBJECTS)) {
        customObjectsCombined[key] = _GLOBAL_CUSTOM_OBJECTS[key];
      }
      for (const key of Object.keys(customObjects)) {
        customObjectsCombined[key] = customObjects[key];
      }
      const nestedConfig = config["config"];
      nestedConfig["customObjects"] = customObjectsCombined;
      const backupCustomObjects = { ..._GLOBAL_CUSTOM_OBJECTS };
      for (const key of Object.keys(customObjects)) {
        _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
      }
      convertNDArrayScalarsInConfig(config["config"]);
      const returnObj = fromConfig(cls, config["config"], customObjects, fastWeightInit);
      _GLOBAL_CUSTOM_OBJECTS = { ...backupCustomObjects };
      return returnObj;
    } else {
      const backupCustomObjects = { ..._GLOBAL_CUSTOM_OBJECTS };
      for (const key of Object.keys(customObjects)) {
        _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
      }
      const returnObj = new cls(config["config"]);
      _GLOBAL_CUSTOM_OBJECTS = { ...backupCustomObjects };
      return returnObj;
    }
  }
}
function numberCompare(a, b) {
  return a < b ? -1 : a > b ? 1 : 0;
}
function reverseNumberCompare(a, b) {
  return -1 * numberCompare(a, b);
}
function unique3(xs) {
  if (xs == null) {
    return xs;
  }
  const out = [];
  for (const x of xs) {
    if (out.indexOf(x) === -1) {
      out.push(x);
    }
  }
  return out;
}
function isObjectEmpty(obj) {
  if (obj == null) {
    throw new ValueError(`Invalid value in obj: ${JSON.stringify(obj)}`);
  }
  for (const key in obj) {
    if (obj.hasOwnProperty(key)) {
      return false;
    }
  }
  return true;
}
function checkStringTypeUnionValue(values, label, value) {
  if (value == null) {
    return;
  }
  if (values.indexOf(value) < 0) {
    throw new ValueError(`${value} is not a valid ${label}.  Valid values are ${values} or null/undefined.`);
  }
}
function checkArrayTypeAndLength(x, expectedType, minLength = 0, maxLength = Infinity) {
  assert3(minLength >= 0);
  assert3(maxLength >= minLength);
  return Array.isArray(x) && x.length >= minLength && x.length <= maxLength && x.every((e) => typeof e === expectedType);
}
function assertPositiveInteger(value, name) {
  if (Array.isArray(value)) {
    util_exports2.assert(value.length > 0, () => `${name} is unexpectedly an empty array.`);
    value.forEach((v, i) => assertPositiveInteger(v, `element ${i + 1} of ${name}`));
  } else {
    util_exports2.assert(Number.isInteger(value) && value > 0, () => `Expected ${name} to be a positive integer, but got ${formatAsFriendlyString(value)}.`);
  }
}
function formatAsFriendlyString(value) {
  if (value === null) {
    return "null";
  } else if (Array.isArray(value)) {
    return "[" + value.map((v) => formatAsFriendlyString(v)).join(",") + "]";
  } else if (typeof value === "string") {
    return `"${value}"`;
  } else {
    return `${value}`;
  }
}
function debounce(f, waitMs) {
  let lastTime = util_exports2.now();
  let lastResult;
  const f2 = (...args) => {
    const now3 = util_exports2.now();
    if (now3 - lastTime < waitMs) {
      return lastResult;
    }
    lastTime = now3;
    lastResult = f(...args);
    return lastResult;
  };
  return f2;
}
function mapActivationToFusedKernel(activationName) {
  if (activationName === "relu") {
    return "relu";
  }
  if (activationName === "linear") {
    return "linear";
  }
  if (activationName === "elu") {
    return "elu";
  }
  return null;
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/constraints.ts
function calcL2Norms(w, axis) {
  return tidy2(() => sqrt2(sum4(mul2(w, w), axis, true)));
}
var Constraint = class extends serialization_exports2.Serializable {
  getConfig() {
    return {};
  }
};
var MaxNorm = class extends Constraint {
  constructor(args) {
    super();
    this.defaultMaxValue = 2;
    this.defaultAxis = 0;
    this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
    this.axis = args.axis != null ? args.axis : this.defaultAxis;
  }
  apply(w) {
    return tidy2(() => {
      const norms = calcL2Norms(w, this.axis);
      const desired = clipByValue2(norms, 0, this.maxValue);
      return mul2(w, div2(desired, add4(epsilon(), norms)));
    });
  }
  getConfig() {
    return { maxValue: this.maxValue, axis: this.axis };
  }
};
MaxNorm.className = "MaxNorm";
serialization_exports2.registerClass(MaxNorm);
var UnitNorm = class extends Constraint {
  constructor(args) {
    super();
    this.defaultAxis = 0;
    this.axis = args.axis != null ? args.axis : this.defaultAxis;
  }
  apply(w) {
    return tidy2(() => div2(w, add4(epsilon(), calcL2Norms(w, this.axis))));
  }
  getConfig() {
    return { axis: this.axis };
  }
};
UnitNorm.className = "UnitNorm";
serialization_exports2.registerClass(UnitNorm);
var NonNeg = class extends Constraint {
  apply(w) {
    return relu2(w);
  }
};
NonNeg.className = "NonNeg";
serialization_exports2.registerClass(NonNeg);
var MinMaxNorm = class extends Constraint {
  constructor(args) {
    super();
    this.defaultMinValue = 0;
    this.defaultMaxValue = 1;
    this.defaultRate = 1;
    this.defaultAxis = 0;
    this.minValue = args.minValue != null ? args.minValue : this.defaultMinValue;
    this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
    this.rate = args.rate != null ? args.rate : this.defaultRate;
    this.axis = args.axis != null ? args.axis : this.defaultAxis;
  }
  apply(w) {
    return tidy2(() => {
      const norms = calcL2Norms(w, this.axis);
      const desired = add4(mul2(this.rate, clipByValue2(norms, this.minValue, this.maxValue)), mul2(1 - this.rate, norms));
      return mul2(w, div2(desired, add4(epsilon(), norms)));
    });
  }
  getConfig() {
    return {
      minValue: this.minValue,
      maxValue: this.maxValue,
      rate: this.rate,
      axis: this.axis
    };
  }
};
MinMaxNorm.className = "MinMaxNorm";
serialization_exports2.registerClass(MinMaxNorm);
var CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  "maxNorm": "MaxNorm",
  "minMaxNorm": "MinMaxNorm",
  "nonNeg": "NonNeg",
  "unitNorm": "UnitNorm"
};
function serializeConstraint(constraint) {
  return serializeKerasObject(constraint);
}
function deserializeConstraint(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports2.SerializationMap.getMap().classNameMap, customObjects, "constraint");
}
function getConstraint(identifier) {
  if (identifier == null) {
    return null;
  }
  if (typeof identifier === "string") {
    const className = identifier in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP ? CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    const config = { className, config: {} };
    return deserializeConstraint(config);
  } else if (identifier instanceof Constraint) {
    return identifier;
  } else {
    return deserializeConstraint(identifier);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_constraints.ts
function maxNorm(args) {
  return new MaxNorm(args);
}
function unitNorm(args) {
  return new UnitNorm(args);
}
function nonNeg() {
  return new NonNeg();
}
function minMaxNorm(config) {
  return new MinMaxNorm(config);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_initializers.ts
var exports_initializers_exports = {};
__export(exports_initializers_exports, {
  constant: () => constant,
  glorotNormal: () => glorotNormal,
  glorotUniform: () => glorotUniform,
  heNormal: () => heNormal,
  heUniform: () => heUniform,
  identity: () => identity,
  leCunNormal: () => leCunNormal,
  leCunUniform: () => leCunUniform,
  ones: () => ones5,
  orthogonal: () => orthogonal,
  randomNormal: () => randomNormal4,
  randomUniform: () => randomUniform3,
  truncatedNormal: () => truncatedNormal3,
  varianceScaling: () => varianceScaling,
  zeros: () => zeros3
});

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/keras_format/common.ts
var VALID_DATA_FORMAT_VALUES = ["channelsFirst", "channelsLast"];
var VALID_INTERPOLATION_FORMAT_VALUES = ["nearest", "bilinear"];
var VALID_PADDING_MODE_VALUES = ["valid", "same", "causal"];
var VALID_POOL_MODE_VALUES = ["max", "avg"];
var VALID_BIDIRECTIONAL_MERGE_MODES = ["sum", "mul", "concat", "ave"];

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/common.ts
var nameMap = new Map();
function checkDataFormat(value) {
  checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES, "DataFormat", value);
}
function checkInterpolationFormat(value) {
  checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES, "InterpolationFormat", value);
}
function checkPaddingMode(value) {
  checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES, "PaddingMode", value);
}
function checkPoolMode(value) {
  checkStringTypeUnionValue(VALID_POOL_MODE_VALUES, "PoolMode", value);
}
var _nameScopeStack = [];
var _nameScopeDivider = "/";
function nameScope(name, fn) {
  _nameScopeStack.push(name);
  try {
    const val = fn();
    _nameScopeStack.pop();
    return val;
  } catch (e) {
    _nameScopeStack.pop();
    throw e;
  }
}
function currentNameScopePrefix() {
  if (_nameScopeStack.length === 0) {
    return "";
  } else {
    return _nameScopeStack.join(_nameScopeDivider) + _nameScopeDivider;
  }
}
function getScopedTensorName(tensorName) {
  if (!isValidTensorName(tensorName)) {
    throw new Error("Not a valid tensor name: '" + tensorName + "'");
  }
  return currentNameScopePrefix() + tensorName;
}
function getUniqueTensorName(scopedName) {
  if (!isValidTensorName(scopedName)) {
    throw new Error("Not a valid tensor name: '" + scopedName + "'");
  }
  if (!nameMap.has(scopedName)) {
    nameMap.set(scopedName, 0);
  }
  const index = nameMap.get(scopedName);
  nameMap.set(scopedName, nameMap.get(scopedName) + 1);
  if (index > 0) {
    const result = `${scopedName}_${index}`;
    nameMap.set(result, 1);
    return result;
  } else {
    return scopedName;
  }
}
var tensorNameRegex = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
function isValidTensorName(name) {
  return !!name.match(tensorNameRegex);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/math_utils.ts
function isInteger(x) {
  return x === parseInt(x.toString(), 10);
}
function arrayProd(array2, begin, end) {
  if (begin == null) {
    begin = 0;
  }
  if (end == null) {
    end = array2.length;
  }
  let prod6 = 1;
  for (let i = begin; i < end; ++i) {
    prod6 *= array2[i];
  }
  return prod6;
}
function min3(array2) {
  if (array2.length === 0) {
    return Number.NaN;
  }
  let min7 = Number.POSITIVE_INFINITY;
  for (let i = 0; i < array2.length; i++) {
    const value = array2[i];
    if (value < min7) {
      min7 = value;
    }
  }
  return min7;
}
function max3(array2) {
  if (array2.length === 0) {
    return Number.NaN;
  }
  let max7 = Number.NEGATIVE_INFINITY;
  for (let i = 0; i < array2.length; i++) {
    const value = array2[i];
    if (value > max7) {
      max7 = value;
    }
  }
  return max7;
}
function range3(begin, end) {
  if (end < begin) {
    throw new ValueError(`end (${end}) < begin (${begin}) is forbidden.`);
  }
  const out = [];
  for (let i = begin; i < end; ++i) {
    out.push(i);
  }
  return out;
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/backend/tfjs_backend.ts
function cast3(x, dtype) {
  return x.asType(dtype);
}
function expandDims3(x, axis = -1) {
  const outShape = x.shape.slice();
  if (axis < 0) {
    axis = outShape.length + axis + 1;
  }
  outShape.splice(axis, 0, 1);
  return x.reshape(outShape);
}
function repeat(x, n) {
  return tidy2(() => {
    if (x.shape.length !== 2) {
      throw new ValueError(`repeat() expects a rank-2 tensor, but received a rank-${x.shape.length} tensor.`);
    }
    const y = expandDims3(x, 1);
    return tile3(y, [1, n, 1]);
  });
}
function flatten3(x) {
  const newShape = [arrayProd(x.shape)];
  return x.reshape(newShape);
}
function batchFlatten(x) {
  if (x.rank <= 1) {
    throw new ValueError(`batchFlatten requires a minimum rank of 2. Got rank: ${x.rank}.`);
  }
  const newShape = [x.shape[0], arrayProd(x.shape, 1)];
  return x.reshape(newShape);
}
function sliceAlongFirstAxis(array2, start, size) {
  return tidy2(() => {
    switch (array2.rank) {
      case 1:
        return slice1d2(array2, start, size);
      case 2:
        return slice2d2(array2, [start, 0], [size, array2.shape[1]]);
      case 3:
        return slice3d2(array2, [start, 0, 0], [size, array2.shape[1], array2.shape[2]]);
      case 4:
        return slice4d2(array2, [start, 0, 0, 0], [size, array2.shape[1], array2.shape[2], array2.shape[3]]);
      case 5:
        return slice2(array2, [start, 0, 0, 0, 0], [
          size,
          array2.shape[1],
          array2.shape[2],
          array2.shape[3],
          array2.shape[4]
        ]);
      case 6:
        return slice2(array2, [start, 0, 0, 0, 0, 0], [
          size,
          array2.shape[1],
          array2.shape[2],
          array2.shape[3],
          array2.shape[4],
          array2.shape[5]
        ]);
      default:
        throw new ValueError(`sliceAlongFirstAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function sliceAlongLastAxis(array2, start, size) {
  return tidy2(() => {
    switch (array2.rank) {
      case 1:
        return slice1d2(array2, start, size);
      case 2:
        return slice2d2(array2, [0, start], [array2.shape[0], size]);
      case 3:
        return slice3d2(array2, [0, 0, start], [array2.shape[0], array2.shape[1], size]);
      case 4:
        return slice4d2(array2, [0, 0, 0, start], [array2.shape[0], array2.shape[1], array2.shape[2], size]);
      default:
        throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function sliceAlongAxis(array2, start, size, axis) {
  return tidy2(() => {
    switch (array2.rank) {
      case 1:
        return slice1d2(array2, start, size);
      case 2:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      case 3:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return slice3d2(array2, [0, start, 0], [array2.shape[0], size, array2.shape[2]]);
          case 3:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      case 4:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return slice4d2(array2, [0, start, 0, 0], [array2.shape[0], size, array2.shape[2], array2.shape[3]]);
          case 3:
            return slice4d2(array2, [0, 0, start, 0], [array2.shape[0], array2.shape[1], size, array2.shape[3]]);
          case 4:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      default:
        throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function concatenate(tensors, axis = -1) {
  let rank;
  if (axis < 0) {
    rank = tensors[0].rank;
    if (rank !== 0) {
      axis = rank;
    } else {
      axis = 0;
    }
  }
  if (axis === tensors[0].rank) {
    axis = -1;
  }
  return concat2(tensors, axis);
}
function concatAlongFirstAxis(a, b) {
  switch (a.rank) {
    case 1:
      return concat1d2([a, b]);
    case 2:
      return concat2d2([a, b], 0);
    case 3:
      return concat3d2([a, b], 0);
    case 4:
      return concat4d2([a, b], 0);
    default:
      throw new ValueError(`concatAlongFirstAxis() received an unsupported tensor rank: ${a.rank}`);
  }
}
function tile3(x, n) {
  if (!Array.isArray(n)) {
    n = [n];
  }
  if (x.rank !== n.length) {
    throw new ValueError(`The length of input n (${n.length}) does not match the number of dimensions in input x (${x.rank})`);
  }
  return tile2(x, n);
}
function randomNormal3(shape, mean5 = 0, stddev = 1, dtype, seed) {
  return randomNormal2(shape, mean5, stddev, dtype, seed);
}
function dot3(a, b, activation2, bias) {
  if (a.rank < 2 || b.rank < 2) {
    throw new NotImplementedError(`dot requires both inputs to be rank >= 2 but got x shape = ${a.shape} and y shape = ${b.shape}`);
  }
  if (b.rank >= 3) {
    const xLastDim = a.shape.slice(-1)[0];
    const ySecondLastDim = b.shape.slice(-2)[0];
    if (xLastDim !== ySecondLastDim) {
      throw new NotImplementedError(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${a.shape} and  y shape = ${b.shape}`);
    }
  }
  if (a.rank === 2 && b.rank === 2) {
    const transposeA = false;
    const transposeB = false;
    return fused_ops_exports2.matMul({
      a,
      b,
      transposeA,
      transposeB,
      bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
      activation: activation2
    });
  } else {
    const aFirstDims = a.shape.slice();
    const aLastDim = aFirstDims.pop();
    a = a.reshape([-1, aLastDim]);
    const bShape = b.shape.slice();
    const bLastDim = bShape.pop();
    const ySecondLastDim = bShape.pop();
    const yOtherDims = [...bShape, bLastDim];
    const perm = Array.from({ length: b.rank }, (_, i) => {
      if (i === 0) {
        return b.rank - 2;
      } else if (i <= b.rank - 2) {
        return i - 1;
      }
      return i;
    });
    b = b.transpose(perm).reshape([ySecondLastDim, -1]);
    const outputShape = [...aFirstDims, ...yOtherDims];
    const transposeA = false;
    const transposeB = false;
    return fused_ops_exports2.matMul({
      a,
      b,
      transposeA,
      transposeB,
      bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
      activation: activation2
    }).reshape(outputShape);
  }
}
function gather3(reference, indices, axis) {
  return tidy2(() => {
    if (Array.isArray(indices)) {
      indices = tensor1d2(indices, "int32");
    } else {
      indices = indices.toInt();
    }
    return gather2(reference, indices, axis);
  });
}
function square3(x) {
  return mul2(x, x);
}
function reshapeBias(xRank, bias, dataFormat) {
  const biasShape = bias.shape;
  if (bias.rank !== 1 && bias.rank !== xRank) {
    throw new ValueError(`Unexpected bias dimensions: ${bias.rank}; expected it to be 1 or ${xRank}`);
  }
  if (xRank === 5) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return bias.reshape([1, biasShape[0], 1, 1, 1]);
      } else {
        return bias.reshape([1, biasShape[3], biasShape[0], biasShape[1], biasShape[2]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return bias.reshape([1, 1, 1, 1, biasShape[0]]);
      } else {
        return bias.reshape([1].concat(biasShape));
      }
    }
  } else if (xRank === 4) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return bias.reshape([1, biasShape[0], 1, 1]);
      } else {
        return bias.reshape([1, biasShape[2], biasShape[0], biasShape[1]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return bias.reshape([1, 1, 1, biasShape[0]]);
      } else {
        return bias.reshape([1].concat(biasShape));
      }
    }
  } else if (xRank === 3) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return bias.reshape([1, biasShape[0], 1]);
      } else {
        return bias.reshape([1, biasShape[1], biasShape[0]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return bias.reshape([1, 1, biasShape[0]]);
      } else {
        return bias.reshape([1].concat(biasShape));
      }
    }
  } else if (xRank < 3) {
    return bias;
  }
  throw new ValueError(`Unsupported input rank by biasAdd: ${bias.rank}`);
}
function biasAdd(x, bias, dataFormat) {
  return tidy2(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    return x.add(reshapeBias(x.rank, bias, dataFormat));
  });
}
function elu3(x, alpha = 1) {
  if (alpha !== 1) {
    throw new NotImplementedError(`Support for alpha values other than 1 (${alpha}) is not implemented yet.`);
  }
  return elu2(x);
}
function softsign(x) {
  return tidy2(() => div2(x, abs2(x).add(1)));
}
function dropout3(x, level, noiseShape, seed) {
  return tidy2(() => dropout2(x, level, noiseShape, seed));
}
function hardSigmoid(x) {
  return tidy2(() => {
    const y = add4(0.5, mul2(0.2, x));
    return clipByValue2(y, 0, 1);
  });
}
function inTrainPhase(x, alt, training = false) {
  return training ? x() : alt();
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/keras_format/initializer_config.ts
var VALID_FAN_MODE_VALUES = ["fanIn", "fanOut", "fanAvg"];
var VALID_DISTRIBUTION_VALUES = ["normal", "uniform", "truncatedNormal"];

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/initializers.ts
function checkFanMode(value) {
  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, "FanMode", value);
}
function checkDistribution(value) {
  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, "Distribution", value);
}
var Initializer = class extends serialization_exports2.Serializable {
  fromConfigUsesCustomObjects() {
    return false;
  }
  getConfig() {
    return {};
  }
};
var Zeros = class extends Initializer {
  apply(shape, dtype) {
    return zeros2(shape, dtype);
  }
};
Zeros.className = "Zeros";
serialization_exports2.registerClass(Zeros);
var Ones = class extends Initializer {
  apply(shape, dtype) {
    return ones4(shape, dtype);
  }
};
Ones.className = "Ones";
serialization_exports2.registerClass(Ones);
var Constant = class extends Initializer {
  constructor(args) {
    super();
    if (typeof args !== "object") {
      throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);
    }
    if (args.value === void 0) {
      throw new ValueError(`config must have value set but got ${args}`);
    }
    this.value = args.value;
  }
  apply(shape, dtype) {
    return tidy2(() => mul2(scalar2(this.value), ones4(shape, dtype)));
  }
  getConfig() {
    return {
      value: this.value
    };
  }
};
Constant.className = "Constant";
serialization_exports2.registerClass(Constant);
var RandomUniform = class extends Initializer {
  constructor(args) {
    super();
    this.DEFAULT_MINVAL = -0.05;
    this.DEFAULT_MAXVAL = 0.05;
    this.minval = args.minval || this.DEFAULT_MINVAL;
    this.maxval = args.maxval || this.DEFAULT_MAXVAL;
    this.seed = args.seed;
  }
  apply(shape, dtype) {
    return randomUniform2(shape, this.minval, this.maxval, dtype);
  }
  getConfig() {
    return { minval: this.minval, maxval: this.maxval, seed: this.seed };
  }
};
RandomUniform.className = "RandomUniform";
serialization_exports2.registerClass(RandomUniform);
var RandomNormal = class extends Initializer {
  constructor(args) {
    super();
    this.DEFAULT_MEAN = 0;
    this.DEFAULT_STDDEV = 0.05;
    this.mean = args.mean || this.DEFAULT_MEAN;
    this.stddev = args.stddev || this.DEFAULT_STDDEV;
    this.seed = args.seed;
  }
  apply(shape, dtype) {
    dtype = dtype || "float32";
    if (dtype !== "float32" && dtype !== "int32") {
      throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);
    }
    return randomNormal3(shape, this.mean, this.stddev, dtype, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
RandomNormal.className = "RandomNormal";
serialization_exports2.registerClass(RandomNormal);
var TruncatedNormal = class extends Initializer {
  constructor(args) {
    super();
    this.DEFAULT_MEAN = 0;
    this.DEFAULT_STDDEV = 0.05;
    this.mean = args.mean || this.DEFAULT_MEAN;
    this.stddev = args.stddev || this.DEFAULT_STDDEV;
    this.seed = args.seed;
  }
  apply(shape, dtype) {
    dtype = dtype || "float32";
    if (dtype !== "float32" && dtype !== "int32") {
      throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);
    }
    return truncatedNormal2(shape, this.mean, this.stddev, dtype, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
TruncatedNormal.className = "TruncatedNormal";
serialization_exports2.registerClass(TruncatedNormal);
var Identity3 = class extends Initializer {
  constructor(args) {
    super();
    this.gain = args.gain != null ? args.gain : 1;
  }
  apply(shape, dtype) {
    return tidy2(() => {
      if (shape.length !== 2 || shape[0] !== shape[1]) {
        throw new ValueError("Identity matrix initializer can only be used for 2D square matrices.");
      } else {
        return mul2(this.gain, eye2(shape[0]));
      }
    });
  }
  getConfig() {
    return { gain: this.gain };
  }
};
Identity3.className = "Identity";
serialization_exports2.registerClass(Identity3);
function computeFans(shape, dataFormat = "channelsLast") {
  let fanIn;
  let fanOut;
  checkDataFormat(dataFormat);
  if (shape.length === 2) {
    fanIn = shape[0];
    fanOut = shape[1];
  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {
    if (dataFormat === "channelsFirst") {
      const receptiveFieldSize = arrayProd(shape, 2);
      fanIn = shape[1] * receptiveFieldSize;
      fanOut = shape[0] * receptiveFieldSize;
    } else if (dataFormat === "channelsLast") {
      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);
      fanIn = shape[shape.length - 2] * receptiveFieldSize;
      fanOut = shape[shape.length - 1] * receptiveFieldSize;
    }
  } else {
    const shapeProd = arrayProd(shape);
    fanIn = Math.sqrt(shapeProd);
    fanOut = Math.sqrt(shapeProd);
  }
  return [fanIn, fanOut];
}
var VarianceScaling = class extends Initializer {
  constructor(args) {
    super();
    if (args.scale < 0) {
      throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);
    }
    this.scale = args.scale == null ? 1 : args.scale;
    this.mode = args.mode == null ? "fanIn" : args.mode;
    checkFanMode(this.mode);
    this.distribution = args.distribution == null ? "normal" : args.distribution;
    checkDistribution(this.distribution);
    this.seed = args.seed;
  }
  apply(shape, dtype) {
    const fans = computeFans(shape);
    const fanIn = fans[0];
    const fanOut = fans[1];
    let scale2 = this.scale;
    if (this.mode === "fanIn") {
      scale2 /= Math.max(1, fanIn);
    } else if (this.mode === "fanOut") {
      scale2 /= Math.max(1, fanOut);
    } else {
      scale2 /= Math.max(1, (fanIn + fanOut) / 2);
    }
    if (this.distribution === "normal") {
      const stddev = Math.sqrt(scale2);
      dtype = dtype || "float32";
      if (dtype !== "float32" && dtype !== "int32") {
        throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);
      }
      return truncatedNormal2(shape, 0, stddev, dtype, this.seed);
    } else {
      const limit = Math.sqrt(3 * scale2);
      return randomUniform2(shape, -limit, limit, dtype);
    }
  }
  getConfig() {
    return {
      scale: this.scale,
      mode: this.mode,
      distribution: this.distribution,
      seed: this.seed
    };
  }
};
VarianceScaling.className = "VarianceScaling";
serialization_exports2.registerClass(VarianceScaling);
var GlorotUniform = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "uniform",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
GlorotUniform.className = "GlorotUniform";
serialization_exports2.registerClass(GlorotUniform);
var GlorotNormal = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "normal",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
GlorotNormal.className = "GlorotNormal";
serialization_exports2.registerClass(GlorotNormal);
var HeNormal = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "normal",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
HeNormal.className = "HeNormal";
serialization_exports2.registerClass(HeNormal);
var HeUniform = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "uniform",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
HeUniform.className = "HeUniform";
serialization_exports2.registerClass(HeUniform);
var LeCunNormal = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "normal",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
LeCunNormal.className = "LeCunNormal";
serialization_exports2.registerClass(LeCunNormal);
var LeCunUniform = class extends VarianceScaling {
  constructor(args) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "uniform",
      seed: args == null ? null : args.seed
    });
  }
  getClassName() {
    return VarianceScaling.className;
  }
};
LeCunUniform.className = "LeCunNormal";
serialization_exports2.registerClass(LeCunUniform);
var Orthogonal = class extends Initializer {
  constructor(args) {
    super();
    this.DEFAULT_GAIN = 1;
    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;
    this.seed = args.seed;
    if (this.seed != null) {
      throw new NotImplementedError("Random seed is not implemented for Orthogonal Initializer yet.");
    }
  }
  apply(shape, dtype) {
    return tidy2(() => {
      if (shape.length < 2) {
        throw new NotImplementedError("Shape must be at least 2D.");
      }
      if (shape[0] * shape[1] > 2e3) {
        console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${shape[0] * shape[1]}) elements: Slowness may result.`);
      }
      const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;
      const a = randomNormal3(normalizedShape, 0, 1, "float32");
      let q = linalg2.gramSchmidt(a);
      if (shape[0] > shape[1]) {
        q = q.transpose();
      }
      return mul2(this.gain, q);
    });
  }
  getConfig() {
    return {
      gain: this.gain,
      seed: this.seed
    };
  }
};
Orthogonal.className = "Orthogonal";
serialization_exports2.registerClass(Orthogonal);
var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  "constant": "Constant",
  "glorotNormal": "GlorotNormal",
  "glorotUniform": "GlorotUniform",
  "heNormal": "HeNormal",
  "heUniform": "HeUniform",
  "identity": "Identity",
  "leCunNormal": "LeCunNormal",
  "leCunUniform": "LeCunUniform",
  "ones": "Ones",
  "orthogonal": "Orthogonal",
  "randomNormal": "RandomNormal",
  "randomUniform": "RandomUniform",
  "truncatedNormal": "TruncatedNormal",
  "varianceScaling": "VarianceScaling",
  "zeros": "Zeros"
};
function deserializeInitializer(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports2.SerializationMap.getMap().classNameMap, customObjects, "initializer");
}
function serializeInitializer(initializer) {
  return serializeKerasObject(initializer);
}
function getInitializer(identifier) {
  if (typeof identifier === "string") {
    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    if (className === "GlorotNormal") {
      return new GlorotNormal();
    } else if (className === "GlorotUniform") {
      return new GlorotUniform();
    } else if (className === "HeNormal") {
      return new HeNormal();
    } else if (className === "HeUniform") {
      return new HeUniform();
    } else if (className === "LeCunNormal") {
      return new LeCunNormal();
    } else if (className === "LeCunUniform") {
      return new LeCunUniform();
    } else {
      const config = {};
      config["className"] = className;
      config["config"] = {};
      return deserializeInitializer(config);
    }
  } else if (identifier instanceof Initializer) {
    return identifier;
  } else {
    return deserializeInitializer(identifier);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_initializers.ts
function zeros3() {
  return new Zeros();
}
function ones5() {
  return new Ones();
}
function constant(args) {
  return new Constant(args);
}
function randomUniform3(args) {
  return new RandomUniform(args);
}
function randomNormal4(args) {
  return new RandomNormal(args);
}
function truncatedNormal3(args) {
  return new TruncatedNormal(args);
}
function identity(args) {
  return new Identity3(args);
}
function varianceScaling(config) {
  return new VarianceScaling(config);
}
function glorotUniform(args) {
  return new GlorotUniform(args);
}
function glorotNormal(args) {
  return new GlorotNormal(args);
}
function heNormal(args) {
  return new HeNormal(args);
}
function heUniform(args) {
  return new HeUniform(args);
}
function leCunNormal(args) {
  return new LeCunNormal(args);
}
function leCunUniform(args) {
  return new LeCunUniform(args);
}
function orthogonal(args) {
  return new Orthogonal(args);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_layers.ts
var exports_layers_exports = {};
__export(exports_layers_exports, {
  Layer: () => Layer,
  RNN: () => RNN,
  RNNCell: () => RNNCell,
  activation: () => activation,
  add: () => add5,
  alphaDropout: () => alphaDropout,
  average: () => average,
  averagePooling1d: () => averagePooling1d,
  averagePooling2d: () => averagePooling2d,
  averagePooling3d: () => averagePooling3d,
  avgPool1d: () => avgPool1d,
  avgPool2d: () => avgPool2d,
  avgPool3d: () => avgPool3d3,
  avgPooling1d: () => avgPooling1d,
  avgPooling2d: () => avgPooling2d,
  avgPooling3d: () => avgPooling3d,
  batchNormalization: () => batchNormalization2,
  bidirectional: () => bidirectional,
  concatenate: () => concatenate2,
  conv1d: () => conv1d3,
  conv2d: () => conv2d5,
  conv2dTranspose: () => conv2dTranspose3,
  conv3d: () => conv3d3,
  conv3dTranspose: () => conv3dTranspose3,
  convLstm2d: () => convLstm2d,
  convLstm2dCell: () => convLstm2dCell,
  cropping2D: () => cropping2D,
  dense: () => dense,
  depthwiseConv2d: () => depthwiseConv2d6,
  dot: () => dot4,
  dropout: () => dropout4,
  elu: () => elu4,
  embedding: () => embedding,
  flatten: () => flatten4,
  gaussianDropout: () => gaussianDropout,
  gaussianNoise: () => gaussianNoise,
  globalAveragePooling1d: () => globalAveragePooling1d,
  globalAveragePooling2d: () => globalAveragePooling2d,
  globalMaxPool1d: () => globalMaxPool1d,
  globalMaxPool2d: () => globalMaxPool2d,
  globalMaxPooling1d: () => globalMaxPooling1d,
  globalMaxPooling2d: () => globalMaxPooling2d,
  gru: () => gru,
  gruCell: () => gruCell,
  input: () => input,
  inputLayer: () => inputLayer,
  layerNormalization: () => layerNormalization,
  leakyReLU: () => leakyReLU,
  lstm: () => lstm,
  lstmCell: () => lstmCell,
  masking: () => masking,
  maxPool1d: () => maxPool1d,
  maxPool2d: () => maxPool2d,
  maxPooling1d: () => maxPooling1d,
  maxPooling2d: () => maxPooling2d,
  maxPooling3d: () => maxPooling3d,
  maximum: () => maximum3,
  minimum: () => minimum3,
  multiply: () => multiply,
  permute: () => permute,
  prelu: () => prelu3,
  reLU: () => reLU,
  repeatVector: () => repeatVector,
  reshape: () => reshape3,
  rnn: () => rnn2,
  separableConv2d: () => separableConv2d3,
  simpleRNN: () => simpleRNN,
  simpleRNNCell: () => simpleRNNCell,
  softmax: () => softmax3,
  spatialDropout1d: () => spatialDropout1d,
  stackedRNNCells: () => stackedRNNCells,
  thresholdedReLU: () => thresholdedReLU,
  timeDistributed: () => timeDistributed,
  upSampling2d: () => upSampling2d,
  zeroPadding2d: () => zeroPadding2d
});

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/backend/state.ts
var _nextUniqueTensorId = 0;
function getNextUniqueTensorId() {
  return _nextUniqueTensorId++;
}
var _uidPrefixes = {};
function getUid(prefix = "") {
  if (!(prefix in _uidPrefixes)) {
    _uidPrefixes[prefix] = 0;
  }
  _uidPrefixes[prefix] += 1;
  return prefix + _uidPrefixes[prefix].toString();
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/types_utils.ts
function isArrayOfShapes(x) {
  return Array.isArray(x) && Array.isArray(x[0]);
}
function normalizeShapeList(x) {
  if (x.length === 0) {
    return [];
  }
  if (!Array.isArray(x[0])) {
    return [x];
  }
  return x;
}
function getExactlyOneTensor(xs) {
  let x;
  if (Array.isArray(xs)) {
    if (xs.length !== 1) {
      throw new ValueError(`Expected Tensor length to be 1; got ${xs.length}`);
    }
    x = xs[0];
  } else {
    x = xs;
  }
  return x;
}
function getExactlyOneShape(shapes) {
  if (Array.isArray(shapes) && Array.isArray(shapes[0])) {
    if (shapes.length === 1) {
      shapes = shapes;
      return shapes[0];
    } else {
      throw new ValueError(`Expected exactly 1 Shape; got ${shapes.length}`);
    }
  } else {
    return shapes;
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/variable_utils.ts
function countParamsInWeights(weights) {
  let count2 = 0;
  for (const weight of weights) {
    if (weight.shape.length === 0) {
      count2 += 1;
    } else {
      count2 += weight.shape.reduce((a, b) => a * b);
    }
  }
  return count2;
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/variables.ts
var DEFAULT_VARIABLE_NAME_PREFIX = "Variable";
var LayerVariable = class {
  constructor(val, dtype = "float32", name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {
    this.dtype = dtype == null ? "float32" : dtype;
    this.shape = val.shape;
    this.id = getNextUniqueTensorId();
    name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;
    this.originalName = getScopedTensorName(name);
    this.name = getUniqueTensorName(this.originalName);
    this.trainable_ = trainable;
    this.constraint = constraint;
    this.val = variable2(val, this.trainable_, this.name, this.dtype);
  }
  read() {
    this.assertNotDisposed();
    return this.val;
  }
  write(newVal) {
    this.assertNotDisposed();
    checkShapesMatch(this.val, newVal);
    if (this.val.id !== newVal.id) {
      this.val.assign(newVal);
      if (this.constraint != null) {
        this.val.assign(this.constraint.apply(this.val));
      }
    }
    return this;
  }
  dispose() {
    this.assertNotDisposed();
    this.val.dispose();
  }
  assertNotDisposed() {
    if (this.val.isDisposed) {
      throw new Error(`LayersVariable ${this.name} is already disposed.`);
    }
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(trainable) {
    this.trainable_ = trainable;
    this.val.trainable = trainable;
  }
};
function checkShapesMatch(x, y) {
  if (x.shape.toString() !== y.shape.toString()) {
    throw new Error("Shape mismatch: " + JSON.stringify(x.shape) + " vs. " + JSON.stringify(y.shape));
  }
}
function batchGetValue(xs) {
  return xs.map((x) => x.read());
}
function batchSetValue(variablesAndValues) {
  variablesAndValues.forEach((variableAndValue) => {
    const variable3 = variableAndValue[0];
    variable3.write(variableAndValue[1]);
  });
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/topology.ts
var InputSpec = class {
  constructor(args) {
    this.dtype = args.dtype;
    this.shape = args.shape;
    if (args.shape != null) {
      this.ndim = args.shape.length;
    } else {
      this.ndim = args.ndim;
    }
    this.maxNDim = args.maxNDim;
    this.minNDim = args.minNDim;
    this.axes = args.axes || {};
  }
};
var SymbolicTensor = class {
  constructor(dtype, shape, sourceLayer, inputs, callArgs, name, outputTensorIndex) {
    this.dtype = dtype;
    this.shape = shape;
    this.sourceLayer = sourceLayer;
    this.inputs = inputs;
    this.callArgs = callArgs;
    this.outputTensorIndex = outputTensorIndex;
    this.id = getNextUniqueTensorId();
    if (name != null) {
      this.originalName = getScopedTensorName(name);
      this.name = getUniqueTensorName(this.originalName);
    }
    this.rank = shape.length;
  }
};
var _nextNodeID = 0;
var Node = class {
  constructor(args, callArgs) {
    this.callArgs = callArgs;
    this.id = _nextNodeID++;
    this.outboundLayer = args.outboundLayer;
    this.inboundLayers = args.inboundLayers;
    this.nodeIndices = args.nodeIndices;
    this.tensorIndices = args.tensorIndices;
    this.inputTensors = args.inputTensors;
    this.outputTensors = args.outputTensors;
    this.inputMasks = args.inputMasks;
    this.outputMasks = args.outputMasks;
    this.inputShapes = args.inputShapes;
    this.outputShapes = args.outputShapes;
    for (const layer of args.inboundLayers) {
      if (layer != null) {
        layer.outboundNodes.push(this);
      }
    }
    args.outboundLayer.inboundNodes.push(this);
  }
  getConfig() {
    const inboundNames = [];
    for (const layer of this.inboundLayers) {
      if (layer != null) {
        inboundNames.push(layer.name);
      } else {
        inboundNames.push(null);
      }
    }
    return {
      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
      inboundLayers: inboundNames,
      nodeIndices: this.nodeIndices,
      tensorIndices: this.tensorIndices
    };
  }
};
var _nextLayerID = 0;
var Layer = class extends serialization_exports2.Serializable {
  constructor(args = {}) {
    super();
    this._callHook = null;
    this._addedWeightNames = [];
    this._stateful = false;
    this.id = _nextLayerID++;
    this.activityRegularizer = null;
    this.inputSpec = null;
    this.supportsMasking = false;
    this._trainableWeights = [];
    this._nonTrainableWeights = [];
    this._losses = [];
    this._updates = [];
    this._built = false;
    this.inboundNodes = [];
    this.outboundNodes = [];
    let name = args.name;
    if (!name) {
      const prefix = this.getClassName();
      name = toSnakeCase(prefix) + "_" + getUid(prefix);
    }
    this.name = name;
    this.trainable_ = args.trainable == null ? true : args.trainable;
    if (args.inputShape != null || args.batchInputShape != null) {
      let batchInputShape;
      if (args.batchInputShape != null) {
        batchInputShape = args.batchInputShape;
      } else if (args.inputShape != null) {
        let batchSize = null;
        if (args.batchSize != null) {
          batchSize = args.batchSize;
        }
        batchInputShape = [batchSize].concat(args.inputShape);
      }
      this.batchInputShape = batchInputShape;
      let dtype = args.dtype;
      if (dtype == null) {
        dtype = args.inputDType;
      }
      if (dtype == null) {
        dtype = "float32";
      }
      this.dtype = dtype;
    }
    if (args.weights != null) {
      this.initialWeights = args.weights;
    } else {
      this.initialWeights = null;
    }
    this._refCount = null;
    this.fastWeightInitDuringBuild = false;
  }
  static nodeKey(layer, nodeIndex) {
    return layer.name + "_ib-" + nodeIndex.toString();
  }
  getNodeAtIndex(nodeIndex, attrName) {
    if (this.inboundNodes.length === 0) {
      throw new RuntimeError(`The layer has never been called and thus has no defined ${attrName}.`);
    }
    if (this.inboundNodes.length <= nodeIndex) {
      throw new ValueError(`Asked to get ${attrName} at node ${nodeIndex}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
    }
    return this.inboundNodes[nodeIndex];
  }
  getInputAt(nodeIndex) {
    return singletonOrArray(this.getNodeAtIndex(nodeIndex, "input").inputTensors);
  }
  getOutputAt(nodeIndex) {
    return singletonOrArray(this.getNodeAtIndex(nodeIndex, "output").outputTensors);
  }
  get input() {
    if (this.inboundNodes.length > 1) {
      throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
    } else if (this.inboundNodes.length === 0) {
      throw new AttributeError(`Layer ${this.name} is not connected, no input to return.`);
    }
    return singletonOrArray(this.getNodeAtIndex(0, "input").inputTensors);
  }
  get output() {
    if (this.inboundNodes.length === 0) {
      throw new AttributeError(`Layer ${this.name} has no inbound nodes.`);
    }
    if (this.inboundNodes.length > 1) {
      throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
    }
    return singletonOrArray(this.getNodeAtIndex(0, "output").outputTensors);
  }
  get losses() {
    return this._losses;
  }
  calculateLosses() {
    return this.losses.map((lossFn) => lossFn());
  }
  get updates() {
    return this._updates;
  }
  get built() {
    return this._built;
  }
  set built(built) {
    this._built = built;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(trainable) {
    this._trainableWeights.forEach((w) => w.trainable = trainable);
    this.trainable_ = trainable;
  }
  get trainableWeights() {
    if (this.trainable_) {
      return this._trainableWeights.filter((w) => w.trainable);
    } else {
      return [];
    }
  }
  set trainableWeights(weights) {
    this._trainableWeights = weights;
  }
  get nonTrainableWeights() {
    if (this.trainable) {
      return this._trainableWeights.filter((w) => !w.trainable).concat(this._nonTrainableWeights);
    } else {
      return this._trainableWeights.concat(this._nonTrainableWeights);
    }
  }
  set nonTrainableWeights(weights) {
    this._nonTrainableWeights = weights;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  get stateful() {
    return this._stateful;
  }
  resetStates() {
    if (!this.stateful) {
      throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
    }
  }
  assertInputCompatibility(inputs) {
    inputs = toList(inputs);
    if (this.inputSpec == null || this.inputSpec.length === 0) {
      return;
    }
    const inputSpec = toList(this.inputSpec);
    if (inputs.length !== inputSpec.length) {
      throw new ValueError(`Layer ${this.name} expects ${inputSpec.length} inputs, but it received ${inputs.length} input tensors. Input received: ${inputs}`);
    }
    for (let inputIndex = 0; inputIndex < inputs.length; inputIndex++) {
      const x = inputs[inputIndex];
      const spec = inputSpec[inputIndex];
      if (spec == null) {
        continue;
      }
      const ndim = x.rank;
      if (spec.ndim != null) {
        if (ndim !== spec.ndim) {
          throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected ndim=${spec.ndim}, found ndim=${ndim}`);
        }
      }
      if (spec.maxNDim != null) {
        if (ndim > spec.maxNDim) {
          throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected max_ndim=${spec.maxNDim}, found ndim=${ndim}`);
        }
      }
      if (spec.minNDim != null) {
        if (ndim < spec.minNDim) {
          throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected min_ndim=${spec.minNDim}, found ndim=${ndim}.`);
        }
      }
      if (spec.dtype != null) {
        if (x.dtype !== spec.dtype) {
          throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name} : expected dtype=${spec.dtype}, found dtype=${x.dtype}.`);
        }
      }
      if (spec.axes) {
        const xShape = x.shape;
        for (const key in spec.axes) {
          const axis = Number(key);
          const value = spec.axes[key];
          const xShapeAtAxis = axis >= 0 ? xShape[axis] : xShape[xShape.length + axis];
          if (value != null && [value, null].indexOf(xShapeAtAxis) === -1) {
            throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected axis ${axis} of input shape to have value ${value} but got shape ${xShape}.`);
          }
        }
      }
      if (spec.shape != null) {
        for (let i = 0; i < spec.shape.length; ++i) {
          const specDim = spec.shape[i];
          const dim = x.shape[i];
          if (specDim != null && dim != null) {
            if (specDim !== dim) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected shape=${spec.shape}, found shape=${x.shape}.`);
            }
          }
        }
      }
    }
  }
  call(inputs, kwargs) {
    return inputs;
  }
  invokeCallHook(inputs, kwargs) {
    if (this._callHook != null) {
      this._callHook(inputs, kwargs);
    }
  }
  setCallHook(callHook) {
    this._callHook = callHook;
  }
  clearCallHook() {
    this._callHook = null;
  }
  apply(inputs, kwargs) {
    kwargs = kwargs || {};
    this.assertNotDisposed();
    const inputsList = toList(inputs);
    let allAreSymbolic = true;
    for (const input2 of inputsList) {
      if (!(input2 instanceof SymbolicTensor)) {
        allAreSymbolic = false;
        break;
      }
    }
    let noneAreSymbolic = true;
    for (const input2 of inputsList) {
      if (input2 instanceof SymbolicTensor) {
        noneAreSymbolic = false;
        break;
      }
    }
    if (allAreSymbolic === noneAreSymbolic) {
      throw new ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");
    }
    return nameScope(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(inputs);
        const inputShapes = [];
        for (const xElem of toList(inputs)) {
          inputShapes.push(xElem.shape);
        }
        this.build(singletonOrArray(inputShapes));
        this.built = true;
        if (this.initialWeights) {
          this.setWeights(this.initialWeights);
        }
        if (this._refCount === null && noneAreSymbolic) {
          this._refCount = 1;
        }
      }
      this.assertInputCompatibility(inputs);
      if (noneAreSymbolic) {
        let output = this.call(inputs, kwargs);
        const outputList = toList(output);
        const outputListCopy = [];
        for (let x of outputList) {
          if (inputsList.indexOf(x) !== -1) {
            x = x.clone();
          }
          outputListCopy.push(x);
        }
        output = singletonOrArray(outputListCopy);
        if (this.activityRegularizer != null) {
          throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        }
        return output;
      } else {
        const inputShape = collectInputShape(inputs);
        const outputShape = this.computeOutputShape(inputShape);
        let output;
        const outputDType = guessOutputDType(inputs);
        this.warnOnIncompatibleInputShape(Array.isArray(inputs) ? inputShape[0] : inputShape);
        if (outputShape != null && outputShape.length > 0 && Array.isArray(outputShape[0])) {
          output = outputShape.map((shape, index) => new SymbolicTensor(outputDType, shape, this, toList(inputs), kwargs, this.name, index));
        } else {
          output = new SymbolicTensor(outputDType, outputShape, this, toList(inputs), kwargs, this.name);
        }
        this.addInboundNode(inputs, output, null, null, inputShape, outputShape, kwargs);
        this._refCount++;
        if (this.activityRegularizer != null) {
          throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        }
        return output;
      }
    });
  }
  warnOnIncompatibleInputShape(inputShape) {
    if (this.batchInputShape == null) {
      return;
    } else if (inputShape.length !== this.batchInputShape.length) {
      console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(inputShape)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
    } else {
      let dimMismatch = false;
      this.batchInputShape.forEach((dimension, i) => {
        if (dimension != null && inputShape[i] != null && inputShape[i] !== dimension) {
          dimMismatch = true;
        }
      });
      if (dimMismatch) {
        console.warn(`The shape of the input tensor (${JSON.stringify(inputShape)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
      }
    }
  }
  get outputShape() {
    if (this.inboundNodes == null || this.inboundNodes.length === 0) {
      throw new AttributeError(`The layer ${this.name} has never been called and thus has no defined output shape.`);
    }
    const allOutputShapes = [];
    for (const node of this.inboundNodes) {
      const shapeString = JSON.stringify(node.outputShapes);
      if (allOutputShapes.indexOf(shapeString) === -1) {
        allOutputShapes.push(shapeString);
      }
    }
    if (allOutputShapes.length === 1) {
      const outputShapes = this.inboundNodes[0].outputShapes;
      if (Array.isArray(outputShapes) && Array.isArray(outputShapes[0]) && outputShapes.length === 1) {
        return outputShapes[0];
      } else {
        return outputShapes;
      }
    } else {
      throw new AttributeError(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
    }
  }
  countParams() {
    if (!this.built) {
      throw new RuntimeError(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
    }
    return countParamsInWeights(this.weights);
  }
  build(inputShape) {
    this.built = true;
  }
  getWeights(trainableOnly = false) {
    return batchGetValue(trainableOnly ? this.trainableWeights : this.weights);
  }
  setWeights(weights) {
    tidy2(() => {
      const params = this.weights;
      if (params.length !== weights.length) {
        throw new ValueError(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${weights.length}, but the layer was expecting ${params.length} weights. Provided weights: ${weights}...`);
      }
      if (params.length === 0) {
        return;
      }
      const weightValueTuples = [];
      const paramValues = batchGetValue(params);
      for (let i = 0; i < paramValues.length; ++i) {
        const pv = paramValues[i];
        const p2 = params[i];
        const w = weights[i];
        if (!util_exports2.arraysEqual(pv.shape, w.shape)) {
          throw new ValueError(`Layer weight shape ${pv.shape} not compatible with provided weight shape ${w.shape}`);
        }
        weightValueTuples.push([p2, w]);
      }
      batchSetValue(weightValueTuples);
    });
  }
  addWeight(name, shape, dtype, initializer, regularizer, trainable, constraint) {
    if (this._addedWeightNames.indexOf(name) !== -1) {
      throw new ValueError(`Duplicate weight name ${name} for layer ${this.name}`);
    }
    this._addedWeightNames.push(name);
    if (dtype == null) {
      dtype = "float32";
    }
    if (this.fastWeightInitDuringBuild) {
      initializer = getInitializer("zeros");
    }
    const initValue = initializer.apply(shape, dtype);
    const weight = new LayerVariable(initValue, dtype, name, trainable, constraint);
    initValue.dispose();
    if (regularizer != null) {
      this.addLoss(() => regularizer.apply(weight.read()));
    }
    if (trainable == null) {
      trainable = true;
    }
    if (trainable) {
      this._trainableWeights.push(weight);
    } else {
      this._nonTrainableWeights.push(weight);
    }
    return weight;
  }
  setFastWeightInitDuringBuild(value) {
    this.fastWeightInitDuringBuild = value;
  }
  addLoss(losses4) {
    if (losses4 == null || Array.isArray(losses4) && losses4.length === 0) {
      return;
    }
    losses4 = toList(losses4);
    if (this._losses !== void 0 && this._losses !== null) {
      this.losses.push(...losses4);
    }
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  computeMask(inputs, mask) {
    if (!this.supportsMasking) {
      if (mask != null) {
        if (Array.isArray(mask)) {
          mask.forEach((maskElement) => {
            if (maskElement != null) {
              throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
            }
          });
        } else {
          throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
        }
      }
      return null;
    }
    return mask;
  }
  addInboundNode(inputTensors, outputTensors, inputMasks, outputMasks, inputShapes, outputShapes, kwargs = null) {
    const inputTensorList = toList(inputTensors);
    outputTensors = toList(outputTensors);
    inputMasks = toList(inputMasks);
    outputMasks = toList(outputMasks);
    inputShapes = normalizeShapeList(inputShapes);
    outputShapes = normalizeShapeList(outputShapes);
    const inboundLayers = [];
    const nodeIndices = [];
    const tensorIndices = [];
    for (const x of inputTensorList) {
      inboundLayers.push(x.sourceLayer);
      nodeIndices.push(x.nodeIndex);
      tensorIndices.push(x.tensorIndex);
    }
    new Node({
      outboundLayer: this,
      inboundLayers,
      nodeIndices,
      tensorIndices,
      inputTensors: inputTensorList,
      outputTensors,
      inputMasks,
      outputMasks,
      inputShapes,
      outputShapes
    }, kwargs);
    for (let i = 0; i < outputTensors.length; i++) {
      outputTensors[i].sourceLayer = this;
      outputTensors[i].nodeIndex = this.inboundNodes.length - 1;
      outputTensors[i].tensorIndex = i;
    }
  }
  getConfig() {
    const config = { name: this.name, trainable: this.trainable };
    if (this.batchInputShape != null) {
      config["batchInputShape"] = this.batchInputShape;
    }
    if (this.dtype != null) {
      config["dtype"] = this.dtype;
    }
    return config;
  }
  disposeWeights() {
    this.weights.forEach((weight) => weight.dispose());
    return this.weights.length;
  }
  assertNotDisposed() {
    if (this._refCount === 0) {
      throw new Error(`Layer '${this.name}' is already disposed.`);
    }
  }
  dispose() {
    if (!this.built) {
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
    }
    if (this._refCount === null) {
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
    }
    this.assertNotDisposed();
    let numDisposedVariables = 0;
    if (--this._refCount === 0) {
      numDisposedVariables = this.disposeWeights();
    }
    return { refCountAfterDispose: this._refCount, numDisposedVariables };
  }
};
function collectInputShape(inputTensors) {
  inputTensors = toList(inputTensors);
  const shapes = [];
  for (const x of inputTensors) {
    shapes.push(x.shape);
  }
  return singletonOrArray(shapes);
}
function guessOutputDType(inputTensors) {
  return "float32";
}
function getSourceInputs(tensor3, layer, nodeIndex) {
  if (layer == null || nodeIndex != null && nodeIndex > 0) {
    layer = tensor3.sourceLayer;
    nodeIndex = tensor3.nodeIndex;
  }
  if (layer.inboundNodes.length === 0) {
    return [tensor3];
  } else {
    const node = layer.inboundNodes[nodeIndex];
    if (node.inboundLayers.length === 0) {
      return node.inputTensors;
    } else {
      const sourceTensors = [];
      for (let i = 0; i < node.inboundLayers.length; i++) {
        const x = node.inputTensors[i];
        const layer2 = node.inboundLayers[i];
        const nodeIndex2 = node.nodeIndices[i];
        const previousSources = getSourceInputs(x, layer2, nodeIndex2);
        for (const x2 of previousSources) {
          if (sourceTensors.indexOf(x2) === -1) {
            sourceTensors.push(x2);
          }
        }
      }
      return sourceTensors;
    }
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/input_layer.ts
var InputLayer = class extends Layer {
  constructor(args) {
    super({
      dtype: args.dtype,
      name: args.name != null ? args.name : getUid("input").toString()
    });
    if (args.batchSize == null) {
      args.batchSize = null;
    }
    if (args.sparse == null) {
      args.sparse = false;
    }
    this.trainable = false;
    this.built = true;
    this.sparse = args.sparse;
    if (args.inputShape != null && args.batchInputShape != null) {
      throw new ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    }
    let batchInputShape = args.batchInputShape;
    if (batchInputShape == null) {
      if (args.inputShape == null) {
        throw new ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      } else {
        batchInputShape = [args.batchSize].concat(args.inputShape);
      }
    } else {
      if (args.batchSize != null) {
        throw new ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
      }
    }
    const dtype = args.dtype || "float32";
    this.batchInputShape = batchInputShape;
    this.dtype = dtype;
    this.inputSpec = [{ shape: batchInputShape }];
    const inputTensor = new SymbolicTensor(this.dtype, this.batchInputShape, this, [], {}, this.name);
    inputTensor.nodeIndex = 0;
    inputTensor.tensorIndex = 0;
    new Node({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: [inputTensor],
      outputTensors: [inputTensor],
      inputMasks: [null],
      outputMasks: [null],
      inputShapes: [batchInputShape],
      outputShapes: [batchInputShape]
    });
  }
  apply(inputs, kwargs) {
    throw new ValueError(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
  }
  dispose() {
    return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
  }
  getConfig() {
    return {
      batchInputShape: this.batchInputShape,
      dtype: this.dtype,
      sparse: this.sparse,
      name: this.name
    };
  }
};
InputLayer.className = "InputLayer";
serialization_exports2.registerClass(InputLayer);
function Input(config) {
  if (config.batchShape == null && config.shape == null) {
    throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  }
  if (config.batchShape != null && config.shape != null) {
    throw new ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  }
  let batchShape = config.batchShape;
  if (config.shape != null && batchShape == null) {
    batchShape = [null].concat(config.shape);
  }
  let dtype = config.dtype;
  if (dtype == null) {
    dtype = "float32";
  }
  const inputLayer2 = new InputLayer({
    batchInputShape: batchShape,
    name: config.name,
    dtype,
    sparse: config.sparse
  });
  const outputs = inputLayer2.inboundNodes[0].outputTensors;
  return outputs[0];
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/logs.ts
async function resolveScalarsInLogs(logs) {
  if (logs == null) {
    return;
  }
  const promises = [];
  const keys = [];
  const scalarsToDispose = [];
  for (const key in logs) {
    const value = logs[key];
    if (typeof value !== "number") {
      const valueScalar = value;
      promises.push(valueScalar.data());
      keys.push(key);
      scalarsToDispose.push(valueScalar);
    }
  }
  if (promises.length > 0) {
    const values = await Promise.all(promises);
    for (let i = 0; i < values.length; ++i) {
      logs[keys[i]] = values[i][0];
    }
    dispose2(scalarsToDispose);
  }
}
function disposeTensorsInLogs(logs) {
  if (logs == null) {
    return;
  }
  for (const key in logs) {
    const value = logs[key];
    if (typeof value !== "number") {
      value.dispose();
    }
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/base_callbacks.ts
var ModelLoggingVerbosity;
(function(ModelLoggingVerbosity4) {
  ModelLoggingVerbosity4[ModelLoggingVerbosity4["SILENT"] = 0] = "SILENT";
  ModelLoggingVerbosity4[ModelLoggingVerbosity4["VERBOSE"] = 1] = "VERBOSE";
})(ModelLoggingVerbosity || (ModelLoggingVerbosity = {}));
var DEFAULT_YIELD_EVERY_MS = 125;
var BaseCallback = class {
  constructor() {
    this.validationData = null;
  }
  setParams(params) {
    this.params = params;
  }
  async onEpochBegin(epoch, logs) {
  }
  async onEpochEnd(epoch, logs) {
  }
  async onBatchBegin(batch, logs) {
  }
  async onBatchEnd(batch, logs) {
  }
  async onTrainBegin(logs) {
  }
  async onTrainEnd(logs) {
  }
  setModel(model2) {
  }
};
var CallbackList = class {
  constructor(callbacks2, queueLength = 10) {
    if (callbacks2 == null) {
      callbacks2 = [];
    }
    this.callbacks = callbacks2;
    this.queueLength = queueLength;
  }
  append(callback) {
    this.callbacks.push(callback);
  }
  setParams(params) {
    for (const callback of this.callbacks) {
      callback.setParams(params);
    }
  }
  setModel(model2) {
    for (const callback of this.callbacks) {
      callback.setModel(model2);
    }
  }
  async onEpochBegin(epoch, logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onEpochBegin(epoch, logs);
    }
  }
  async onEpochEnd(epoch, logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onEpochEnd(epoch, logs);
    }
  }
  async onBatchBegin(batch, logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onBatchBegin(batch, logs);
    }
  }
  async onBatchEnd(batch, logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onBatchEnd(batch, logs);
    }
  }
  async onTrainBegin(logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onTrainBegin(logs);
    }
  }
  async onTrainEnd(logs) {
    if (logs == null) {
      logs = {};
    }
    for (const callback of this.callbacks) {
      await callback.onTrainEnd(logs);
    }
  }
};
var BaseLogger = class extends BaseCallback {
  constructor() {
    super();
  }
  async onEpochBegin(epoch) {
    this.seen = 0;
    this.totals = {};
  }
  async onBatchEnd(batch, logs) {
    if (logs == null) {
      logs = {};
    }
    const batchSize = logs["size"] == null ? 0 : logs["size"];
    this.seen += batchSize;
    for (const key in logs) {
      const value = logs[key];
      if (typeof value === "number") {
        if (!this.totals.hasOwnProperty(key)) {
          this.totals[key] = 0;
        }
        this.totals[key] = this.totals[key] + value * batchSize;
      } else {
        let oldTotalsToDispose;
        if (key in this.totals) {
          oldTotalsToDispose = this.totals[key];
        } else {
          this.totals[key] = 0;
        }
        const total = tidy2(() => add4(this.totals[key], mul2(value, batchSize)));
        this.totals[key] = total;
        if (oldTotalsToDispose != null) {
          oldTotalsToDispose.dispose();
        }
      }
    }
  }
  async onEpochEnd(epoch, logs) {
    if (logs != null) {
      for (const key of this.params["metrics"]) {
        if (this.totals[key] == null) {
          continue;
        }
        if (typeof this.totals[key] === "number") {
          logs[key] = this.totals[key] / this.seen;
        } else {
          tidy2(() => {
            const log8 = mul2(div2(1, this.seen), this.totals[key]);
            logs[key] = log8;
            this.totals[key].dispose();
            keep2(logs[key]);
          });
        }
      }
    }
  }
};
var History = class extends BaseCallback {
  async onTrainBegin(logs) {
    this.epoch = [];
    this.history = {};
  }
  async onEpochEnd(epoch, logs) {
    if (logs == null) {
      logs = {};
    }
    this.epoch.push(epoch);
    for (const key in logs) {
      if (this.history[key] == null) {
        this.history[key] = [];
      }
      this.history[key].push(logs[key]);
    }
  }
  async syncData() {
    const promises = [];
    const keys = [];
    const indices = [];
    for (const key in this.history) {
      const valueArray = this.history[key];
      for (let i = 0; i < valueArray.length; ++i) {
        if (typeof valueArray[i] !== "number") {
          const valueScalar = valueArray[i];
          promises.push(valueScalar.data());
          keys.push(key);
          indices.push(i);
        }
      }
    }
    const values = await Promise.all(promises);
    for (let n = 0; n < values.length; ++n) {
      const tensorToDispose = this.history[keys[n]][indices[n]];
      tensorToDispose.dispose();
      this.history[keys[n]][indices[n]] = values[n][0];
    }
  }
};
var CustomCallback = class extends BaseCallback {
  constructor(args, yieldEvery) {
    super();
    this.currentEpoch = 0;
    this.yieldEvery = yieldEvery || "auto";
    if (this.yieldEvery === "auto") {
      this.yieldEvery = DEFAULT_YIELD_EVERY_MS;
    }
    if (this.yieldEvery === "never" && args.onYield != null) {
      throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    }
    if (util_exports2.isNumber(this.yieldEvery)) {
      this.maybeWait = debounce(this.maybeWait.bind(this), this.yieldEvery);
    }
    this.trainBegin = args.onTrainBegin;
    this.trainEnd = args.onTrainEnd;
    this.epochBegin = args.onEpochBegin;
    this.epochEnd = args.onEpochEnd;
    this.batchBegin = args.onBatchBegin;
    this.batchEnd = args.onBatchEnd;
    this.yield = args.onYield;
  }
  async maybeWait(epoch, batch, logs) {
    const ps = [];
    if (this.yield != null) {
      await resolveScalarsInLogs(logs);
      ps.push(this.yield(epoch, batch, logs));
    }
    ps.push(nextFrame2());
    await Promise.all(ps);
  }
  async onEpochBegin(epoch, logs) {
    this.currentEpoch = epoch;
    if (this.epochBegin != null) {
      await resolveScalarsInLogs(logs);
      await this.epochBegin(epoch, logs);
    }
  }
  async onEpochEnd(epoch, logs) {
    const ps = [];
    if (this.epochEnd != null) {
      await resolveScalarsInLogs(logs);
      ps.push(this.epochEnd(epoch, logs));
    }
    if (this.yieldEvery === "epoch") {
      ps.push(nextFrame2());
    }
    await Promise.all(ps);
  }
  async onBatchBegin(batch, logs) {
    if (this.batchBegin != null) {
      await resolveScalarsInLogs(logs);
      await this.batchBegin(batch, logs);
    }
  }
  async onBatchEnd(batch, logs) {
    const ps = [];
    if (this.batchEnd != null) {
      await resolveScalarsInLogs(logs);
      ps.push(this.batchEnd(batch, logs));
    }
    if (this.yieldEvery === "batch") {
      ps.push(nextFrame2());
    } else if (util_exports2.isNumber(this.yieldEvery)) {
      ps.push(this.maybeWait(this.currentEpoch, batch, logs));
    }
    await Promise.all(ps);
  }
  async onTrainBegin(logs) {
    if (this.trainBegin != null) {
      await resolveScalarsInLogs(logs);
      await this.trainBegin(logs);
    }
  }
  async onTrainEnd(logs) {
    if (this.trainEnd != null) {
      await resolveScalarsInLogs(logs);
      await this.trainEnd(logs);
    }
  }
};
function standardizeCallbacks(callbacks2, yieldEvery) {
  if (callbacks2 == null) {
    callbacks2 = {};
  }
  if (callbacks2 instanceof BaseCallback) {
    return [callbacks2];
  }
  if (Array.isArray(callbacks2) && callbacks2[0] instanceof BaseCallback) {
    return callbacks2;
  }
  const callbackConfigs = toList(callbacks2);
  return callbackConfigs.map((callbackConfig) => new CustomCallback(callbackConfig, yieldEvery));
}
var _CallbackConstructorRegistry = class {
  constructor() {
  }
  static registerCallbackConstructor(verbosityLevel, callbackConstructor) {
    util_exports2.assert(verbosityLevel >= 0 && Number.isInteger(verbosityLevel), () => `Verbosity level is expected to be an integer >= 0, but got ${verbosityLevel}`);
    _CallbackConstructorRegistry.checkForDuplicate(callbackConstructor);
    if (_CallbackConstructorRegistry.constructors[verbosityLevel] == null) {
      _CallbackConstructorRegistry.constructors[verbosityLevel] = [];
    }
    _CallbackConstructorRegistry.constructors[verbosityLevel].push(callbackConstructor);
  }
  static checkForDuplicate(callbackConstructor) {
    for (const levelName in _CallbackConstructorRegistry.constructors) {
      const constructors = _CallbackConstructorRegistry.constructors[+levelName];
      constructors.forEach((ctor) => {
        if (ctor === callbackConstructor) {
          throw new ValueError("Duplicate callback constructor.");
        }
      });
    }
  }
  static clear() {
    _CallbackConstructorRegistry.constructors = {};
  }
  static createCallbacks(verbosityLevel) {
    const constructors = [];
    for (const levelName in _CallbackConstructorRegistry.constructors) {
      const level = +levelName;
      if (verbosityLevel >= level) {
        constructors.push(..._CallbackConstructorRegistry.constructors[level]);
      }
    }
    return constructors.map((ctor) => new ctor());
  }
};
var CallbackConstructorRegistry = _CallbackConstructorRegistry;
CallbackConstructorRegistry.constructors = {};
function configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics) {
  const history = new History();
  const actualCallbacks = [
    new BaseLogger(),
    ...CallbackConstructorRegistry.createCallbacks(verbose)
  ];
  if (callbacks2 != null) {
    actualCallbacks.push(...callbacks2);
  }
  actualCallbacks.push(history);
  const callbackList = new CallbackList(actualCallbacks);
  callbackList.setParams({
    epochs,
    initialEpoch,
    samples: numTrainSamples,
    steps: stepsPerEpoch,
    batchSize,
    verbose,
    doValidation,
    metrics: callbackMetrics
  });
  return { callbackList, history };
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/serialization.ts
function deserialize(config, customObjects = {}, fastWeightInit = false) {
  return deserializeKerasObject(config, serialization_exports2.SerializationMap.getMap().classNameMap, customObjects, "layer", fastWeightInit);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/losses.ts
function l2Normalize(x, axis) {
  return tidy2(() => {
    if (x.dtype !== "float32") {
      x = x.asType("float32");
    }
    const squareSum = sum4(square3(x), axis, true);
    const epsilonTensor = fill2(squareSum.shape, epsilon());
    const norm3 = sqrt2(maximum2(squareSum, epsilonTensor));
    return div2(x, norm3);
  });
}
function meanSquaredError3(yTrue, yPred) {
  return tidy2(() => mean2(square3(sub2(yPred, yTrue)), -1));
}
function meanAbsoluteError(yTrue, yPred) {
  return tidy2(() => mean2(abs2(sub2(yPred, yTrue)), -1));
}
function meanAbsolutePercentageError(yTrue, yPred) {
  return tidy2(() => {
    const diff = sub2(yTrue, yPred);
    const clippedTrue = clipByValue2(abs2(yTrue), epsilon(), Number.MAX_VALUE);
    const absResult = abs2(div2(diff, clippedTrue));
    return mul2(100, mean2(absResult, -1));
  });
}
function meanSquaredLogarithmicError(yTrue, yPred) {
  return tidy2(() => {
    const clippedPred = clipByValue2(yPred, epsilon(), Number.MAX_VALUE);
    const firstLog = log3(add4(1, clippedPred));
    const clippedTrue = clipByValue2(yTrue, epsilon(), Number.MAX_VALUE);
    const secondLog = log3(add4(1, clippedTrue));
    return mean2(square3(sub2(firstLog, secondLog)), -1);
  });
}
function squaredHinge(yTrue, yPred) {
  return tidy2(() => {
    const maxResult = maximum2(0, sub2(1, mul2(yTrue, yPred)));
    return mean2(square3(maxResult), -1);
  });
}
function hinge(yTrue, yPred) {
  return tidy2(() => {
    const maxResult = maximum2(0, sub2(1, mul2(yTrue, yPred)));
    return mean2(maxResult, -1);
  });
}
function categoricalHinge(yTrue, yPred) {
  return tidy2(() => {
    const pos = sum4(mul2(yTrue, yPred), -1);
    const neg5 = max2(mul2(sub2(1, yTrue), yPred), -1);
    return maximum2(0, add4(1, sub2(neg5, pos)));
  });
}
function logcosh(yTrue, yPred) {
  return tidy2(() => {
    const log22 = Math.log(2);
    const predictionDiff = sub2(yPred, yTrue);
    const logcoshResult = sub2(add4(predictionDiff, softplus2(mul2(-2, predictionDiff))), log22);
    return mean2(logcoshResult, -1);
  });
}
function categoricalCrossentropy(target, output, fromLogits = false) {
  return tidy2(() => {
    if (fromLogits) {
      output = softmax2(output);
    } else {
      const outputSum = sum4(output, output.shape.length - 1, true);
      output = div2(output, outputSum);
    }
    output = clipByValue2(output, epsilon(), 1 - epsilon());
    return neg2(sum4(mul2(target.toFloat(), log3(output)), output.shape.length - 1));
  });
}
function sparseCategoricalCrossentropy(target, output, fromLogits = false) {
  return tidy2(() => {
    const flatTarget = floor2(flatten3(target)).toInt();
    output = clipByValue2(output, epsilon(), 1 - epsilon());
    const outputShape = output.shape;
    const oneHotTarget = oneHot2(flatTarget, outputShape[outputShape.length - 1]).reshape(outputShape);
    return categoricalCrossentropy(oneHotTarget, output, fromLogits);
  });
}
function sigmoidCrossEntropyWithLogits(labels, logits) {
  if (!util_exports2.arraysEqual(labels.shape, logits.shape)) {
    throw new ValueError(`logits and labels must have the same shape, but got shapes ${JSON.stringify(labels.shape)} and ${JSON.stringify(logits.shape)}`);
  }
  return tidy2(() => {
    const reluLogits = logits.relu();
    const negAbsLogits = logits.abs().neg();
    return reluLogits.sub(logits.mul(labels)).add(negAbsLogits.exp().log1p());
  });
}
function binaryCrossentropy(yTrue, yPred) {
  return tidy2(() => {
    let y;
    y = clipByValue2(yPred, epsilon(), 1 - epsilon());
    y = log3(div2(y, sub2(1, y)));
    return mean2(sigmoidCrossEntropyWithLogits(yTrue, y), -1);
  });
}
function kullbackLeiblerDivergence(yTrue, yPred) {
  return tidy2(() => {
    const clippedTrue = clipByValue2(yTrue, epsilon(), 1);
    const clippedPred = clipByValue2(yPred, epsilon(), 1);
    return sum4(mul2(yTrue, log3(div2(clippedTrue, clippedPred))), -1);
  });
}
function poisson(yTrue, yPred) {
  return tidy2(() => {
    const logPred = log3(add4(epsilon(), yPred));
    return mean2(sub2(yPred, mul2(yTrue, logPred)), -1);
  });
}
function cosineProximity(yTrue, yPred) {
  return tidy2(() => {
    const trueNormalized = l2Normalize(yTrue, -1);
    const predNormalized = l2Normalize(yPred, -1);
    const trueXPred = mul2(trueNormalized, predNormalized);
    return neg2(sum4(trueXPred, -1));
  });
}
var lossesMap = {
  meanSquaredError: meanSquaredError3,
  meanAbsoluteError,
  meanAbsolutePercentageError,
  meanSquaredLogarithmicError,
  squaredHinge,
  hinge,
  categoricalHinge,
  logcosh,
  categoricalCrossentropy,
  sparseCategoricalCrossentropy,
  binaryCrossentropy,
  kullbackLeiblerDivergence,
  poisson,
  cosineProximity
};
function get(identifierOrFn) {
  if (typeof identifierOrFn === "string") {
    if (identifierOrFn in lossesMap) {
      return lossesMap[identifierOrFn];
    }
    let errMsg = `Unknown loss ${identifierOrFn}`;
    if (identifierOrFn.toLowerCase().includes("softmaxcrossentropy")) {
      errMsg = `Unknown loss ${identifierOrFn}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`;
    }
    throw new ValueError(errMsg);
  } else {
    return identifierOrFn;
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/metrics.ts
function binaryAccuracy(yTrue, yPred) {
  return tidy2(() => {
    const threshold4 = mul2(0.5, onesLike2(yPred));
    const yPredThresholded = cast3(greater2(yPred, threshold4), yTrue.dtype);
    return mean2(equal2(yTrue, yPredThresholded), -1);
  });
}
function categoricalAccuracy(yTrue, yPred) {
  return tidy2(() => cast3(equal2(argMax2(yTrue, -1), argMax2(yPred, -1)), "float32"));
}
function truePositives(yTrue, yPred) {
  return tidy2(() => {
    return logicalAnd2(yTrue.equal(1), yPred.equal(1)).sum().cast("float32");
  });
}
function falseNegatives(yTrue, yPred) {
  return tidy2(() => {
    return logicalAnd2(yTrue.equal(1), yPred.equal(0)).sum().cast("float32");
  });
}
function falsePositives(yTrue, yPred) {
  return tidy2(() => {
    return logicalAnd2(yTrue.equal(0), yPred.equal(1)).sum().cast("float32");
  });
}
function precision(yTrue, yPred) {
  return tidy2(() => {
    const tp = truePositives(yTrue, yPred);
    const fp = falsePositives(yTrue, yPred);
    const denominator = tp.add(fp);
    return where2(greater2(denominator, 0), tp.div(denominator), 0).cast("float32");
  });
}
function recall(yTrue, yPred) {
  return tidy2(() => {
    const tp = truePositives(yTrue, yPred);
    const fn = falseNegatives(yTrue, yPred);
    const denominator = tp.add(fn);
    return where2(greater2(denominator, 0), tp.div(denominator), 0).cast("float32");
  });
}
function binaryCrossentropy2(yTrue, yPred) {
  return binaryCrossentropy(yTrue, yPred);
}
function sparseCategoricalAccuracy(yTrue, yPred) {
  if (yTrue.rank === yPred.rank) {
    yTrue = yTrue.squeeze([yTrue.rank - 1]);
  }
  yPred = yPred.argMax(-1);
  if (yPred.dtype !== yTrue.dtype) {
    yPred = yPred.asType(yTrue.dtype);
  }
  return equal2(yTrue, yPred).asType("float32");
}
var mse = meanSquaredError3;
var MSE = meanSquaredError3;
var mae = meanAbsoluteError;
var MAE = meanAbsoluteError;
var mape = meanAbsolutePercentageError;
var MAPE = meanAbsolutePercentageError;
var categoricalCrossentropy2 = categoricalCrossentropy;
var cosine = cosineProximity;
var sparseCategoricalCrossentropy2 = sparseCategoricalCrossentropy;
var metricsMap = {
  binaryAccuracy,
  categoricalAccuracy,
  precision,
  categoricalCrossentropy: categoricalCrossentropy2,
  sparseCategoricalCrossentropy: sparseCategoricalCrossentropy2,
  mse,
  MSE,
  mae,
  MAE,
  mape,
  MAPE,
  cosine
};
function get2(identifier) {
  if (typeof identifier === "string" && identifier in metricsMap) {
    return metricsMap[identifier];
  } else if (typeof identifier !== "string" && identifier != null) {
    return identifier;
  } else {
    throw new ValueError(`Unknown metric ${identifier}`);
  }
}
function getLossOrMetricName(fn) {
  assert3(fn !== null, `Unknown LossOrMetricFn ${fn}`);
  if (typeof fn === "string") {
    return fn;
  } else {
    let fnName;
    for (const key of Object.keys(lossesMap)) {
      if (lossesMap[key] === fn) {
        fnName = key;
        break;
      }
    }
    if (fnName !== void 0) {
      return fnName;
    }
    for (const key of Object.keys(metricsMap)) {
      if (metricsMap[key] === fn) {
        fnName = key;
        break;
      }
    }
    if (fnName !== void 0) {
      return fnName;
    }
    return fn.name;
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/optimizers.ts
function getOptimizer(identifier) {
  const optimizerMap = {
    "Adagrad": () => train2.adagrad(0.01),
    "Adadelta": () => train2.adadelta(1, 0.95, epsilon()),
    "Adam": () => train2.adam(1e-3, 0.9, 0.999, epsilon()),
    "Adamax": () => train2.adamax(2e-3, 0.9, 0.999, epsilon(), 0),
    "RMSProp": () => train2.rmsprop(1e-3, 0.9, 0, epsilon()),
    "SGD": () => train2.sgd(0.01)
  };
  optimizerMap["adagrad"] = optimizerMap["Adagrad"];
  optimizerMap["adadelta"] = optimizerMap["Adadelta"];
  optimizerMap["adam"] = optimizerMap["Adam"];
  optimizerMap["adamax"] = optimizerMap["Adamax"];
  optimizerMap["rmsprop"] = optimizerMap["RMSProp"];
  optimizerMap["sgd"] = optimizerMap["SGD"];
  if (identifier in optimizerMap) {
    return optimizerMap[identifier]();
  }
  throw new ValueError(`Unknown Optimizer ${identifier}`);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/user_defined_metadata.ts
var MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH = 1 * 1024 * 1024;
function checkUserDefinedMetadata(userDefinedMetadata, modelName, checkSize = false) {
  if (userDefinedMetadata == null || typeof userDefinedMetadata !== "object" || Object.getPrototypeOf(userDefinedMetadata) !== Object.prototype || !plainObjectCheck(userDefinedMetadata)) {
    throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
  }
  if (checkSize) {
    const out = JSON.stringify(userDefinedMetadata);
    if (out.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH) {
      console.warn(`User-defined metadata of model "${modelName}" is too large in size (length=${out.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH}.`);
    }
  }
}
function plainObjectCheck(x) {
  if (x === null) {
    return true;
  } else if (typeof x === "object") {
    if (Object.getPrototypeOf(x) === Object.prototype) {
      const keys = Object.keys(x);
      for (const key of keys) {
        if (typeof key !== "string") {
          return false;
        }
        if (!plainObjectCheck(x[key])) {
          return false;
        }
      }
      return true;
    } else {
      if (Array.isArray(x)) {
        for (const item of x) {
          if (!plainObjectCheck(item)) {
            return false;
          }
        }
        return true;
      } else {
        return false;
      }
    }
  } else {
    const xType = typeof x;
    return xType === "string" || xType === "number" || xType === "boolean";
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/layer_utils.ts
function printSummary(model2, lineLength, positions, printFn = console.log) {
  const sequentialLike = isModelSequentialLike(model2);
  const toDisplay = ["Layer (type)", "Output shape", "Param #"];
  if (sequentialLike) {
    lineLength = lineLength || 65;
    positions = positions || [0.45, 0.85, 1];
  } else {
    lineLength = lineLength || 98;
    positions = positions || [0.33, 0.55, 0.67, 1];
  }
  if (positions[positions.length - 1] <= 1) {
    positions = positions.map((p2) => Math.floor(lineLength * p2));
  }
  let relevantNodes;
  if (!sequentialLike) {
    toDisplay.push("Receives inputs");
    relevantNodes = [];
    for (const depth in model2.nodesByDepth) {
      relevantNodes.push(...model2.nodesByDepth[depth]);
    }
  }
  printFn("_".repeat(lineLength));
  printRow(toDisplay, positions, printFn);
  printFn("=".repeat(lineLength));
  const layers = model2.layers;
  for (let i = 0; i < layers.length; ++i) {
    if (sequentialLike) {
      printLayerSummary(layers[i], positions, printFn);
    } else {
      printLayerSummaryWithConnections(layers[i], positions, relevantNodes, printFn);
    }
    printFn((i === layers.length - 1 ? "=" : "_").repeat(lineLength));
  }
  model2.checkTrainableWeightsConsistency();
  const trainableCount = countTrainableParams(model2);
  const nonTrainableCount = countParamsInWeights(model2.nonTrainableWeights);
  printFn(`Total params: ${trainableCount + nonTrainableCount}`);
  printFn(`Trainable params: ${trainableCount}`);
  printFn(`Non-trainable params: ${nonTrainableCount}`);
  printFn("_".repeat(lineLength));
}
function countTrainableParams(model2) {
  let trainableCount;
  if (model2.collectedTrainableWeights != null) {
    trainableCount = countParamsInWeights(model2.collectedTrainableWeights);
  } else {
    trainableCount = countParamsInWeights(model2.trainableWeights);
  }
  return trainableCount;
}
function isModelSequentialLike(model2) {
  let sequentialLike = true;
  const nodesByDepth = [];
  const nodes = [];
  for (const depth in model2.nodesByDepth) {
    nodesByDepth.push(model2.nodesByDepth[depth]);
  }
  for (const depthNodes of nodesByDepth) {
    if (depthNodes.length > 1 || depthNodes.length === 1 && depthNodes[0].inboundLayers.length > 1) {
      sequentialLike = false;
      break;
    }
    nodes.push(...depthNodes);
  }
  if (sequentialLike) {
    for (const layer of model2.layers) {
      let flag = false;
      for (const node of layer.inboundNodes) {
        if (nodes.indexOf(node) !== -1) {
          if (flag) {
            sequentialLike = false;
            break;
          } else {
            flag = true;
          }
        }
      }
      if (!sequentialLike) {
        break;
      }
    }
  }
  return sequentialLike;
}
function printRow(fields, positions, printFn = console.log) {
  let line = "";
  for (let i = 0; i < fields.length; ++i) {
    if (i > 0) {
      line = line.slice(0, line.length - 1) + " ";
    }
    line += fields[i];
    line = line.slice(0, positions[i]);
    line += " ".repeat(positions[i] - line.length);
  }
  printFn(line);
}
function printLayerSummary(layer, positions, printFn) {
  let outputShape;
  try {
    outputShape = JSON.stringify(layer.outputShape);
  } catch (err) {
    outputShape = "multiple";
  }
  const name = layer.name;
  const className = layer.getClassName();
  const fields = [`${name} (${className})`, outputShape, layer.countParams().toString()];
  printRow(fields, positions, printFn);
}
function printLayerSummaryWithConnections(layer, positions, relevantNodes, printFn) {
  let outputShape;
  try {
    outputShape = JSON.stringify(layer.outputShape);
  } catch (err) {
    outputShape = "multiple";
  }
  const connections = [];
  for (const node of layer.inboundNodes) {
    if (relevantNodes != null && relevantNodes.length > 0 && relevantNodes.indexOf(node) === -1) {
      continue;
    }
    for (let i = 0; i < node.inboundLayers.length; ++i) {
      const inboundLayer = node.inboundLayers[i].name;
      const inboundLayerIndex = node.nodeIndices[i];
      const inboundTensorIndex = node.tensorIndices[i];
      connections.push(`${inboundLayer}[${inboundLayerIndex}][${inboundTensorIndex}]`);
    }
  }
  const name = layer.name;
  const className = layer.getClassName();
  const firstConnection = connections.length === 0 ? "" : connections[0];
  const fields = [
    `${name} (${className})`,
    outputShape,
    layer.countParams().toString(),
    firstConnection
  ];
  printRow(fields, positions, printFn);
  for (let i = 1; i < connections.length; ++i) {
    printRow(["", "", "", connections[i]], positions, printFn);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/serialization_utils.ts
function isArrayItemInputOrOutputName(key, index, value) {
  return (key === "inboundNodes" || key === "outputLayers" || key === "inputLayers") && index === 0 && typeof value === "string";
}
function convertPythonicToTs(pythonicConfig, key) {
  if (pythonicConfig === null) {
    return null;
  } else if (typeof pythonicConfig === "string") {
    return toCamelCase(pythonicConfig);
  } else if (typeof pythonicConfig === "number" || typeof pythonicConfig === "boolean") {
    return pythonicConfig;
  } else if (pythonicConfig instanceof Array) {
    const tsArray = [];
    const arrayLength = pythonicConfig.length;
    for (let i = 0; i < arrayLength; ++i) {
      const item = pythonicConfig[i];
      if (isArrayItemInputOrOutputName(key, i, item)) {
        tsArray.push(item);
      } else {
        tsArray.push(convertPythonicToTs(item, key));
      }
    }
    return tsArray;
  } else {
    const tsDict = {};
    for (const pythonicKey of Object.keys(pythonicConfig)) {
      const pythonicValue = pythonicConfig[pythonicKey];
      if (pythonicKey === "name" && typeof pythonicValue === "string") {
        tsDict[pythonicKey] = pythonicValue;
      } else {
        const tsKey = toCamelCase(pythonicKey);
        tsDict[tsKey] = convertPythonicToTs(pythonicValue, tsKey);
      }
    }
    return tsDict;
  }
}
function convertTsToPythonic(tsConfig, key) {
  if (tsConfig === null || tsConfig === void 0) {
    return null;
  } else if (typeof tsConfig === "string") {
    return toSnakeCase(tsConfig);
  } else if (typeof tsConfig === "number" || typeof tsConfig === "boolean") {
    return tsConfig;
  } else if (tsConfig instanceof Array) {
    const pyArray = [];
    const arrayLength = tsConfig.length;
    for (let i = 0; i < arrayLength; ++i) {
      const item = tsConfig[i];
      if (isArrayItemInputOrOutputName(key, i, item)) {
        pyArray.push(item);
      } else {
        pyArray.push(convertTsToPythonic(item, key));
      }
    }
    return pyArray;
  } else {
    const pyDict = {};
    for (const tsKey of Object.keys(tsConfig)) {
      const tsValue = tsConfig[tsKey];
      const pyKey = toSnakeCase(tsKey);
      if ((tsKey === "name" || tsKey === "className") && typeof tsValue === "string") {
        pyDict[pyKey] = tsValue;
      } else {
        pyDict[pyKey] = convertTsToPythonic(tsValue, tsKey);
      }
    }
    return pyDict;
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/version.ts
var version11 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/executor.ts
function assertFeedCompatibility(key, val) {
  if (key.dtype == null || key.dtype === val.dtype) {
    return val;
  }
  try {
    return cast2(val, key.dtype);
  } catch (err) {
    throw new ValueError(`The dtype of the feed (${val.dtype}) can not be cast to the dtype of the key '${key.name}' (${key.dtype}).`);
  }
}
var FeedDict = class {
  constructor(feeds) {
    this.id2Value = {};
    this.id2Mask = {};
    this.name2Id = {};
    if (feeds instanceof FeedDict) {
      for (const id in feeds.id2Value) {
        this.id2Value[id] = feeds.id2Value[id];
        if (id in feeds.id2Mask) {
          this.id2Mask[id] = feeds.id2Mask[id];
        }
      }
    } else {
      if (feeds == null) {
        return;
      }
      for (const feed of feeds) {
        this.add(feed.key, feed.value);
      }
    }
  }
  add(key, value, mask) {
    if (this.id2Value[key.id] == null) {
      this.id2Value[key.id] = assertFeedCompatibility(key, value);
      this.name2Id[key.name] = key.id;
      if (mask != null) {
        this.id2Mask[key.id] = mask;
      }
    } else {
      throw new ValueError(`Duplicate key: name=${key.name}, id=${key.id}`);
    }
    return this;
  }
  addFeed(feed) {
    this.add(feed.key, feed.value);
  }
  hasKey(key) {
    return this.id2Value[key.id] != null;
  }
  names() {
    return Object.keys(this.name2Id);
  }
  getValue(key) {
    if (key instanceof SymbolicTensor) {
      if (this.id2Value[key.id] == null) {
        throw new ValueError(`Nonexistent key: ${key.name}`);
      } else {
        return this.id2Value[key.id];
      }
    } else {
      const id = this.name2Id[key];
      if (id == null) {
        throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
      }
      return this.id2Value[id];
    }
  }
  getMask(key) {
    if (key instanceof SymbolicTensor) {
      if (this.id2Value[key.id] == null) {
        throw new ValueError(`Nonexistent key: ${key.name}`);
      } else {
        return this.id2Mask[key.id];
      }
    } else {
      const id = this.name2Id[key];
      if (id == null) {
        throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
      }
      return this.id2Mask[id];
    }
  }
  disposeMasks() {
    if (this.id2Mask != null) {
      dispose2(this.id2Mask);
    }
  }
};
var cachedSorted = {};
var cachedRecipientCounts = {};
function execute(fetches, feedDict, kwargs, probe) {
  const training = kwargs == null ? false : kwargs["training"];
  const arrayFetches = Array.isArray(fetches);
  const fetchArray = arrayFetches ? fetches : [fetches];
  const outputNames = fetchArray.map((t) => t.name);
  const finalOutputs = [];
  const feedNames = feedDict.names();
  for (const outputName of outputNames) {
    if (feedNames.indexOf(outputName) !== -1) {
      finalOutputs.push(feedDict.getValue(outputName));
    } else {
      finalOutputs.push(null);
    }
  }
  if (probe != null) {
    probe.maxNumTensors = -Infinity;
    probe.minNumTensors = Infinity;
  }
  const fetchAndFeedKey = outputNames.join(",") + "|" + feedDict.names().join(",");
  let sorted;
  let recipientCounts;
  if (cachedSorted[fetchAndFeedKey] == null) {
    const out = getTopologicalSortAndRecipientCounts(fetchArray, feedDict);
    sorted = out.sorted;
    recipientCounts = out.recipientCounts;
    cachedSorted[fetchAndFeedKey] = sorted;
    cachedRecipientCounts[fetchAndFeedKey] = recipientCounts;
  }
  sorted = cachedSorted[fetchAndFeedKey];
  recipientCounts = {};
  if (!training) {
    Object.assign(recipientCounts, cachedRecipientCounts[fetchAndFeedKey]);
  }
  const internalFeedDict = new FeedDict(feedDict);
  for (let i = 0; i < sorted.length; ++i) {
    if (probe != null) {
      const numTensors = memory2().numTensors;
      if (numTensors > probe.maxNumTensors) {
        probe.maxNumTensors = numTensors;
      }
      if (numTensors < probe.minNumTensors) {
        probe.minNumTensors = numTensors;
      }
    }
    const symbolic = sorted[i];
    const srcLayer = symbolic.sourceLayer;
    if (srcLayer instanceof InputLayer) {
      continue;
    }
    const inputValues = [];
    const inputMasks = [];
    const tensorsToDispose = [];
    let maskExists = false;
    for (const input2 of symbolic.inputs) {
      const value = internalFeedDict.getValue(input2);
      const mask = internalFeedDict.getMask(input2);
      inputValues.push(value);
      inputMasks.push(mask);
      if (mask != null) {
        maskExists = true;
      }
      if (!training) {
        recipientCounts[input2.name]--;
        if (recipientCounts[input2.name] === 0 && !feedDict.hasKey(input2) && outputNames.indexOf(input2.name) === -1 && !value.isDisposed && input2.sourceLayer.stateful !== true) {
          tensorsToDispose.push(value);
        }
      }
    }
    if (maskExists) {
      kwargs = kwargs || {};
      kwargs["mask"] = inputMasks[0];
    }
    const outputTensors = toList(srcLayer.apply(inputValues, kwargs));
    let outputMask = null;
    if (srcLayer.supportsMasking) {
      outputMask = srcLayer.computeMask(inputValues, inputMasks);
    }
    const layerOutputs = getNodeOutputs(symbolic);
    const outputSymbolicTensors = Array.isArray(layerOutputs) ? layerOutputs : [layerOutputs];
    for (let i2 = 0; i2 < outputSymbolicTensors.length; ++i2) {
      if (!internalFeedDict.hasKey(outputSymbolicTensors[i2])) {
        internalFeedDict.add(outputSymbolicTensors[i2], outputTensors[i2], Array.isArray(outputMask) ? outputMask[0] : outputMask);
      }
      const index = outputNames.indexOf(outputSymbolicTensors[i2].name);
      if (index !== -1) {
        finalOutputs[index] = outputTensors[i2];
      }
    }
    if (!training) {
      dispose2(tensorsToDispose);
    }
  }
  internalFeedDict.disposeMasks();
  return arrayFetches ? finalOutputs : finalOutputs[0];
}
function getTopologicalSortAndRecipientCounts(fetches, feedDict) {
  util_exports2.assert(fetches != null && fetches.length > 0, () => `Expected at least one fetch, got none`);
  let finalSorted = [];
  let finalRecipientMap = {};
  if (fetches.length === 1) {
    const out = getTopologicalSortAndRecipientCountsForOneFetch(fetches[0], feedDict);
    finalSorted = out.sorted;
    finalRecipientMap = out.recipientMap;
  } else {
    const visited = new Set();
    for (const fetch6 of fetches) {
      const { sorted, recipientMap } = getTopologicalSortAndRecipientCountsForOneFetch(fetch6, feedDict);
      for (const symbolicTensor of sorted) {
        if (!visited.has(symbolicTensor.name)) {
          finalSorted.push(symbolicTensor);
          visited.add(symbolicTensor.name);
        }
      }
      for (const name in recipientMap) {
        if (finalRecipientMap[name] == null) {
          finalRecipientMap[name] = new Set();
        }
        recipientMap[name].forEach((recipient) => finalRecipientMap[name].add(recipient));
      }
    }
  }
  return {
    sorted: finalSorted,
    recipientCounts: recipientMap2Counts(finalRecipientMap)
  };
}
function recipientMap2Counts(recipientMap) {
  const recipientCounts = {};
  for (const name in recipientMap) {
    recipientCounts[name] = recipientMap[name].size;
  }
  return recipientCounts;
}
function getTopologicalSortAndRecipientCountsForOneFetch(fetch6, feedDict) {
  const visited = new Set();
  const sorted = [];
  const recipientMap = {};
  for (const key of feedDict.names()) {
    visited.add(key);
  }
  const stack3 = [];
  const marks = [];
  stack3.push(fetch6);
  while (stack3.length > 0) {
    const top = stack3[stack3.length - 1];
    if (visited.has(top.name)) {
      stack3.pop();
      continue;
    }
    const topIsMarked = marks[marks.length - 1] === stack3.length - 1;
    if (top.inputs.length === 0 || topIsMarked) {
      stack3.pop();
      sorted.push(top);
      visited.add(top.name);
      if (topIsMarked) {
        marks.pop();
      }
    } else {
      marks.push(stack3.length - 1);
      for (const input2 of top.inputs) {
        if (recipientMap[input2.name] == null) {
          recipientMap[input2.name] = new Set();
        }
        recipientMap[input2.name].add(top.name);
        if (visited.has(input2.name)) {
          continue;
        }
        stack3.push(input2);
      }
    }
  }
  return { sorted, recipientMap };
}
function getNodeOutputs(fetch6) {
  let layerOutputs;
  if (fetch6.sourceLayer.inboundNodes.length === 1) {
    layerOutputs = fetch6.sourceLayer.output;
  } else {
    let nodeIndex = null;
    for (let i = 0; i < fetch6.sourceLayer.inboundNodes.length; ++i) {
      for (const outputTensor of fetch6.sourceLayer.inboundNodes[i].outputTensors) {
        if (outputTensor.id === fetch6.id) {
          nodeIndex = i;
          break;
        }
      }
    }
    layerOutputs = fetch6.sourceLayer.getOutputAt(nodeIndex);
  }
  return layerOutputs;
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/container.ts
var Container = class extends Layer {
  constructor(args) {
    super({});
    this.containerNodes = new Set();
    this.name = args.name;
    if (this.name == null) {
      const prefix = this.getClassName().toLowerCase();
      this.name = getUid(prefix);
    }
    this.supportsMasking = false;
    this.trainable_ = true;
    if (Array.isArray(args.inputs)) {
      this.inputs = args.inputs.slice();
    } else {
      this.inputs = [args.inputs];
    }
    if (Array.isArray(args.outputs)) {
      this.outputs = args.outputs.slice();
    } else {
      this.outputs = [args.outputs];
    }
    if (unique3(this.inputs).length !== this.inputs.length) {
      throw new ValueError(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((x) => x.name)}`);
    }
    if (unique3(this.outputs).length !== this.outputs.length) {
      console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((x) => x.name)}`);
    }
    this.inputLayers = [];
    this.inputLayersNodeIndices = [];
    this.inputLayersTensorIndices = [];
    this.outputLayers = [];
    this.outputLayersNodeIndices = [];
    this.outputLayersTensorIndices = [];
    this.layers = [];
    this.internalContainerRefs = [];
    for (const x of this.outputs) {
      const layer = x.sourceLayer;
      const nodeIndex = x.nodeIndex;
      const tensorIndex = x.tensorIndex;
      this.outputLayers.push(layer);
      this.outputLayersNodeIndices.push(nodeIndex);
      this.outputLayersTensorIndices.push(tensorIndex);
    }
    for (const x of this.inputs) {
      const layer = x.sourceLayer;
      const nodeIndex = x.nodeIndex;
      const tensorIndex = x.tensorIndex;
      assert3(nodeIndex === 0, "input layer has >1 nodes");
      assert3(tensorIndex === 0, "input layer has >1 tensors");
      this.inputLayers.push(layer);
      this.inputLayersNodeIndices.push(nodeIndex);
      this.inputLayersTensorIndices.push(tensorIndex);
    }
    this.inputNames = [];
    this.outputNames = [];
    this.feedInputShapes = [];
    this.feedInputNames = [];
    this.feedOutputNames = [];
    for (let i = 0; i < this.inputLayers.length; i++) {
      const layer = this.inputLayers[i];
      if (!(layer instanceof InputLayer)) {
        throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${args.inputs}. Input ${i} (0-based) originates from layer type ${layer.getClassName()}.`);
      }
      this.inputNames.push(layer.name);
      this.feedInputShapes.push(layer.batchInputShape);
      this.feedInputNames.push(layer.name);
    }
    for (const layer of this.outputLayers) {
      this.outputNames.push(layer.name);
    }
    this.internalInputShapes = this.inputs.map((x) => x.shape);
    this.internalOutputShapes = this.outputs.map((x) => x.shape);
    const nodesDepths = {};
    const nodeIDToNode = {};
    const layersDepths = {};
    const layerIDToLayer = {};
    const layerIndices = {};
    const nodesInDecreasingDepth = [];
    const buildMapOfGraph = (tensor3, finishedNodes2, nodesInProgress2, layer, nodeIndex, tensorIndex) => {
      if (layer == null || nodeIndex == null || tensorIndex == null) {
        layer = tensor3.sourceLayer;
        nodeIndex = tensor3.nodeIndex;
        tensorIndex = tensor3.tensorIndex;
      }
      const node = layer.inboundNodes[nodeIndex];
      if (nodesInProgress2.indexOf(node) !== -1) {
        throw new RuntimeError(`The tensor ${tensor3.name} at layer "${layer.name}" is part of a cycle.`);
      }
      if (finishedNodes2.indexOf(node) !== -1) {
        return;
      }
      this.containerNodes.add(Container.nodeKey(layer, nodeIndex));
      if (!(layer.id in layerIndices)) {
        layerIndices[layer.id] = Object.keys(layerIndices).length;
      }
      if (nodesInProgress2.indexOf(node) === -1) {
        nodesInProgress2.push(node);
      }
      const numInboundLayers = node.inboundLayers.length;
      for (let i = 0; i < numInboundLayers; i++) {
        const x = node.inputTensors[i];
        const layer2 = node.inboundLayers[i];
        const nodeIndex2 = node.nodeIndices[i];
        const tensorIndex2 = node.tensorIndices[i];
        buildMapOfGraph(x, finishedNodes2, nodesInProgress2, layer2, nodeIndex2, tensorIndex2);
      }
      finishedNodes2.push(node);
      while (nodesInProgress2.indexOf(node) >= 0) {
        nodesInProgress2.splice(nodesInProgress2.indexOf(node), 1);
      }
      nodesInDecreasingDepth.push(node);
    };
    const finishedNodes = [];
    const nodesInProgress = [];
    for (const x of this.outputs) {
      buildMapOfGraph(x, finishedNodes, nodesInProgress);
    }
    const reversedNodesInDecreasingDepth = nodesInDecreasingDepth.slice().reverse();
    for (const node of reversedNodesInDecreasingDepth) {
      nodeIDToNode[node.id] = node;
      if (!(node.id in nodesDepths)) {
        nodesDepths[node.id] = 0;
      }
      let depth = nodesDepths[node.id];
      const previousDepth = layersDepths[node.outboundLayer.id] == null ? 0 : layersDepths[node.outboundLayer.id];
      depth = Math.max(depth, previousDepth);
      layersDepths[node.outboundLayer.id] = depth;
      layerIDToLayer[node.outboundLayer.id] = node.outboundLayer;
      nodesDepths[node.id] = depth;
      for (let i = 0; i < node.inboundLayers.length; i++) {
        const inboundLayer = node.inboundLayers[i];
        const nodeIndex = node.nodeIndices[i];
        const inboundNode = inboundLayer.inboundNodes[nodeIndex];
        const previousDepth2 = nodesDepths[inboundNode.id] == null ? 0 : nodesDepths[inboundNode.id];
        nodesDepths[inboundNode.id] = Math.max(depth + 1, previousDepth2);
        nodeIDToNode[inboundNode.id] = inboundNode;
      }
    }
    const nodesByDepth = {};
    for (const nodeID in nodesDepths) {
      const depth = nodesDepths[nodeID];
      if (!(depth in nodesByDepth)) {
        nodesByDepth[depth] = [];
      }
      nodesByDepth[depth].push(nodeIDToNode[nodeID]);
    }
    const layersByDepth = {};
    for (const layerID in layersDepths) {
      const depth = layersDepths[layerID];
      if (!(depth in layersByDepth)) {
        layersByDepth[depth] = [];
      }
      layersByDepth[depth].push(layerIDToLayer[layerID]);
    }
    let depthKeys = Object.keys(layersByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
    this.layers = [];
    for (const depth of depthKeys) {
      const layersForDepth = layersByDepth[depth];
      layersForDepth.sort((a, b) => {
        const aIndex = layerIndices[a.id];
        const bIndex = layerIndices[b.id];
        if (aIndex < bIndex) {
          return -1;
        }
        if (aIndex > bIndex) {
          return 1;
        }
        return 0;
      });
      for (const layer of layersForDepth) {
        if (layer instanceof Container) {
          this.internalContainerRefs.push(layer);
        }
        this.layers.push(layer);
      }
    }
    this.layersByDepth = layersByDepth;
    depthKeys = Object.keys(nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
    const computableTensors = this.inputs.slice();
    const layersWithCompleteInput = [];
    for (const depth of depthKeys) {
      for (const node of nodesByDepth[depth]) {
        const layer = node.outboundLayer;
        if (layer != null) {
          for (const x of node.inputTensors) {
            if (computableTensors.indexOf(x) === -1) {
              throw new RuntimeError(`Graph disconnected: cannot obtain value for tensor ${x} at layer "${layer.name}". The following previous layers were accessed without issue: ${layersWithCompleteInput}`);
            }
          }
          for (const x of node.outputTensors) {
            computableTensors.push(x);
          }
          layersWithCompleteInput.push(layer.name);
        }
      }
    }
    this.nodesByDepth = nodesByDepth;
    const allNames = this.layers.map((x) => x.name);
    for (const name of allNames) {
      const numOccurrences = allNames.filter((x) => x === name).length;
      if (numOccurrences !== 1) {
        throw new RuntimeError(`The name "${name}" is used ${numOccurrences} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(allNames));
      }
    }
    this.outboundNodes = [];
    this.inboundNodes = [];
    new Node({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: this.inputs,
      outputTensors: this.outputs,
      inputMasks: this.inputs.map((x) => null),
      outputMasks: this.outputs.map((x) => null),
      inputShapes: this.inputs.map((x) => x.shape),
      outputShapes: this.outputs.map((x) => x.shape)
    });
    this.built = true;
    this._refCount = 1;
  }
  assertNotDisposed() {
    if (this._refCount === 0) {
      throw new Error(`Container '${this.name}' is already disposed.`);
    }
  }
  dispose() {
    this.assertNotDisposed();
    const result = { refCountAfterDispose: null, numDisposedVariables: 0 };
    if (--this._refCount === 0) {
      for (const layer of this.layers) {
        result.numDisposedVariables += layer.dispose().numDisposedVariables;
      }
      for (const container of this.internalContainerRefs) {
        result.numDisposedVariables += container.dispose().numDisposedVariables;
      }
    }
    result.refCountAfterDispose = this._refCount;
    return result;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(trainable) {
    this.layers.forEach((layer) => {
      layer._trainableWeights.forEach((w) => w.trainable = trainable);
    });
    this.trainable_ = trainable;
  }
  get trainableWeights() {
    if (this._trainableWeights.length > 0) {
      throw new ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    }
    if (!this.trainable) {
      return [];
    }
    let weights = [];
    for (const layer of this.layers) {
      weights = weights.concat(layer.trainableWeights);
    }
    return weights;
  }
  get nonTrainableWeights() {
    const weights = [];
    for (const layer of this.layers) {
      weights.push(...layer.nonTrainableWeights);
    }
    if (!this.trainable) {
      const trainableWeights = [];
      for (const layer of this.layers) {
        trainableWeights.push(...layer.trainableWeights);
      }
      return trainableWeights.concat(weights);
    }
    return weights;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  loadWeights(weights, strict = true) {
    const nameToWeight = {};
    let totalWeightsCount = 0;
    for (const layer of this.layers) {
      for (const weight of layer.weights) {
        if (nameToWeight[weight.originalName] != null) {
          throw new ValueError(`Duplicate weight name: ${weight.originalName}`);
        }
        nameToWeight[weight.originalName] = weight;
        totalWeightsCount++;
      }
    }
    const weightValueTuples = [];
    for (const name in weights) {
      let validatedName = name;
      if (nameToWeight[name] == null) {
        const tokens = name.split("/");
        const shortenNameArray = tokens.slice(0, -2).concat([tokens[tokens.length - 1]]);
        validatedName = shortenNameArray.join("/");
      }
      if (nameToWeight[validatedName] != null) {
        weightValueTuples.push([nameToWeight[validatedName], weights[name]]);
      } else if (strict) {
        throw new ValueError(`Provided weight data has no target variable: ${name}`);
      }
      delete nameToWeight[validatedName];
    }
    if (strict) {
      const unsetNames = [];
      for (const name in nameToWeight) {
        unsetNames.push(name);
      }
      if (unsetNames.length > 0) {
        throw new ValueError(`${unsetNames.length} of ${totalWeightsCount} weights are not set: ${unsetNames}`);
      }
    }
    batchSetValue(weightValueTuples);
  }
  updatedConfig() {
    const theConfig = this.getConfig();
    const modelConfig = {};
    modelConfig["className"] = this.getClassName();
    modelConfig["config"] = theConfig;
    modelConfig["kerasVersion"] = `tfjs-layers ${version11}`;
    modelConfig["backend"] = "TensorFlow.js";
    return modelConfig;
  }
  toJSON(unused, returnString = true) {
    const modelConfig = convertTsToPythonic(this.updatedConfig());
    return returnString ? JSON.stringify(modelConfig) : modelConfig;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = toList(inputs);
      const feedDict = new FeedDict();
      for (let i = 0; i < this.inputs.length; ++i) {
        feedDict.add(this.inputs[i], inputs[i]);
      }
      return execute(this.outputs, feedDict, kwargs);
    });
  }
  computeMask(inputs, mask) {
    return tidy2(() => {
      inputs = toList(inputs);
      let masks;
      if (mask == null) {
        masks = pyListRepeat(null, inputs.length);
      } else {
        masks = toList(mask);
      }
      return this.runInternalGraph(inputs, masks)[1];
    });
  }
  computeOutputShape(inputShape) {
    const inputShapes = normalizeShapeList(inputShape);
    if (inputShapes.length !== this.inputLayers.length) {
      throw new ValueError(`Invalid inputShape argument ${inputShape}: model has ${this.inputLayers.length} tensor inputs.`);
    }
    const layersToOutputShapes = {};
    for (let i = 0; i < inputShapes.length; i++) {
      const layer = this.inputLayers[i];
      const inputShape2 = inputShapes[i];
      const shapeKey = layer.name + "_0_0";
      layersToOutputShapes[shapeKey] = inputShape2;
    }
    const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
    if (depthKeys.length > 1) {
      for (const depth of depthKeys) {
        const nodes = this.nodesByDepth[depth];
        for (const node of nodes) {
          const layer = node.outboundLayer;
          if (this.inputLayers.map((x) => x.id).indexOf(layer.id) !== -1) {
            continue;
          }
          const inputShapes2 = [];
          for (let j = 0; j < node.inboundLayers.length; j++) {
            const inboundLayer = node.inboundLayers[j];
            const nodeIndex2 = node.nodeIndices[j];
            const tensorIndex = node.tensorIndices[j];
            const shapeKey = `${inboundLayer.name}_${nodeIndex2}_${tensorIndex}`;
            const inputShape2 = layersToOutputShapes[shapeKey];
            inputShapes2.push(inputShape2);
          }
          const outputShape = layer.computeOutputShape(singletonOrArray(inputShapes2));
          const outputShapes2 = normalizeShapeList(outputShape);
          const nodeIndex = layer.inboundNodes.indexOf(node);
          for (let j = 0; j < outputShapes2.length; j++) {
            const shapeKey = `${layer.name}_${nodeIndex}_${j}`;
            layersToOutputShapes[shapeKey] = outputShapes2[j];
          }
        }
      }
    }
    const outputShapes = [];
    const outputShapeKeys = [];
    for (let i = 0; i < this.outputLayers.length; i++) {
      const layer = this.outputLayers[i];
      const nodeIndex = this.outputLayersNodeIndices[i];
      const tensorIndex = this.outputLayersTensorIndices[i];
      const shapeKey = `${layer.name}_${nodeIndex}_${tensorIndex}`;
      outputShapeKeys.push(shapeKey);
    }
    for (let i = 0; i < outputShapeKeys.length; i++) {
      const key = outputShapeKeys[i];
      assert3(key in layersToOutputShapes);
      outputShapes.push(layersToOutputShapes[key]);
    }
    return singletonOrArray(outputShapes);
  }
  runInternalGraph(inputs, masks) {
    if (masks == null) {
      masks = pyListRepeat(null, inputs.length);
    }
    const tensorMap = {};
    for (let i = 0; i < this.inputs.length; ++i) {
      const x = this.inputs[i];
      const y = inputs[i];
      const mask = masks[i];
      tensorMap[x.id] = [y, mask];
    }
    const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
    for (const depth of depthKeys) {
      const nodes = this.nodesByDepth[depth];
      for (const node of nodes) {
        const layer = node.outboundLayer;
        const referenceInputTensors = node.inputTensors;
        const referenceOutputTensors = node.outputTensors;
        const computedData = new Array();
        for (const x of referenceInputTensors) {
          if (x.id in tensorMap) {
            computedData.push(tensorMap[x.id]);
          }
        }
        if (computedData.length === referenceInputTensors.length) {
          let kwargs = {};
          let computedTensors;
          let computedMasks;
          let outputTensors2;
          let outputMasks2;
          if (node.callArgs != null) {
            kwargs = node.callArgs;
          }
          if (computedData.length === 1) {
            const [computedTensor, computedMask] = computedData[0];
            if (kwargs["mask"] == null) {
              kwargs["mask"] = computedMask;
            }
            outputTensors2 = toList(layer.call(computedTensor, kwargs));
            outputMasks2 = toList(layer.computeMask(computedTensor, computedMask));
            computedTensors = [computedTensor];
            computedMasks = [computedMask];
          } else {
            computedTensors = computedData.map((x) => x[0]);
            computedMasks = computedData.map((x) => x[1]);
            if (kwargs["mask"] == null) {
              kwargs["mask"] = computedMasks;
            }
            outputTensors2 = toList(layer.call(computedTensors, kwargs));
            outputMasks2 = toList(layer.computeMask(computedTensors, computedMasks));
          }
          if (layer.activityRegularizer) {
            throw new NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
          }
          for (let i = 0; i < referenceOutputTensors.length; ++i) {
            const x = referenceOutputTensors[i];
            const y = outputTensors2[i];
            const mask = outputMasks2[i];
            tensorMap[x.id] = [y, mask];
          }
        }
      }
    }
    const outputTensors = [];
    const outputMasks = [];
    const outputShapes = [];
    for (const x of this.outputs) {
      assert3(x.id in tensorMap, `Could not compute output ${x.name} : ${x.id}`);
      const [tensor3, mask] = tensorMap[x.id];
      outputShapes.push(tensor3.shape);
      outputTensors.push(tensor3);
      outputMasks.push(mask);
    }
    return [outputTensors, outputMasks, outputShapes];
  }
  buildNodeConversionMap(layers) {
    const nodeConversionMap = {};
    let keptNodes;
    for (const layer of this.layers) {
      keptNodes = layer instanceof Container ? 1 : 0;
      for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
        const nodeKey = Container.nodeKey(layer, originalNodeIndex);
        if (this.containerNodes.has(nodeKey)) {
          nodeConversionMap[nodeKey] = keptNodes;
          keptNodes += 1;
        }
      }
    }
    return nodeConversionMap;
  }
  getLayer(name, index) {
    if (index != null) {
      if (this.layers.length <= index) {
        throw new ValueError(`Was asked to retrieve layer at index ${index}, but model only has ${this.layers.length} layer(s).`);
      } else {
        return this.layers[index];
      }
    } else {
      if (name == null) {
        throw new ValueError("Provide either a layer name or layer index");
      }
    }
    for (const layer of this.layers) {
      if (layer.name === name) {
        return layer;
      }
    }
    throw new ValueError(`No such layer: ${name}`);
  }
  calculateLosses() {
    return tidy2(() => {
      const losses4 = [];
      for (const layer of this.layers) {
        for (let nodeIndex = 0; nodeIndex < layer.inboundNodes.length; ++nodeIndex) {
          const nodeKey = Container.nodeKey(layer, nodeIndex);
          if (this.containerNodes.has(nodeKey)) {
            losses4.push(...layer.calculateLosses());
          }
        }
      }
      return losses4;
    });
  }
  getConfig() {
    const config = { name: this.name };
    const nodeConversionMap = this.buildNodeConversionMap(this.layers);
    const layerConfigs = [];
    for (const layer of this.layers) {
      const layerClassName = layer.getClassName();
      const layerConfig = layer.getConfig();
      const filteredInboundNodes = [];
      for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
        const node = layer.inboundNodes[originalNodeIndex];
        const nodeKey = Container.nodeKey(layer, originalNodeIndex);
        let kwargs = {};
        if (this.containerNodes.has(nodeKey)) {
          if (node.callArgs) {
            try {
              JSON.stringify(node.callArgs);
              kwargs = node.callArgs;
            } catch (err) {
              console.warn(`Layer ${layer.name} was passed non-serializable keyword arguments: ${node.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`);
              kwargs = {};
            }
          }
          if (node.inboundLayers.length > 0) {
            const nodeData = [];
            for (let i = 0; i < node.inboundLayers.length; i++) {
              const inboundLayer = node.inboundLayers[i];
              const nodeIndex = node.nodeIndices[i];
              const tensorIndex = node.tensorIndices[i];
              const nodeKey2 = Container.nodeKey(inboundLayer, nodeIndex);
              let newNodeIndex = nodeConversionMap[nodeKey2];
              if (newNodeIndex == null) {
                newNodeIndex = 0;
              }
              nodeData.push([inboundLayer.name, newNodeIndex, tensorIndex, kwargs]);
            }
            filteredInboundNodes.push(nodeData);
          }
        }
      }
      const dict = {};
      dict["name"] = layer.name;
      dict["className"] = layerClassName;
      dict["config"] = layerConfig;
      dict["inboundNodes"] = filteredInboundNodes;
      layerConfigs.push(dict);
    }
    config["layers"] = layerConfigs;
    const modelInputs = [];
    for (let i = 0; i < this.inputLayers.length; i++) {
      const layer = this.inputLayers[i];
      const nodeIndex = this.inputLayersNodeIndices[i];
      const nodeKey = Container.nodeKey(layer, nodeIndex);
      if (!this.containerNodes.has(nodeKey)) {
        continue;
      }
      let newNodeIndex = nodeConversionMap[nodeKey];
      if (newNodeIndex === null || newNodeIndex === void 0) {
        newNodeIndex = 0;
      }
      const tensorIndex = this.inputLayersTensorIndices[i];
      modelInputs.push([layer.name, newNodeIndex, tensorIndex]);
    }
    config["inputLayers"] = modelInputs;
    const modelOutputs = [];
    for (let i = 0; i < this.outputLayers.length; i++) {
      const layer = this.outputLayers[i];
      const nodeIndex = this.outputLayersNodeIndices[i];
      const nodeKey = Container.nodeKey(layer, nodeIndex);
      if (!this.containerNodes.has(nodeKey)) {
        continue;
      }
      let newNodeIndex = nodeConversionMap[nodeKey];
      if (newNodeIndex === null || newNodeIndex === void 0) {
        newNodeIndex = 0;
      }
      const tensorIndex = this.outputLayersTensorIndices[i];
      modelOutputs.push([layer.name, newNodeIndex, tensorIndex]);
    }
    config["outputLayers"] = modelOutputs;
    return config;
  }
  static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
    const createdLayers = {};
    const unprocessedNodes = {};
    function addUnprocessedNode(layer, nodeData) {
      if (!(layer.name in unprocessedNodes)) {
        unprocessedNodes[layer.name] = [nodeData];
      } else {
        unprocessedNodes[layer.name].push(nodeData);
      }
    }
    function processNode(layer, nodeData) {
      const inputTensors2 = [];
      let kwargs;
      for (const inputData of nodeData) {
        const inboundLayerName = inputData[0];
        const inboundNodeIndex = inputData[1];
        const inboundTensorIndex = inputData[2];
        kwargs = inputData[3] == null ? {} : inputData[3];
        if (!(inboundLayerName in createdLayers)) {
          addUnprocessedNode(layer, nodeData);
          return;
        }
        const inboundLayer = createdLayers[inboundLayerName];
        if (inboundLayer.inboundNodes.length <= inboundNodeIndex) {
          addUnprocessedNode(layer, nodeData);
          return;
        }
        const inboundNode = inboundLayer.inboundNodes[inboundNodeIndex];
        inputTensors2.push(inboundNode.outputTensors[inboundTensorIndex]);
      }
      if (inputTensors2.length > 0) {
        layer.apply(singletonOrArray(inputTensors2), kwargs);
      }
    }
    function processLayer(layerData) {
      const layerName = layerData["name"];
      const layer = deserialize(layerData, config["customObjects"] != null ? config["customObjects"] : {});
      layer.setFastWeightInitDuringBuild(fastWeightInit);
      createdLayers[layerName] = layer;
      const inboundNodesData = layerData["inboundNodes"];
      inboundNodesData.forEach((nodeData) => {
        if (!(nodeData instanceof Array)) {
          throw new ValueError(`Corrupted configuration, expected array for nodeData: ${nodeData}`);
        }
        addUnprocessedNode(layer, nodeData);
      });
    }
    const name = config["name"];
    const layersFromConfig = config["layers"];
    for (const layerData of layersFromConfig) {
      processLayer(layerData);
    }
    while (!isObjectEmpty(unprocessedNodes)) {
      for (const layerData of layersFromConfig) {
        const layer = createdLayers[layerData["name"]];
        if (layer.name in unprocessedNodes) {
          const currentUnprocessedNodesForLayer = unprocessedNodes[layer.name];
          delete unprocessedNodes[layer.name];
          for (const nodeData of currentUnprocessedNodesForLayer) {
            processNode(layer, nodeData);
          }
        }
      }
    }
    const inputTensors = [];
    const outputTensors = [];
    const inputLayersFromConfig = config["inputLayers"];
    for (const layerData of inputLayersFromConfig) {
      const layerName = layerData[0];
      const nodeIndex = layerData[1];
      const tensorIndex = layerData[2];
      assert3(layerName in createdLayers);
      const layer = createdLayers[layerName];
      const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
      inputTensors.push(layerOutputTensors[tensorIndex]);
    }
    const outputLayersFromConfig = config["outputLayers"];
    for (const layerData of outputLayersFromConfig) {
      const layerName = layerData[0];
      const nodeIndex = layerData[1];
      const tensorIndex = layerData[2];
      assert3(layerName in createdLayers);
      const layer = createdLayers[layerName];
      const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
      outputTensors.push(layerOutputTensors[tensorIndex]);
    }
    return new cls({ inputs: inputTensors, outputs: outputTensors, name });
  }
  get stateful() {
    if (this._stateful) {
      throw new ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
    }
    for (const layer of this.layers) {
      if (layer.stateful) {
        return true;
      }
    }
    return false;
  }
  resetStates() {
    tidy2(() => {
      this.layers.forEach((layer) => {
        if (layer.stateful) {
          layer.resetStates();
        }
      });
    });
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/training_utils.ts
function standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {
  const numOutputs = outputNames.length;
  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {
    return outputNames.map((name) => null);
  }
  if (numOutputs === 1) {
    if (Array.isArray(xWeight) && xWeight.length === 1) {
      return xWeight;
    } else if (typeof xWeight === "object" && outputNames[0] in xWeight) {
      return [xWeight[outputNames[0]]];
    } else {
      return [xWeight];
    }
  }
  if (Array.isArray(xWeight)) {
    if (xWeight.length !== numOutputs) {
      throw new Error(`Provided ${weightType} is an array of ${xWeight.length} element(s), but the model has ${numOutputs} outputs. Make sure a set of weights is provided for each model output.`);
    }
    return xWeight;
  } else if (typeof xWeight === "object" && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === "object") {
    const output = [];
    outputNames.forEach((outputName) => {
      if (outputName in xWeight) {
        output.push(xWeight[outputName]);
      } else {
        output.push(null);
      }
    });
    return output;
  } else {
    throw new Error(`The model has multiple (${numOutputs}) outputs, so ${weightType} must be either an array with ${numOutputs} elements or an object with ${outputNames} keys. Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);
  }
}
function standardizeClassWeights(classWeight, outputNames) {
  return standardizeSampleOrClassWeights(classWeight, outputNames, "classWeight");
}
async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {
  if (sampleWeight != null || sampleWeightMode != null) {
    throw new Error("Support sampleWeight is not implemented yet");
  }
  if (classWeight != null) {
    const yClasses = tidy2(() => {
      if (y.shape.length === 1) {
        return y.clone();
      } else if (y.shape.length === 2) {
        if (y.shape[1] > 1) {
          const axis = 1;
          return y.argMax(axis);
        } else if (y.shape[1] === 1) {
          return y.reshape([y.shape[0]]);
        } else {
          throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
        }
      } else {
        throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
      }
    });
    const yClassIndices = Array.from(await yClasses.data());
    dispose2(yClasses);
    const classSampleWeight = [];
    yClassIndices.forEach((classIndex) => {
      if (classWeight[classIndex] == null) {
        throw new Error(`classWeight must contain all classes in the training data. The class ${classIndex} exists in the data but not in classWeight`);
      } else {
        classSampleWeight.push(classWeight[classIndex]);
      }
    });
    return tensor1d2(classSampleWeight, "float32");
  } else {
    return null;
  }
}
function computeWeightedLoss3(losses4, sampleWeights) {
  return mul2(losses4, sampleWeights);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/training_dataset.ts
var DEFAULT_VALIDATION_BATCH_SIZE = 32;
function standardizeDataIteratorOutput(model2, iteratorOut) {
  let xs;
  let ys;
  const iteratorOutObj = iteratorOut;
  xs = iteratorOutObj["xs"];
  ys = iteratorOutObj["ys"];
  util_exports2.assert(xs != null && ys != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${iteratorOut}`);
  const flattenedXs = flattenTensorOrArrayOrMap("input", model2.inputNames, xs);
  const flattenedYs = flattenTensorOrArrayOrMap("output", model2.outputNames, ys);
  const batchSize = flattenedXs[0].shape[0];
  util_exports2.assert(flattenedXs.length === model2.inputs.length, () => `LayersModel has ${model2.inputs.length} inputs, but the dataset provides ${flattenedXs.length} inputs.  (Expected input keys: ${JSON.stringify(model2.inputNames)})`);
  util_exports2.assert(flattenedYs.length === model2.outputs.length, () => `LayersModel has ${model2.outputs.length} outputs, but the dataset provides ${flattenedYs.length} outputs.  (Expected output keys: ${JSON.stringify(model2.outputNames)})`);
  for (let xIndex = 0; xIndex < flattenedXs.length; xIndex++) {
    util_exports2.assert(flattenedXs[xIndex].shape[0] === batchSize, () => `Batch size mismatch: input ${model2.inputNames[xIndex]} has ${flattenedXs[xIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
  }
  for (let yIndex = 0; yIndex < flattenedYs.length; yIndex++) {
    util_exports2.assert(flattenedYs[yIndex].shape[0] === batchSize, () => `Batch size mismatch: output ${model2.outputNames[yIndex]} has ${flattenedYs[yIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
  }
  return { xs: flattenedXs, ys: flattenedYs };
}
function flattenTensorOrArrayOrMap(inputOrOutput, names, values) {
  if (values instanceof Tensor4) {
    return [values];
  } else if (Array.isArray(values)) {
    util_exports2.assert(values.length === names.length, () => `Received an array of ${values.length} Tensors, but expected ${names.length} to match the ${inputOrOutput} keys ${names}.`);
    return values;
  } else {
    const result = [];
    for (const name of names) {
      if (values[name] == null) {
        throw new ValueError(`The feature data generated by the dataset lacks the required ${inputOrOutput} key '${name}'.`);
      }
      result.push(values[name]);
    }
    return result;
  }
}
function standardizeTensorValidationData(data) {
  if (data.length === 3) {
    throw new NotImplementedError("Validation with sample weights is not implemented yet.");
  }
  return { xs: data[0], ys: data[1] };
}
async function fitDataset(model2, dataset, args) {
  const hasBatchesPerEpoch = args.batchesPerEpoch != null;
  util_exports2.assert(model2.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).");
  util_exports2.assert(args != null, () => `For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.`);
  util_exports2.assert(args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${args.epochs}`);
  util_exports2.assert(!hasBatchesPerEpoch || args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${args.batchesPerEpoch}`);
  util_exports2.assert(args["validationSplit"] == null, () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead.");
  if (model2.isTraining) {
    throw new Error("Cannot start training because another fit() call is ongoing.");
  }
  model2.isTraining = true;
  try {
    const doValidation = args.validationData != null;
    let valXs;
    let valYs;
    if (doValidation) {
      if (isDatasetObject(args.validationData)) {
        util_exports2.assert(args.validationBatches == null || args.validationBatches > 0 && Number.isInteger(args.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${args.validationBatches}`);
      } else {
        const validationData = standardizeTensorValidationData(args.validationData);
        valXs = validationData.xs;
        valYs = validationData.ys;
      }
    }
    const trainFunction = model2.makeTrainFunction();
    const outLabels = model2.getDedupedMetricsNames();
    let callbackMetrics;
    if (doValidation) {
      callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
    } else {
      callbackMetrics = outLabels.slice();
    }
    const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
    const verbose = args.verbose == null ? 1 : args.verbose;
    const { callbackList, history } = configureCallbacks(callbacks2, verbose, args.epochs, null, null, getStepsPerEpoch(dataset, args), null, doValidation, callbackMetrics);
    callbackList.setModel(model2);
    model2.history = history;
    await callbackList.onTrainBegin();
    model2.stopTraining_ = false;
    let epoch = args.initialEpoch == null ? 0 : args.initialEpoch;
    let dataIterator = await dataset.iterator();
    while (epoch < args.epochs) {
      const epochLogs = {};
      await callbackList.onEpochBegin(epoch);
      let stepsDone = 0;
      let batchIndex = 0;
      if (!hasBatchesPerEpoch) {
        dataIterator = await dataset.iterator();
      }
      while (hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true) {
        const iteratorOut = await dataIterator.next();
        if (hasBatchesPerEpoch && iteratorOut.done) {
          console.warn(`You provided \`batchesPerEpoch\` as ${args.batchesPerEpoch}, but your dataset iterator ran out of data after ${stepsDone} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${args.batchesPerEpoch * args.epochs} batches). You may need to use the repeat() function when building your dataset.`);
          break;
        }
        if (iteratorOut.value != null) {
          const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
          const batchLogs = {};
          batchLogs["batch"] = batchIndex;
          batchLogs["size"] = xs[0].shape[0];
          await callbackList.onBatchBegin(batchIndex, batchLogs);
          const sampleWeights = [];
          if (args.classWeight != null) {
            const standardClassWeights = standardizeClassWeights(args.classWeight, model2.outputNames);
            for (let i = 0; i < standardClassWeights.length; ++i) {
              sampleWeights.push(await standardizeWeights(ys[i], null, standardClassWeights[i]));
            }
          }
          const ins = xs.concat(ys).concat(sampleWeights);
          const outs = trainFunction(ins);
          dispose2(ins);
          for (let i = 0; i < outLabels.length; ++i) {
            const label = outLabels[i];
            const out = outs[i];
            batchLogs[label] = out;
            keep2(out);
          }
          await callbackList.onBatchEnd(batchIndex, batchLogs);
          disposeTensorsInLogs(batchLogs);
          batchIndex++;
          stepsDone++;
        }
        if (hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch : iteratorOut.done) {
          if (doValidation) {
            let valOuts;
            if (isDatasetObject(args.validationData)) {
              valOuts = toList(await model2.evaluateDataset(args.validationData, { batches: args.validationBatches }));
            } else {
              valOuts = toList(model2.evaluate(valXs, valYs, {
                batchSize: args.validationBatchSize == null ? DEFAULT_VALIDATION_BATCH_SIZE : args.validationBatchSize,
                verbose: 0
              }));
            }
            for (let i = 0; i < model2.metricsNames.length; ++i) {
              epochLogs[`val_${model2.metricsNames[i]}`] = valOuts[i];
            }
          }
          break;
        }
        if (model2.stopTraining_) {
          break;
        }
      }
      await callbackList.onEpochEnd(epoch, epochLogs);
      epoch++;
      if (model2.stopTraining_) {
        break;
      }
    }
    await callbackList.onTrainEnd();
    await model2.history.syncData();
    return model2.history;
  } finally {
    model2.isTraining = false;
  }
}
function getStepsPerEpoch(dataset, args) {
  let stepsPerEpoch = null;
  if (args.batchesPerEpoch != null) {
    stepsPerEpoch = args.batchesPerEpoch;
  } else if (Number.isFinite(dataset.size)) {
    stepsPerEpoch = dataset.size;
  }
  return stepsPerEpoch;
}
function isDatasetObject(dataset) {
  return typeof dataset.iterator === "function";
}
function isLazyIteratorObject(iterator) {
  return typeof iterator.next === "function";
}
async function evaluateDataset(model2, dataset, args) {
  args = args || {};
  const hasBatches = args.batches != null;
  const f = model2.testFunction;
  let outs = [];
  if (args.verbose > 0) {
    throw new NotImplementedError("Verbose mode is not implemented yet.");
  }
  util_exports2.assert(!hasBatches || args.batches > 0 && Number.isInteger(args.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(args.batches)}`);
  const dataIterator = isLazyIteratorObject(dataset) ? dataset : await dataset.iterator();
  let numExamples = 0;
  let batch = 0;
  while (hasBatches ? batch < args.batches : true) {
    const iteratorOut = await dataIterator.next();
    outs = tidy2(() => {
      if (iteratorOut.value) {
        const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
        const xsAndYs = xs.concat(ys);
        const batchOuts = tidy2(() => f(xsAndYs));
        dispose2(xsAndYs);
        if (batch === 0) {
          for (let i = 0; i < batchOuts.length; ++i) {
            outs.push(scalar2(0));
          }
        }
        const batchSize = xsAndYs[0].shape[0];
        for (let i = 0; i < batchOuts.length; ++i) {
          const batchOut = batchOuts[i];
          const oldScalar = outs[i];
          outs[i] = tidy2(() => add4(outs[i], mul2(batchSize, batchOut)));
          if (batch > 0) {
            dispose2(oldScalar);
          }
        }
        dispose2(batchOuts);
        numExamples += batchSize;
        ++batch;
      }
      return outs;
    });
    if (iteratorOut.done) {
      if (hasBatches) {
        console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${args.batches} batches). You may need to use the repeat() function when building your dataset.`);
      }
      break;
    }
  }
  for (let i = 0; i < outs.length; ++i) {
    const oldScalar = outs[i];
    outs[i] = div2(outs[i], numExamples);
    dispose2(oldScalar);
  }
  return singletonOrArray(outs);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/training_tensors.ts
function checkBatchSize(batchSize) {
  util_exports2.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);
}
function sliceArrays(arrays, start, stop) {
  if (arrays == null) {
    return [null];
  } else if (Array.isArray(arrays)) {
    return arrays.map((array2) => sliceAlongFirstAxis(array2, start, stop - start));
  } else {
    return sliceAlongFirstAxis(arrays, start, stop - start);
  }
}
function sliceArraysByIndices(arrays, indices) {
  return tidy2(() => {
    if (arrays == null) {
      return null;
    } else if (Array.isArray(arrays)) {
      return arrays.map((array2) => sliceArraysByIndices(array2, indices));
    } else {
      return gather3(arrays, indices.dtype === "int32" ? indices : indices.toInt());
    }
  });
}
function makeBatches(size, batchSize) {
  const output = [];
  let batchStart = 0;
  let batchEnd = null;
  while (batchStart < size) {
    batchEnd = batchStart + batchSize;
    if (batchEnd >= size) {
      batchEnd = size;
    }
    output.push([batchStart, batchEnd]);
    batchStart = batchEnd;
  }
  return output;
}
async function fitLoop(model2, f, ins, outLabels, batchSize, epochs, verbose, callbacks2, valF, valIns, shuffle3, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {
  if (batchSize == null) {
    batchSize = 32;
  }
  if (epochs == null) {
    epochs = 1;
  }
  if (shuffle3 == null) {
    shuffle3 = true;
  }
  if (initialEpoch == null) {
    initialEpoch = 0;
  }
  let doValidation = false;
  if (valF != null && valIns != null) {
    doValidation = true;
  }
  if (validationSteps != null) {
    doValidation = true;
    if (stepsPerEpoch == null) {
      throw new ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    }
  }
  const numTrainSamples = model2.checkNumSamples(ins, batchSize, stepsPerEpoch, "steps_per_epoch");
  let indexArray;
  if (numTrainSamples != null) {
    indexArray = range3(0, numTrainSamples);
  }
  if (verbose == null) {
    verbose = 1;
  }
  const { callbackList, history } = configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);
  callbackList.setModel(model2);
  model2.history = history;
  await callbackList.onTrainBegin();
  model2.stopTraining_ = false;
  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {
    await callbackList.onEpochBegin(epoch);
    const epochLogs = {};
    if (stepsPerEpoch != null) {
      throw new NotImplementedError("stepsPerEpoch mode is not implemented yet.");
    } else {
      if (shuffle3 === "batch") {
        throw new NotImplementedError("batch shuffling is not implemneted yet");
      } else if (shuffle3) {
        util_exports2.shuffle(indexArray);
      }
      const epochIndexArray1D = tensor1d2(indexArray);
      const batches = makeBatches(numTrainSamples, batchSize);
      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
        const batchLogs = {};
        await callbackList.onBatchBegin(batchIndex, batchLogs);
        tidy2(() => {
          const batchStart = batches[batchIndex][0];
          const batchEnd = batches[batchIndex][1];
          const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);
          batchLogs["batch"] = batchIndex;
          batchLogs["size"] = batchEnd - batchStart;
          const insBatch = sliceArraysByIndices(ins, batchIds);
          const outs = f(insBatch);
          for (let i = 0; i < outLabels.length; ++i) {
            const label = outLabels[i];
            const out = outs[i];
            batchLogs[label] = out;
            keep2(out);
          }
          if (batchIndex === batches.length - 1) {
            if (doValidation) {
              const valOuts = model2.testLoop(valF, valIns, batchSize);
              for (let i = 0; i < outLabels.length; ++i) {
                const label = outLabels[i];
                const out = valOuts[i];
                keep2(out);
                epochLogs["val_" + label] = out;
              }
            }
          }
        });
        await callbackList.onBatchEnd(batchIndex, batchLogs);
        disposeTensorsInLogs(batchLogs);
        if (model2.stopTraining_) {
          break;
        }
      }
      epochIndexArray1D.dispose();
    }
    await callbackList.onEpochEnd(epoch, epochLogs);
    if (model2.stopTraining_) {
      break;
    }
  }
  await callbackList.onTrainEnd();
  await model2.history.syncData();
  return model2.history;
}
async function fitTensors(model2, x, y, args = {}) {
  if (model2.isTraining) {
    throw new Error("Cannot start training because another fit() call is ongoing.");
  }
  model2.isTraining = true;
  let inputs;
  let targets;
  let inputValX;
  let inputValY;
  let valX;
  let valY;
  let sampleWeights;
  try {
    const batchSize = args.batchSize == null ? 32 : args.batchSize;
    checkBatchSize(batchSize);
    const checkBatchAxis = false;
    const standardizedOuts = await model2.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);
    inputs = standardizedOuts[0];
    targets = standardizedOuts[1];
    sampleWeights = standardizedOuts[2];
    let doValidation = false;
    let valIns;
    if (args.validationData != null && args.validationData.length > 0) {
      doValidation = true;
      if (args.validationData.length === 2) {
        inputValX = args.validationData[0];
        inputValY = args.validationData[1];
      } else if (args.validationData.length === 3) {
        throw new NotImplementedError("validationData including sample weights is not supported yet.");
      } else {
        throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${args.validationData} is invalid.`);
      }
      const checkBatchAxis2 = true;
      const valStandardized = await model2.standardizeUserData(inputValX, inputValY, null, null, checkBatchAxis2, batchSize);
      valX = valStandardized[0];
      valY = valStandardized[1];
      valIns = valX.concat(valY);
    } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {
      doValidation = true;
      const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));
      const originalBatchSize = inputs[0].shape[0];
      valX = sliceArrays(inputs, splitAt, originalBatchSize);
      inputs = sliceArrays(inputs, 0, splitAt);
      valY = sliceArrays(targets, splitAt, originalBatchSize);
      targets = sliceArrays(targets, 0, splitAt);
      valIns = valX.concat(valY);
    } else if (args.validationSteps != null) {
      doValidation = true;
    }
    const ins = inputs.concat(targets).concat(sampleWeights);
    model2.checkTrainableWeightsConsistency();
    const trainFunction = model2.makeTrainFunction();
    const outLabels = model2.getDedupedMetricsNames();
    let valFunction;
    let callbackMetrics;
    if (doValidation) {
      model2.makeTestFunction();
      valFunction = model2.testFunction;
      callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
    } else {
      valFunction = null;
      valIns = [];
      callbackMetrics = outLabels.slice();
    }
    const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
    const out = await fitLoop(model2, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks2, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);
    return out;
  } finally {
    model2.isTraining = false;
    disposeNewTensors(inputs, x);
    disposeNewTensors(targets, y);
    disposeNewTensors(valX, inputValX);
    disposeNewTensors(valY, inputValY);
    if (sampleWeights != null) {
      dispose2(sampleWeights);
    }
  }
}
function ensureTensorsRank2OrHigher(tensors) {
  const outs = [];
  if (tensors instanceof Tensor4) {
    tensors = [tensors];
  }
  for (let i = 0; i < tensors.length; ++i) {
    const tensor3 = tensors[i];
    if (tensor3.rank === 1) {
      outs.push(expandDims3(tensor3, 1));
    } else if (tensor3.rank === 0) {
      throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
    } else {
      outs.push(tensor3);
    }
  }
  return outs;
}
function disposeNewTensors(tensors, refTensors) {
  if (tensors == null) {
    return;
  }
  const oldTensorIds = [];
  if (refTensors instanceof Tensor4) {
    oldTensorIds.push(refTensors.id);
  } else if (Array.isArray(refTensors)) {
    refTensors.forEach((t) => oldTensorIds.push(t.id));
  } else if (refTensors != null) {
    for (const name in refTensors) {
      const oldTensor = refTensors[name];
      oldTensorIds.push(oldTensor.id);
    }
  }
  const tensorsToDispose = [];
  if (tensors instanceof Tensor4) {
    if (oldTensorIds.indexOf(tensors.id) === -1) {
      tensorsToDispose.push(tensors);
    }
  } else if (Array.isArray(tensors)) {
    tensors.forEach((t) => {
      if (oldTensorIds.indexOf(t.id) === -1) {
        tensorsToDispose.push(t);
      }
    });
  } else if (tensors != null) {
    for (const name in tensors) {
      const tensor3 = tensors[name];
      if (oldTensorIds.indexOf(tensor3.id) === -1) {
        tensorsToDispose.push(tensor3);
      }
    }
  }
  tensorsToDispose.forEach((t) => {
    if (!t.isDisposed) {
      t.dispose();
    }
  });
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/engine/training.ts
function isDataTensor(x) {
  return x instanceof Tensor4;
}
function isDataArray(x) {
  return Array.isArray(x);
}
function isDataDict(x) {
  return !isDataTensor(x) && !isDataArray(x);
}
function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
  if (names == null || names.length === 0) {
    if (data != null) {
      let gotUnexpectedData = false;
      if (isDataArray(data) && data.length > 0) {
        gotUnexpectedData = true;
      } else if (isDataDict(data)) {
        for (const key in data) {
          if (data.hasOwnProperty(key)) {
            gotUnexpectedData = true;
            break;
          }
        }
      } else {
        gotUnexpectedData = true;
      }
      if (gotUnexpectedData) {
        throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, but got ${data}`);
      }
    }
    return [];
  }
  if (data == null) {
    return names.map((name) => null);
  }
  let arrays;
  if (isDataDict(data)) {
    data = data;
    arrays = [];
    for (const name of names) {
      if (data[name] == null) {
        throw new ValueError(`No data provided for "${name}". Need data for each key in: ${names}`);
      }
      arrays.push(data[name]);
    }
  } else if (isDataArray(data)) {
    data = data;
    if (data.length !== names.length) {
      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${names.length} Tensor(s), but instead got the following list of Tensor(s): ${data}`);
    }
    arrays = data;
  } else {
    data = data;
    if (names.length > 1) {
      throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${data.shape}`);
    }
    arrays = [data];
  }
  arrays = ensureTensorsRank2OrHigher(arrays);
  if (shapes != null) {
    for (let i = 0; i < names.length; ++i) {
      if (shapes[i] == null) {
        continue;
      }
      const array2 = arrays[i];
      if (array2.shape.length !== shapes[i].length) {
        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s). but got array with shape ${array2.shape}`);
      }
      for (let j = 0; j < shapes[i].length; ++j) {
        if (j === 0 && !checkBatchAxis) {
          continue;
        }
        const dim = array2.shape[j];
        const refDim = shapes[i][j];
        if (refDim != null && refDim >= 0 && dim !== refDim) {
          throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have shape [${shapes[i]}], but got array with shape [${array2.shape}].`);
        }
      }
    }
  }
  return arrays;
}
function checkArrayLengths(inputs, targets, weights) {
  const setX = unique3(inputs.map((input2) => input2.shape[0]));
  setX.sort();
  const setY = unique3(targets.map((target) => target.shape[0]));
  setY.sort();
  if (setX.length > 1) {
    throw new ValueError(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(inputs.map((input2) => input2.shape))}`);
  }
  if (setY.length > 1) {
    throw new ValueError(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(targets.map((target) => target.shape))}`);
  }
  if (setX.length > 0 && setY.length > 0 && !util_exports2.arraysEqual(setX, setY)) {
    throw new ValueError(`Input Tensors should have the same number of samples as target Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target sample(s).`);
  }
}
function checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {
  const keyLosses = [
    meanSquaredError3,
    binaryCrossentropy,
    categoricalCrossentropy
  ];
  for (let i = 0; i < targets.length; ++i) {
    const y = targets[i];
    const loss = lossFns[i];
    const shape = outputShapes[i];
    if (loss == null) {
      continue;
    }
    if (loss === categoricalCrossentropy) {
      if (y.shape[y.shape.length - 1] === 1) {
        throw new ValueError(`You are passing a target array of shape ${y.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
      }
    }
    if (keyLosses.indexOf(loss) !== -1) {
      const slicedYShape = y.shape.slice(1);
      const slicedShape = shape.slice(1);
      for (let j = 0; j < slicedYShape.length; ++j) {
        const targetDim = slicedYShape[j];
        const outDim = slicedShape[j];
        if (outDim != null && targetDim !== outDim) {
          throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an output of shape ${shape}, while using a loss function that expects targets to have the same shape as the output.`);
        }
      }
    }
  }
}
function checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
  let arrays;
  if (Array.isArray(data)) {
    if (data.length !== names.length) {
      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${names.length} Tensor(s), but instead got ${data.length} Tensors(s).`);
    }
    arrays = data;
  } else {
    if (names.length > 1) {
      throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(data.shape)}.`);
    }
    arrays = [data];
  }
  if (shapes != null) {
    for (let i = 0; i < names.length; ++i) {
      if (shapes[i] == null) {
        continue;
      }
      const array2 = arrays[i];
      if (array2.shape.length !== shapes[i].length) {
        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s), but got array with shape ${JSON.stringify(array2.shape)}`);
      }
      for (let j = 0; j < shapes[i].length; ++j) {
        if (j === 0 && !checkBatchAxis) {
          continue;
        }
        const dim = array2.shape[j];
        const refDim = shapes[i][j];
        if (refDim != null) {
          if (refDim !== dim) {
            throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have shape ${JSON.stringify(shapes[i])} but got array with shape ${JSON.stringify(array2.shape)}.`);
          }
        }
      }
    }
  }
}
function collectMetrics(metrics2, outputNames) {
  if (metrics2 == null || Array.isArray(metrics2) && metrics2.length === 0) {
    return outputNames.map((name) => []);
  }
  let wrappedMetrics;
  if (typeof metrics2 === "string" || typeof metrics2 === "function") {
    wrappedMetrics = [metrics2];
  } else if (Array.isArray(metrics2) || typeof metrics2 === "object") {
    wrappedMetrics = metrics2;
  } else {
    throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${metrics2}`);
  }
  if (Array.isArray(wrappedMetrics)) {
    return outputNames.map((name) => wrappedMetrics);
  } else {
    const nestedMetrics = [];
    for (const name of outputNames) {
      let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];
      if (!Array.isArray(outputMetrics)) {
        outputMetrics = [outputMetrics];
      }
      nestedMetrics.push(outputMetrics);
    }
    return nestedMetrics;
  }
}
var LAYERS_MODEL_FORMAT_NAME = "layers-model";
var LayersModel = class extends Container {
  constructor(args) {
    super(args);
    this.isTraining = false;
  }
  summary(lineLength, positions, printFn = console.log) {
    if (!this.built) {
      throw new ValueError(`This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).`);
    }
    printSummary(this, lineLength, positions, printFn);
  }
  compile(args) {
    if (args.loss == null) {
      args.loss = [];
    }
    this.loss = args.loss;
    if (typeof args.optimizer === "string") {
      this.optimizer_ = getOptimizer(args.optimizer);
      this.isOptimizerOwned = true;
    } else {
      if (!(args.optimizer instanceof Optimizer2)) {
        throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);
      }
      this.optimizer_ = args.optimizer;
      this.isOptimizerOwned = false;
    }
    let lossFunctions = [];
    if (!Array.isArray(args.loss) && typeof args.loss !== "string" && typeof args.loss !== "function") {
      args.loss = args.loss;
      for (const name in args.loss) {
        if (this.outputNames.indexOf(name) === -1) {
          throw new ValueError(`Unknown entry in loss dictionary: "${name}". Only expected the following keys: ${this.outputNames}`);
        }
      }
      for (const name of this.outputNames) {
        if (args.loss[name] == null) {
          console.warn(`Output "${name}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${name} during training`);
        }
        lossFunctions.push(get(args.loss[name]));
      }
    } else if (Array.isArray(args.loss)) {
      if (args.loss.length !== this.outputs.length) {
        throw new ValueError(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${args.loss}.`);
      }
      const theLosses = args.loss;
      lossFunctions = theLosses.map((l) => get(l));
    } else {
      const lossFunction = get(args.loss);
      this.outputs.forEach((_) => {
        lossFunctions.push(lossFunction);
      });
    }
    this.lossFunctions = lossFunctions;
    this.feedOutputNames = [];
    this.feedOutputShapes = [];
    this.feedLossFns = [];
    for (let i = 0; i < this.outputs.length; ++i) {
      const shape = this.internalOutputShapes[i];
      const name = this.outputNames[i];
      this.feedOutputNames.push(name);
      this.feedOutputShapes.push(shape);
      this.feedLossFns.push(this.lossFunctions[i]);
    }
    const skipTargetIndices = [];
    this.metrics = args.metrics;
    this.metricsNames = ["loss"];
    this.metricsTensors = [];
    nameScope("loss", () => {
      for (let i = 0; i < this.outputs.length; ++i) {
        if (skipTargetIndices.indexOf(i) !== -1) {
          continue;
        }
        const weightedLoss = this.lossFunctions[i];
        if (this.outputs.length > 1) {
          this.metricsTensors.push([weightedLoss, i]);
          this.metricsNames.push(this.outputNames[i] + "_loss");
        }
      }
    });
    const nestedMetrics = collectMetrics(args.metrics, this.outputNames);
    const appendMetric = (outputIndex, metricName, metricTensor) => {
      if (this.outputNames.length > 1) {
        metricName = this.outputNames[outputIndex] + "_" + metricName;
      }
      this.metricsNames.push(metricName);
      this.metricsTensors.push([metricTensor, outputIndex]);
    };
    nameScope("metric", () => {
      for (let i = 0; i < this.outputs.length; ++i) {
        if (skipTargetIndices.indexOf(i) !== -1) {
          continue;
        }
        const outputMetrics = nestedMetrics[i];
        const handleMetrics = (metrics2) => {
          const metricNamePrefix = "";
          let metricName;
          let accFn;
          let weightedMetricFn;
          for (const metric of metrics2) {
            if (typeof metric === "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(metric) !== -1) {
              const outputShape = this.internalOutputShapes[i];
              if (outputShape[outputShape.length - 1] === 1 || this.lossFunctions[i] === binaryCrossentropy) {
                if (["accuracy", "acc"].indexOf(metric) !== -1) {
                  accFn = binaryAccuracy;
                } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                  accFn = binaryCrossentropy2;
                }
              } else if (this.lossFunctions[i] === sparseCategoricalCrossentropy) {
                if (["accuracy", "acc"].indexOf(metric) !== -1) {
                  accFn = sparseCategoricalAccuracy;
                } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                  accFn = sparseCategoricalCrossentropy2;
                }
              } else {
                if (["accuracy", "acc"].indexOf(metric) !== -1) {
                  accFn = categoricalAccuracy;
                } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                  accFn = categoricalCrossentropy2;
                }
              }
              let suffix;
              if (["accuracy", "acc"].indexOf(metric) !== -1) {
                suffix = "acc";
              } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                suffix = "ce";
              }
              weightedMetricFn = accFn;
              metricName = metricNamePrefix + suffix;
            } else {
              const metricFn = get2(metric);
              weightedMetricFn = metricFn;
              metricName = metricNamePrefix + getLossOrMetricName(metric);
            }
            let metricResult;
            nameScope(metricName, () => {
              metricResult = weightedMetricFn;
            });
            appendMetric(i, metricName, metricResult);
          }
        };
        handleMetrics(outputMetrics);
      }
    });
    this.collectedTrainableWeights = this.trainableWeights;
  }
  checkTrainableWeightsConsistency() {
    if (this.collectedTrainableWeights == null) {
      return;
    }
    if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {
      console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
    }
  }
  evaluate(x, y, args = {}) {
    const batchSize = args.batchSize == null ? 32 : args.batchSize;
    checkBatchSize(batchSize);
    const checkBatchAxis = true;
    const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
    try {
      const ins = standardizedOuts[0].concat(standardizedOuts[1]);
      this.makeTestFunction();
      const f = this.testFunction;
      const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);
      return singletonOrArray(testOuts);
    } finally {
      disposeNewTensors(standardizedOuts[0], x);
      disposeNewTensors(standardizedOuts[1], y);
    }
  }
  async evaluateDataset(dataset, args) {
    this.makeTestFunction();
    return evaluateDataset(this, dataset, args);
  }
  checkNumSamples(ins, batchSize, steps, stepsName = "steps") {
    let numSamples;
    if (steps != null) {
      numSamples = null;
      if (batchSize != null) {
        throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.Got batchSize = ${batchSize}`);
      }
    } else if (ins != null) {
      if (Array.isArray(ins)) {
        numSamples = ins[0].shape[0];
      } else {
        numSamples = ins.shape[0];
      }
    } else {
      throw new ValueError(`Either the input data should have a defined shape, or ${stepsName} shoud be specified.`);
    }
    return numSamples;
  }
  execute(inputs, outputs) {
    if (Array.isArray(outputs) && outputs.length === 0) {
      throw new ValueError("`outputs` is an empty Array, which is not allowed.");
    }
    const outputsIsArray = Array.isArray(outputs);
    const outputNames = outputsIsArray ? outputs : [outputs];
    const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);
    const feedDict = new FeedDict();
    if (inputs instanceof Tensor4) {
      inputs = [inputs];
    }
    if (Array.isArray(inputs)) {
      if (inputs.length !== this.inputs.length) {
        throw new ValueError(`The number of inputs provided (${inputs.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
      }
      for (let i = 0; i < this.inputs.length; ++i) {
        feedDict.add(this.inputs[i], inputs[i]);
      }
    } else {
      for (const input2 of this.inputs) {
        const tensorValue = inputs[input2.name];
        if (tensorValue == null) {
          throw new ValueError(`No value is provided for the model's input ${input2.name}`);
        }
        feedDict.add(input2, tensorValue);
      }
    }
    const executeOutputs = execute(outputSymbolicTensors, feedDict);
    return outputsIsArray ? executeOutputs : executeOutputs[0];
  }
  retrieveSymbolicTensors(symbolicTensorNames) {
    const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);
    let outputsRemaining = symbolicTensorNames.length;
    for (const layer of this.layers) {
      const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];
      const layerOutputNames = layerOutputs.map((output) => output.name);
      for (let i = 0; i < symbolicTensorNames.length; ++i) {
        const index = layerOutputNames.indexOf(symbolicTensorNames[i]);
        if (index !== -1) {
          outputSymbolicTensors[i] = layerOutputs[index];
          outputsRemaining--;
        }
        if (outputsRemaining === 0) {
          break;
        }
      }
      if (outputsRemaining === 0) {
        break;
      }
    }
    if (outputsRemaining > 0) {
      const remainingNames = [];
      outputSymbolicTensors.forEach((tensor3, i) => {
        if (tensor3 == null) {
          remainingNames.push(symbolicTensorNames[i]);
        }
      });
      throw new ValueError(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(remainingNames)}`);
    }
    return outputSymbolicTensors;
  }
  predictLoop(ins, batchSize = 32, verbose = false) {
    return tidy2(() => {
      const numSamples = this.checkNumSamples(ins);
      if (verbose) {
        throw new NotImplementedError("Verbose predictLoop() is not implemented yet.");
      }
      const batches = makeBatches(numSamples, batchSize);
      const outsBatches = this.outputs.map((output) => []);
      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
        const batchOuts = tidy2(() => {
          const batchStart = batches[batchIndex][0];
          const batchEnd = batches[batchIndex][1];
          const insBatch = sliceArrays(ins, batchStart, batchEnd);
          const feeds = [];
          if (Array.isArray(insBatch)) {
            for (let i = 0; i < insBatch.length; ++i) {
              feeds.push({ key: this.inputs[i], value: insBatch[i] });
            }
          } else {
            feeds.push({ key: this.inputs[0], value: insBatch });
          }
          const feedDict = new FeedDict(feeds);
          return execute(this.outputs, feedDict);
        });
        batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));
      }
      return singletonOrArray(outsBatches.map((batches2) => concat2(batches2, 0)));
    });
  }
  predict(x, args = {}) {
    const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);
    checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);
    try {
      const batchSize = args.batchSize == null ? 32 : args.batchSize;
      checkBatchSize(batchSize);
      return this.predictLoop(xsRank2OrHigher, batchSize);
    } finally {
      disposeNewTensors(xsRank2OrHigher, x);
    }
  }
  predictOnBatch(x) {
    checkInputData(x, this.inputNames, this.feedInputShapes, true);
    const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];
    return this.predictLoop(x, batchSize);
  }
  standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {
    if (this.optimizer_ == null) {
      throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    }
    const outputShapes = [];
    for (let i = 0; i < this.feedOutputShapes.length; ++i) {
      const outputShape = this.feedOutputShapes[i];
      const lossFn = this.feedLossFns[i];
      if (lossFn === sparseCategoricalCrossentropy) {
        outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));
      } else {
        outputShapes.push(outputShape);
      }
    }
    x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, "input");
    y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, "target");
    checkArrayLengths(x, y, null);
    checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);
    if (this.stateful && batchSize != null && batchSize > 0) {
      if (x[0].shape[0] % batchSize !== 0) {
        throw new ValueError(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${batchSize}. Found: ${x[0].shape[0]} sample(s).`);
      }
    }
    return [x, y];
  }
  async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {
    const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
    if (sampleWeight != null) {
      throw new Error("sample weight is not supported yet.");
    }
    let standardSampleWeights = null;
    if (classWeight != null) {
      const classWeights = standardizeClassWeights(classWeight, this.outputNames);
      standardSampleWeights = [];
      for (let i = 0; i < classWeights.length; ++i) {
        standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));
      }
    }
    return [standardXs, standardYs, standardSampleWeights];
  }
  testLoop(f, ins, batchSize, verbose = 0, steps) {
    return tidy2(() => {
      const numSamples = this.checkNumSamples(ins, batchSize, steps, "steps");
      const outs = [];
      if (verbose > 0) {
        throw new NotImplementedError("Verbose mode is not implemented yet.");
      }
      if (steps != null) {
        throw new NotImplementedError("steps mode in testLoop() is not implemented yet");
      } else {
        const batches = makeBatches(numSamples, batchSize);
        const indexArray = tensor1d2(range3(0, numSamples));
        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
          const batchStart = batches[batchIndex][0];
          const batchEnd = batches[batchIndex][1];
          const batchIds = sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);
          const insBatch = sliceArraysByIndices(ins, batchIds);
          const batchOuts = f(insBatch);
          if (batchIndex === 0) {
            for (let i = 0; i < batchOuts.length; ++i) {
              outs.push(scalar2(0));
            }
          }
          for (let i = 0; i < batchOuts.length; ++i) {
            const batchOut = batchOuts[i];
            outs[i] = add4(outs[i], mul2(batchEnd - batchStart, batchOut));
          }
        }
        for (let i = 0; i < outs.length; ++i) {
          outs[i] = div2(outs[i], numSamples);
        }
      }
      return outs;
    });
  }
  getDedupedMetricsNames() {
    const outLabels = this.metricsNames;
    const dedupedOutLabels = [];
    for (let i = 0; i < outLabels.length; ++i) {
      const label = outLabels[i];
      let newLabel = label;
      if (count(outLabels, label) > 1) {
        const dupIndex = count(outLabels.slice(0, i), label);
        newLabel += `_${dupIndex}`;
      }
      dedupedOutLabels.push(newLabel);
    }
    return dedupedOutLabels;
  }
  makeTrainFunction() {
    return (data) => {
      const lossValues = [];
      const inputs = data.slice(0, this.inputs.length);
      const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
      const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);
      const metricsValues = [];
      const totalLossFunction = () => {
        const feeds = [];
        for (let i = 0; i < this.inputs.length; ++i) {
          feeds.push({ key: this.inputs[i], value: inputs[i] });
        }
        const feedDict = new FeedDict(feeds);
        const outputs = execute(this.outputs, feedDict, { "training": true });
        let totalLoss;
        for (let i = 0; i < this.lossFunctions.length; ++i) {
          const lossFunction = this.lossFunctions[i];
          let loss = lossFunction(targets[i], outputs[i]);
          if (sampleWeights[i] != null) {
            loss = computeWeightedLoss3(loss, sampleWeights[i]);
          }
          const meanLoss = mean2(loss);
          lossValues.push(meanLoss);
          if (i === 0) {
            totalLoss = loss;
          } else {
            totalLoss = add4(totalLoss, loss);
          }
        }
        for (let i = 0; i < this.metricsTensors.length; ++i) {
          let weightedMetric;
          if (this.outputs.length > 1 && i < this.outputs.length) {
            weightedMetric = lossValues[i];
          } else {
            const metric = this.metricsTensors[i][0];
            const outputIndex = this.metricsTensors[i][1];
            weightedMetric = mean2(metric(targets[outputIndex], outputs[outputIndex]));
          }
          keep2(weightedMetric);
          metricsValues.push(weightedMetric);
        }
        totalLoss = mean2(totalLoss);
        this.calculateLosses().forEach((regularizerLoss) => {
          totalLoss = add4(totalLoss, regularizerLoss);
        });
        return totalLoss;
      };
      const variables = this.collectedTrainableWeights.map((param) => param.read());
      const returnCost = true;
      const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);
      return [totalLossValue].concat(metricsValues);
    };
  }
  makeTestFunction() {
    this.testFunction = (data) => {
      return tidy2(() => {
        const valOutputs = [];
        let totalLoss;
        const inputs = data.slice(0, this.inputs.length);
        const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
        const feeds = [];
        for (let i = 0; i < this.inputs.length; ++i) {
          feeds.push({ key: this.inputs[i], value: inputs[i] });
        }
        const feedDict = new FeedDict(feeds);
        const outputs = execute(this.outputs, feedDict);
        for (let i = 0; i < this.lossFunctions.length; ++i) {
          const lossFunction = this.lossFunctions[i];
          const loss = mean2(lossFunction(targets[i], outputs[i]));
          if (i === 0) {
            totalLoss = loss;
          } else {
            totalLoss = add4(totalLoss, loss);
          }
          valOutputs.push(totalLoss);
        }
        for (let i = 0; i < this.metricsTensors.length; ++i) {
          const metric = this.metricsTensors[i][0];
          const outputIndex = this.metricsTensors[i][1];
          const meanMetric = mean2(metric(targets[outputIndex], outputs[outputIndex]));
          valOutputs.push(meanMetric);
        }
        return valOutputs;
      });
    };
  }
  async fit(x, y, args = {}) {
    return fitTensors(this, x, y, args);
  }
  async fitDataset(dataset, args) {
    return fitDataset(this, dataset, args);
  }
  async trainOnBatch(x, y) {
    const standardizeOut = await this.standardizeUserData(x, y);
    const inputs = standardizeOut[0];
    const targets = standardizeOut[1];
    const trainFunction = this.makeTrainFunction();
    const losses4 = trainFunction(inputs.concat(targets));
    const lossValues = [];
    for (const loss of losses4) {
      const v = await loss.data();
      lossValues.push(v[0]);
    }
    dispose2(losses4);
    return singletonOrArray(lossValues);
  }
  getNamedWeights(config) {
    const namedWeights = [];
    const trainableOnly = config != null && config.trainableOnly;
    const weights = trainableOnly ? this.trainableWeights : this.weights;
    const weightValues = this.getWeights(trainableOnly);
    for (let i = 0; i < weights.length; ++i) {
      if (trainableOnly && !weights[i].trainable) {
        continue;
      }
      namedWeights.push({ name: weights[i].originalName, tensor: weightValues[i] });
    }
    return namedWeights;
  }
  set stopTraining(stop) {
    this.stopTraining_ = stop;
  }
  get stopTraining() {
    return this.stopTraining_;
  }
  get optimizer() {
    return this.optimizer_;
  }
  set optimizer(optimizer) {
    if (this.optimizer_ !== optimizer) {
      this.optimizer_ = optimizer;
      this.isOptimizerOwned = false;
    }
  }
  dispose() {
    const result = super.dispose();
    if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
      const numTensorsBeforeOptmizerDisposal = memory2().numTensors;
      this.optimizer_.dispose();
      result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - memory2().numTensors;
    }
    return result;
  }
  getLossIdentifiers() {
    let lossNames;
    if (typeof this.loss === "string") {
      lossNames = toSnakeCase(this.loss);
    } else if (Array.isArray(this.loss)) {
      for (const loss of this.loss) {
        if (typeof loss !== "string") {
          throw new Error("Serialization of non-string loss is not supported.");
        }
      }
      lossNames = this.loss.map((name) => toSnakeCase(name));
    } else {
      const outputNames = Object.keys(this.loss);
      lossNames = {};
      const losses4 = this.loss;
      for (const outputName of outputNames) {
        if (typeof losses4[outputName] === "string") {
          lossNames[outputName] = toSnakeCase(losses4[outputName]);
        } else {
          throw new Error("Serialization of non-string loss is not supported.");
        }
      }
    }
    return lossNames;
  }
  getMetricIdentifiers() {
    if (typeof this.metrics === "string" || typeof this.metrics === "function") {
      return [toSnakeCase(getLossOrMetricName(this.metrics))];
    } else if (Array.isArray(this.metrics)) {
      return this.metrics.map((metric) => toSnakeCase(getLossOrMetricName(metric)));
    } else {
      const metricsIdentifiers = {};
      for (const key in this.metrics) {
        metricsIdentifiers[key] = toSnakeCase(getLossOrMetricName(this.metrics[key]));
      }
      return metricsIdentifiers;
    }
  }
  getTrainingConfig() {
    return {
      loss: this.getLossIdentifiers(),
      metrics: this.getMetricIdentifiers(),
      optimizer_config: {
        class_name: this.optimizer.getClassName(),
        config: this.optimizer.getConfig()
      }
    };
  }
  loadTrainingConfig(trainingConfig) {
    if (trainingConfig.weighted_metrics != null) {
      throw new Error("Loading weight_metrics is not supported yet.");
    }
    if (trainingConfig.loss_weights != null) {
      throw new Error("Loading loss_weights is not supported yet.");
    }
    if (trainingConfig.sample_weight_mode != null) {
      throw new Error("Loading sample_weight_mode is not supported yet.");
    }
    const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);
    const optimizer = deserialize(tsConfig);
    let loss;
    if (typeof trainingConfig.loss === "string") {
      loss = toCamelCase(trainingConfig.loss);
    } else if (Array.isArray(trainingConfig.loss)) {
      loss = trainingConfig.loss.map((lossEntry) => toCamelCase(lossEntry));
    } else if (trainingConfig.loss != null) {
      loss = {};
      for (const key in trainingConfig.loss) {
        loss[key] = toCamelCase(trainingConfig.loss[key]);
      }
    }
    let metrics2;
    if (Array.isArray(trainingConfig.metrics)) {
      metrics2 = trainingConfig.metrics.map((metric) => toCamelCase(metric));
    } else if (trainingConfig.metrics != null) {
      metrics2 = {};
      for (const key in trainingConfig.metrics) {
        metrics2[key] = toCamelCase(trainingConfig.metrics[key]);
      }
    }
    this.compile({ loss, metrics: metrics2, optimizer });
  }
  async save(handlerOrURL, config) {
    if (typeof handlerOrURL === "string") {
      const handlers = io_exports2.getSaveHandlers(handlerOrURL);
      if (handlers.length === 0) {
        throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);
      } else if (handlers.length > 1) {
        throw new ValueError(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
      }
      handlerOrURL = handlers[0];
    }
    if (handlerOrURL.save == null) {
      throw new ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    }
    const weightDataAndSpecs = await io_exports2.encodeWeights(this.getNamedWeights(config));
    const returnString = false;
    const unusedArg = null;
    const modelConfig = this.toJSON(unusedArg, returnString);
    const modelArtifacts = {
      modelTopology: modelConfig,
      format: LAYERS_MODEL_FORMAT_NAME,
      generatedBy: `TensorFlow.js tfjs-layers v${version11}`,
      convertedBy: null
    };
    const includeOptimizer = config == null ? false : config.includeOptimizer;
    if (includeOptimizer && this.optimizer != null) {
      modelArtifacts.trainingConfig = this.getTrainingConfig();
      const weightType = "optimizer";
      const { data: optimizerWeightData, specs: optimizerWeightSpecs } = await io_exports2.encodeWeights(await this.optimizer.getWeights(), weightType);
      weightDataAndSpecs.specs.push(...optimizerWeightSpecs);
      weightDataAndSpecs.data = io_exports2.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);
    }
    if (this.userDefinedMetadata != null) {
      const checkSize = true;
      checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);
      modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;
    }
    modelArtifacts.weightData = weightDataAndSpecs.data;
    modelArtifacts.weightSpecs = weightDataAndSpecs.specs;
    return handlerOrURL.save(modelArtifacts);
  }
  setUserDefinedMetadata(userDefinedMetadata) {
    checkUserDefinedMetadata(userDefinedMetadata, this.name);
    this.userDefinedMetadata = userDefinedMetadata;
  }
  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }
};
LayersModel.className = "Model";
serialization_exports2.registerClass(LayersModel);
var Functional = class extends LayersModel {
};
Functional.className = "Functional";
serialization_exports2.registerClass(Functional);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/models.ts
async function modelFromJSON(modelAndWeightsConfig, customObjects) {
  if (!("modelTopology" in modelAndWeightsConfig)) {
    modelAndWeightsConfig = { modelTopology: modelAndWeightsConfig };
  }
  modelAndWeightsConfig = modelAndWeightsConfig;
  let modelTopology = modelAndWeightsConfig.modelTopology;
  if (modelTopology["model_config"] != null) {
    modelTopology = modelTopology["model_config"];
  }
  const tsConfig = convertPythonicToTs(modelTopology);
  const model2 = deserialize(tsConfig, customObjects);
  if (modelAndWeightsConfig.weightsManifest != null) {
    const weightValues = await io_exports2.loadWeights(modelAndWeightsConfig.weightsManifest, modelAndWeightsConfig.pathPrefix, model2.weights.map((weight) => weight.originalName));
    const uniqueWeightValues = {};
    for (const weight of model2.weights) {
      uniqueWeightValues[weight.originalName] = weightValues[weight.originalName];
    }
    model2.loadWeights(uniqueWeightValues);
    dispose2(weightValues);
  }
  return model2;
}
async function loadLayersModelInternal(pathOrIOHandler, options) {
  if (options == null) {
    options = {};
  }
  if (typeof pathOrIOHandler === "string") {
    const handlers = io_exports2.getLoadHandlers(pathOrIOHandler, options);
    if (handlers.length === 0) {
      handlers.push(io_exports2.browserHTTPRequest(pathOrIOHandler, options));
    } else if (handlers.length > 1) {
      throw new ValueError(`Found more than one (${handlers.length}) load handlers for URL '${pathOrIOHandler}'`);
    }
    pathOrIOHandler = handlers[0];
  }
  return loadLayersModelFromIOHandler(pathOrIOHandler, void 0, options);
}
async function loadLayersModelFromIOHandler(handler, customObjects, options) {
  if (options == null) {
    options = {};
  }
  if (handler.load == null) {
    throw new ValueError("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
  }
  const artifacts = await handler.load();
  let modelTopology = artifacts.modelTopology;
  if (modelTopology["model_config"] != null) {
    modelTopology = modelTopology["model_config"];
  }
  const strict = options.strict == null ? true : options.strict;
  const fastWeightInit = artifacts.weightData != null && artifacts.weightSpecs != null && strict;
  const model2 = deserialize(convertPythonicToTs(modelTopology), customObjects, fastWeightInit);
  const trainingConfig = artifacts.trainingConfig;
  if (trainingConfig != null) {
    model2.loadTrainingConfig(trainingConfig);
  }
  if (artifacts.userDefinedMetadata != null) {
    model2.setUserDefinedMetadata(artifacts.userDefinedMetadata);
  }
  if (artifacts.weightData != null) {
    if (artifacts.weightSpecs == null) {
      throw new ValueError("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
    }
    const { modelWeights, optimizerWeights } = decodeModelAndOptimizerWeights(artifacts.weightData, artifacts.weightSpecs);
    model2.loadWeights(modelWeights, strict);
    if (model2.optimizer != null && optimizerWeights.length > 0) {
      await model2.optimizer.setWeights(optimizerWeights);
    }
    dispose2(modelWeights);
    dispose2(optimizerWeights.map((w) => w.tensor));
  }
  return model2;
}
function decodeModelAndOptimizerWeights(buffer3, specs) {
  const name2Tensor = io_exports2.decodeWeights(buffer3, specs);
  const modelWeights = {};
  const optimizerWeights = [];
  specs.forEach((spec) => {
    if (spec.group === "optimizer") {
      optimizerWeights.push({ name: spec.name, tensor: name2Tensor[spec.name] });
    } else {
      modelWeights[spec.name] = name2Tensor[spec.name];
    }
  });
  return { modelWeights, optimizerWeights };
}
var _Sequential = class extends LayersModel {
  constructor(args) {
    super({ inputs: [], outputs: [] });
    args = args || {};
    this.trainable = true;
    this.built = false;
    this.name = args.name != null ? args.name : getUid("sequential_");
    if (args.layers != null) {
      for (const layer of args.layers) {
        this.add(layer);
      }
    }
  }
  checkShape(layer) {
    const shape = layer.inboundNodes[0].outputTensors[0].shape;
    if (shape.some((x) => x < 0)) {
      throw new ValueError(`Negative dimension size caused by adding layer ${layer.name} with input shape [${layer.inboundNodes[0].inputTensors[0].shape}]`);
    }
  }
  add(layer) {
    const isLayerModelInstance = layer instanceof _Sequential || layer instanceof LayersModel;
    let modelLayer;
    if (isLayerModelInstance) {
      modelLayer = layer;
      if (modelLayer.outputs.length !== 1) {
        throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      }
      if (modelLayer.inputs.length !== 1) {
        throw new ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
      }
    }
    if (this.outputs.length === 0) {
      if (layer.inboundNodes.length === 0) {
        if (layer.batchInputShape == null) {
          throw new ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
        }
        const x = Input({
          batchShape: layer.batchInputShape,
          dtype: layer.dtype,
          name: layer.name + "_input"
        });
        layer.apply(x);
      }
      if (isLayerModelInstance) {
        this.outputs = modelLayer.outputs;
        this.inputs = modelLayer.inputs;
      } else {
        if (layer.inboundNodes.length !== 1) {
          throw new ValueError(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${layer.name} which has ${layer.inboundNodes.length} pre-existing inbound connections.`);
        }
        if (layer.inboundNodes[0].outputTensors.length !== 1) {
          throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        }
        this.checkShape(layer);
        this.outputs = [layer.inboundNodes[0].outputTensors[0]];
        this.inputs = getSourceInputs(this.outputs[0]);
      }
      this.inboundNodes = [];
      new Node({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        inputMasks: pyListRepeat(null, this.inputs.length),
        outputMasks: [null],
        inputShapes: this.inputs.map((x) => x.shape),
        outputShapes: this.outputs[0].shape
      });
    } else {
      const outputTensor = layer.apply(this.outputs[0]);
      if (Array.isArray(outputTensor)) {
        throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      }
      this.checkShape(layer);
      this.outputs = [outputTensor];
      this.inboundNodes[0].outputTensors = this.outputs;
      this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
    this.layers.push(layer);
    this.built = false;
  }
  pop() {
    if (this.layers.length === 0) {
      throw new TypeError("There are no layers in the model.");
    }
    this.layers.pop();
    if (this.layers.length === 0) {
      this.outputs = [];
      this.inboundNodes = [];
      this.outboundNodes = [];
    } else {
      const lastLayerIndex = this.layers.length - 1;
      this.layers[lastLayerIndex].outboundNodes = [];
      this.outputs = [this.layers[lastLayerIndex].output];
      this.inboundNodes[0].outputTensors = this.outputs;
      this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }
  call(inputs, kwargs) {
    if (this.model == null) {
      this.build();
    }
    return this.model.call(inputs, kwargs);
  }
  build(inputShape) {
    getExactlyOneShape(inputShape);
    if (this.inputs.length === 0 || this.outputs.length === 0) {
      throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    }
    this.model = new LayersModel({
      inputs: this.inputs,
      outputs: this.outputs[0],
      name: this.name + "_model"
    });
    this.model.trainable = this.trainable;
    this.supportsMasking = this.model.supportsMasking;
    this.inputLayers = this.model.inputLayers;
    this.inputLayersNodeIndices = this.model.inputLayersNodeIndices;
    this.inputLayersTensorIndices = this.model.inputLayersTensorIndices;
    this.outputLayers = this.model.outputLayers;
    this.outputLayersNodeIndices = this.model.outputLayersNodeIndices;
    this.outputLayersTensorIndices = this.model.outputLayersTensorIndices;
    this.nodesByDepth = this.model.nodesByDepth;
    this.containerNodes = this.model.containerNodes;
    this.outputNames = this.model.outputNames;
    this.inputNames = this.model.inputNames;
    this.built = true;
  }
  countParams() {
    if (!this.built) {
      this.build();
    }
    return super.countParams();
  }
  summary(lineLength, positions, printFn = console.log) {
    if (!this.built) {
      this.build();
    }
    super.summary(lineLength, positions, printFn);
  }
  setWeights(weights) {
    if (this.model == null) {
      this.build();
    }
    this.model.setWeights(weights);
  }
  evaluate(x, y, args = {}) {
    if (!this.built) {
      throw new RuntimeError("The model needs to be compiled before being used.");
    }
    return this.model.evaluate(x, y, args);
  }
  async evaluateDataset(dataset, args) {
    if (!this.built) {
      throw new RuntimeError("The model needs to be compiled before being used.");
    }
    return this.model.evaluateDataset(dataset, args);
  }
  predict(x, args = {}) {
    if (this.model == null) {
      this.build();
    }
    return this.model.predict(x, args);
  }
  predictOnBatch(x) {
    if (this.model == null) {
      this.build();
    }
    return this.model.predictOnBatch(x);
  }
  compile(args) {
    this.build();
    this.model.compile(args);
    this.optimizer_ = this.model.optimizer;
    this.isOptimizerOwned = this.model.isOptimizerOwned;
    this.loss = this.model.loss;
    this.metrics = this.model.metrics;
    this.metricsTensors = this.model.metricsTensors;
    this.metricsNames = this.model.metricsNames;
  }
  get optimizer() {
    return this.model == null ? void 0 : this.model.optimizer;
  }
  set optimizer(optimizer) {
    this.model.optimizer = optimizer;
  }
  async fit(x, y, args = {}) {
    if (!this.built) {
      throw new RuntimeError("The model needs to be compiled before being used.");
    }
    return this.model.fit(x, y, args);
  }
  async fitDataset(dataset, args) {
    if (!this.built) {
      throw new RuntimeError("The model needs to be compiled before being used.");
    }
    return this.model.fitDataset(dataset, args);
  }
  async trainOnBatch(x, y) {
    return this.model.trainOnBatch(x, y);
  }
  static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
    let configArray;
    let extraModelConfig = {};
    if (config instanceof Array) {
      if (!(config[0].className != null) || config[0]["className"] === "Merge") {
        throw new ValueError("Legacy serialization format not supported yet.");
      }
      configArray = config;
    } else {
      util_exports2.assert(config["layers"] != null, () => `When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.`);
      configArray = config["layers"];
      delete config["layers"];
      extraModelConfig = config;
    }
    const model2 = new cls(extraModelConfig);
    if (!(model2 instanceof _Sequential)) {
      throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model2}`);
    }
    for (const conf of configArray) {
      const customObjects2 = void 0;
      const layer = deserialize(conf, customObjects2, fastWeightInit);
      if (fastWeightInit) {
        layer.setFastWeightInitDuringBuild(true);
      }
      model2.add(layer);
    }
    return model2;
  }
  set stopTraining(stop) {
    if (this.model == null) {
      throw new ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");
    }
    this.model.stopTraining = stop;
  }
  get stopTraining() {
    if (this.model == null) {
      throw new ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");
    }
    return this.model.stopTraining;
  }
  getConfig() {
    const layers = [];
    for (const layer of this.layers) {
      const dict = {};
      dict["className"] = layer.getClassName();
      dict["config"] = layer.getConfig();
      layers.push(dict);
    }
    return { name: this.name, layers };
  }
};
var Sequential = _Sequential;
Sequential.className = "Sequential";
serialization_exports2.registerClass(Sequential);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports.ts
function model(args) {
  return new LayersModel(args);
}
function sequential(config) {
  return new Sequential(config);
}
function loadLayersModel(pathOrIOHandler, options) {
  if (options == null) {
    options = {};
  }
  return loadLayersModelInternal(pathOrIOHandler, options);
}
function input(config) {
  return Input(config);
}
function registerCallbackConstructor(verbosityLevel, callbackConstructor) {
  CallbackConstructorRegistry.registerCallbackConstructor(verbosityLevel, callbackConstructor);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/activations.ts
var Activation2 = class extends serialization_exports2.Serializable {
  getConfig() {
    return {};
  }
};
var Elu3 = class extends Activation2 {
  apply(x, alpha = 1) {
    return elu3(x, alpha);
  }
};
Elu3.className = "elu";
serialization_exports2.registerClass(Elu3);
var Selu3 = class extends Activation2 {
  apply(x) {
    return selu2(x);
  }
};
Selu3.className = "selu";
serialization_exports2.registerClass(Selu3);
var Relu3 = class extends Activation2 {
  apply(x) {
    return relu2(x);
  }
};
Relu3.className = "relu";
serialization_exports2.registerClass(Relu3);
var Relu63 = class extends Activation2 {
  apply(x) {
    return tidy2(() => minimum2(6, relu2(x)));
  }
};
Relu63.className = "relu6";
serialization_exports2.registerClass(Relu63);
var Linear = class extends Activation2 {
  apply(x) {
    return x;
  }
};
Linear.className = "linear";
serialization_exports2.registerClass(Linear);
var Sigmoid3 = class extends Activation2 {
  apply(x) {
    return sigmoid2(x);
  }
};
Sigmoid3.className = "sigmoid";
serialization_exports2.registerClass(Sigmoid3);
var HardSigmoid = class extends Activation2 {
  apply(x) {
    return hardSigmoid(x);
  }
};
HardSigmoid.className = "hardSigmoid";
serialization_exports2.registerClass(HardSigmoid);
var Softplus3 = class extends Activation2 {
  apply(x) {
    return softplus2(x);
  }
};
Softplus3.className = "softplus";
serialization_exports2.registerClass(Softplus3);
var Softsign = class extends Activation2 {
  apply(x) {
    return softsign(x);
  }
};
Softsign.className = "softsign";
serialization_exports2.registerClass(Softsign);
var Tanh3 = class extends Activation2 {
  apply(x) {
    return tanh4(x);
  }
};
Tanh3.className = "tanh";
serialization_exports2.registerClass(Tanh3);
var Softmax3 = class extends Activation2 {
  apply(x, axis = -1) {
    return softmax2(x, axis);
  }
};
Softmax3.className = "softmax";
serialization_exports2.registerClass(Softmax3);
var LogSoftmax3 = class extends Activation2 {
  apply(x, axis = -1) {
    return logSoftmax2(x, axis);
  }
};
LogSoftmax3.className = "logSoftmax";
serialization_exports2.registerClass(LogSoftmax3);
var Swish = class extends Activation2 {
  apply(x, alpha = 1) {
    return tidy2(() => sigmoid2(x.mul(alpha)).mul(x));
  }
};
Swish.className = "swish";
serialization_exports2.registerClass(Swish);
var Mish = class extends Activation2 {
  apply(x) {
    return tidy2(() => mul2(x, tanh4(softplus2(x))));
  }
};
Mish.className = "mish";
serialization_exports2.registerClass(Mish);
function serializeActivation(activation2) {
  return activation2.getClassName();
}
function deserializeActivation(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports2.SerializationMap.getMap().classNameMap, customObjects, "activation");
}
function getActivation(identifier) {
  if (identifier == null) {
    const config = {};
    config["className"] = "linear";
    config["config"] = {};
    return deserializeActivation(config);
  }
  if (typeof identifier === "string") {
    const config = {};
    config["className"] = identifier;
    config["config"] = {};
    return deserializeActivation(config);
  } else if (identifier instanceof Activation2) {
    return identifier;
  } else {
    return deserializeActivation(identifier);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/regularizers.ts
function assertObjectArgs(args) {
  if (args != null && typeof args !== "object") {
    throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${args}`);
  }
}
var Regularizer = class extends serialization_exports2.Serializable {
};
var L1L2 = class extends Regularizer {
  constructor(args) {
    super();
    assertObjectArgs(args);
    this.l1 = args == null || args.l1 == null ? 0.01 : args.l1;
    this.l2 = args == null || args.l2 == null ? 0.01 : args.l2;
    this.hasL1 = this.l1 !== 0;
    this.hasL2 = this.l2 !== 0;
  }
  apply(x) {
    return tidy2(() => {
      let regularization = zeros2([1]);
      if (this.hasL1) {
        regularization = add4(regularization, sum4(mul2(this.l1, abs2(x))));
      }
      if (this.hasL2) {
        regularization = add4(regularization, sum4(mul2(this.l2, square3(x))));
      }
      return regularization.asScalar();
    });
  }
  getConfig() {
    return { "l1": this.l1, "l2": this.l2 };
  }
  static fromConfig(cls, config) {
    return new cls({ l1: config["l1"], l2: config["l2"] });
  }
};
L1L2.className = "L1L2";
serialization_exports2.registerClass(L1L2);
function l1(args) {
  assertObjectArgs(args);
  return new L1L2({ l1: args != null ? args.l1 : null, l2: 0 });
}
function l2(args) {
  assertObjectArgs(args);
  return new L1L2({ l2: args != null ? args.l2 : null, l1: 0 });
}
var REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  "l1l2": "L1L2"
};
function serializeRegularizer(constraint) {
  return serializeKerasObject(constraint);
}
function deserializeRegularizer(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports2.SerializationMap.getMap().classNameMap, customObjects, "regularizer");
}
function getRegularizer(identifier) {
  if (identifier == null) {
    return null;
  }
  if (typeof identifier === "string") {
    const className = identifier in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    const config = { className, config: {} };
    return deserializeRegularizer(config);
  } else if (identifier instanceof Regularizer) {
    return identifier;
  } else {
    return deserializeRegularizer(identifier);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/advanced_activations.ts
var ReLU = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.supportsMasking = true;
    if (args != null) {
      this.maxValue = args.maxValue;
    }
  }
  call(inputs, kwargs) {
    inputs = getExactlyOneTensor(inputs);
    let output = relu2(inputs);
    if (this.maxValue != null) {
      output = clipByValue2(output, 0, this.maxValue);
    }
    return output;
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const config = { maxValue: this.maxValue };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
ReLU.className = "ReLU";
serialization_exports2.registerClass(ReLU);
var LeakyReLU = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.DEFAULT_ALPHA = 0.3;
    if (args == null) {
      args = {};
    }
    this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
  }
  call(inputs, kwargs) {
    const x = getExactlyOneTensor(inputs);
    return leakyRelu2(x, this.alpha);
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const config = { alpha: this.alpha };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
LeakyReLU.className = "LeakyReLU";
serialization_exports2.registerClass(LeakyReLU);
var PReLU = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.DEFAULT_ALPHA_INITIALIZER = "zeros";
    if (args == null) {
      args = {};
    }
    this.supportsMasking = true;
    this.alphaInitializer = getInitializer(args.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER);
    this.alphaRegularizer = getRegularizer(args.alphaRegularizer);
    this.alphaConstraint = getConstraint(args.alphaConstraint);
    if (args.sharedAxes == null) {
      this.sharedAxes = null;
    } else if (Array.isArray(args.sharedAxes)) {
      this.sharedAxes = args.sharedAxes;
    } else if (typeof args.sharedAxes === "number") {
      this.sharedAxes = [args.sharedAxes];
    } else {
      throw new ValueError(`Expected sharedAxes to be a number or an array of numbers, but got ${args.sharedAxes}`);
    }
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const paramShape = inputShape.slice(1);
    if (this.sharedAxes != null) {
      for (const i of this.sharedAxes) {
        paramShape[i - 1] = 1;
      }
    }
    this.alpha = this.addWeight("alpha", paramShape, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
    const axes = {};
    if (this.sharedAxes != null) {
      for (let i = 1; i < inputShape.length; ++i) {
        axes[i] = inputShape[i];
      }
    }
    this.inputSpec = [new InputSpec({
      ndim: inputShape.length,
      axes
    })];
    this.built = true;
  }
  call(inputs, kwargs) {
    inputs = getExactlyOneTensor(inputs);
    return prelu2(inputs, this.alpha.read());
  }
  getConfig() {
    const config = {
      alphaInitializer: serializeInitializer(this.alphaInitializer),
      alphaRegularizer: serializeRegularizer(this.alphaRegularizer),
      alphaConstraint: serializeConstraint(this.alphaConstraint),
      sharedAxes: this.sharedAxes
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
PReLU.className = "PReLU";
serialization_exports2.registerClass(PReLU);
var ELU = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.DEFAULT_ALPHA = 1;
    if (args == null) {
      args = {};
    }
    if (args.alpha != null && args.alpha !== this.DEFAULT_ALPHA) {
      throw new NotImplementedError(`Non-default alpha value (${args.alpha}) is not supported by the ELU layer yet.`);
    }
    this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
  }
  call(inputs, kwargs) {
    const x = getExactlyOneTensor(inputs);
    return elu2(x);
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const config = { alpha: this.alpha };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
ELU.className = "ELU";
serialization_exports2.registerClass(ELU);
var ThresholdedReLU = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.DEFAULT_THETA = 1;
    if (args == null) {
      args = {};
    }
    this.theta = args.theta == null ? this.DEFAULT_THETA : args.theta;
  }
  call(inputs, kwargs) {
    const x = getExactlyOneTensor(inputs);
    return x.mul(cast3(x.greater(this.theta), "float32"));
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const config = { theta: this.theta };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
ThresholdedReLU.className = "ThresholdedReLU";
serialization_exports2.registerClass(ThresholdedReLU);
var Softmax4 = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.DEFAULT_AXIS = 1;
    if (args == null) {
      args = {};
    }
    this.softmax = new Softmax3().apply;
    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
  }
  call(inputs, kwargs) {
    const x = getExactlyOneTensor(inputs);
    return this.softmax(x, this.axis);
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const config = { axis: this.axis };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Softmax4.className = "Softmax";
serialization_exports2.registerClass(Softmax4);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/utils/conv_utils.ts
function normalizeArray(value, n, name) {
  if (typeof value === "number") {
    return pyListRepeat(value, n);
  } else {
    if (value.length !== n) {
      throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${value.length} elements.`);
    }
    for (let i = 0; i < n; ++i) {
      const singleValue = value[i];
      if (!isInteger(singleValue)) {
        throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${JSON.stringify(value)} including a non-integer number ${singleValue}`);
      }
    }
    return value;
  }
}
function convOutputLength(inputLength, filterSize, padding, stride, dilation = 1) {
  if (inputLength == null) {
    return inputLength;
  }
  const dilatedFilterSize = filterSize + (filterSize - 1) * (dilation - 1);
  let outputLength;
  if (padding === "same") {
    outputLength = inputLength;
  } else {
    outputLength = inputLength - dilatedFilterSize + 1;
  }
  return Math.floor((outputLength + stride - 1) / stride);
}
function deconvLength(dimSize, strideSize, kernelSize, padding) {
  if (dimSize == null) {
    return null;
  }
  if (padding === "valid") {
    dimSize = dimSize * strideSize + max3([kernelSize - strideSize, 0]);
  } else if (padding === "same") {
    dimSize = dimSize * strideSize;
  } else {
    throw new ValueError(`Unsupport padding mode: ${padding}.`);
  }
  return dimSize;
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/convolutional.ts
function preprocessConv2DInput(x, dataFormat) {
  return tidy2(() => {
    checkDataFormat(dataFormat);
    if (dataFormat === "channelsFirst") {
      return transpose2(x, [0, 2, 3, 1]);
    } else {
      return x;
    }
  });
}
function preprocessConv3DInput(x, dataFormat) {
  return tidy2(() => {
    checkDataFormat(dataFormat);
    if (dataFormat === "channelsFirst") {
      return transpose2(x, [0, 2, 3, 4, 1]);
    } else {
      return x;
    }
  });
}
function conv1dWithBias(x, kernel, bias, strides = 1, padding = "valid", dataFormat, dilationRate = 1) {
  return tidy2(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.shape.length !== 3) {
      throw new ValueError(`The input of a conv1dWithBias operation should be 3, but is ${x.shape.length} instead.`);
    }
    if (kernel.shape.length !== 3) {
      throw new ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ${kernel.shape.length} instead`);
    }
    if (bias != null && bias.shape.length !== 1) {
      throw new ValueError(`The bias for a conv1dWithBias operation should be 1, but is ${kernel.shape.length} instead`);
    }
    if (dataFormat === "channelsFirst") {
      x = transpose2(x, [0, 2, 1]);
    }
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    }
    let y = conv1d2(x, kernel, strides, padding === "same" ? "same" : "valid", "NWC", dilationRate);
    if (bias != null) {
      y = biasAdd(y, bias);
    }
    return y;
  });
}
function conv2dWithBiasActivation(x, kernel, bias, strides = [1, 1], padding = "valid", dataFormat, dilationRate, activation2 = null) {
  return tidy2(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.rank !== 3 && x.rank !== 4) {
      throw new ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${x.rank}.`);
    }
    if (kernel.rank !== 3 && kernel.rank !== 4) {
      throw new ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${x.rank}.`);
    }
    let y = preprocessConv2DInput(x, dataFormat);
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    }
    y = fused_ops_exports2.conv2d({
      x: y,
      filter: kernel,
      strides,
      pad: padding === "same" ? "same" : "valid",
      dilations: dilationRate,
      dataFormat: "NHWC",
      bias,
      activation: activation2
    });
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
function conv3dWithBias(x, kernel, bias, strides = [1, 1, 1], padding = "valid", dataFormat, dilationRate) {
  return tidy2(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.rank !== 4 && x.rank !== 5) {
      throw new ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ${x.rank}.`);
    }
    if (kernel.rank !== 4 && kernel.rank !== 5) {
      throw new ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${x.rank}.`);
    }
    let y = preprocessConv3DInput(x, dataFormat);
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    }
    y = conv3d2(y, kernel, strides, padding === "same" ? "same" : "valid", "NDHWC", dilationRate);
    if (bias != null) {
      y = biasAdd(y, bias);
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 4, 1, 2, 3]);
    }
    return y;
  });
}
var BaseConv = class extends Layer {
  constructor(rank, args) {
    super(args);
    this.bias = null;
    this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
    this.DEFAULT_BIAS_INITIALIZER = "zeros";
    BaseConv.verifyArgs(args);
    this.rank = rank;
    assertPositiveInteger(this.rank, "rank");
    if (this.rank !== 1 && this.rank !== 2 && this.rank !== 3) {
      throw new NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
    }
    this.kernelSize = normalizeArray(args.kernelSize, rank, "kernelSize");
    this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, "strides");
    this.padding = args.padding == null ? "valid" : args.padding;
    checkPaddingMode(this.padding);
    this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
    checkDataFormat(this.dataFormat);
    this.activation = getActivation(args.activation);
    this.useBias = args.useBias == null ? true : args.useBias;
    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
    this.biasConstraint = getConstraint(args.biasConstraint);
    this.biasRegularizer = getRegularizer(args.biasRegularizer);
    this.activityRegularizer = getRegularizer(args.activityRegularizer);
    this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, "dilationRate");
    if (this.rank === 1 && (Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)) {
      throw new ValueError(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    } else if (this.rank === 2) {
      if (typeof this.dilationRate === "number") {
        this.dilationRate = [this.dilationRate, this.dilationRate];
      } else if (this.dilationRate.length !== 2) {
        throw new ValueError(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
      }
    } else if (this.rank === 3) {
      if (typeof this.dilationRate === "number") {
        this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
      } else if (this.dilationRate.length !== 3) {
        throw new ValueError(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
      }
    }
  }
  static verifyArgs(args) {
    assert3("kernelSize" in args, `required key 'kernelSize' not in config`);
    if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 3)) {
      throw new ValueError(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(args.kernelSize)}.`);
    }
  }
  getConfig() {
    const config = {
      kernelSize: this.kernelSize,
      strides: this.strides,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      biasInitializer: serializeInitializer(this.biasInitializer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      biasConstraint: serializeConstraint(this.biasConstraint)
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
var Conv = class extends BaseConv {
  constructor(rank, args) {
    super(rank, args);
    this.kernel = null;
    Conv.verifyArgs(args);
    this.filters = args.filters;
    assertPositiveInteger(this.filters, "filters");
    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.kernelConstraint = getConstraint(args.kernelConstraint);
    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
    if (inputShape[channelAxis] == null) {
      throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
    }
    const inputDim = inputShape[channelAxis];
    const kernelShape = this.kernelSize.concat([inputDim, this.filters]);
    this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    }
    this.inputSpec = [{ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } }];
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      let outputs;
      const biasValue = this.bias == null ? null : this.bias.read();
      const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
      if (fusedActivationName != null && this.rank === 2) {
        outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate, fusedActivationName);
      } else {
        if (this.rank === 1) {
          outputs = conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
        } else if (this.rank === 2) {
          outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
        } else if (this.rank === 3) {
          outputs = conv3dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
        } else {
          throw new NotImplementedError("convolutions greater than 3D are not implemented yet.");
        }
        if (this.activation != null) {
          outputs = this.activation.apply(outputs);
        }
      }
      return outputs;
    });
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const newSpace = [];
    const space = this.dataFormat === "channelsLast" ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);
    for (let i = 0; i < space.length; ++i) {
      const newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === "number" ? this.dilationRate : this.dilationRate[i]);
      newSpace.push(newDim);
    }
    let outputShape = [inputShape[0]];
    if (this.dataFormat === "channelsLast") {
      outputShape = outputShape.concat(newSpace);
      outputShape.push(this.filters);
    } else {
      outputShape.push(this.filters);
      outputShape = outputShape.concat(newSpace);
    }
    return outputShape;
  }
  getConfig() {
    const config = {
      filters: this.filters,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint)
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
  static verifyArgs(args) {
    if (!("filters" in args) || typeof args.filters !== "number" || args.filters < 1) {
      throw new ValueError(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(args.filters)}`);
    }
  }
};
var _Conv2D = class extends Conv {
  constructor(args) {
    super(2, args);
    _Conv2D.verifyArgs(args);
  }
  getConfig() {
    const config = super.getConfig();
    delete config["rank"];
    return config;
  }
  static verifyArgs(args) {
    if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 2)) {
      throw new ValueError(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(args.kernelSize)}.`);
    }
  }
};
var Conv2D3 = _Conv2D;
Conv2D3.className = "Conv2D";
serialization_exports2.registerClass(Conv2D3);
var _Conv3D = class extends Conv {
  constructor(args) {
    super(3, args);
    _Conv3D.verifyArgs(args);
  }
  getConfig() {
    const config = super.getConfig();
    delete config["rank"];
    return config;
  }
  static verifyArgs(args) {
    if (typeof args.kernelSize !== "number") {
      if (!(Array.isArray(args.kernelSize) && (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {
        throw new ValueError(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(args.kernelSize)}.`);
      }
    }
  }
};
var Conv3D3 = _Conv3D;
Conv3D3.className = "Conv3D";
serialization_exports2.registerClass(Conv3D3);
var Conv2DTranspose = class extends Conv2D3 {
  constructor(args) {
    super(args);
    this.inputSpec = [new InputSpec({ ndim: 4 })];
    if (this.padding !== "same" && this.padding !== "valid") {
      throw new ValueError(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
    }
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (inputShape.length !== 4) {
      throw new ValueError("Input should have rank 4; Received input shape: " + JSON.stringify(inputShape));
    }
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
    if (inputShape[channelAxis] == null) {
      throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
    }
    const inputDim = inputShape[channelAxis];
    const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
    this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    }
    this.inputSpec = [new InputSpec({ ndim: 4, axes: { [channelAxis]: inputDim } })];
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      let input2 = getExactlyOneTensor(inputs);
      if (input2.shape.length !== 4) {
        throw new ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
      }
      const inputShape = input2.shape;
      const batchSize = inputShape[0];
      let hAxis;
      let wAxis;
      if (this.dataFormat === "channelsFirst") {
        hAxis = 2;
        wAxis = 3;
      } else {
        hAxis = 1;
        wAxis = 2;
      }
      const height = inputShape[hAxis];
      const width = inputShape[wAxis];
      const kernelH = this.kernelSize[0];
      const kernelW = this.kernelSize[1];
      const strideH = this.strides[0];
      const strideW = this.strides[1];
      const outHeight = deconvLength(height, strideH, kernelH, this.padding);
      const outWidth = deconvLength(width, strideW, kernelW, this.padding);
      const outputShape = [batchSize, outHeight, outWidth, this.filters];
      if (this.dataFormat !== "channelsLast") {
        input2 = transpose2(input2, [0, 2, 3, 1]);
      }
      let outputs = conv2dTranspose2(input2, this.kernel.read(), outputShape, this.strides, this.padding);
      if (this.dataFormat !== "channelsLast") {
        outputs = transpose2(outputs, [0, 3, 1, 2]);
      }
      if (this.bias != null) {
        outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
      }
      if (this.activation != null) {
        outputs = this.activation.apply(outputs);
      }
      return outputs;
    });
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const outputShape = inputShape.slice();
    let channelAxis;
    let heightAxis;
    let widthAxis;
    if (this.dataFormat === "channelsFirst") {
      channelAxis = 1;
      heightAxis = 2;
      widthAxis = 3;
    } else {
      channelAxis = 3;
      heightAxis = 1;
      widthAxis = 2;
    }
    const kernelH = this.kernelSize[0];
    const kernelW = this.kernelSize[1];
    const strideH = this.strides[0];
    const strideW = this.strides[1];
    outputShape[channelAxis] = this.filters;
    outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
    outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
    return outputShape;
  }
  getConfig() {
    const config = super.getConfig();
    delete config["dilationRate"];
    return config;
  }
};
Conv2DTranspose.className = "Conv2DTranspose";
serialization_exports2.registerClass(Conv2DTranspose);
var Conv3DTranspose = class extends Conv3D3 {
  constructor(args) {
    super(args);
    this.inputSpec = [new InputSpec({ ndim: 5 })];
    if (this.padding !== "same" && this.padding !== "valid") {
      throw new ValueError(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
    }
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (inputShape.length !== 5) {
      throw new ValueError("Input should have rank 5; Received input shape: " + JSON.stringify(inputShape));
    }
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
    if (inputShape[channelAxis] == null) {
      throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
    }
    const inputDim = inputShape[channelAxis];
    const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
    this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    }
    this.inputSpec = [new InputSpec({ ndim: 5, axes: { [channelAxis]: inputDim } })];
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      let input2 = getExactlyOneTensor(inputs);
      if (input2.shape.length !== 5) {
        throw new ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
      }
      const inputShape = input2.shape;
      const batchSize = inputShape[0];
      let hAxis;
      let wAxis;
      let dAxis;
      if (this.dataFormat === "channelsFirst") {
        dAxis = 2;
        hAxis = 3;
        wAxis = 4;
      } else {
        dAxis = 1;
        hAxis = 2;
        wAxis = 3;
      }
      const depth = inputShape[dAxis];
      const height = inputShape[hAxis];
      const width = inputShape[wAxis];
      const kernelD = this.kernelSize[0];
      const kernelH = this.kernelSize[1];
      const kernelW = this.kernelSize[2];
      const strideD = this.strides[0];
      const strideH = this.strides[1];
      const strideW = this.strides[2];
      const outDepth = deconvLength(depth, strideD, kernelD, this.padding);
      const outHeight = deconvLength(height, strideH, kernelH, this.padding);
      const outWidth = deconvLength(width, strideW, kernelW, this.padding);
      const outputShape = [batchSize, outDepth, outHeight, outWidth, this.filters];
      if (this.dataFormat !== "channelsLast") {
        input2 = transpose2(input2, [0, 2, 3, 4, 1]);
      }
      let outputs = conv3dTranspose2(input2, this.kernel.read(), outputShape, this.strides, this.padding);
      if (this.dataFormat !== "channelsLast") {
        outputs = transpose2(outputs, [0, 4, 1, 2, 3]);
      }
      if (this.bias !== null) {
        outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
      }
      if (this.activation !== null) {
        outputs = this.activation.apply(outputs);
      }
      return outputs;
    });
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const outputShape = inputShape.slice();
    let channelAxis;
    let depthAxis;
    let heightAxis;
    let widthAxis;
    if (this.dataFormat === "channelsFirst") {
      channelAxis = 1;
      depthAxis = 2;
      heightAxis = 3;
      widthAxis = 4;
    } else {
      channelAxis = 4;
      depthAxis = 1;
      heightAxis = 2;
      widthAxis = 3;
    }
    const kernelD = this.kernelSize[0];
    const kernelH = this.kernelSize[1];
    const kernelW = this.kernelSize[2];
    const strideD = this.strides[0];
    const strideH = this.strides[1];
    const strideW = this.strides[2];
    outputShape[channelAxis] = this.filters;
    outputShape[depthAxis] = deconvLength(outputShape[depthAxis], strideD, kernelD, this.padding);
    outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
    outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
    return outputShape;
  }
  getConfig() {
    const config = super.getConfig();
    delete config["dilationRate"];
    return config;
  }
};
Conv3DTranspose.className = "Conv3DTranspose";
serialization_exports2.registerClass(Conv3DTranspose);
var SeparableConv = class extends Conv {
  constructor(rank, config) {
    super(rank, config);
    this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform";
    this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform";
    this.depthwiseKernel = null;
    this.pointwiseKernel = null;
    if (config.filters == null) {
      throw new ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    }
    if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {
      throw new ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    }
    if (config.padding != null && config.padding !== "same" && config.padding !== "valid") {
      throw new ValueError(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(config.padding)}`);
    }
    this.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;
    this.depthwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER);
    this.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);
    this.depthwiseConstraint = getConstraint(config.depthwiseConstraint);
    this.pointwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER);
    this.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);
    this.pointwiseConstraint = getConstraint(config.pointwiseConstraint);
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (inputShape.length < this.rank + 2) {
      throw new ValueError(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(inputShape)}`);
    }
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
    if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
      throw new ValueError(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(inputShape[channelAxis])}`);
    }
    const inputDim = inputShape[channelAxis];
    const depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);
    const pointwiseKernelShape = [];
    for (let i = 0; i < this.rank; ++i) {
      pointwiseKernelShape.push(1);
    }
    pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);
    const trainable = true;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);
    this.pointwiseKernel = this.addWeight("pointwise_kernel", pointwiseKernelShape, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);
    } else {
      this.bias = null;
    }
    this.inputSpec = [new InputSpec({ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } })];
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      let output;
      if (this.rank === 1) {
        throw new NotImplementedError("1D separable convolution is not implemented yet.");
      } else if (this.rank === 2) {
        if (this.dataFormat === "channelsFirst") {
          inputs = transpose2(inputs, [0, 2, 3, 1]);
        }
        output = separableConv2d2(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC");
      }
      if (this.useBias) {
        output = biasAdd(output, this.bias.read(), this.dataFormat);
      }
      if (this.activation != null) {
        output = this.activation.apply(output);
      }
      if (this.dataFormat === "channelsFirst") {
        output = transpose2(output, [0, 3, 1, 2]);
      }
      return output;
    });
  }
  getConfig() {
    const config = super.getConfig();
    delete config["rank"];
    delete config["kernelInitializer"];
    delete config["kernelRegularizer"];
    delete config["kernelConstraint"];
    config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
    config["pointwiseInitializer"] = serializeInitializer(this.pointwiseInitializer);
    config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
    config["pointwiseRegularizer"] = serializeRegularizer(this.pointwiseRegularizer);
    config["depthwiseConstraint"] = serializeConstraint(this.depthwiseConstraint);
    config["pointwiseConstraint"] = serializeConstraint(this.pointwiseConstraint);
    return config;
  }
};
SeparableConv.className = "SeparableConv";
var SeparableConv2D = class extends SeparableConv {
  constructor(args) {
    super(2, args);
  }
};
SeparableConv2D.className = "SeparableConv2D";
serialization_exports2.registerClass(SeparableConv2D);
var _Conv1D = class extends Conv {
  constructor(args) {
    super(1, args);
    _Conv1D.verifyArgs(args);
    this.inputSpec = [{ ndim: 3 }];
  }
  getConfig() {
    const config = super.getConfig();
    delete config["rank"];
    delete config["dataFormat"];
    return config;
  }
  static verifyArgs(args) {
    if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 1)) {
      throw new ValueError(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(args.kernelSize)}.`);
    }
  }
};
var Conv1D = _Conv1D;
Conv1D.className = "Conv1D";
serialization_exports2.registerClass(Conv1D);
var Cropping2D = class extends Layer {
  constructor(args) {
    super(args);
    if (typeof args.cropping === "number") {
      this.cropping = [[args.cropping, args.cropping], [args.cropping, args.cropping]];
    } else if (typeof args.cropping[0] === "number") {
      this.cropping = [
        [args.cropping[0], args.cropping[0]],
        [args.cropping[1], args.cropping[1]]
      ];
    } else {
      this.cropping = args.cropping;
    }
    this.dataFormat = args.dataFormat === void 0 ? "channelsLast" : args.dataFormat;
    this.inputSpec = [{ ndim: 4 }];
  }
  computeOutputShape(inputShape) {
    if (this.dataFormat === "channelsFirst") {
      return [
        inputShape[0],
        inputShape[1],
        inputShape[2] - this.cropping[0][0] - this.cropping[0][1],
        inputShape[3] - this.cropping[1][0] - this.cropping[1][1]
      ];
    } else {
      return [
        inputShape[0],
        inputShape[1] - this.cropping[0][0] - this.cropping[0][1],
        inputShape[2] - this.cropping[1][0] - this.cropping[1][1],
        inputShape[3]
      ];
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      if (this.dataFormat === "channelsLast") {
        const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
        return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      } else {
        const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
        return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }
  getConfig() {
    const config = { cropping: this.cropping, dataFormat: this.dataFormat };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Cropping2D.className = "Cropping2D";
serialization_exports2.registerClass(Cropping2D);
var UpSampling2D = class extends Layer {
  constructor(args) {
    super(args);
    this.DEFAULT_SIZE = [2, 2];
    this.inputSpec = [{ ndim: 4 }];
    this.size = args.size == null ? this.DEFAULT_SIZE : args.size;
    this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
    checkDataFormat(this.dataFormat);
    this.interpolation = args.interpolation == null ? "nearest" : args.interpolation;
    checkInterpolationFormat(this.interpolation);
  }
  computeOutputShape(inputShape) {
    if (this.dataFormat === "channelsFirst") {
      const height = inputShape[2] == null ? null : this.size[0] * inputShape[2];
      const width = inputShape[3] == null ? null : this.size[1] * inputShape[3];
      return [inputShape[0], inputShape[1], height, width];
    } else {
      const height = inputShape[1] == null ? null : this.size[0] * inputShape[1];
      const width = inputShape[2] == null ? null : this.size[1] * inputShape[2];
      return [inputShape[0], height, width, inputShape[3]];
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      let input2 = getExactlyOneTensor(inputs);
      const inputShape = input2.shape;
      if (this.dataFormat === "channelsFirst") {
        input2 = transpose2(input2, [0, 2, 3, 1]);
        const height = this.size[0] * inputShape[2];
        const width = this.size[1] * inputShape[3];
        const resized = this.interpolation === "nearest" ? input2.resizeNearestNeighbor([height, width]) : input2.resizeBilinear([height, width]);
        return transpose2(resized, [0, 3, 1, 2]);
      } else {
        const height = this.size[0] * inputShape[1];
        const width = this.size[1] * inputShape[2];
        return this.interpolation === "nearest" ? input2.resizeNearestNeighbor([height, width]) : input2.resizeBilinear([height, width]);
      }
    });
  }
  getConfig() {
    const config = { size: this.size, dataFormat: this.dataFormat };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
UpSampling2D.className = "UpSampling2D";
serialization_exports2.registerClass(UpSampling2D);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/convolutional_depthwise.ts
function depthwiseConv2d5(x, depthwiseKernel, strides = [1, 1], padding = "valid", dataFormat, dilationRate) {
  return tidy2(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    let y = preprocessConv2DInput(x, dataFormat);
    if (x.rank !== 4) {
      throw new ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ${x.rank}-D`);
    }
    if (depthwiseKernel.rank !== 4) {
      throw new ValueError(`depthwiseKernel is required to be 4-D, but is instead ${depthwiseKernel.rank}-D`);
    }
    y = depthwiseConv2d3(y, depthwiseKernel, strides, padding === "same" ? "same" : "valid", "NHWC", dilationRate);
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
var DepthwiseConv2D = class extends BaseConv {
  constructor(args) {
    super(2, args);
    this.depthwiseKernel = null;
    this.depthMultiplier = args.depthMultiplier == null ? 1 : args.depthMultiplier;
    this.depthwiseInitializer = getInitializer(args.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.depthwiseConstraint = getConstraint(args.depthwiseConstraint);
    this.depthwiseRegularizer = getRegularizer(args.depthwiseRegularizer);
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (inputShape.length < 4) {
      throw new ValueError(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(inputShape)}.`);
    }
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : 3;
    if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
      throw new ValueError(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${inputShape[channelAxis]}).`);
    }
    const inputDim = inputShape[channelAxis];
    const depthwiseKernelShape = [
      this.kernelSize[0],
      this.kernelSize[1],
      inputDim,
      this.depthMultiplier
    ];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [inputDim * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    } else {
      this.bias = null;
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      let outputs = depthwiseConv2d5(inputs, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      if (this.useBias) {
        outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
      }
      if (this.activation != null) {
        outputs = this.activation.apply(outputs);
      }
      return outputs;
    });
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
    const cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
    const outFilters = this.dataFormat === "channelsFirst" ? inputShape[1] * this.depthMultiplier : inputShape[3] * this.depthMultiplier;
    const outRows = convOutputLength(rows, this.kernelSize[0], this.padding, this.strides[0]);
    const outCols = convOutputLength(cols, this.kernelSize[1], this.padding, this.strides[1]);
    if (this.dataFormat === "channelsFirst") {
      return [inputShape[0], outFilters, outRows, outCols];
    } else {
      return [inputShape[0], outRows, outCols, outFilters];
    }
  }
  getConfig() {
    const config = super.getConfig();
    config["depthMultiplier"] = this.depthMultiplier;
    config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
    config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
    config["depthwiseConstraint"] = serializeConstraint(this.depthwiseRegularizer);
    return config;
  }
};
DepthwiseConv2D.className = "DepthwiseConv2D";
serialization_exports2.registerClass(DepthwiseConv2D);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/recurrent.ts
function standardizeArgs(inputs, initialState, constants, numConstants) {
  if (Array.isArray(inputs)) {
    if (initialState != null || constants != null) {
      throw new ValueError("When inputs is an array, neither initialState or constants should be provided");
    }
    if (numConstants != null) {
      constants = inputs.slice(inputs.length - numConstants, inputs.length);
      inputs = inputs.slice(0, inputs.length - numConstants);
    }
    if (inputs.length > 1) {
      initialState = inputs.slice(1, inputs.length);
    }
    inputs = inputs[0];
  }
  function toListOrNull(x) {
    if (x == null || Array.isArray(x)) {
      return x;
    } else {
      return [x];
    }
  }
  initialState = toListOrNull(initialState);
  constants = toListOrNull(constants);
  return { inputs, initialState, constants };
}
function rnn(stepFunction, inputs, initialStates, goBackwards = false, mask, constants, unroll = false, needPerStepOutputs = false) {
  return tidy2(() => {
    const ndim = inputs.shape.length;
    if (ndim < 3) {
      throw new ValueError(`Input should be at least 3D, but is ${ndim}D.`);
    }
    const axes = [1, 0].concat(range3(2, ndim));
    inputs = transpose2(inputs, axes);
    if (constants != null) {
      throw new NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    }
    if (unroll) {
      console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend.");
    }
    if (mask != null) {
      mask = mask.asType("bool").asType("float32");
      if (mask.rank === ndim - 1) {
        mask = expandDims2(mask, -1);
      }
      mask = transpose2(mask, axes);
    }
    if (goBackwards) {
      inputs = reverse2(inputs, 0);
      if (mask != null) {
        mask = reverse2(mask, 0);
      }
    }
    const perStepOutputs = [];
    let lastOutput;
    let states = initialStates;
    const timeSteps = inputs.shape[0];
    const perStepInputs = unstack2(inputs);
    let perStepMasks;
    if (mask != null) {
      perStepMasks = unstack2(mask);
    }
    for (let t = 0; t < timeSteps; ++t) {
      const currentInput = perStepInputs[t];
      const stepOutputs = tidy2(() => stepFunction(currentInput, states));
      if (mask == null) {
        lastOutput = stepOutputs[0];
        states = stepOutputs[1];
      } else {
        const maskedOutputs = tidy2(() => {
          const stepMask = perStepMasks[t];
          const negStepMask = onesLike2(stepMask).sub(stepMask);
          const output = stepOutputs[0].mul(stepMask).add(states[0].mul(negStepMask));
          const newStates = states.map((state, i) => {
            return stepOutputs[1][i].mul(stepMask).add(state.mul(negStepMask));
          });
          return { output, newStates };
        });
        lastOutput = maskedOutputs.output;
        states = maskedOutputs.newStates;
      }
      if (needPerStepOutputs) {
        perStepOutputs.push(lastOutput);
      }
    }
    let outputs;
    if (needPerStepOutputs) {
      const axis = 1;
      outputs = stack2(perStepOutputs, axis);
    }
    return [lastOutput, outputs, states];
  });
}
var _RNN = class extends Layer {
  constructor(args) {
    super(args);
    let cell;
    if (args.cell == null) {
      throw new ValueError("cell property is missing for the constructor of RNN.");
    } else if (Array.isArray(args.cell)) {
      cell = new StackedRNNCells({ cells: args.cell });
    } else {
      cell = args.cell;
    }
    if (cell.stateSize == null) {
      throw new ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    }
    this.cell = cell;
    this.returnSequences = args.returnSequences == null ? false : args.returnSequences;
    this.returnState = args.returnState == null ? false : args.returnState;
    this.goBackwards = args.goBackwards == null ? false : args.goBackwards;
    this._stateful = args.stateful == null ? false : args.stateful;
    this.unroll = args.unroll == null ? false : args.unroll;
    this.supportsMasking = true;
    this.inputSpec = [new InputSpec({ ndim: 3 })];
    this.stateSpec = null;
    this.states_ = null;
    this.numConstants = null;
    this.keptStates = [];
  }
  getStates() {
    if (this.states_ == null) {
      const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      return range3(0, numStates).map((x) => null);
    } else {
      return this.states_;
    }
  }
  setStates(states) {
    this.states_ = states;
  }
  computeOutputShape(inputShape) {
    if (isArrayOfShapes(inputShape)) {
      inputShape = inputShape[0];
    }
    inputShape = inputShape;
    let stateSize = this.cell.stateSize;
    if (!Array.isArray(stateSize)) {
      stateSize = [stateSize];
    }
    const outputDim = stateSize[0];
    let outputShape;
    if (this.returnSequences) {
      outputShape = [inputShape[0], inputShape[1], outputDim];
    } else {
      outputShape = [inputShape[0], outputDim];
    }
    if (this.returnState) {
      const stateShape = [];
      for (const dim of stateSize) {
        stateShape.push([inputShape[0], dim]);
      }
      return [outputShape].concat(stateShape);
    } else {
      return outputShape;
    }
  }
  computeMask(inputs, mask) {
    return tidy2(() => {
      if (Array.isArray(mask)) {
        mask = mask[0];
      }
      const outputMask = this.returnSequences ? mask : null;
      if (this.returnState) {
        const stateMask = this.states.map((s) => null);
        return [outputMask].concat(stateMask);
      } else {
        return outputMask;
      }
    });
  }
  get states() {
    if (this.states_ == null) {
      const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      const output = [];
      for (let i = 0; i < numStates; ++i) {
        output.push(null);
      }
      return output;
    } else {
      return this.states_;
    }
  }
  set states(s) {
    this.states_ = s;
  }
  build(inputShape) {
    const constantShape = null;
    if (this.numConstants != null) {
      throw new NotImplementedError("Constants support is not implemented in RNN yet.");
    }
    if (isArrayOfShapes(inputShape)) {
      inputShape = inputShape[0];
    }
    inputShape = inputShape;
    const batchSize = this.stateful ? inputShape[0] : null;
    const inputDim = inputShape.slice(2);
    this.inputSpec[0] = new InputSpec({ shape: [batchSize, null, ...inputDim] });
    const stepInputShape = [inputShape[0]].concat(inputShape.slice(2));
    if (constantShape != null) {
      throw new NotImplementedError("Constants support is not implemented in RNN yet.");
    } else {
      this.cell.build(stepInputShape);
    }
    let stateSize;
    if (Array.isArray(this.cell.stateSize)) {
      stateSize = this.cell.stateSize;
    } else {
      stateSize = [this.cell.stateSize];
    }
    if (this.stateSpec != null) {
      if (!util_exports2.arraysEqual(this.stateSpec.map((spec) => spec.shape[spec.shape.length - 1]), stateSize)) {
        throw new ValueError(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
      }
    } else {
      this.stateSpec = stateSize.map((dim) => new InputSpec({ shape: [null, dim] }));
    }
    if (this.stateful) {
      this.resetStates();
    }
  }
  resetStates(states, training = false) {
    tidy2(() => {
      if (!this.stateful) {
        throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
      }
      const batchSize = this.inputSpec[0].shape[0];
      if (batchSize == null) {
        throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      }
      if (this.states_ == null) {
        if (Array.isArray(this.cell.stateSize)) {
          this.states_ = this.cell.stateSize.map((dim) => zeros2([batchSize, dim]));
        } else {
          this.states_ = [zeros2([batchSize, this.cell.stateSize])];
        }
      } else if (states == null) {
        dispose2(this.states_);
        if (this.keptStates != null) {
          dispose2(this.keptStates);
          this.keptStates = [];
        }
        if (Array.isArray(this.cell.stateSize)) {
          this.states_ = this.cell.stateSize.map((dim) => zeros2([batchSize, dim]));
        } else {
          this.states_[0] = zeros2([batchSize, this.cell.stateSize]);
        }
      } else {
        if (!Array.isArray(states)) {
          states = [states];
        }
        if (states.length !== this.states_.length) {
          throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
        }
        if (training === true) {
          this.keptStates.push(this.states_.slice());
        } else {
          dispose2(this.states_);
        }
        for (let index = 0; index < this.states_.length; ++index) {
          const value = states[index];
          const dim = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[index] : this.cell.stateSize;
          const expectedShape = [batchSize, dim];
          if (!util_exports2.arraysEqual(value.shape, expectedShape)) {
            throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
          }
          this.states_[index] = value;
        }
      }
      this.states_ = this.states_.map((state) => keep2(state.clone()));
    });
  }
  apply(inputs, kwargs) {
    let initialState = kwargs == null ? null : kwargs["initialState"];
    let constants = kwargs == null ? null : kwargs["constants"];
    if (kwargs == null) {
      kwargs = {};
    }
    const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
    inputs = standardized.inputs;
    initialState = standardized.initialState;
    constants = standardized.constants;
    let additionalInputs = [];
    let additionalSpecs = [];
    if (initialState != null) {
      kwargs["initialState"] = initialState;
      additionalInputs = additionalInputs.concat(initialState);
      this.stateSpec = [];
      for (const state of initialState) {
        this.stateSpec.push(new InputSpec({ shape: state.shape }));
      }
      additionalSpecs = additionalSpecs.concat(this.stateSpec);
    }
    if (constants != null) {
      kwargs["constants"] = constants;
      additionalInputs = additionalInputs.concat(constants);
      this.numConstants = constants.length;
    }
    const isTensor = additionalInputs[0] instanceof SymbolicTensor;
    if (isTensor) {
      const fullInput = [inputs].concat(additionalInputs);
      const fullInputSpec = this.inputSpec.concat(additionalSpecs);
      const originalInputSpec = this.inputSpec;
      this.inputSpec = fullInputSpec;
      const output = super.apply(fullInput, kwargs);
      this.inputSpec = originalInputSpec;
      return output;
    } else {
      return super.apply(inputs, kwargs);
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const mask = kwargs == null ? null : kwargs["mask"];
      const training = kwargs == null ? null : kwargs["training"];
      let initialState = kwargs == null ? null : kwargs["initialState"];
      inputs = getExactlyOneTensor(inputs);
      if (initialState == null) {
        if (this.stateful) {
          initialState = this.states_;
        } else {
          initialState = this.getInitialState(inputs);
        }
      }
      const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (initialState.length !== numStates) {
        throw new ValueError(`RNN Layer has ${numStates} state(s) but was passed ${initialState.length} initial state(s).`);
      }
      if (this.unroll) {
        console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      }
      const cellCallKwargs = { training };
      const step6 = (inputs2, states2) => {
        const outputs2 = this.cell.call([inputs2].concat(states2), cellCallKwargs);
        return [outputs2[0], outputs2.slice(1)];
      };
      const rnnOutputs = rnn(step6, inputs, initialState, this.goBackwards, mask, null, this.unroll, this.returnSequences);
      const lastOutput = rnnOutputs[0];
      const outputs = rnnOutputs[1];
      const states = rnnOutputs[2];
      if (this.stateful) {
        this.resetStates(states, training);
      }
      const output = this.returnSequences ? outputs : lastOutput;
      if (this.returnState) {
        return [output].concat(states);
      } else {
        return output;
      }
    });
  }
  getInitialState(inputs) {
    return tidy2(() => {
      let initialState = zeros2(inputs.shape);
      initialState = sum4(initialState, [1, 2]);
      initialState = expandDims3(initialState);
      if (Array.isArray(this.cell.stateSize)) {
        return this.cell.stateSize.map((dim) => dim > 1 ? tile3(initialState, [1, dim]) : initialState);
      } else {
        return this.cell.stateSize > 1 ? [tile3(initialState, [1, this.cell.stateSize])] : [initialState];
      }
    });
  }
  get trainableWeights() {
    if (!this.trainable) {
      return [];
    }
    return this.cell.trainableWeights;
  }
  get nonTrainableWeights() {
    if (!this.trainable) {
      return this.cell.weights;
    }
    return this.cell.nonTrainableWeights;
  }
  setFastWeightInitDuringBuild(value) {
    super.setFastWeightInitDuringBuild(value);
    if (this.cell != null) {
      this.cell.setFastWeightInitDuringBuild(value);
    }
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = {
      returnSequences: this.returnSequences,
      returnState: this.returnState,
      goBackwards: this.goBackwards,
      stateful: this.stateful,
      unroll: this.unroll
    };
    if (this.numConstants != null) {
      config["numConstants"] = this.numConstants;
    }
    const cellConfig = this.cell.getConfig();
    if (this.getClassName() === _RNN.className) {
      config["cell"] = {
        "className": this.cell.getClassName(),
        "config": cellConfig
      };
    }
    return { ...cellConfig, ...baseConfig, ...config };
  }
  static fromConfig(cls, config, customObjects = {}) {
    const cellConfig = config["cell"];
    const cell = deserialize(cellConfig, customObjects);
    return new cls(Object.assign(config, { cell }));
  }
};
var RNN = _RNN;
RNN.className = "RNN";
serialization_exports2.registerClass(RNN);
var RNNCell = class extends Layer {
};
var SimpleRNNCell = class extends RNNCell {
  constructor(args) {
    super(args);
    this.DEFAULT_ACTIVATION = "tanh";
    this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
    this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
    this.DEFAULT_BIAS_INITIALIZER = "zeros";
    this.units = args.units;
    assertPositiveInteger(this.units, `units`);
    this.activation = getActivation(args.activation == null ? this.DEFAULT_ACTIVATION : args.activation);
    this.useBias = args.useBias == null ? true : args.useBias;
    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
    this.biasRegularizer = getRegularizer(args.biasRegularizer);
    this.kernelConstraint = getConstraint(args.kernelConstraint);
    this.recurrentConstraint = getConstraint(args.recurrentConstraint);
    this.biasConstraint = getConstraint(args.biasConstraint);
    this.dropout = min3([1, max3([0, args.dropout == null ? 0 : args.dropout])]);
    this.recurrentDropout = min3([
      1,
      max3([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
    ]);
    this.stateSize = this.units;
    this.dropoutMask = null;
    this.recurrentDropoutMask = null;
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    this.kernel = this.addWeight("kernel", [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    } else {
      this.bias = null;
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = inputs;
      if (inputs.length !== 2) {
        throw new ValueError(`SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);
      }
      let prevOutput = inputs[1];
      inputs = inputs[0];
      const training = kwargs["training"] == null ? false : kwargs["training"];
      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
        this.dropoutMask = generateDropoutMask({
          ones: () => onesLike2(inputs),
          rate: this.dropout,
          training
        });
      }
      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
        this.recurrentDropoutMask = generateDropoutMask({
          ones: () => onesLike2(prevOutput),
          rate: this.recurrentDropout,
          training
        });
      }
      let h;
      const dpMask = this.dropoutMask;
      const recDpMask = this.recurrentDropoutMask;
      if (dpMask != null) {
        h = dot3(mul2(inputs, dpMask), this.kernel.read());
      } else {
        h = dot3(inputs, this.kernel.read());
      }
      if (this.bias != null) {
        h = biasAdd(h, this.bias.read());
      }
      if (recDpMask != null) {
        prevOutput = mul2(prevOutput, recDpMask);
      }
      let output = add4(h, dot3(prevOutput, this.recurrentKernel.read()));
      if (this.activation != null) {
        output = this.activation.apply(output);
      }
      return [output, output];
    });
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = {
      units: this.units,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout
    };
    return { ...baseConfig, ...config };
  }
};
SimpleRNNCell.className = "SimpleRNNCell";
serialization_exports2.registerClass(SimpleRNNCell);
var SimpleRNN = class extends RNN {
  constructor(args) {
    args.cell = new SimpleRNNCell(args);
    super(args);
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (this.cell.dropoutMask != null) {
        dispose2(this.cell.dropoutMask);
        this.cell.dropoutMask = null;
      }
      if (this.cell.recurrentDropoutMask != null) {
        dispose2(this.cell.recurrentDropoutMask);
        this.cell.recurrentDropoutMask = null;
      }
      const mask = kwargs == null ? null : kwargs["mask"];
      const training = kwargs == null ? null : kwargs["training"];
      const initialState = kwargs == null ? null : kwargs["initialState"];
      return super.call(inputs, { mask, training, initialState });
    });
  }
  static fromConfig(cls, config) {
    return new cls(config);
  }
};
SimpleRNN.className = "SimpleRNN";
serialization_exports2.registerClass(SimpleRNN);
var GRUCell = class extends RNNCell {
  constructor(args) {
    super(args);
    this.DEFAULT_ACTIVATION = "tanh";
    this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
    this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
    this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
    this.DEFAULT_BIAS_INITIALIZER = "zeros";
    if (args.resetAfter) {
      throw new ValueError(`GRUCell does not support reset_after parameter set to true.`);
    }
    this.units = args.units;
    assertPositiveInteger(this.units, "units");
    this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
    this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
    this.useBias = args.useBias == null ? true : args.useBias;
    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
    this.biasRegularizer = getRegularizer(args.biasRegularizer);
    this.kernelConstraint = getConstraint(args.kernelConstraint);
    this.recurrentConstraint = getConstraint(args.recurrentConstraint);
    this.biasConstraint = getConstraint(args.biasConstraint);
    this.dropout = min3([1, max3([0, args.dropout == null ? 0 : args.dropout])]);
    this.recurrentDropout = min3([
      1,
      max3([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
    ]);
    this.implementation = args.implementation;
    this.stateSize = this.units;
    this.dropoutMask = null;
    this.recurrentDropoutMask = null;
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const inputDim = inputShape[inputShape.length - 1];
    this.kernel = this.addWeight("kernel", [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    if (this.useBias) {
      this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    } else {
      this.bias = null;
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = inputs;
      if (inputs.length !== 2) {
        throw new ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ${inputs.length}.`);
      }
      const training = kwargs["training"] == null ? false : kwargs["training"];
      let hTMinus1 = inputs[1];
      inputs = inputs[0];
      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
        this.dropoutMask = generateDropoutMask({
          ones: () => onesLike2(inputs),
          rate: this.dropout,
          training,
          count: 3
        });
      }
      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
        this.recurrentDropoutMask = generateDropoutMask({
          ones: () => onesLike2(hTMinus1),
          rate: this.recurrentDropout,
          training,
          count: 3
        });
      }
      const dpMask = this.dropoutMask;
      const recDpMask = this.recurrentDropoutMask;
      let z;
      let r;
      let hh;
      if (0 < this.dropout && this.dropout < 1) {
        inputs = mul2(inputs, dpMask[0]);
      }
      let matrixX = dot3(inputs, this.kernel.read());
      if (this.useBias) {
        matrixX = biasAdd(matrixX, this.bias.read());
      }
      if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
        hTMinus1 = mul2(hTMinus1, recDpMask[0]);
      }
      const recurrentKernelValue = this.recurrentKernel.read();
      const [rk1, rk2] = split2(recurrentKernelValue, [2 * this.units, this.units], recurrentKernelValue.rank - 1);
      const matrixInner = dot3(hTMinus1, rk1);
      const [xZ, xR, xH] = split2(matrixX, 3, matrixX.rank - 1);
      const [recurrentZ, recurrentR] = split2(matrixInner, 2, matrixInner.rank - 1);
      z = this.recurrentActivation.apply(add4(xZ, recurrentZ));
      r = this.recurrentActivation.apply(add4(xR, recurrentR));
      const recurrentH = dot3(mul2(r, hTMinus1), rk2);
      hh = this.activation.apply(add4(xH, recurrentH));
      const h = add4(mul2(z, hTMinus1), mul2(add4(1, neg2(z)), hh));
      return [h, h];
    });
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = {
      units: this.units,
      activation: serializeActivation(this.activation),
      recurrentActivation: serializeActivation(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation,
      resetAfter: false
    };
    return { ...baseConfig, ...config };
  }
};
GRUCell.className = "GRUCell";
serialization_exports2.registerClass(GRUCell);
var GRU = class extends RNN {
  constructor(args) {
    if (args.implementation === 0) {
      console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
    }
    args.cell = new GRUCell(args);
    super(args);
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (this.cell.dropoutMask != null) {
        dispose2(this.cell.dropoutMask);
        this.cell.dropoutMask = null;
      }
      if (this.cell.recurrentDropoutMask != null) {
        dispose2(this.cell.recurrentDropoutMask);
        this.cell.recurrentDropoutMask = null;
      }
      const mask = kwargs == null ? null : kwargs["mask"];
      const training = kwargs == null ? null : kwargs["training"];
      const initialState = kwargs == null ? null : kwargs["initialState"];
      return super.call(inputs, { mask, training, initialState });
    });
  }
  static fromConfig(cls, config) {
    if (config["implmentation"] === 0) {
      config["implementation"] = 1;
    }
    return new cls(config);
  }
};
GRU.className = "GRU";
serialization_exports2.registerClass(GRU);
var LSTMCell = class extends RNNCell {
  constructor(args) {
    super(args);
    this.DEFAULT_ACTIVATION = "tanh";
    this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
    this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
    this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
    this.DEFAULT_BIAS_INITIALIZER = "zeros";
    this.units = args.units;
    assertPositiveInteger(this.units, "units");
    this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
    this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
    this.useBias = args.useBias == null ? true : args.useBias;
    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
    this.unitForgetBias = args.unitForgetBias;
    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
    this.biasRegularizer = getRegularizer(args.biasRegularizer);
    this.kernelConstraint = getConstraint(args.kernelConstraint);
    this.recurrentConstraint = getConstraint(args.recurrentConstraint);
    this.biasConstraint = getConstraint(args.biasConstraint);
    this.dropout = min3([1, max3([0, args.dropout == null ? 0 : args.dropout])]);
    this.recurrentDropout = min3([
      1,
      max3([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
    ]);
    this.implementation = args.implementation;
    this.stateSize = [this.units, this.units];
    this.dropoutMask = null;
    this.recurrentDropoutMask = null;
  }
  build(inputShape) {
    var _a;
    inputShape = getExactlyOneShape(inputShape);
    const inputDim = inputShape[inputShape.length - 1];
    this.kernel = this.addWeight("kernel", [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    let biasInitializer;
    if (this.useBias) {
      if (this.unitForgetBias) {
        const capturedBiasInit = this.biasInitializer;
        const capturedUnits = this.units;
        biasInitializer = new (_a = class extends Initializer {
          apply(shape, dtype) {
            const bI = capturedBiasInit.apply([capturedUnits]);
            const bF = new Ones().apply([capturedUnits]);
            const bCAndH = capturedBiasInit.apply([capturedUnits * 2]);
            return concatAlongFirstAxis(concatAlongFirstAxis(bI, bF), bCAndH);
          }
        }, _a.className = "CustomInit", _a)();
      } else {
        biasInitializer = this.biasInitializer;
      }
      this.bias = this.addWeight("bias", [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    } else {
      this.bias = null;
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const training = kwargs["training"] == null ? false : kwargs["training"];
      inputs = inputs;
      if (inputs.length !== 3) {
        throw new ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
      }
      let hTMinus1 = inputs[1];
      const cTMinus1 = inputs[2];
      inputs = inputs[0];
      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
        this.dropoutMask = generateDropoutMask({
          ones: () => onesLike2(inputs),
          rate: this.dropout,
          training,
          count: 4
        });
      }
      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
        this.recurrentDropoutMask = generateDropoutMask({
          ones: () => onesLike2(hTMinus1),
          rate: this.recurrentDropout,
          training,
          count: 4
        });
      }
      const dpMask = this.dropoutMask;
      const recDpMask = this.recurrentDropoutMask;
      let i;
      let f;
      let c;
      let o;
      if (0 < this.dropout && this.dropout < 1) {
        inputs = mul2(inputs, dpMask[0]);
      }
      let z = dot3(inputs, this.kernel.read());
      if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
        hTMinus1 = mul2(hTMinus1, recDpMask[0]);
      }
      z = add4(z, dot3(hTMinus1, this.recurrentKernel.read()));
      if (this.useBias) {
        z = biasAdd(z, this.bias.read());
      }
      const [z0, z1, z2, z3] = split2(z, 4, z.rank - 1);
      i = this.recurrentActivation.apply(z0);
      f = this.recurrentActivation.apply(z1);
      c = add4(mul2(f, cTMinus1), mul2(i, this.activation.apply(z2)));
      o = this.recurrentActivation.apply(z3);
      const h = mul2(o, this.activation.apply(c));
      return [h, h, c];
    });
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = {
      units: this.units,
      activation: serializeActivation(this.activation),
      recurrentActivation: serializeActivation(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      unitForgetBias: this.unitForgetBias,
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation
    };
    return { ...baseConfig, ...config };
  }
};
LSTMCell.className = "LSTMCell";
serialization_exports2.registerClass(LSTMCell);
var LSTM = class extends RNN {
  constructor(args) {
    if (args.implementation === 0) {
      console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
    }
    args.cell = new LSTMCell(args);
    super(args);
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (this.cell.dropoutMask != null) {
        dispose2(this.cell.dropoutMask);
        this.cell.dropoutMask = null;
      }
      if (this.cell.recurrentDropoutMask != null) {
        dispose2(this.cell.recurrentDropoutMask);
        this.cell.recurrentDropoutMask = null;
      }
      const mask = kwargs == null ? null : kwargs["mask"];
      const training = kwargs == null ? null : kwargs["training"];
      const initialState = kwargs == null ? null : kwargs["initialState"];
      return super.call(inputs, { mask, training, initialState });
    });
  }
  static fromConfig(cls, config) {
    if (config["implmentation"] === 0) {
      config["implementation"] = 1;
    }
    return new cls(config);
  }
};
LSTM.className = "LSTM";
serialization_exports2.registerClass(LSTM);
var StackedRNNCells = class extends RNNCell {
  constructor(args) {
    super(args);
    this.cells = args.cells;
  }
  get stateSize() {
    const stateSize = [];
    for (const cell of this.cells.slice().reverse()) {
      if (Array.isArray(cell.stateSize)) {
        stateSize.push(...cell.stateSize);
      } else {
        stateSize.push(cell.stateSize);
      }
    }
    return stateSize;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = inputs;
      let states = inputs.slice(1);
      const nestedStates = [];
      for (const cell of this.cells.slice().reverse()) {
        if (Array.isArray(cell.stateSize)) {
          nestedStates.push(states.splice(0, cell.stateSize.length));
        } else {
          nestedStates.push(states.splice(0, 1));
        }
      }
      nestedStates.reverse();
      const newNestedStates = [];
      let callInputs;
      for (let i = 0; i < this.cells.length; ++i) {
        const cell = this.cells[i];
        states = nestedStates[i];
        if (i === 0) {
          callInputs = [inputs[0]].concat(states);
        } else {
          callInputs = [callInputs[0]].concat(states);
        }
        callInputs = cell.call(callInputs, kwargs);
        newNestedStates.push(callInputs.slice(1));
      }
      states = [];
      for (const cellStates of newNestedStates.slice().reverse()) {
        states.push(...cellStates);
      }
      return [callInputs[0]].concat(states);
    });
  }
  build(inputShape) {
    if (isArrayOfShapes(inputShape)) {
      inputShape = inputShape[0];
    }
    inputShape = inputShape;
    let outputDim;
    this.cells.forEach((cell, i) => {
      nameScope(`RNNCell_${i}`, () => {
        cell.build(inputShape);
        if (Array.isArray(cell.stateSize)) {
          outputDim = cell.stateSize[0];
        } else {
          outputDim = cell.stateSize;
        }
        inputShape = [inputShape[0], outputDim];
      });
    });
    this.built = true;
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const getCellConfig = (cell) => {
      return {
        "className": cell.getClassName(),
        "config": cell.getConfig()
      };
    };
    const cellConfigs = this.cells.map(getCellConfig);
    const config = { "cells": cellConfigs };
    return { ...baseConfig, ...config };
  }
  static fromConfig(cls, config, customObjects = {}) {
    const cells = [];
    for (const cellConfig of config["cells"]) {
      cells.push(deserialize(cellConfig, customObjects));
    }
    return new cls({ cells });
  }
  get trainableWeights() {
    if (!this.trainable) {
      return [];
    }
    const weights = [];
    for (const cell of this.cells) {
      weights.push(...cell.trainableWeights);
    }
    return weights;
  }
  get nonTrainableWeights() {
    const weights = [];
    for (const cell of this.cells) {
      weights.push(...cell.nonTrainableWeights);
    }
    if (!this.trainable) {
      const trainableWeights = [];
      for (const cell of this.cells) {
        trainableWeights.push(...cell.trainableWeights);
      }
      return trainableWeights.concat(weights);
    }
    return weights;
  }
  getWeights() {
    const weights = [];
    for (const cell of this.cells) {
      weights.push(...cell.weights);
    }
    return batchGetValue(weights);
  }
  setWeights(weights) {
    const tuples = [];
    for (const cell of this.cells) {
      const numParams = cell.weights.length;
      const inputWeights = weights.splice(numParams);
      for (let i = 0; i < cell.weights.length; ++i) {
        tuples.push([cell.weights[i], inputWeights[i]]);
      }
    }
    batchSetValue(tuples);
  }
};
StackedRNNCells.className = "StackedRNNCells";
serialization_exports2.registerClass(StackedRNNCells);
function generateDropoutMask(args) {
  const { ones: ones6, rate, training = false, count: count2 = 1 } = args;
  const droppedInputs = () => dropout3(ones6(), rate);
  const createMask = () => inTrainPhase(droppedInputs, ones6, training);
  if (!count2 || count2 <= 1) {
    return keep2(createMask().clone());
  }
  const masks = Array(count2).fill(void 0).map(createMask);
  return masks.map((m) => keep2(m.clone()));
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/convolutional_recurrent.ts
var ConvRNN2D = class extends RNN {
  constructor(args) {
    if (args.unroll) {
      throw new NotImplementedError("Unrolling is not possible with convolutional RNNs.");
    }
    if (Array.isArray(args.cell)) {
      throw new NotImplementedError("It is not possible at the moment to stack convolutional cells.");
    }
    super(args);
    this.inputSpec = [new InputSpec({ ndim: 5 })];
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (this.cell.dropoutMask != null) {
        dispose2(this.cell.dropoutMask);
        this.cell.dropoutMask = null;
      }
      if (this.cell.recurrentDropoutMask != null) {
        dispose2(this.cell.recurrentDropoutMask);
        this.cell.recurrentDropoutMask = null;
      }
      if (kwargs && kwargs["constants"]) {
        throw new ValueError("ConvRNN2D cell does not support constants");
      }
      const mask = kwargs == null ? null : kwargs["mask"];
      const training = kwargs == null ? null : kwargs["training"];
      const initialState = kwargs == null ? null : kwargs["initialState"];
      return super.call(inputs, { mask, training, initialState });
    });
  }
  computeOutputShape(inputShape) {
    let outShape = this.computeSingleOutputShape(inputShape);
    if (!this.returnSequences) {
      outShape = [outShape[0], ...outShape.slice(2)];
    }
    if (this.returnState) {
      outShape = [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];
    }
    return outShape;
  }
  getInitialState(inputs) {
    return tidy2(() => {
      const { stateSize } = this.cell;
      const inputShape = inputs.shape;
      const outputShape = this.computeSingleOutputShape(inputShape);
      const stateShape = [outputShape[0], ...outputShape.slice(2)];
      const initialState = zeros2(stateShape);
      if (Array.isArray(stateSize)) {
        return Array(stateSize.length).fill(initialState);
      }
      return [initialState];
    });
  }
  resetStates(states, training = false) {
    tidy2(() => {
      if (!this.stateful) {
        throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
      }
      const inputShape = this.inputSpec[0].shape;
      const outputShape = this.computeSingleOutputShape(inputShape);
      const stateShape = [outputShape[0], ...outputShape.slice(2)];
      const batchSize = inputShape[0];
      if (batchSize == null) {
        throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      }
      if (this.getStates() == null) {
        if (Array.isArray(this.cell.stateSize)) {
          this.states_ = this.cell.stateSize.map(() => zeros2(stateShape));
        } else {
          this.states_ = [zeros2(stateShape)];
        }
      } else if (states == null) {
        dispose2(this.states_);
        if (this.keptStates != null) {
          dispose2(this.keptStates);
          this.keptStates = [];
        }
        if (Array.isArray(this.cell.stateSize)) {
          this.states_ = this.cell.stateSize.map(() => zeros2(stateShape));
        } else {
          this.states_[0] = zeros2(stateShape);
        }
      } else {
        if (!Array.isArray(states)) {
          states = [states];
        }
        if (states.length !== this.states_.length) {
          throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
        }
        if (training) {
          this.keptStates.push(this.states_.slice());
        } else {
          dispose2(this.states_);
        }
        for (let index = 0; index < this.states_.length; ++index) {
          const value = states[index];
          const expectedShape = stateShape;
          if (!util_exports2.arraysEqual(value.shape, expectedShape)) {
            throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
          }
          this.states_[index] = value;
        }
      }
      this.states_ = this.states_.map((state) => keep2(state.clone()));
    });
  }
  computeSingleOutputShape(inputShape) {
    const { dataFormat, filters, kernelSize, padding, strides, dilationRate } = this.cell;
    const isChannelsFirst = dataFormat === "channelsFirst";
    const h = inputShape[isChannelsFirst ? 3 : 2];
    const w = inputShape[isChannelsFirst ? 4 : 3];
    const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);
    const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);
    const outShape = [
      ...inputShape.slice(0, 2),
      ...isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]
    ];
    return outShape;
  }
};
ConvRNN2D.className = "ConvRNN2D";
var ConvLSTM2DCell = class extends LSTMCell {
  constructor(args) {
    const {
      filters,
      kernelSize,
      strides,
      padding,
      dataFormat,
      dilationRate
    } = args;
    super({ ...args, units: filters });
    this.filters = filters;
    assertPositiveInteger(this.filters, "filters");
    this.kernelSize = normalizeArray(kernelSize, 2, "kernelSize");
    this.kernelSize.forEach((size) => assertPositiveInteger(size, "kernelSize"));
    this.strides = normalizeArray(strides || 1, 2, "strides");
    this.strides.forEach((stride) => assertPositiveInteger(stride, "strides"));
    this.padding = padding || "valid";
    checkPaddingMode(this.padding);
    this.dataFormat = dataFormat || "channelsLast";
    checkDataFormat(this.dataFormat);
    this.dilationRate = normalizeArray(dilationRate || 1, 2, "dilationRate");
    this.dilationRate.forEach((rate) => assertPositiveInteger(rate, "dilationRate"));
  }
  build(inputShape) {
    var _a;
    inputShape = getExactlyOneShape(inputShape);
    const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
    if (inputShape[channelAxis] == null) {
      throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
    }
    const inputDim = inputShape[channelAxis];
    const numOfKernels = 4;
    const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);
    this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);
    this.recurrentKernel = this.addWeight("recurrent_kernel", recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    if (this.useBias) {
      let biasInitializer;
      if (this.unitForgetBias) {
        const init2 = this.biasInitializer;
        const filters = this.filters;
        biasInitializer = new (_a = class extends Initializer {
          apply(shape, dtype) {
            const biasI = init2.apply([filters]);
            const biasF = ones4([filters]);
            const biasCAndO = init2.apply([filters * 2]);
            return concatenate([biasI, biasF, biasCAndO]);
          }
        }, _a.className = "CustomInit", _a)();
      } else {
        biasInitializer = this.biasInitializer;
      }
      this.bias = this.addWeight("bias", [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (inputs.length !== 3) {
        throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
      }
      const training = kwargs["training"] || false;
      const x = inputs[0];
      const hTMinus1 = inputs[1];
      const cTMinus1 = inputs[2];
      const numOfKernels = 4;
      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
        this.dropoutMask = generateDropoutMask({
          ones: () => onesLike2(x),
          rate: this.dropout,
          training,
          count: numOfKernels
        });
      }
      const dropoutMask = this.dropoutMask;
      const applyDropout = (x2, mask, index) => {
        if (!mask || !mask[index]) {
          return x2;
        }
        return mul2(mask[index], x2);
      };
      let xI = applyDropout(x, dropoutMask, 0);
      let xF = applyDropout(x, dropoutMask, 1);
      let xC = applyDropout(x, dropoutMask, 2);
      let xO = applyDropout(x, dropoutMask, 3);
      if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
        this.recurrentDropoutMask = generateDropoutMask({
          ones: () => onesLike2(hTMinus1),
          rate: this.recurrentDropout,
          training,
          count: numOfKernels
        });
      }
      const recDropoutMask = this.recurrentDropoutMask;
      let hI = applyDropout(hTMinus1, recDropoutMask, 0);
      let hF = applyDropout(hTMinus1, recDropoutMask, 1);
      let hC = applyDropout(hTMinus1, recDropoutMask, 2);
      let hO = applyDropout(hTMinus1, recDropoutMask, 3);
      const kernelChannelAxis = 3;
      const [kernelI, kernelF, kernelC, kernelO] = split2(this.kernel.read(), numOfKernels, kernelChannelAxis);
      const [biasI, biasF, biasC, biasO] = this.useBias ? split2(this.bias.read(), numOfKernels) : [null, null, null, null];
      xI = this.inputConv(xI, kernelI, biasI, this.padding);
      xF = this.inputConv(xF, kernelF, biasF, this.padding);
      xC = this.inputConv(xC, kernelC, biasC, this.padding);
      xO = this.inputConv(xO, kernelO, biasO, this.padding);
      const [recKernelI, recKernelF, recKernelC, recKernelO] = split2(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);
      hI = this.recurrentConv(hI, recKernelI);
      hF = this.recurrentConv(hF, recKernelF);
      hC = this.recurrentConv(hC, recKernelC);
      hO = this.recurrentConv(hO, recKernelO);
      const i = this.recurrentActivation.apply(add4(xI, hI));
      const f = this.recurrentActivation.apply(add4(xF, hF));
      const c = add4(mul2(f, cTMinus1), mul2(i, this.activation.apply(add4(xC, hC))));
      const h = mul2(this.recurrentActivation.apply(add4(xO, hO)), this.activation.apply(c));
      return [h, h, c];
    });
  }
  getConfig() {
    const { "units": _, ...baseConfig } = super.getConfig();
    const config = {
      filters: this.filters,
      kernelSize: this.kernelSize,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      strides: this.strides
    };
    return { ...baseConfig, ...config };
  }
  inputConv(x, w, b, padding) {
    const out = conv2d3(x, w, this.strides, padding || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
    if (b) {
      return biasAdd(out, b, this.dataFormat);
    }
    return out;
  }
  recurrentConv(x, w) {
    const strides = 1;
    return conv2d3(x, w, strides, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
  }
};
ConvLSTM2DCell.className = "ConvLSTM2DCell";
serialization_exports2.registerClass(ConvLSTM2DCell);
var ConvLSTM2D = class extends ConvRNN2D {
  constructor(args) {
    const cell = new ConvLSTM2DCell(args);
    super({ ...args, cell });
  }
  static fromConfig(cls, config) {
    return new cls(config);
  }
};
ConvLSTM2D.className = "ConvLSTM2D";
serialization_exports2.registerClass(ConvLSTM2D);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/core.ts
var Dropout = class extends Layer {
  constructor(args) {
    super(args);
    this.rate = Math.max(Math.min(args.rate, 1), 0);
    this.noiseShape = args.noiseShape;
    this.seed = args.seed;
    this.supportsMasking = true;
  }
  getNoiseShape(input2) {
    if (this.noiseShape == null) {
      return this.noiseShape;
    }
    const inputShape = input2.shape;
    const noiseShape = [];
    for (let i = 0; i < this.noiseShape.length; ++i) {
      noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);
    }
    return noiseShape;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      if (0 < this.rate && this.rate < 1) {
        const training = kwargs["training"] == null ? false : kwargs["training"];
        const noiseShape = this.getNoiseShape(input2);
        const output = inTrainPhase(() => dropout3(input2, this.rate, noiseShape, this.seed), () => input2, training);
        return output;
      }
      return inputs;
    });
  }
  getConfig() {
    const config = {
      rate: this.rate,
      noiseShape: this.noiseShape,
      seed: this.seed
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
  dispose() {
    return super.dispose();
  }
};
Dropout.className = "Dropout";
serialization_exports2.registerClass(Dropout);
var SpatialDropout1D = class extends Dropout {
  constructor(args) {
    super(args);
    this.inputSpec = [{ ndim: 3 }];
  }
  getNoiseShape(input2) {
    const inputShape = input2.shape;
    return [inputShape[0], 1, inputShape[2]];
  }
};
SpatialDropout1D.className = "SpatialDropout1D";
serialization_exports2.registerClass(SpatialDropout1D);
var Dense = class extends Layer {
  constructor(args) {
    super(args);
    this.activation = null;
    this.useBias = true;
    this.kernel = null;
    this.bias = null;
    this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
    this.DEFAULT_BIAS_INITIALIZER = "zeros";
    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {
      let batchSize = null;
      if (args.batchSize != null) {
        batchSize = args.batchSize;
      }
      this.batchInputShape = [batchSize, args.inputDim];
    }
    this.units = args.units;
    assertPositiveInteger(this.units, "units");
    this.activation = getActivation(args.activation);
    if (args.useBias != null) {
      this.useBias = args.useBias;
    }
    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
    this.kernelConstraint = getConstraint(args.kernelConstraint);
    this.biasConstraint = getConstraint(args.biasConstraint);
    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
    this.biasRegularizer = getRegularizer(args.biasRegularizer);
    this.activityRegularizer = getRegularizer(args.activityRegularizer);
    this.supportsMasking = true;
    this.inputSpec = [{ minNDim: 2 }];
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const inputLastDim = inputShape[inputShape.length - 1];
    if (this.kernel == null) {
      this.kernel = this.addWeight("kernel", [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
      if (this.useBias) {
        this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
      }
    }
    this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];
    this.built = true;
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const outputShape = inputShape.slice();
    outputShape[outputShape.length - 1] = this.units;
    return outputShape;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
      let output;
      if (fusedActivationName != null) {
        output = dot3(input2, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);
      } else {
        output = dot3(input2, this.kernel.read());
        if (this.bias != null) {
          output = biasAdd(output, this.bias.read());
        }
        if (this.activation != null) {
          output = this.activation.apply(output);
        }
      }
      return output;
    });
  }
  getConfig() {
    const config = {
      units: this.units,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint)
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Dense.className = "Dense";
serialization_exports2.registerClass(Dense);
var Flatten = class extends Layer {
  constructor(args) {
    args = args || {};
    super(args);
    this.inputSpec = [{ minNDim: 3 }];
    this.dataFormat = args.dataFormat;
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    for (const dim of inputShape.slice(1)) {
      if (dim == null) {
        throw new ValueError(`The shape of the input to "Flatten" is not fully defined (got ${inputShape.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
      }
    }
    return [inputShape[0], arrayProd(inputShape, 1)];
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      let input2 = getExactlyOneTensor(inputs);
      if (this.dataFormat === "channelsFirst" && input2.rank > 1) {
        const permutation = [0];
        for (let i = 2; i < input2.rank; ++i) {
          permutation.push(i);
        }
        permutation.push(1);
        input2 = input2.transpose(permutation);
      }
      return batchFlatten(input2);
    });
  }
  getConfig() {
    const config = {};
    if (this.dataFormat != null) {
      config["dataFormat"] = this.dataFormat;
    }
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Flatten.className = "Flatten";
serialization_exports2.registerClass(Flatten);
var Activation5 = class extends Layer {
  constructor(args) {
    super(args);
    this.supportsMasking = true;
    this.activation = getActivation(args.activation);
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      return this.activation.apply(input2);
    });
  }
  getConfig() {
    const config = { activation: serializeActivation(this.activation) };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Activation5.className = "Activation";
serialization_exports2.registerClass(Activation5);
var RepeatVector = class extends Layer {
  constructor(args) {
    super(args);
    this.n = args.n;
    this.inputSpec = [{ ndim: 2 }];
  }
  computeOutputShape(inputShape) {
    return [inputShape[0], this.n, inputShape[1]];
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      return repeat(inputs, this.n);
    });
  }
  getConfig() {
    const config = {
      n: this.n
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
RepeatVector.className = "RepeatVector";
serialization_exports2.registerClass(RepeatVector);
var Reshape3 = class extends Layer {
  constructor(args) {
    super(args);
    this.targetShape = args.targetShape;
    for (let i = 0; i < this.targetShape.length; ++i) {
      if (this.isUnknown(this.targetShape[i])) {
        this.targetShape[i] = null;
      }
    }
  }
  isUnknown(dim) {
    return dim < 0 || dim == null;
  }
  fixUnknownDimension(inputShape, outputShape) {
    const errorMsg = "Total size of new array must be unchanged.";
    const finalShape = outputShape.slice();
    let known = 1;
    let unknown = null;
    for (let i = 0; i < finalShape.length; ++i) {
      const dim = finalShape[i];
      if (this.isUnknown(dim)) {
        if (unknown === null) {
          unknown = i;
        } else {
          throw new ValueError("Can only specifiy one unknown dimension.");
        }
      } else {
        known *= dim;
      }
    }
    const originalSize = arrayProd(inputShape);
    if (unknown !== null) {
      if (known === 0 || originalSize % known !== 0) {
        throw new ValueError(errorMsg);
      }
      finalShape[unknown] = originalSize / known;
    } else if (originalSize !== known) {
      throw new ValueError(errorMsg);
    }
    return finalShape;
  }
  computeOutputShape(inputShape) {
    let anyUnknownDims = false;
    for (let i = 0; i < inputShape.length; ++i) {
      if (this.isUnknown(inputShape[i])) {
        anyUnknownDims = true;
        break;
      }
    }
    if (anyUnknownDims) {
      return inputShape.slice(0, 1).concat(this.targetShape);
    } else {
      return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      const inputShape = input2.shape;
      const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
      return input2.reshape(outputShape);
    });
  }
  getConfig() {
    const config = {
      targetShape: this.targetShape
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Reshape3.className = "Reshape";
serialization_exports2.registerClass(Reshape3);
var Permute = class extends Layer {
  constructor(args) {
    super(args);
    if (args.dims == null) {
      throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    }
    if (!Array.isArray(args.dims)) {
      throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${args.dims} instead.`);
    }
    const expectedSortedIndices = range3(1, args.dims.length + 1);
    if (!util_exports2.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {
      throw new Error("Invalid permutation `dims`: " + JSON.stringify(args.dims) + " `dims` must contain consecutive integers starting from 1.");
    }
    this.dims = args.dims;
    this.dimsIncludingBatch = [0].concat(this.dims);
    this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const outputShape = inputShape.slice();
    this.dims.forEach((dim, i) => {
      outputShape[i + 1] = inputShape[dim];
    });
    return outputShape;
  }
  call(inputs, kwargs) {
    return transpose2(getExactlyOneTensor(inputs), this.dimsIncludingBatch);
  }
  getConfig() {
    const config = {
      dims: this.dims
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Permute.className = "Permute";
serialization_exports2.registerClass(Permute);
var Masking = class extends Layer {
  constructor(args) {
    super(args == null ? {} : args);
    this.supportsMasking = true;
    if (args != null) {
      this.maskValue = args.maskValue == null ? 0 : args.maskValue;
    } else {
      this.maskValue = 0;
    }
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = { maskValue: this.maskValue };
    Object.assign(config, baseConfig);
    return config;
  }
  computeMask(inputs, mask) {
    const input2 = getExactlyOneTensor(inputs);
    const axis = -1;
    return any2(notEqual2(input2, this.maskValue), axis);
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      const axis = -1;
      const keepDims = true;
      const booleanMask = any2(notEqual2(input2, this.maskValue), axis, keepDims);
      const output = input2.mul(booleanMask.asType(input2.dtype));
      return output;
    });
  }
};
Masking.className = "Masking";
serialization_exports2.registerClass(Masking);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/embeddings.ts
var Embedding = class extends Layer {
  constructor(args) {
    super(args);
    this.embeddings = null;
    this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform";
    if (args.batchInputShape == null && args.inputShape == null) {
      let batchSize = null;
      if (args.batchSize != null) {
        batchSize = args.batchSize;
      }
      if (args.inputLength == null) {
        this.batchInputShape = [batchSize, null];
      } else {
        this.batchInputShape = [batchSize].concat(toList(args.inputLength));
      }
    }
    this.inputDim = args.inputDim;
    assertPositiveInteger(this.inputDim, "inputDim");
    this.outputDim = args.outputDim;
    assertPositiveInteger(this.outputDim, "outputDim");
    this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);
    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);
    this.activityRegularizer = getRegularizer(args.activityRegularizer);
    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);
    this.maskZero = args.maskZero;
    this.supportsMasking = args.maskZero;
    this.inputLength = args.inputLength;
  }
  build(inputShape) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);
    this.built = true;
  }
  warnOnIncompatibleInputShape(inputShape) {
  }
  computeMask(inputs, mask) {
    return tidy2(() => {
      if (!this.maskZero) {
        return null;
      } else {
        inputs = getExactlyOneTensor(inputs);
        return notEqual2(inputs, zerosLike2(inputs));
      }
    });
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (this.inputLength == null) {
      return [...inputShape, this.outputDim];
    }
    const inLens = toList(this.inputLength);
    if (inLens.length !== inputShape.length - 1) {
      throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
    } else {
      let i = 0;
      for (let k = 0; k < inLens.length; ++k) {
        const s1 = inLens[k];
        const s2 = inputShape[k + 1];
        if (s1 != null && s2 != null && s1 !== s2) {
          throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
        } else if (s1 == null) {
          inLens[i] = s2;
        }
        i++;
      }
    }
    return [inputShape[0], ...inLens, this.outputDim];
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      let input2 = getExactlyOneTensor(inputs);
      if (input2.dtype !== "int32") {
        input2 = cast3(input2, "int32");
      }
      const output = gather3(this.embeddings.read(), input2.as1D());
      return output.reshape(getExactlyOneShape(this.computeOutputShape(input2.shape)));
    });
  }
  getConfig() {
    const config = {
      inputDim: this.inputDim,
      outputDim: this.outputDim,
      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),
      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),
      maskZero: this.maskZero,
      inputLength: this.inputLength
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Embedding.className = "Embedding";
serialization_exports2.registerClass(Embedding);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/merge.ts
var Merge = class extends Layer {
  constructor(args) {
    super(args || {});
    this.supportsMasking = true;
  }
  mergeFunction(inputs) {
    throw new NotImplementedError();
  }
  computeElementwiseOpOutputShape(shape1, shape2) {
    if (shape1 == null || shape2 == null) {
      return null;
    } else if (shape1.length < shape2.length) {
      return this.computeElementwiseOpOutputShape(shape2, shape1);
    } else if (shape2.length === 0) {
      return shape1;
    }
    const outputShape = shape1.slice(0, shape1.length - shape2.length);
    for (let k = 0; k < shape2.length; ++k) {
      const i = shape1[shape1.length - shape2.length + k];
      const j = shape2[k];
      if (i == null || j == null || i < 0 || j < 0) {
        outputShape.push(null);
      } else if (i === 1) {
        outputShape.push(j);
      } else if (j === 1) {
        outputShape.push(i);
      } else {
        if (i !== j) {
          throw new ValueError("Operands could not be broadcast together with shapes " + JSON.stringify(shape1) + " " + JSON.stringify(shape2));
        }
        outputShape.push(i);
      }
    }
    return outputShape;
  }
  build(inputShape) {
    if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {
      inputShape = [getExactlyOneShape(inputShape)];
    }
    inputShape = inputShape;
    if (inputShape.length < 2) {
      throw new ValueError(`A merge layer should be called on an Array of at least 2 inputs. Got ${inputShape.length} input(s).`);
    }
    let batchSizes = [];
    for (const shape of inputShape) {
      if (shape != null && shape[0] !== null) {
        batchSizes.push(shape[0]);
      }
    }
    batchSizes = unique3(batchSizes);
    if (batchSizes.length > 1) {
      throw new ValueError(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(inputShape)}.`);
    }
    let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);
    for (let i = 1; i < inputShape.length; ++i) {
      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
    }
    const allRanks = inputShape.map((shape) => shape.length);
    if (inputShape.indexOf(null) === -1 && unique3(allRanks).length === 1) {
      this.reshapeRequired = false;
    } else {
      this.reshapeRequired = true;
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = inputs;
      if (this.reshapeRequired) {
        const reshapedInputs = [];
        const inputDims = inputs.map((input2) => input2.rank);
        if (inputDims.indexOf(null) === -1) {
          const maxNDim = max3(inputDims);
          for (let x of inputs) {
            const xNDim = x.rank;
            for (let k = 0; k < maxNDim - xNDim; ++k) {
              x = expandDims3(x, 1);
            }
            reshapedInputs.push(x);
          }
          return this.mergeFunction(reshapedInputs);
        } else {
          let transposed = false;
          for (const x of inputs) {
            const xNDim = x.rank;
            if (xNDim == null) {
              const xShape = x.shape;
              const batchSize = xShape[0];
              const newShape = xShape.slice(1).concat([batchSize]);
              let xTransposed = x.reshape([batchSize].concat(arrayProd(xShape.slice(1))));
              xTransposed = transpose2(xTransposed, [1, 0]);
              xTransposed = xTransposed.reshape(newShape);
              reshapedInputs.push(xTransposed);
              transposed = true;
            } else if (xNDim > 1) {
              const dims = range3(1, xNDim).concat([0]);
              reshapedInputs.push(transpose2(x, dims));
              transposed = true;
            } else {
              reshapedInputs.push(x);
            }
          }
          let y = this.mergeFunction(reshapedInputs);
          const yNDim = y.rank;
          if (transposed) {
            if (yNDim == null) {
              const yShape = y.shape;
              const yNDim2 = yShape.length;
              const batchSize = yShape[yNDim2 - 1];
              const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));
              y = transpose2(y.reshape([-1, batchSize]), [1, 0]).reshape(newShape);
            } else if (yNDim > 1) {
              const dims = [yNDim - 1].concat(range3(0, yNDim - 1));
              y = transpose2(y, dims);
            }
          }
          return y;
        }
      } else {
        return this.mergeFunction(inputs);
      }
    });
  }
  computeOutputShape(inputShape) {
    inputShape = inputShape;
    let outputShape;
    if (inputShape[0] == null) {
      outputShape = null;
    } else {
      outputShape = inputShape[0].slice(1);
    }
    for (let i = 1; i < inputShape.length; ++i) {
      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
    }
    let batchSizes = [];
    for (const shape of inputShape) {
      if (shape != null && shape[0] !== null) {
        batchSizes.push(shape[0]);
      }
    }
    batchSizes = unique3(batchSizes);
    if (batchSizes.length === 1) {
      outputShape = batchSizes.concat(outputShape);
    } else {
      outputShape = [null].concat(outputShape);
    }
    return outputShape;
  }
  computeMask(inputs, mask) {
    return tidy2(() => {
      if (mask == null) {
        return null;
      }
      if (!Array.isArray(mask)) {
        throw new ValueError("`mask` should be an Array");
      }
      if (!Array.isArray(inputs)) {
        throw new ValueError("`inputs` should be an Array");
      }
      if (mask.length !== inputs.length) {
        throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${inputs.length} vs ${mask.length})`);
      }
      if (mask.every((m) => m == null)) {
        return null;
      }
      mask = mask.map((m) => m == null ? m : expandDims2(m, 0));
      let output = mask[0];
      for (let i = 1; i < mask.length - 1; ++i) {
        output = logicalAnd2(output, mask[i]);
      }
      return output;
    });
  }
};
var Add3 = class extends Merge {
  constructor(args) {
    super(args);
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      let output = inputs[0].clone();
      for (let i = 1; i < inputs.length; ++i) {
        output = add4(output, inputs[i]);
      }
      return output;
    });
  }
};
Add3.className = "Add";
serialization_exports2.registerClass(Add3);
var Multiply3 = class extends Merge {
  constructor(args) {
    super(args);
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      let output = inputs[0].clone();
      for (let i = 1; i < inputs.length; ++i) {
        output = mul2(output, inputs[i]);
      }
      return output;
    });
  }
};
Multiply3.className = "Multiply";
serialization_exports2.registerClass(Multiply3);
var Average = class extends Merge {
  constructor(args) {
    super(args);
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      let output = inputs[0].clone();
      for (let i = 1; i < inputs.length; ++i) {
        output = add4(output, inputs[i]);
      }
      return mul2(1 / inputs.length, output);
    });
  }
};
Average.className = "Average";
serialization_exports2.registerClass(Average);
var Maximum3 = class extends Merge {
  constructor(args) {
    super(args);
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      let output = inputs[0];
      for (let i = 1; i < inputs.length; ++i) {
        output = maximum2(output, inputs[i]);
      }
      return output;
    });
  }
};
Maximum3.className = "Maximum";
serialization_exports2.registerClass(Maximum3);
var Minimum3 = class extends Merge {
  constructor(args) {
    super(args);
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      let output = inputs[0];
      for (let i = 1; i < inputs.length; ++i) {
        output = minimum2(output, inputs[i]);
      }
      return output;
    });
  }
};
Minimum3.className = "Minimum";
serialization_exports2.registerClass(Minimum3);
var Concatenate = class extends Merge {
  constructor(args) {
    super(args);
    this.DEFAULT_AXIS = -1;
    if (args == null) {
      args = {};
    }
    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
    this.supportsMasking = true;
    this.reshapeRequired = false;
  }
  build(inputShape) {
    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {
      throw new ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");
    }
    inputShape = inputShape;
    let allNoneShape = true;
    for (const shape of inputShape) {
      if (shape != null) {
        allNoneShape = false;
        break;
      }
    }
    if (allNoneShape) {
      return;
    }
    const shapeSet = [];
    for (let i = 0; i < inputShape.length; ++i) {
      const shapeWithoutConcatAxis = inputShape[i].slice();
      shapeWithoutConcatAxis.splice(this.axis, 1);
      let exists = false;
      for (const shape of shapeSet) {
        if (util_exports2.arraysEqual(shape, shapeWithoutConcatAxis)) {
          exists = true;
          break;
        }
      }
      if (!exists) {
        shapeSet.push(shapeWithoutConcatAxis);
      }
    }
    if (shapeSet.length > 1) {
      throw new ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(inputShape));
    }
  }
  mergeFunction(inputs) {
    return tidy2(() => {
      return concatenate(inputs, this.axis);
    });
  }
  computeOutputShape(inputShape) {
    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {
      throw new ValueError("A `Concatenate` layer should be called on a list of inputs.");
    }
    const inputShapes = inputShape;
    const outputShape = inputShapes[0].slice();
    const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;
    for (const shape of inputShapes.slice(1)) {
      if (outputShape[axis] == null || shape[axis] == null) {
        outputShape[axis] = null;
        break;
      }
      outputShape[axis] += shape[axis];
    }
    return outputShape;
  }
  computeMask(inputs, mask) {
    if (mask == null) {
      return null;
    }
    if (!Array.isArray(mask)) {
      throw new ValueError("`mask` should be an array for Concatenate");
    }
    if (!Array.isArray(inputs)) {
      throw new ValueError("`inputs` should be an array for Concatenate");
    }
    if (mask.length !== inputs.length) {
      throw new ValueError(`Mismatch in the length of mask (${mask.length}) and the legnth of inputs (${inputs.length})`);
    }
    return tidy2(() => {
      let allNullMasks = true;
      mask.forEach((m) => {
        if (m != null) {
          allNullMasks = false;
          return;
        }
      });
      if (allNullMasks) {
        return null;
      }
      const outputMasks = [];
      for (let i = 0; i < inputs.length; ++i) {
        if (mask[i] == null) {
          outputMasks.push(onesLike2(inputs[i]).asType("bool"));
        } else if (mask[i].rank < inputs[i].rank) {
          outputMasks.push(expandDims2(mask[i], -1));
        } else {
          outputMasks.push(mask[i]);
        }
      }
      const concatenatedMasks = concat2(outputMasks, this.axis);
      return all2(concatenatedMasks, -1, false);
    });
  }
  getConfig() {
    const config = {
      "axis": this.axis
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Concatenate.className = "Concatenate";
serialization_exports2.registerClass(Concatenate);
function interpretAxis(axis, dim) {
  while (axis < 0) {
    axis += dim;
  }
  return axis;
}
function batchDot(x, y, axes) {
  if (x.shape.length > 3 || y.shape.length > 3) {
    throw new NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");
  }
  util_exports2.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${x.shape.length}`);
  util_exports2.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${y.shape.length}`);
  if (typeof axes === "number") {
    axes = [axes, axes];
  }
  if (x.dtype === "complex64" || y.dtype === "complex64") {
    throw new NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");
  }
  const xNDim = x.shape.length;
  const yNDim = y.shape.length;
  if (axes == null) {
    axes = [xNDim - 1, yNDim - 2];
  }
  const axesArray = axes;
  return tidy2(() => {
    let diff;
    if (xNDim > yNDim) {
      diff = xNDim - yNDim;
      const diffShape = [];
      for (let i = 0; i < diff; ++i) {
        diffShape.push(1);
      }
      y = y.reshape(y.shape.concat(diffShape));
    } else if (yNDim > xNDim) {
      diff = yNDim - xNDim;
      const diffShape = [];
      for (let i = 0; i < diff; ++i) {
        diffShape.push(1);
      }
      x = x.reshape(x.shape.concat(diffShape));
    } else {
      diff = 0;
    }
    let out;
    if (x.shape.length === 2 && y.shape.length === 2) {
      if (axesArray[0] === axesArray[1]) {
        out = x.mul(y).sum(axesArray[0]);
      } else {
        out = x.transpose([1, 0]).mul(y).sum(axesArray[1]);
      }
    } else {
      const adjX = axesArray[0] !== x.shape.length - 1;
      const adjY = axesArray[1] === y.shape.length - 1;
      out = x.matMul(y, adjX, adjY);
    }
    if (diff > 0) {
      let idx;
      if (xNDim > yNDim) {
        idx = xNDim + yNDim - 3;
      } else {
        idx = xNDim - 1;
      }
      const squeezeAxes = [];
      for (let i = idx; i < idx + diff; ++i) {
        squeezeAxes.push(i);
      }
      out = out.squeeze(squeezeAxes);
    }
    if (out.shape.length === 1) {
      out = out.expandDims(1);
    }
    return out;
  });
}
var Dot = class extends Merge {
  constructor(args) {
    super(args);
    this.axes = args.axes;
    this.normalize = args.normalize == null ? false : args.normalize;
    this.supportsMasking = true;
    this.reshapeRequired = false;
  }
  build(inputShape) {
    util_exports2.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const shape1 = inputShape[0];
    const shape2 = inputShape[1];
    if (shape1.length > 3 || shape2.length > 3) {
      throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
    }
    const axes = this.interpretAxes(shape1, shape2);
    if (shape1[axes[0]] !== shape2[axes[1]]) {
      throw new ValueError(`Dimension incompatibility: ${shape1[axes[0]]} !== ${shape2[axes[1]]}`);
    }
  }
  mergeFunction(inputs) {
    if (inputs.length !== 2) {
      throw new ValueError(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${inputs.length} input(s).`);
    }
    let x1 = inputs[0];
    let x2 = inputs[1];
    let axes;
    if (!Array.isArray(this.axes)) {
      axes = [
        interpretAxis(this.axes, x1.shape.length),
        interpretAxis(this.axes, x2.shape.length)
      ];
    } else {
      axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));
    }
    if (this.normalize) {
      x1 = l2Normalize(x1, axes[0]);
      x2 = l2Normalize(x2, axes[1]);
    }
    return batchDot(x1, x2, axes);
  }
  interpretAxes(shape1, shape2) {
    let axes;
    if (!Array.isArray(this.axes)) {
      axes = [
        interpretAxis(this.axes, shape1.length),
        interpretAxis(this.axes, shape2.length)
      ];
    } else {
      axes = this.axes;
    }
    return axes;
  }
  computeOutputShape(inputShape) {
    util_exports2.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const shape1 = inputShape[0].slice();
    const shape2 = inputShape[1].slice();
    if (shape1.length > 3 || shape2.length > 3) {
      throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
    }
    const axes = this.interpretAxes(shape1, shape2);
    shape1.splice(axes[0], 1);
    shape2.splice(axes[1], 1);
    shape2.splice(0, 1);
    const outputShape = shape1.concat(shape2);
    if (outputShape.length === 1) {
      outputShape.push(1);
    }
    return outputShape;
  }
  computeMask(inputs, mask) {
    return null;
  }
  getConfig() {
    const config = {
      "axes": this.axes,
      "normalize": this.normalize
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
Dot.className = "Dot";
serialization_exports2.registerClass(Dot);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/noise.ts
var GaussianNoise = class extends Layer {
  constructor(args) {
    super(args);
    this.supportsMasking = true;
    this.stddev = args.stddev;
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = { stddev: this.stddev };
    Object.assign(config, baseConfig);
    return config;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      const noised = () => randomNormal3(input2.shape, 0, this.stddev).add(input2);
      const output = inTrainPhase(noised, () => input2, kwargs["training"] || false);
      return output;
    });
  }
};
GaussianNoise.className = "GaussianNoise";
serialization_exports2.registerClass(GaussianNoise);
var GaussianDropout = class extends Layer {
  constructor(args) {
    super(args);
    this.supportsMasking = true;
    this.rate = args.rate;
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = { rate: this.rate };
    Object.assign(config, baseConfig);
    return config;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      const input2 = getExactlyOneTensor(inputs);
      if (this.rate > 0 && this.rate < 1) {
        const noised = () => {
          const stddev = Math.sqrt(this.rate / (1 - this.rate));
          return input2.mul(randomNormal3(input2.shape, 1, stddev));
        };
        return inTrainPhase(noised, () => input2, kwargs["training"] || false);
      }
      return input2;
    });
  }
};
GaussianDropout.className = "GaussianDropout";
serialization_exports2.registerClass(GaussianDropout);
var AlphaDropout = class extends Layer {
  constructor(args) {
    super(args);
    this.supportsMasking = true;
    this.rate = args.rate;
    this.noiseShape = args.noiseShape;
  }
  _getNoiseShape(inputs) {
    return this.noiseShape || getExactlyOneTensor(inputs).shape;
  }
  computeOutputShape(inputShape) {
    return inputShape;
  }
  getConfig() {
    const baseConfig = super.getConfig();
    const config = { rate: this.rate };
    Object.assign(config, baseConfig);
    return config;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      if (this.rate < 1 && this.rate > 0) {
        const noiseShape = this._getNoiseShape(inputs);
        const droppedInputs = () => {
          const input2 = getExactlyOneTensor(inputs);
          const alpha = 1.6732632423543772;
          const scale2 = 1.0507009873554805;
          const alphaP = -alpha * scale2;
          let keptIdx = greaterEqual2(randomUniform2(noiseShape), this.rate);
          keptIdx = cast3(keptIdx, "float32");
          const a = ((1 - this.rate) * (1 + this.rate * alphaP ** 2)) ** -0.5;
          const b = -a * alphaP * this.rate;
          const x = input2.mul(keptIdx).add(keptIdx.add(-1).mul(alphaP));
          return x.mul(a).add(b);
        };
        return inTrainPhase(droppedInputs, () => getExactlyOneTensor(inputs), kwargs["training"] || false);
      }
      return inputs;
    });
  }
};
AlphaDropout.className = "AlphaDropout";
serialization_exports2.registerClass(AlphaDropout);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/normalization.ts
function batchNormalization(x, mean5, variance, beta, gamma, epsilon3 = 1e-3) {
  let out;
  if (x.rank === 2) {
    out = batchNorm2d2(x, mean5, variance, beta, gamma, epsilon3);
  } else if (x.rank === 3) {
    out = batchNorm3d2(x, mean5, variance, beta, gamma, epsilon3);
  } else if (x.rank === 4) {
    out = batchNorm4d2(x, mean5, variance, beta, gamma, epsilon3);
  } else {
    throw new NotImplementedError(`batchNormalization is not implemented for array of rank ${x.rank} yet`);
  }
  return out;
}
function regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  return tidy2(() => {
    const meanAndVariance = moments2(x, reductionAxes);
    const mean5 = meanAndVariance.mean;
    const variance = meanAndVariance.variance;
    const normed = batchNormalization(x, mean5, variance, beta, gamma, epsilon3);
    return [normed, mean5, variance];
  });
}
function broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  return tidy2(() => {
    const meanAndVariance = moments2(x, reductionAxes);
    const mean5 = meanAndVariance.mean;
    const variance = meanAndVariance.variance;
    const targetShape = [];
    for (const axis of range3(0, x.rank)) {
      if (reductionAxes.indexOf(axis) !== -1) {
        targetShape.push(1);
      } else {
        targetShape.push(x.shape[axis]);
      }
    }
    const broadcastMean = mean5.reshape(targetShape);
    const broadcastVariance = variance.reshape(targetShape);
    const broadcastGamma = gamma == null ? null : gamma.reshape(targetShape);
    const broadcastBeta = beta == null ? null : beta.reshape(targetShape);
    const normed = batchNormalization(x, broadcastMean, broadcastVariance, broadcastBeta, broadcastGamma, epsilon3);
    return [normed, mean5, variance];
  });
}
function normalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  if (util_exports2.arraysEqual(reductionAxes.slice().sort(), range3(0, x.rank - 1))) {
    return regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
  } else {
    return broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
  }
}
var BatchNormalization = class extends Layer {
  constructor(args) {
    if (args == null) {
      args = {};
    }
    super(args);
    this.supportsMasking = true;
    this.axis = args.axis == null ? -1 : args.axis;
    this.momentum = args.momentum == null ? 0.99 : args.momentum;
    this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
    this.center = args.center == null ? true : args.center;
    this.scale = args.scale == null ? true : args.scale;
    this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
    this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
    this.movingMeanInitializer = getInitializer(args.movingMeanInitializer || "zeros");
    this.movingVarianceInitializer = getInitializer(args.movingVarianceInitializer || "ones");
    this.betaConstraint = getConstraint(args.betaConstraint);
    this.gammaConstraint = getConstraint(args.gammaConstraint);
    this.betaRegularizer = getRegularizer(args.betaRegularizer);
    this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const axis = this.axis >= 0 ? this.axis : this.axis + inputShape.length;
    const dim = inputShape[axis];
    if (dim == null) {
      throw new ValueError(`Axis ${axis} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(inputShape)}.`);
    }
    this.inputSpec = [new InputSpec({ ndim: inputShape.length, axes: { [axis]: dim } })];
    const shape = [dim];
    if (this.scale) {
      this.gamma = this.addWeight("gamma", shape, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint);
    }
    if (this.center) {
      this.beta = this.addWeight("beta", shape, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint);
    }
    this.movingMean = this.addWeight("moving_mean", shape, null, this.movingMeanInitializer, null, false);
    this.movingVariance = this.addWeight("moving_variance", shape, null, this.movingVarianceInitializer, null, false);
    this.built = true;
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const training = kwargs["training"] == null ? false : kwargs["training"];
      const input2 = getExactlyOneTensor(inputs);
      const inputShape = input2.shape;
      const ndim = inputShape.length;
      const reductionAxes = range3(0, ndim);
      const axis = this.axis >= 0 ? this.axis : this.axis + ndim;
      reductionAxes.splice(axis, 1);
      const broadcastShape = pyListRepeat(1, ndim);
      broadcastShape[axis] = inputShape[axis];
      const sortedReductionAxes = reductionAxes.slice();
      sortedReductionAxes.sort();
      const needsBroadcasting = !util_exports2.arraysEqual(sortedReductionAxes, range3(0, ndim).slice(0, ndim - 1));
      const normalizeInference = () => {
        if (needsBroadcasting) {
          const broadcastMovingMean = this.movingMean.read().reshape(broadcastShape);
          const broadcastMovingVariance = this.movingVariance.read().reshape(broadcastShape);
          const broadcastBeta = this.center ? this.beta.read().reshape(broadcastShape) : null;
          const broadcastGamma = this.scale ? this.gamma.read().reshape(broadcastShape) : null;
          return batchNormalization(input2, broadcastMovingMean, broadcastMovingVariance, broadcastBeta, broadcastGamma, this.epsilon);
        } else {
          return batchNormalization(input2, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
        }
      };
      if (!training) {
        return normalizeInference();
      }
      const [normedTraining, mean5, variance] = normalizeBatchInTraining(input2, this.gamma.read(), this.beta.read(), reductionAxes, this.epsilon);
      const doMovingAverage = (variable3, value, momentum) => {
        tidy2(() => {
          const decay = 1 - momentum;
          const origValue = variable3.read();
          const updateDelta = origValue.sub(value).mul(decay);
          variable3.write(origValue.sub(updateDelta));
        });
      };
      const updateMovingMeanAndVariance = () => {
        doMovingAverage(this.movingMean, mean5, this.momentum);
        doMovingAverage(this.movingVariance, variance, this.momentum);
      };
      updateMovingMeanAndVariance();
      return normedTraining;
    });
  }
  getConfig() {
    const config = {
      axis: this.axis,
      momentum: this.momentum,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer(this.betaInitializer),
      gammaInitializer: serializeInitializer(this.gammaInitializer),
      movingMeanInitializer: serializeInitializer(this.movingMeanInitializer),
      movingVarianceInitializer: serializeInitializer(this.movingVarianceInitializer),
      betaRegularizer: serializeRegularizer(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer(this.gammaRegularizer),
      betaConstraint: serializeConstraint(this.betaConstraint),
      gammaConstraint: serializeConstraint(this.gammaConstraint)
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
BatchNormalization.className = "BatchNormalization";
serialization_exports2.registerClass(BatchNormalization);
var LayerNormalization = class extends Layer {
  constructor(args) {
    if (args == null) {
      args = {};
    }
    super(args);
    this.axis = args.axis == null ? -1 : args.axis;
    if (typeof this.axis === "number") {
      if (!Number.isInteger(this.axis)) {
        throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
      }
    } else if (Array.isArray(this.axis)) {
      for (const axis of this.axis) {
        if (!Number.isInteger(axis)) {
          throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
        }
      }
    } else {
      throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
    }
    this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
    this.center = args.center == null ? true : args.center;
    this.scale = args.scale == null ? true : args.scale;
    this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
    this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
    this.betaRegularizer = getRegularizer(args.betaRegularizer);
    this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
    this.supportsMasking = true;
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const nDims = inputShape.length;
    if (typeof this.axis === "number") {
      this.axis = [this.axis];
    }
    for (let i = 0; i < this.axis.length; ++i) {
      if (this.axis[i] < 0) {
        this.axis[i] += nDims;
      }
    }
    for (const axis of this.axis) {
      if (axis < 0 || axis >= nDims) {
        throw new Error(`Invalid axis: ${axis}`);
      }
    }
    if (this.axis.length !== unique3(this.axis).length) {
      throw new Error(`Found duplicate axes in: ${this.axis}`);
    }
    const paramShape = this.axis.map((axis) => inputShape[axis]);
    const trainable = true;
    if (this.scale) {
      this.gamma = this.addWeight("gamma", paramShape, "float32", this.gammaInitializer, this.gammaRegularizer, trainable);
    } else {
      this.gamma = null;
    }
    if (this.center) {
      this.beta = this.addWeight("beta", paramShape, "float32", this.betaInitializer, this.betaRegularizer, trainable);
    } else {
      this.beta = null;
    }
    this.built = true;
  }
  call(inputs, kwargs) {
    const input2 = getExactlyOneTensor(inputs);
    const inputShape = input2.shape;
    const nDims = inputShape.length;
    return tidy2(() => {
      const keepDims = true;
      let { mean: mean5, variance } = moments2(input2, this.axis, keepDims);
      const broadcastShape = pyListRepeat(1, nDims);
      for (const dim of this.axis) {
        broadcastShape[dim] = inputShape[dim];
      }
      const broadcast = (v) => {
        if (v != null && v.shape.length !== nDims && this.axis !== [nDims - 1]) {
          return v.reshape(broadcastShape);
        } else {
          return v;
        }
      };
      let scale2 = broadcast(this.gamma.read());
      let offset = broadcast(this.beta.read());
      const momentsTiling = [];
      const scaleOffsetTiling = [];
      for (let i = 0; i < nDims; ++i) {
        if (this.axis.indexOf(i) !== -1) {
          momentsTiling.push(inputShape[i]);
          scaleOffsetTiling.push(1);
        } else {
          momentsTiling.push(1);
          scaleOffsetTiling.push(inputShape[i]);
        }
      }
      mean5 = mean5.tile(momentsTiling);
      variance = variance.tile(momentsTiling);
      scale2 = scale2.tile(scaleOffsetTiling);
      offset = offset.tile(scaleOffsetTiling);
      return batchNormalization(input2, mean5, variance, offset, scale2, this.epsilon);
    });
  }
  getConfig() {
    const config = {
      axis: this.axis,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer(this.betaInitializer),
      gammaInitializer: serializeInitializer(this.gammaInitializer),
      betaRegularizer: serializeRegularizer(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer(this.gammaRegularizer)
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
LayerNormalization.className = "LayerNormalization";
serialization_exports2.registerClass(LayerNormalization);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/padding.ts
function spatial2dPadding(x, padding, dataFormat) {
  return tidy2(() => {
    if (x.rank !== 4) {
      throw new ValueError(`temporalPadding expects input tensor to be 4-D, but received a ${x.rank}-D tensor.`);
    }
    if (padding == null) {
      padding = [[1, 1], [1, 1]];
    }
    if (padding.length !== 2 || padding[0].length !== 2 || padding[1].length !== 2) {
      throw new ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (dataFormat !== "channelsLast" && dataFormat !== "channelsFirst") {
      throw new ValueError(`Unknown data format: ${dataFormat}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
    }
    let pattern;
    if (dataFormat === "channelsFirst") {
      pattern = [[0, 0], [0, 0], padding[0], padding[1]];
    } else {
      pattern = [[0, 0], padding[0], padding[1], [0, 0]];
    }
    return pad2(x, pattern);
  });
}
var ZeroPadding2D = class extends Layer {
  constructor(args) {
    if (args == null) {
      args = {};
    }
    super(args);
    this.dataFormat = args.dataFormat == null ? imageDataFormat() : args.dataFormat;
    if (args.padding == null) {
      this.padding = [[1, 1], [1, 1]];
    } else if (typeof args.padding === "number") {
      this.padding = [[args.padding, args.padding], [args.padding, args.padding]];
    } else {
      args.padding = args.padding;
      if (args.padding.length !== 2) {
        throw new ValueError(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${args.padding.length} array.`);
      }
      let heightPadding;
      let widthPadding;
      if (typeof args.padding[0] === "number") {
        heightPadding = [args.padding[0], args.padding[0]];
        widthPadding = [args.padding[1], args.padding[1]];
      } else {
        args.padding = args.padding;
        if (args.padding[0].length !== 2) {
          throw new ValueError(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${args.padding[0].length} array.`);
        }
        heightPadding = args.padding[0];
        if (args.padding[1].length !== 2) {
          throw new ValueError(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${args.padding[1].length} array.`);
        }
        widthPadding = args.padding[1];
      }
      this.padding = [heightPadding, widthPadding];
    }
    this.inputSpec = [new InputSpec({ ndim: 4 })];
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    let rows;
    let cols;
    if (this.dataFormat === "channelsFirst") {
      if (inputShape[2] != null && inputShape[2] >= 0) {
        rows = inputShape[2] + this.padding[0][0] + this.padding[0][1];
      } else {
        rows = null;
      }
      if (inputShape[3] != null && inputShape[3] >= 0) {
        cols = inputShape[3] + this.padding[1][0] + this.padding[1][1];
      } else {
        cols = null;
      }
      return [inputShape[0], inputShape[1], rows, cols];
    } else {
      if (inputShape[1] != null && inputShape[1] >= 0) {
        rows = inputShape[1] + this.padding[0][0] + this.padding[0][1];
      } else {
        rows = null;
      }
      if (inputShape[2] != null && inputShape[2] >= 0) {
        cols = inputShape[2] + this.padding[1][0] + this.padding[1][1];
      } else {
        cols = null;
      }
      return [inputShape[0], rows, cols, inputShape[3]];
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => spatial2dPadding(getExactlyOneTensor(inputs), this.padding, this.dataFormat));
  }
  getConfig() {
    const config = {
      padding: this.padding,
      dataFormat: this.dataFormat
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
ZeroPadding2D.className = "ZeroPadding2D";
serialization_exports2.registerClass(ZeroPadding2D);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/pooling.ts
function pool2d(x, poolSize, strides, padding, dataFormat, poolMode) {
  return tidy2(() => {
    checkDataFormat(dataFormat);
    checkPoolMode(poolMode);
    checkPaddingMode(padding);
    if (strides == null) {
      strides = [1, 1];
    }
    if (padding == null) {
      padding = "valid";
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (poolMode == null) {
      poolMode = "max";
    }
    x = preprocessConv2DInput(x, dataFormat);
    let y;
    const paddingString = padding === "same" ? "same" : "valid";
    if (poolMode === "max") {
      y = maxPool2(x, poolSize, strides, paddingString);
    } else {
      y = avgPool2(x, poolSize, strides, paddingString);
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
function pool3d(x, poolSize, strides, padding, dataFormat, poolMode) {
  return tidy2(() => {
    checkDataFormat(dataFormat);
    checkPoolMode(poolMode);
    checkPaddingMode(padding);
    if (strides == null) {
      strides = [1, 1, 1];
    }
    if (padding == null) {
      padding = "valid";
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (poolMode == null) {
      poolMode = "max";
    }
    x = preprocessConv3DInput(x, dataFormat);
    let y;
    const paddingString = padding === "same" ? "same" : "valid";
    if (poolMode === "max") {
      y = maxPool3d2(x, poolSize, strides, paddingString);
    } else {
      y = avgPool3d2(x, poolSize, strides, paddingString);
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 4, 1, 2, 3]);
    }
    return y;
  });
}
var Pooling1D = class extends Layer {
  constructor(args) {
    if (args.poolSize == null) {
      args.poolSize = 2;
    }
    super(args);
    if (typeof args.poolSize === "number") {
      this.poolSize = [args.poolSize];
    } else if (Array.isArray(args.poolSize) && args.poolSize.length === 1 && typeof args.poolSize[0] === "number") {
      this.poolSize = args.poolSize;
    } else {
      throw new ValueError(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.poolSize)}`);
    }
    assertPositiveInteger(this.poolSize, "poolSize");
    if (args.strides == null) {
      this.strides = this.poolSize;
    } else {
      if (typeof args.strides === "number") {
        this.strides = [args.strides];
      } else if (Array.isArray(args.strides) && args.strides.length === 1 && typeof args.strides[0] === "number") {
        this.strides = args.strides;
      } else {
        throw new ValueError(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.strides)}`);
      }
    }
    assertPositiveInteger(this.strides, "strides");
    this.padding = args.padding == null ? "valid" : args.padding;
    checkPaddingMode(this.padding);
    this.inputSpec = [new InputSpec({ ndim: 3 })];
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const length = convOutputLength(inputShape[1], this.poolSize[0], this.padding, this.strides[0]);
    return [inputShape[0], length, inputShape[2]];
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      inputs = expandDims3(getExactlyOneTensor(inputs), 2);
      const output = this.poolingFunction(getExactlyOneTensor(inputs), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return squeeze2(output, [2]);
    });
  }
  getConfig() {
    const config = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
var MaxPooling1D = class extends Pooling1D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
  }
};
MaxPooling1D.className = "MaxPooling1D";
serialization_exports2.registerClass(MaxPooling1D);
var AveragePooling1D = class extends Pooling1D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
  }
};
AveragePooling1D.className = "AveragePooling1D";
serialization_exports2.registerClass(AveragePooling1D);
var Pooling2D = class extends Layer {
  constructor(args) {
    if (args.poolSize == null) {
      args.poolSize = [2, 2];
    }
    super(args);
    this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize];
    if (args.strides == null) {
      this.strides = this.poolSize;
    } else if (Array.isArray(args.strides)) {
      if (args.strides.length !== 2) {
        throw new ValueError(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${args.strides.length}.`);
      }
      this.strides = args.strides;
    } else {
      this.strides = [args.strides, args.strides];
    }
    assertPositiveInteger(this.poolSize, "poolSize");
    assertPositiveInteger(this.strides, "strides");
    this.padding = args.padding == null ? "valid" : args.padding;
    this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
    checkDataFormat(this.dataFormat);
    checkPaddingMode(this.padding);
    this.inputSpec = [new InputSpec({ ndim: 4 })];
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    let rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
    let cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
    rows = convOutputLength(rows, this.poolSize[0], this.padding, this.strides[0]);
    cols = convOutputLength(cols, this.poolSize[1], this.padding, this.strides[1]);
    if (this.dataFormat === "channelsFirst") {
      return [inputShape[0], inputShape[1], rows, cols];
    } else {
      return [inputShape[0], rows, cols, inputShape[3]];
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
    });
  }
  getConfig() {
    const config = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
var MaxPooling2D = class extends Pooling2D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
  }
};
MaxPooling2D.className = "MaxPooling2D";
serialization_exports2.registerClass(MaxPooling2D);
var AveragePooling2D = class extends Pooling2D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
  }
};
AveragePooling2D.className = "AveragePooling2D";
serialization_exports2.registerClass(AveragePooling2D);
var Pooling3D = class extends Layer {
  constructor(args) {
    if (args.poolSize == null) {
      args.poolSize = [2, 2, 2];
    }
    super(args);
    this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize, args.poolSize];
    if (args.strides == null) {
      this.strides = this.poolSize;
    } else if (Array.isArray(args.strides)) {
      if (args.strides.length !== 3) {
        throw new ValueError(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${args.strides.length}.`);
      }
      this.strides = args.strides;
    } else {
      this.strides = [args.strides, args.strides, args.strides];
    }
    assertPositiveInteger(this.poolSize, "poolSize");
    assertPositiveInteger(this.strides, "strides");
    this.padding = args.padding == null ? "valid" : args.padding;
    this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
    checkDataFormat(this.dataFormat);
    checkPaddingMode(this.padding);
    this.inputSpec = [new InputSpec({ ndim: 5 })];
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    let depths = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
    let rows = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
    let cols = this.dataFormat === "channelsFirst" ? inputShape[4] : inputShape[3];
    depths = convOutputLength(depths, this.poolSize[0], this.padding, this.strides[0]);
    rows = convOutputLength(rows, this.poolSize[1], this.padding, this.strides[1]);
    cols = convOutputLength(cols, this.poolSize[2], this.padding, this.strides[2]);
    if (this.dataFormat === "channelsFirst") {
      return [inputShape[0], inputShape[1], depths, rows, cols];
    } else {
      return [inputShape[0], depths, rows, cols, inputShape[4]];
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      this.invokeCallHook(inputs, kwargs);
      return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
    });
  }
  getConfig() {
    const config = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
var MaxPooling3D = class extends Pooling3D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool3d(inputs, poolSize, strides, padding, dataFormat, "max");
  }
};
MaxPooling3D.className = "MaxPooling3D";
serialization_exports2.registerClass(MaxPooling3D);
var AveragePooling3D = class extends Pooling3D {
  constructor(args) {
    super(args);
  }
  poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
    checkDataFormat(dataFormat);
    checkPaddingMode(padding);
    return pool3d(inputs, poolSize, strides, padding, dataFormat, "avg");
  }
};
AveragePooling3D.className = "AveragePooling3D";
serialization_exports2.registerClass(AveragePooling3D);
var GlobalPooling1D = class extends Layer {
  constructor(args) {
    super(args);
    this.inputSpec = [new InputSpec({ ndim: 3 })];
  }
  computeOutputShape(inputShape) {
    return [inputShape[0], inputShape[2]];
  }
  call(inputs, kwargs) {
    throw new NotImplementedError();
  }
};
var GlobalAveragePooling1D = class extends GlobalPooling1D {
  constructor(args) {
    super(args || {});
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const input2 = getExactlyOneTensor(inputs);
      return mean2(input2, 1);
    });
  }
};
GlobalAveragePooling1D.className = "GlobalAveragePooling1D";
serialization_exports2.registerClass(GlobalAveragePooling1D);
var GlobalMaxPooling1D = class extends GlobalPooling1D {
  constructor(args) {
    super(args || {});
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const input2 = getExactlyOneTensor(inputs);
      return max2(input2, 1);
    });
  }
};
GlobalMaxPooling1D.className = "GlobalMaxPooling1D";
serialization_exports2.registerClass(GlobalMaxPooling1D);
var GlobalPooling2D = class extends Layer {
  constructor(args) {
    super(args);
    this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
    checkDataFormat(this.dataFormat);
    this.inputSpec = [new InputSpec({ ndim: 4 })];
  }
  computeOutputShape(inputShape) {
    inputShape = inputShape;
    if (this.dataFormat === "channelsLast") {
      return [inputShape[0], inputShape[3]];
    } else {
      return [inputShape[0], inputShape[1]];
    }
  }
  call(inputs, kwargs) {
    throw new NotImplementedError();
  }
  getConfig() {
    const config = { dataFormat: this.dataFormat };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
};
var GlobalAveragePooling2D = class extends GlobalPooling2D {
  call(inputs, kwargs) {
    return tidy2(() => {
      const input2 = getExactlyOneTensor(inputs);
      if (this.dataFormat === "channelsLast") {
        return mean2(input2, [1, 2]);
      } else {
        return mean2(input2, [2, 3]);
      }
    });
  }
};
GlobalAveragePooling2D.className = "GlobalAveragePooling2D";
serialization_exports2.registerClass(GlobalAveragePooling2D);
var GlobalMaxPooling2D = class extends GlobalPooling2D {
  call(inputs, kwargs) {
    return tidy2(() => {
      const input2 = getExactlyOneTensor(inputs);
      if (this.dataFormat === "channelsLast") {
        return max2(input2, [1, 2]);
      } else {
        return max2(input2, [2, 3]);
      }
    });
  }
};
GlobalMaxPooling2D.className = "GlobalMaxPooling2D";
serialization_exports2.registerClass(GlobalMaxPooling2D);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/layers/wrappers.ts
var Wrapper = class extends Layer {
  constructor(args) {
    super(args);
    this.layer = args.layer;
  }
  build(inputShape) {
    this.built = true;
  }
  get trainable() {
    if (this.layer != null) {
      return this.layer.trainable;
    } else {
      return false;
    }
  }
  set trainable(value) {
    if (this.layer != null) {
      this.layer.trainable = value;
    }
  }
  get trainableWeights() {
    return this.layer.trainableWeights;
  }
  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }
  get updates() {
    return this.layer._updates;
  }
  get losses() {
    return this.layer.losses;
  }
  getWeights() {
    return this.layer.getWeights();
  }
  setWeights(weights) {
    this.layer.setWeights(weights);
  }
  getConfig() {
    const config = {
      "layer": {
        "className": this.layer.getClassName(),
        "config": this.layer.getConfig()
      }
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
  setFastWeightInitDuringBuild(value) {
    super.setFastWeightInitDuringBuild(value);
    if (this.layer != null) {
      this.layer.setFastWeightInitDuringBuild(value);
    }
  }
  static fromConfig(cls, config, customObjects = {}) {
    const layerConfig = config["layer"];
    const layer = deserialize(layerConfig, customObjects);
    delete config["layer"];
    const newConfig = { layer };
    Object.assign(newConfig, config);
    return new cls(newConfig);
  }
};
var TimeDistributed = class extends Wrapper {
  constructor(args) {
    super(args);
    this.supportsMasking = true;
  }
  build(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    if (inputShape.length < 3) {
      throw new ValueError(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(inputShape)}`);
    }
    this.inputSpec = [{ shape: inputShape }];
    const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
    if (!this.layer.built) {
      this.layer.build(childInputShape);
      this.layer.built = true;
    }
    super.build(inputShape);
  }
  computeOutputShape(inputShape) {
    inputShape = getExactlyOneShape(inputShape);
    const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
    const childOutputShape = this.layer.computeOutputShape(childInputShape);
    const timesteps = inputShape[1];
    return [childOutputShape[0], timesteps].concat(childOutputShape.slice(1));
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      inputs = getExactlyOneTensor(inputs);
      const step6 = (inputs2, states) => {
        const output = getExactlyOneTensor(this.layer.call(inputs2, kwargs));
        return [output, []];
      };
      const rnnOutputs = rnn(step6, inputs, [], false, null, null, false, true);
      const y = rnnOutputs[1];
      return y;
    });
  }
};
TimeDistributed.className = "TimeDistributed";
serialization_exports2.registerClass(TimeDistributed);
function checkBidirectionalMergeMode(value) {
  checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES, "BidirectionalMergeMode", value);
}
var DEFAULT_BIDIRECTIONAL_MERGE_MODE = "concat";
var Bidirectional = class extends Wrapper {
  constructor(args) {
    super(args);
    const layerConfig = args.layer.getConfig();
    const forwDict = {};
    forwDict["className"] = args.layer.getClassName();
    forwDict["config"] = layerConfig;
    this.forwardLayer = deserialize(forwDict);
    layerConfig["goBackwards"] = layerConfig["goBackwards"] === true ? false : true;
    const backDict = {};
    backDict["className"] = args.layer.getClassName();
    backDict["config"] = layerConfig;
    this.backwardLayer = deserialize(backDict);
    this.forwardLayer.name = "forward_" + this.forwardLayer.name;
    this.backwardLayer.name = "backward_" + this.backwardLayer.name;
    this.mergeMode = args.mergeMode === void 0 ? DEFAULT_BIDIRECTIONAL_MERGE_MODE : args.mergeMode;
    checkBidirectionalMergeMode(this.mergeMode);
    if (args.weights) {
      throw new NotImplementedError("weights support is not implemented for Bidirectional layer yet.");
    }
    this._stateful = args.layer.stateful;
    this.returnSequences = args.layer.returnSequences;
    this.returnState = args.layer.returnState;
    this.supportsMasking = true;
    this._trainable = true;
    this.inputSpec = args.layer.inputSpec;
    this.numConstants = null;
  }
  get trainable() {
    return this._trainable;
  }
  set trainable(value) {
    this._trainable = value;
    if (this.forwardLayer != null) {
      this.forwardLayer.trainable = value;
    }
    if (this.backwardLayer != null) {
      this.backwardLayer.trainable = value;
    }
  }
  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }
  setWeights(weights) {
    const numWeights = weights.length;
    const numeightsOver2 = Math.floor(numWeights / 2);
    this.forwardLayer.setWeights(weights.slice(0, numeightsOver2));
    this.backwardLayer.setWeights(weights.slice(numeightsOver2));
  }
  computeOutputShape(inputShape) {
    let layerShapes = this.forwardLayer.computeOutputShape(inputShape);
    if (!(Array.isArray(layerShapes) && Array.isArray(layerShapes[0]))) {
      layerShapes = [layerShapes];
    }
    layerShapes = layerShapes;
    let outputShape;
    let outputShapes;
    let stateShape;
    if (this.returnState) {
      stateShape = layerShapes.slice(1);
      outputShape = layerShapes[0];
    } else {
      outputShape = layerShapes[0];
    }
    outputShape = outputShape;
    if (this.mergeMode === "concat") {
      outputShape[outputShape.length - 1] *= 2;
      outputShapes = [outputShape];
    } else if (this.mergeMode == null) {
      outputShapes = [outputShape, outputShape.slice()];
    } else {
      outputShapes = [outputShape];
    }
    if (this.returnState) {
      if (this.mergeMode == null) {
        return outputShapes.concat(stateShape).concat(stateShape.slice());
      }
      return [outputShape].concat(stateShape).concat(stateShape.slice());
    }
    return singletonOrArray(outputShapes);
  }
  apply(inputs, kwargs) {
    let initialState = kwargs == null ? null : kwargs["initialState"];
    let constants = kwargs == null ? null : kwargs["constants"];
    if (kwargs == null) {
      kwargs = {};
    }
    const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
    inputs = standardized.inputs;
    initialState = standardized.initialState;
    constants = standardized.constants;
    if (Array.isArray(inputs)) {
      initialState = inputs.slice(1);
      inputs = inputs[0];
    }
    if ((initialState == null || initialState.length === 0) && constants == null) {
      return super.apply(inputs, kwargs);
    }
    const additionalInputs = [];
    const additionalSpecs = [];
    if (initialState != null) {
      const numStates = initialState.length;
      if (numStates % 2 > 0) {
        throw new ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      }
      kwargs["initialState"] = initialState;
      additionalInputs.push(...initialState);
      const stateSpecs = initialState.map((state) => new InputSpec({ shape: state.shape }));
      this.forwardLayer.stateSpec = stateSpecs.slice(0, numStates / 2);
      this.backwardLayer.stateSpec = stateSpecs.slice(numStates / 2);
      additionalSpecs.push(...stateSpecs);
    }
    if (constants != null) {
      throw new NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");
    }
    const isSymbolicTensor = additionalInputs[0] instanceof SymbolicTensor;
    for (const tensor3 of additionalInputs) {
      if (tensor3 instanceof SymbolicTensor !== isSymbolicTensor) {
        throw new ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
      }
    }
    if (isSymbolicTensor) {
      const fullInput = [inputs].concat(additionalInputs);
      const fullInputSpec = this.inputSpec.concat(additionalSpecs);
      const originalInputSpec = this.inputSpec;
      this.inputSpec = fullInputSpec;
      const output = super.apply(fullInput, kwargs);
      this.inputSpec = originalInputSpec;
      return output;
    } else {
      return super.apply(inputs, kwargs);
    }
  }
  call(inputs, kwargs) {
    return tidy2(() => {
      const initialState = kwargs["initialState"];
      let y;
      let yRev;
      if (initialState == null) {
        y = this.forwardLayer.call(inputs, kwargs);
        yRev = this.backwardLayer.call(inputs, kwargs);
      } else {
        const forwardState = initialState.slice(0, initialState.length / 2);
        const backwardState = initialState.slice(initialState.length / 2);
        y = this.forwardLayer.call(inputs, Object.assign(kwargs, { initialState: forwardState }));
        yRev = this.backwardLayer.call(inputs, Object.assign(kwargs, { initialState: backwardState }));
      }
      let states;
      if (this.returnState) {
        if (Array.isArray(y)) {
          states = y.slice(1).concat(yRev.slice(1));
        } else {
        }
        y = y[0];
        yRev = yRev[0];
      }
      if (this.returnSequences) {
        yRev = reverse2(yRev, 1);
      }
      let output;
      if (this.mergeMode === "concat") {
        output = concatenate([y, yRev]);
      } else if (this.mergeMode === "sum") {
        output = add4(y, yRev);
      } else if (this.mergeMode === "ave") {
        output = mul2(0.5, add4(y, yRev));
      } else if (this.mergeMode === "mul") {
        output = mul2(y, yRev);
      } else if (this.mergeMode == null) {
        output = [y, yRev];
      }
      if (this.returnState) {
        if (this.mergeMode == null) {
          return output.concat(states);
        }
        return [output].concat(states);
      }
      return output;
    });
  }
  resetStates(states) {
    this.forwardLayer.resetStates();
    this.backwardLayer.resetStates();
  }
  build(inputShape) {
    nameScope(this.forwardLayer.name, () => {
      this.forwardLayer.build(inputShape);
    });
    nameScope(this.backwardLayer.name, () => {
      this.backwardLayer.build(inputShape);
    });
    this.built = true;
  }
  computeMask(inputs, mask) {
    if (Array.isArray(mask)) {
      mask = mask[0];
    }
    let outputMask;
    if (this.returnSequences) {
      if (this.mergeMode == null) {
        outputMask = [mask, mask];
      } else {
        outputMask = mask;
      }
    } else {
      if (this.mergeMode == null) {
        outputMask = [null, null];
      } else {
        outputMask = null;
      }
    }
    if (this.returnState) {
      const states = this.forwardLayer.states;
      const stateMask = states.map((state) => null);
      if (Array.isArray(outputMask)) {
        return outputMask.concat(stateMask).concat(stateMask);
      } else {
        return [outputMask].concat(stateMask).concat(stateMask);
      }
    } else {
      return outputMask;
    }
  }
  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }
  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }
  setFastWeightInitDuringBuild(value) {
    super.setFastWeightInitDuringBuild(value);
    if (this.forwardLayer != null) {
      this.forwardLayer.setFastWeightInitDuringBuild(value);
    }
    if (this.backwardLayer != null) {
      this.backwardLayer.setFastWeightInitDuringBuild(value);
    }
  }
  getConfig() {
    const config = {
      "mergeMode": this.mergeMode
    };
    const baseConfig = super.getConfig();
    Object.assign(config, baseConfig);
    return config;
  }
  static fromConfig(cls, config) {
    const rnnLayer = deserialize(config["layer"]);
    delete config["layer"];
    if (config["numConstants"] != null) {
      throw new NotImplementedError(`Deserialization of a Bidirectional layer with numConstants present is not supported yet.`);
    }
    const newConfig = config;
    newConfig["layer"] = rnnLayer;
    return new cls(newConfig);
  }
};
Bidirectional.className = "Bidirectional";
serialization_exports2.registerClass(Bidirectional);

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_layers.ts
function inputLayer(args) {
  return new InputLayer(args);
}
function elu4(args) {
  return new ELU(args);
}
function reLU(args) {
  return new ReLU(args);
}
function leakyReLU(args) {
  return new LeakyReLU(args);
}
function prelu3(args) {
  return new PReLU(args);
}
function softmax3(args) {
  return new Softmax4(args);
}
function thresholdedReLU(args) {
  return new ThresholdedReLU(args);
}
function conv1d3(args) {
  return new Conv1D(args);
}
function conv2d5(args) {
  return new Conv2D3(args);
}
function conv2dTranspose3(args) {
  return new Conv2DTranspose(args);
}
function conv3d3(args) {
  return new Conv3D3(args);
}
function conv3dTranspose3(args) {
  return new Conv3DTranspose(args);
}
function separableConv2d3(args) {
  return new SeparableConv2D(args);
}
function cropping2D(args) {
  return new Cropping2D(args);
}
function upSampling2d(args) {
  return new UpSampling2D(args);
}
function depthwiseConv2d6(args) {
  return new DepthwiseConv2D(args);
}
function activation(args) {
  return new Activation5(args);
}
function dense(args) {
  return new Dense(args);
}
function dropout4(args) {
  return new Dropout(args);
}
function spatialDropout1d(args) {
  return new SpatialDropout1D(args);
}
function flatten4(args) {
  return new Flatten(args);
}
function repeatVector(args) {
  return new RepeatVector(args);
}
function reshape3(args) {
  return new Reshape3(args);
}
function permute(args) {
  return new Permute(args);
}
function embedding(args) {
  return new Embedding(args);
}
function add5(args) {
  return new Add3(args);
}
function average(args) {
  return new Average(args);
}
function concatenate2(args) {
  return new Concatenate(args);
}
function maximum3(args) {
  return new Maximum3(args);
}
function minimum3(args) {
  return new Minimum3(args);
}
function multiply(args) {
  return new Multiply3(args);
}
function dot4(args) {
  return new Dot(args);
}
function batchNormalization2(args) {
  return new BatchNormalization(args);
}
function layerNormalization(args) {
  return new LayerNormalization(args);
}
function zeroPadding2d(args) {
  return new ZeroPadding2D(args);
}
function averagePooling1d(args) {
  return new AveragePooling1D(args);
}
function avgPool1d(args) {
  return averagePooling1d(args);
}
function avgPooling1d(args) {
  return averagePooling1d(args);
}
function averagePooling2d(args) {
  return new AveragePooling2D(args);
}
function avgPool2d(args) {
  return averagePooling2d(args);
}
function avgPooling2d(args) {
  return averagePooling2d(args);
}
function averagePooling3d(args) {
  return new AveragePooling3D(args);
}
function avgPool3d3(args) {
  return averagePooling3d(args);
}
function avgPooling3d(args) {
  return averagePooling3d(args);
}
function globalAveragePooling1d(args) {
  return new GlobalAveragePooling1D(args);
}
function globalAveragePooling2d(args) {
  return new GlobalAveragePooling2D(args);
}
function globalMaxPooling1d(args) {
  return new GlobalMaxPooling1D(args);
}
function globalMaxPooling2d(args) {
  return new GlobalMaxPooling2D(args);
}
function maxPooling1d(args) {
  return new MaxPooling1D(args);
}
function maxPooling2d(args) {
  return new MaxPooling2D(args);
}
function maxPooling3d(args) {
  return new MaxPooling3D(args);
}
function gru(args) {
  return new GRU(args);
}
function gruCell(args) {
  return new GRUCell(args);
}
function lstm(args) {
  return new LSTM(args);
}
function lstmCell(args) {
  return new LSTMCell(args);
}
function simpleRNN(args) {
  return new SimpleRNN(args);
}
function simpleRNNCell(args) {
  return new SimpleRNNCell(args);
}
function convLstm2d(args) {
  return new ConvLSTM2D(args);
}
function convLstm2dCell(args) {
  return new ConvLSTM2DCell(args);
}
function rnn2(args) {
  return new RNN(args);
}
function stackedRNNCells(args) {
  return new StackedRNNCells(args);
}
function bidirectional(args) {
  return new Bidirectional(args);
}
function timeDistributed(args) {
  return new TimeDistributed(args);
}
var globalMaxPool1d = globalMaxPooling1d;
var globalMaxPool2d = globalMaxPooling2d;
var maxPool1d = maxPooling1d;
var maxPool2d = maxPooling2d;
function gaussianNoise(args) {
  return new GaussianNoise(args);
}
function gaussianDropout(args) {
  return new GaussianDropout(args);
}
function alphaDropout(args) {
  return new AlphaDropout(args);
}
function masking(args) {
  return new Masking(args);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_metrics.ts
var exports_metrics_exports = {};
__export(exports_metrics_exports, {
  MAPE: () => MAPE2,
  MSE: () => MSE2,
  binaryAccuracy: () => binaryAccuracy2,
  binaryCrossentropy: () => binaryCrossentropy3,
  categoricalAccuracy: () => categoricalAccuracy2,
  categoricalCrossentropy: () => categoricalCrossentropy3,
  cosineProximity: () => cosineProximity2,
  mape: () => mape2,
  meanAbsoluteError: () => meanAbsoluteError2,
  meanAbsolutePercentageError: () => meanAbsolutePercentageError2,
  meanSquaredError: () => meanSquaredError4,
  mse: () => mse2,
  precision: () => precision2,
  recall: () => recall2,
  sparseCategoricalAccuracy: () => sparseCategoricalAccuracy2
});
function binaryAccuracy2(yTrue, yPred) {
  return binaryAccuracy(yTrue, yPred);
}
function binaryCrossentropy3(yTrue, yPred) {
  return binaryCrossentropy2(yTrue, yPred);
}
function sparseCategoricalAccuracy2(yTrue, yPred) {
  return sparseCategoricalAccuracy(yTrue, yPred);
}
function categoricalAccuracy2(yTrue, yPred) {
  return categoricalAccuracy(yTrue, yPred);
}
function categoricalCrossentropy3(yTrue, yPred) {
  return categoricalCrossentropy2(yTrue, yPred);
}
function precision2(yTrue, yPred) {
  return precision(yTrue, yPred);
}
function recall2(yTrue, yPred) {
  return recall(yTrue, yPred);
}
function cosineProximity2(yTrue, yPred) {
  return cosineProximity(yTrue, yPred);
}
function meanAbsoluteError2(yTrue, yPred) {
  return meanAbsoluteError(yTrue, yPred);
}
function meanAbsolutePercentageError2(yTrue, yPred) {
  return meanAbsolutePercentageError(yTrue, yPred);
}
function MAPE2(yTrue, yPred) {
  return meanAbsolutePercentageError(yTrue, yPred);
}
function mape2(yTrue, yPred) {
  return meanAbsolutePercentageError(yTrue, yPred);
}
function meanSquaredError4(yTrue, yPred) {
  return meanSquaredError3(yTrue, yPred);
}
function MSE2(yTrue, yPred) {
  return meanSquaredError3(yTrue, yPred);
}
function mse2(yTrue, yPred) {
  return meanSquaredError3(yTrue, yPred);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_models.ts
var exports_models_exports = {};
__export(exports_models_exports, {
  modelFromJSON: () => modelFromJSON
});

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/exports_regularizers.ts
var exports_regularizers_exports = {};
__export(exports_regularizers_exports, {
  l1: () => l12,
  l1l2: () => l1l2,
  l2: () => l22
});
function l1l2(config) {
  return new L1L2(config);
}
function l12(config) {
  return l1(config);
}
function l22(config) {
  return l2(config);
}

// node_modules/.pnpm/@tensorflow+tfjs-layers@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-layers/src/callbacks.ts
var Callback = class extends BaseCallback {
  constructor() {
    super(...arguments);
    this.model = null;
  }
  setModel(model2) {
    if (!(model2 instanceof LayersModel)) {
      throw new Error("model must be a LayersModel, not some other Container");
    }
    this.model = model2;
  }
};
function less3(currVal, prevVal) {
  return currVal < prevVal;
}
function greater3(currVal, prevVal) {
  return currVal > prevVal;
}
var EarlyStopping = class extends Callback {
  constructor(args) {
    super();
    if (args == null) {
      args = {};
    }
    if (args.restoreBestWeights) {
      throw new NotImplementedError("restoreBestWeights = True is not implemented in EarlyStopping yet.");
    }
    this.monitor = args.monitor || "val_loss";
    this.minDelta = Math.abs(args.minDelta || 0);
    this.patience = args.patience || 0;
    this.verbose = args.verbose || 0;
    this.mode = args.mode || "auto";
    this.baseline = args.baseline;
    if (["auto", "min", "max"].indexOf(this.mode) === -1) {
      console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`);
      this.mode = "auto";
    }
    if (this.mode === "min") {
      this.monitorFunc = less3;
    } else if (this.mode === "max") {
      this.monitorFunc = greater3;
    } else {
      if (this.monitor.indexOf("acc") !== -1) {
        this.monitorFunc = greater3;
      } else {
        this.monitorFunc = less3;
      }
    }
    if (this.monitorFunc === less3) {
      this.minDelta *= -1;
    }
  }
  async onTrainBegin(logs) {
    this.wait = 0;
    this.stoppedEpoch = 0;
    if (this.baseline != null) {
      this.best = this.baseline;
    } else {
      this.best = this.monitorFunc === less3 ? Infinity : -Infinity;
    }
  }
  async onEpochEnd(epoch, logs) {
    await resolveScalarsInLogs(logs);
    const current = this.getMonitorValue(logs);
    if (current == null) {
      return;
    }
    if (this.monitorFunc(current - this.minDelta, this.best)) {
      this.best = current;
      this.wait = 0;
    } else {
      this.wait++;
      if (this.wait >= this.patience) {
        this.stoppedEpoch = epoch;
        this.model.stopTraining = true;
      }
    }
  }
  async onTrainEnd(logs) {
    if (this.stoppedEpoch > 0 && this.verbose) {
      console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);
    }
  }
  getMonitorValue(logs) {
    if (logs == null) {
      logs = {};
    }
    const monitorValue = logs[this.monitor];
    if (monitorValue == null) {
      console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(logs)}`);
    }
    return monitorValue;
  }
};
function earlyStopping(args) {
  return new EarlyStopping(args);
}
var callbacks = { earlyStopping };

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/data/compiled_api.ts
var DataType8;
(function(DataType43) {
  DataType43[DataType43["DT_INVALID"] = 0] = "DT_INVALID";
  DataType43[DataType43["DT_FLOAT"] = 1] = "DT_FLOAT";
  DataType43[DataType43["DT_DOUBLE"] = 2] = "DT_DOUBLE";
  DataType43[DataType43["DT_INT32"] = 3] = "DT_INT32";
  DataType43[DataType43["DT_UINT8"] = 4] = "DT_UINT8";
  DataType43[DataType43["DT_INT16"] = 5] = "DT_INT16";
  DataType43[DataType43["DT_INT8"] = 6] = "DT_INT8";
  DataType43[DataType43["DT_STRING"] = 7] = "DT_STRING";
  DataType43[DataType43["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
  DataType43[DataType43["DT_INT64"] = 9] = "DT_INT64";
  DataType43[DataType43["DT_BOOL"] = 10] = "DT_BOOL";
  DataType43[DataType43["DT_QINT8"] = 11] = "DT_QINT8";
  DataType43[DataType43["DT_QUINT8"] = 12] = "DT_QUINT8";
  DataType43[DataType43["DT_QINT32"] = 13] = "DT_QINT32";
  DataType43[DataType43["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
  DataType43[DataType43["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
  DataType43[DataType43["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
  DataType43[DataType43["DT_INT32_REF"] = 103] = "DT_INT32_REF";
  DataType43[DataType43["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
  DataType43[DataType43["DT_INT16_REF"] = 105] = "DT_INT16_REF";
  DataType43[DataType43["DT_INT8_REF"] = 106] = "DT_INT8_REF";
  DataType43[DataType43["DT_STRING_REF"] = 107] = "DT_STRING_REF";
  DataType43[DataType43["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
  DataType43[DataType43["DT_INT64_REF"] = 109] = "DT_INT64_REF";
  DataType43[DataType43["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
  DataType43[DataType43["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
  DataType43[DataType43["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
  DataType43[DataType43["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
  DataType43[DataType43["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
})(DataType8 || (DataType8 = {}));
var SaverDef;
(function(SaverDef2) {
  let CheckpointFormatVersion;
  (function(CheckpointFormatVersion2) {
    CheckpointFormatVersion2[CheckpointFormatVersion2["LEGACY"] = 0] = "LEGACY";
    CheckpointFormatVersion2[CheckpointFormatVersion2["V1"] = 1] = "V1";
    CheckpointFormatVersion2[CheckpointFormatVersion2["V2"] = 2] = "V2";
  })(CheckpointFormatVersion = SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
})(SaverDef || (SaverDef = {}));

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/custom_op/register.ts
var CUSTOM_OPS = {};
function registerOp(name, opFunc) {
  const opMapper = {
    tfOpName: name,
    category: "custom",
    inputs: [],
    attrs: [],
    customExecutor: opFunc
  };
  CUSTOM_OPS[name] = opMapper;
}
function getRegisteredOp(name) {
  return CUSTOM_OPS[name];
}
function deregisterOp(name) {
  delete CUSTOM_OPS[name];
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/utils.ts
function getParamValue(paramName, node, tensorMap, context, resourceManager) {
  const inputParam = node.inputParams[paramName];
  if (inputParam && inputParam.inputIndexStart !== void 0) {
    const start = inputParam.inputIndexStart;
    const end = inputParam.inputIndexEnd === 0 ? void 0 : inputParam.inputIndexEnd === void 0 ? start + 1 : inputParam.inputIndexEnd;
    if (inputParam.type === "tensor") {
      return getTensor(node.inputNames[inputParam.inputIndexStart], tensorMap, context, resourceManager);
    }
    if (inputParam.type === "tensors") {
      const inputs = node.inputNames.slice(start, end);
      return inputs.map((name) => getTensor(name, tensorMap, context, resourceManager));
    }
    const tensor3 = getTensor(node.inputNames.slice(start)[0], tensorMap, context, resourceManager);
    const data = tensor3.dataSync();
    return inputParam.type === "number" ? data[0] : util_exports2.toNestedArray(tensor3.shape, data);
  }
  const attrParam = node.attrParams[paramName];
  return attrParam && attrParam.value;
}
function getTensor(name, tensorsMap, context, resourceManager) {
  const [nodeName, index] = parseNodeName(name);
  if (resourceManager != null) {
    const tensor3 = resourceManager.getHashTableHandleByName(nodeName);
    if (tensor3 != null) {
      return tensor3;
    }
  }
  const contextId = context.currentContextIds.find((contextId2) => {
    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId2)];
  });
  return contextId !== void 0 ? tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] : void 0;
}
function getTensorsForCurrentContenxt(name, tensorsMap, context) {
  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];
}
function getNodeNameAndIndex(inputName, context) {
  const [nodeName, index, outputName] = parseNodeName(inputName);
  return [
    getNodeNameWithContextId(nodeName, context && context.currentContextId),
    index,
    outputName
  ];
}
function getNodeNameWithContextId(name, contextId) {
  return !!contextId ? `${name}-${contextId}` : name;
}
function parseNodeName(name) {
  const parts = name.split(":");
  if (parts.length === 1) {
    return [name, 0, void 0];
  }
  const nodeName = parts[0];
  const outputName = parts.length === 3 ? parts[1] : void 0;
  const index = Number(parts[parts.length - 1]);
  return [nodeName, index, outputName];
}
function getPadding(node, tensorMap, context) {
  let pad4 = getParamValue("pad", node, tensorMap, context);
  if (pad4 === "explicit") {
    pad4 = getParamValue("explicitPaddings", node, tensorMap, context);
    const explicitPadding = [[0, 0], [0, 0], [0, 0], [0, 0]];
    for (let i = 0; i < 4; i++) {
      explicitPadding[i][0] = pad4[i * 2];
      explicitPadding[i][1] = pad4[i * 2 + 1];
    }
    return explicitPadding;
  }
  return pad4;
}
function cloneTensor(tensor3) {
  return tensor3.kept ? tensor3 : clone2(tensor3);
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/arithmetic.ts
var arithmetic_exports = {};
__export(arithmetic_exports, {
  json: () => json
});
var json = [
  {
    "tfOpName": "Add",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "AddV2",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "AddN",
    "category": "arithmetic",
    "inputs": [{ "start": 0, "end": 0, "name": "tensors", "type": "tensors" }]
  },
  {
    "tfOpName": "BiasAdd",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Sub",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "RealDiv",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Div",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "DivNoNan",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "FloorDiv",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Mul",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Maximum",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Minimum",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Pow",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "SquaredDifference",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Mod",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "FloorMod",
    "category": "arithmetic",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "T",
      "name": "dtype",
      "type": "dtype",
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/basic_math.ts
var basic_math_exports = {};
__export(basic_math_exports, {
  json: () => json2
});
var json2 = [
  {
    "tfOpName": "Abs",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Acos",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Asin",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Atan",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Atan2",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "y", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Ceil",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "ClipByValue",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "clipValueMin", "type": "number" },
      { "start": 2, "name": "clipValueMax", "type": "number" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Complex",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "real", "type": "tensor" },
      { "start": 1, "name": "imag", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "ComplexAbs",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Cos",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Cosh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Elu",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Exp",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Floor",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Log",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Imag",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "outputType",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Neg",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Real",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "outputType",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Prelu",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "alpha", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Relu",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Relu6",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Selu",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Sigmoid",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Sin",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Sinh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Sqrt",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Rsqrt",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Square",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Tan",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Tanh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Sign",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Round",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Expm1",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Log1p",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Reciprocal",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Softplus",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Asinh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Acosh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Atanh",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Erf",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Prod",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axes", "type": "number[]" }
    ],
    "attrs": [
      {
        "tfName": "keep_dims",
        "name": "keepDims",
        "type": "bool",
        "notSupported": true
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "LeakyRelu",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "alpha",
        "name": "alpha",
        "type": "number",
        "defaultValue": 0.2
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "IsNan",
    "category": "basic_math",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "T",
      "name": "dtype",
      "type": "dtype",
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/control.ts
var control_exports = {};
__export(control_exports, {
  json: () => json3
});
var json3 = [
  {
    "tfOpName": "EmptyTensorList",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "elementShape", "type": "shape" },
      { "start": 1, "name": "maxNumElements", "type": "number" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "LoopCond",
    "category": "control",
    "inputs": [{ "start": 0, "name": "pred", "type": "tensor" }]
  },
  {
    "tfOpName": "Switch",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "data", "type": "tensor" },
      { "start": 1, "name": "pred", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "Merge",
    "category": "control",
    "inputs": [{ "start": 0, "end": 0, "name": "tensors", "type": "tensors" }]
  },
  {
    "tfOpName": "Enter",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      { "tfName": "frame_name", "name": "frameName", "type": "string" },
      { "tfName": "is_constant", "name": "isConstant", "type": "bool" }
    ]
  },
  {
    "tfOpName": "Exit",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "NextIteration",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "TensorArrayV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "size", "type": "number" }
    ],
    "attrs": [
      { "tfName": "dtype", "name": "dtype", "type": "dtype" },
      { "tfName": "element_shape", "name": "elementShape", "type": "shape" },
      { "tfName": "dynamic_size", "name": "dynamicSize", "type": "bool" },
      { "tfName": "clear_after_read", "name": "clearAfterRead", "type": "bool" },
      {
        "tfName": "identical_element_shapes",
        "name": "identicalElementShapes",
        "type": "bool"
      },
      { "tfName": "tensor_array_name", "name": "name", "type": "string" }
    ]
  },
  {
    "tfOpName": "TensorArrayWriteV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "index", "type": "number" },
      { "start": 2, "name": "tensor", "type": "tensor" },
      { "start": 3, "name": "flowIn", "type": "number" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "TensorArrayReadV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "index", "type": "number" },
      { "start": 2, "name": "flowIn", "type": "number" }
    ],
    "attrs": [{
      "tfName": "dtype",
      "name": "dtype",
      "type": "dtype",
      "notSupported": true
    }]
  },
  {
    "tfOpName": "TensorArrayGatherV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "number[]" },
      { "start": 2, "name": "flowIn", "type": "number" }
    ],
    "attrs": [
      { "tfName": "dtype", "name": "dtype", "type": "dtype" },
      { "tfName": "element_shape", "name": "elementShape", "type": "shape" }
    ]
  },
  {
    "tfOpName": "TensorArrayScatterV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "number[]" },
      { "start": 2, "name": "tensor", "type": "tensor" },
      { "start": 3, "name": "flowIn", "type": "number" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorArrayConcatV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "flowIn", "type": "number" }
    ],
    "attrs": [
      { "tfName": "dtype", "name": "dtype", "type": "dtype" },
      {
        "tfName": "element_shape_except0",
        "name": "elementShapeExcept0",
        "type": "shape",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "TensorArraySplitV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "tensor", "type": "tensor" },
      { "start": 2, "name": "lengths", "type": "number[]" },
      { "start": 3, "name": "flowIn", "type": "number" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorArraySizeV3",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorArrayId", "type": "tensor" },
      { "start": 1, "name": "flowIn", "type": "number" }
    ]
  },
  {
    "tfOpName": "TensorArrayCloseV3",
    "category": "control",
    "inputs": [{ "start": 0, "name": "tensorArrayId", "type": "tensor" }]
  },
  {
    "tfOpName": "StatelessIf",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "cond", "type": "tensor" },
      { "start": 1, "end": 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "then_branch", "name": "thenBranch", "type": "func" },
      { "tfName": "else_branch", "name": "elseBranch", "type": "func" }
    ]
  },
  {
    "tfOpName": "If",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "cond", "type": "tensor" },
      { "start": 1, "end": 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "then_branch", "name": "thenBranch", "type": "func" },
      { "tfName": "else_branch", "name": "elseBranch", "type": "func" }
    ]
  },
  {
    "tfOpName": "StatelessWhile",
    "category": "control",
    "inputs": [
      { "start": 0, "end": 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "cond", "name": "cond", "type": "func" },
      { "tfName": "body", "name": "body", "type": "func" }
    ]
  },
  {
    "tfOpName": "While",
    "category": "control",
    "inputs": [
      { "start": 0, "end": 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "cond", "name": "cond", "type": "func" },
      { "tfName": "body", "name": "body", "type": "func" }
    ]
  },
  {
    "tfOpName": "TensorListScatter",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "number[]" },
      { "start": 2, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListScatterV2",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "number[]" },
      { "start": 2, "name": "elementShape", "type": "shape" },
      { "start": 3, "name": "numElements", "type": "number" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListGather",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "number[]" },
      { "start": 2, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListGetItem",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "index", "type": "number" },
      { "start": 2, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListSetItem",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "index", "type": "number" },
      { "start": 2, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListReserve",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "elementShape", "type": "shape" },
      { "start": 1, "name": "numElements", "type": "number" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListFromTensor",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" },
      { "start": 1, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListStack",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [
      { "tfName": "element_dtype", "name": "elementDType", "type": "dtype" },
      { "tfName": "num_elements", "name": "numElements", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "TensorListSplit",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" },
      { "start": 1, "name": "elementShape", "type": "shape" },
      { "start": 2, "name": "lengths", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListConcat",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "element_shape", "name": "elementShape", "type": "shape" },
      { "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "TensorListPopBack",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "elementShape", "type": "shape" }
    ],
    "attrs": [{ "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }]
  },
  {
    "tfOpName": "TensorListPushBack",
    "category": "control",
    "inputs": [
      { "start": 0, "name": "tensorListId", "type": "tensor" },
      { "start": 1, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "element_dtype", "name": "elementDType", "type": "dtype" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/convolution.ts
var convolution_exports = {};
__export(convolution_exports, {
  json: () => json4
});
var json4 = [
  {
    "tfOpName": "AvgPool",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      { "tfName": "ksize", "name": "kernelSize", "type": "number[]" },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "MaxPool",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      { "tfName": "ksize", "name": "kernelSize", "type": "number[]" },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": [],
        "notSupported": true
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "MaxPoolWithArgmax",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      { "tfName": "ksize", "name": "kernelSize", "type": "number[]" },
      {
        "tfName": "include_batch_in_index",
        "name": "includeBatchInIndex",
        "type": "bool"
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "AvgPool3D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      { "tfName": "ksize", "name": "kernelSize", "type": "number[]" },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "MaxPool3D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      { "tfName": "ksize", "name": "kernelSize", "type": "number[]" },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Conv1D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "stride", "name": "stride", "type": "number" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NWC"
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      {
        "tfName": "dilation",
        "name": "dilation",
        "type": "number",
        "defaultValue": 1
      }
    ]
  },
  {
    "tfOpName": "Conv2D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      { "tfName": "useCudnnOnGpu", "name": "useCudnnOnGpu", "type": "bool" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      { "tfName": "dilations", "name": "dilations", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "_FusedConv2D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" },
      { "start": 2, end: 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "num_args", "name": "numArgs", "type": "number" },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "use_cudnn_on_gpu",
        "name": "useCudnnOnGpu",
        "type": "bool",
        "defaultValue": true
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "defaultValue": [1, 1, 1, 1]
      },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-4
      },
      {
        "tfName": "leakyrelu_alpha",
        "name": "leakyreluAlpha",
        "type": "number"
      }
    ]
  },
  {
    "tfOpName": "Conv2DBackpropInput",
    "category": "convolution",
    "inputs": [
      { "start": 2, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" },
      { "start": 0, "name": "outputShape", "type": "number[]" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "DepthwiseConv2d",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "input", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      { "tfName": "dilations", "name": "dilations", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "DepthwiseConv2dNative",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "input", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      },
      { "tfName": "dilations", "name": "dilations", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "FusedDepthwiseConv2dNative",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" },
      { "start": 2, end: 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "num_args", "name": "numArgs", "type": "number" },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      {
        "tfName": "dilations",
        "name": "dilations",
        "type": "number[]",
        "defaultValue": [1, 1, 1, 1]
      },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "explicit_paddings",
        "name": "explicitPaddings",
        "type": "number[]",
        "defaultValue": []
      }
    ]
  },
  {
    "tfOpName": "Conv3D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "defaultValue": "NHWC"
      },
      { "tfName": "dilations", "name": "dilations", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "Dilation2D",
    "category": "convolution",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "filter", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "strides", "name": "strides", "type": "number[]" },
      { "tfName": "rates", "name": "dilations", "type": "number[]" },
      { "tfName": "padding", "name": "pad", "type": "string" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/creation.ts
var creation_exports = {};
__export(creation_exports, {
  json: () => json5
});
var json5 = [
  {
    "tfOpName": "Fill",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "shape", "type": "number[]" },
      { "start": 1, "name": "value", "type": "number" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "LinSpace",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "start", "type": "number" },
      { "start": 1, "name": "stop", "type": "number" },
      { "start": 2, "name": "num", "type": "number" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "OneHot",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "indices", "type": "tensor" },
      { "start": 1, "name": "depth", "type": "number" },
      { "start": 2, "name": "onValue", "type": "number", "defaultValue": 1 },
      { "start": 3, "name": "offValue", "type": "number", "defaultValue": 0 }
    ],
    "attrs": [
      {
        "tfName": "axis",
        "name": "axis",
        "type": "number",
        "notSupported": true
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Ones",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "shape", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "OnesLike",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "dtype", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "RandomUniform",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "shape", "type": "number[]" }
    ],
    "attrs": [
      {
        "tfName": "minval",
        "name": "minval",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "maxval",
        "name": "maxval",
        "type": "number",
        "defaultValue": 1
      },
      { "tfName": "dtype", "name": "dtype", "type": "dtype" },
      { "tfName": "seed", "name": "seed", "type": "number", "defaultValue": 0 },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      },
      { "tfName": "T", "name": "T", "type": "number", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Range",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "start", "type": "number" },
      { "start": 1, "name": "stop", "type": "number" },
      { "start": 2, "name": "step", "type": "number", "defaultValue": 0 }
    ],
    "attrs": [{ "tfName": "Tidx", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "TruncatedNormal",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "shape", "type": "number[]" }
    ],
    "attrs": [
      {
        "tfName": "means",
        "name": "mean",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "stddev",
        "name": "stdDev",
        "type": "number",
        "defaultValue": 1
      },
      { "tfName": "seed", "name": "seed", "type": "number" },
      {
        "tfName": "seed2",
        "name": "seed2",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      },
      { "tfName": "dtype", "name": "dtype", "type": "dtype" },
      { "tfName": "T", "name": "T", "type": "number", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Zeros",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "shape", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "ZerosLike",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "T", "name": "dtype", "type": "dtype" }]
  },
  {
    "tfOpName": "Multinomial",
    "category": "creation",
    "inputs": [
      { "start": 0, "name": "logits", "type": "tensor" },
      { "start": 1, "name": "numSamples", "type": "number" }
    ],
    "attrs": [
      { "tfName": "seed", "name": "seed", "type": "number" },
      { "tfName": "seed2", "name": "seed2", "type": "number" },
      { "tfName": "T", "name": "dtype", "type": "dtype" },
      { "tfName": "output_dtype", "name": "output_dtype", "type": "dtype" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/dynamic.ts
var dynamic_exports = {};
__export(dynamic_exports, {
  json: () => json6
});
var json6 = [
  {
    "tfOpName": "NonMaxSuppressionV2",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "boxes", "type": "tensor" },
      { "start": 1, "name": "scores", "type": "tensor" },
      { "start": 2, "name": "maxOutputSize", "type": "number" },
      { "start": 3, "name": "iouThreshold", "type": "number" }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV3",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "boxes", "type": "tensor" },
      { "start": 1, "name": "scores", "type": "tensor" },
      { "start": 2, "name": "maxOutputSize", "type": "number" },
      { "start": 3, "name": "iouThreshold", "type": "number" },
      { "start": 4, "name": "scoreThreshold", "type": "number" }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV4",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "boxes", "type": "tensor" },
      { "start": 1, "name": "scores", "type": "tensor" },
      { "start": 2, "name": "maxOutputSize", "type": "number" },
      { "start": 3, "name": "iouThreshold", "type": "number" },
      { "start": 4, "name": "scoreThreshold", "type": "number" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true },
      {
        "tfName": "T_threshold",
        "name": "threshold",
        "type": "dtype",
        "notSupported": true
      },
      {
        "tfName": "pad_to_max_output_size",
        "name": "padToMaxOutputSize",
        "type": "bool"
      }
    ]
  },
  {
    "tfOpName": "NonMaxSuppressionV5",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "boxes", "type": "tensor" },
      { "start": 1, "name": "scores", "type": "tensor" },
      { "start": 2, "name": "maxOutputSize", "type": "number" },
      { "start": 3, "name": "iouThreshold", "type": "number" },
      { "start": 4, "name": "scoreThreshold", "type": "number" },
      { "start": 5, "name": "softNmsSigma", "type": "number" }
    ]
  },
  {
    "tfOpName": "Where",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "condition", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "ListDiff",
    "category": "dynamic",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "y", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "T",
      "name": "dtype",
      "type": "dtype",
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/evaluation.ts
var evaluation_exports = {};
__export(evaluation_exports, {
  json: () => json7
});
var json7 = [
  {
    "tfOpName": "TopKV2",
    "category": "evaluation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "k", "type": "number" }
    ],
    "attrs": [{ "tfName": "sorted", "name": "sorted", "type": "bool" }]
  },
  {
    "tfOpName": "Unique",
    "category": "evaluation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "UniqueV2",
    "category": "evaluation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/graph.ts
var graph_exports = {};
__export(graph_exports, {
  json: () => json8
});
var json8 = [
  {
    "tfOpName": "PlaceholderWithDefault",
    "category": "graph",
    "inputs": [
      { "start": 0, "name": "default", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "shape", "name": "shape", "type": "shape" },
      { "tfName": "dtype", "name": "dtype", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "Placeholder",
    "category": "graph",
    "attrs": [
      { "tfName": "shape", "name": "shape", "type": "shape" },
      { "tfName": "dtype", "name": "dtype", "type": "dtype" }
    ]
  },
  { "tfOpName": "Const", "category": "graph" },
  {
    "tfOpName": "Identity",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "IdentityN",
    "category": "graph",
    "inputs": [{ "start": 0, "end": 0, "name": "x", "type": "tensors" }]
  },
  {
    "tfOpName": "Snapshot",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "Rank",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "Size",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "Shape",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "ShapeN",
    "category": "graph",
    "inputs": [{ "start": 0, "end": 0, "name": "x", "type": "tensors" }]
  },
  {
    "tfOpName": "Print",
    "category": "graph",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "data", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "message", "name": "message", "type": "string" },
      {
        "tfName": "first_n",
        "name": "firstN",
        "type": "number",
        "notSupported": true
      },
      {
        "tfName": "summarize",
        "name": "summarize",
        "type": "number",
        "defaultValue": 3
      }
    ]
  },
  { "tfOpName": "NoOp", "category": "graph", "inputs": [] },
  {
    "tfOpName": "StopGradient",
    "category": "graph",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "FakeQuantWithMinMaxVars",
    "category": "graph",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "min", "name": "min", "type": "number" },
      { "tfName": "max", "name": "max", "type": "number" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/hash_table.ts
var hash_table_exports = {};
__export(hash_table_exports, {
  json: () => json9
});
var json9 = [
  {
    "tfOpName": "HashTable",
    "category": "hash_table",
    "inputs": [],
    "attrs": [
      { "tfName": "shared_name", "name": "sharedName", "type": "string" },
      {
        "tfName": "use_node_name_sharing",
        "name": "useNodeNameSharing",
        "type": "bool"
      },
      { "tfName": "key_dtype", "name": "keyDType", "type": "dtype" },
      { "tfName": "value_dtype", "name": "valueDType", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "HashTableV2",
    "category": "hash_table",
    "inputs": [],
    "attrs": [
      { "tfName": "shared_name", "name": "sharedName", "type": "string" },
      {
        "tfName": "use_node_name_sharing",
        "name": "useNodeNameSharing",
        "type": "bool"
      },
      { "tfName": "key_dtype", "name": "keyDType", "type": "dtype" },
      { "tfName": "value_dtype", "name": "valueDType", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "LookupTableImport",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" },
      { "start": 1, "name": "keys", "type": "tensor" },
      { "start": 2, "name": "values", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "Tin", "name": "tIn", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableImportV2",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" },
      { "start": 1, "name": "keys", "type": "tensor" },
      { "start": 2, "name": "values", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "Tin", "name": "tIn", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableFind",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" },
      { "start": 1, "name": "keys", "type": "tensor" },
      { "start": 2, "name": "defaultValue", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "Tin", "name": "tIn", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableFindV2",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" },
      { "start": 1, "name": "keys", "type": "tensor" },
      { "start": 2, "name": "defaultValue", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "Tin", "name": "tIn", "type": "dtype", "notSupported": true },
      {
        "tfName": "Tout",
        "name": "tOut",
        "type": "dtype",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LookupTableSize",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "LookupTableSizeV2",
    "category": "hash_table",
    "inputs": [
      { "start": 0, "name": "tableHandle", "type": "tensor" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/image.ts
var image_exports = {};
__export(image_exports, {
  json: () => json10
});
var json10 = [
  {
    "tfOpName": "ResizeBilinear",
    "category": "image",
    "inputs": [
      { "start": 0, "name": "images", "type": "tensor" },
      { "start": 1, "name": "size", "type": "number[]" }
    ],
    "attrs": [
      { "tfName": "align_corners", "name": "alignCorners", "type": "bool" },
      {
        "tfName": "half_pixel_centers",
        "name": "halfPixelCenters",
        "type": "bool"
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "ResizeNearestNeighbor",
    "category": "image",
    "inputs": [
      { "start": 0, "name": "images", "type": "tensor" },
      { "start": 1, "name": "size", "type": "number[]" }
    ],
    "attrs": [
      { "tfName": "align_corners", "name": "alignCorners", "type": "bool" },
      {
        "tfName": "half_pixel_centers",
        "name": "halfPixelCenters",
        "type": "bool"
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "CropAndResize",
    "category": "image",
    "inputs": [
      { "start": 0, "name": "image", "type": "tensor" },
      { "start": 1, "name": "boxes", "type": "tensor" },
      { "start": 2, "name": "boxInd", "type": "tensor" },
      { "start": 3, "name": "cropSize", "type": "number[]" }
    ],
    "attrs": [
      { "tfName": "method", "name": "method", "type": "string" },
      {
        "tfName": "extrapolation_value",
        "name": "extrapolationValue",
        "type": "number"
      }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/logical.ts
var logical_exports = {};
__export(logical_exports, {
  json: () => json11
});
var json11 = [
  {
    "tfOpName": "Equal",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "NotEqual",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Greater",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "GreaterEqual",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Less",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "LessEqual",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "LogicalAnd",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "LogicalNot",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "LogicalOr",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Select",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "condition", "type": "tensor" },
      { "start": 1, "name": "a", "type": "tensor" },
      { "start": 2, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "SelectV2",
    "category": "logical",
    "inputs": [
      { "start": 0, "name": "condition", "type": "tensor" },
      { "start": 1, "name": "a", "type": "tensor" },
      { "start": 2, "name": "b", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "T",
      "name": "dtype",
      "type": "dtype",
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/matrices.ts
var matrices_exports = {};
__export(matrices_exports, {
  json: () => json12
});
var json12 = [
  {
    "tfOpName": "_FusedMatMul",
    "category": "matrices",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" },
      { "start": 2, end: 0, "name": "args", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "num_args", "name": "numArgs", "type": "number" },
      {
        "tfName": "fused_ops",
        "name": "fusedOps",
        "type": "string[]",
        "defaultValue": []
      },
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-4
      },
      {
        "tfName": "transpose_a",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "transpose_b",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "MatMul",
    "category": "matrices",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "transpose_a",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "transpose_b",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "BatchMatMul",
    "category": "matrices",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "adj_x",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "adj_y",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "BatchMatMulV2",
    "category": "matrices",
    "inputs": [
      { "start": 0, "name": "a", "type": "tensor" },
      { "start": 1, "name": "b", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "adj_x",
        "name": "transposeA",
        "type": "bool",
        "defaultValue": false
      },
      {
        "tfName": "adj_y",
        "name": "transposeB",
        "type": "bool",
        "defaultValue": false
      },
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Transpose",
    "category": "matrices",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "perm", "type": "number[]" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "Einsum",
    "category": "matrices",
    "inputs": [{ "start": 0, "end": 0, "name": "tensors", "type": "tensors" }],
    "attrs": [
      { "tfName": "equation", "name": "equation", "type": "string" },
      { "tfName": "N", "name": "n", "type": "number", "defaultValue": 2 },
      { "tfName": "T", "name": "dtype", "type": "dtype" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/normalization.ts
var normalization_exports = {};
__export(normalization_exports, {
  json: () => json13
});
var json13 = [
  {
    "tfOpName": "FusedBatchNorm",
    "category": "normalization",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "scale", "type": "tensor" },
      { "start": 2, "name": "offset", "type": "tensor" },
      { "start": 3, "name": "mean", "type": "tensor" },
      { "start": 4, "name": "variance", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FusedBatchNormV2",
    "category": "normalization",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "scale", "type": "tensor" },
      { "start": 2, "name": "offset", "type": "tensor" },
      { "start": 3, "name": "mean", "type": "tensor" },
      { "start": 4, "name": "variance", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "FusedBatchNormV3",
    "category": "normalization",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "scale", "type": "tensor" },
      { "start": 2, "name": "offset", "type": "tensor" },
      { "start": 3, "name": "mean", "type": "tensor" },
      { "start": 4, "name": "variance", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "epsilon",
        "name": "epsilon",
        "type": "number",
        "defaultValue": 1e-3
      },
      {
        "tfName": "data_format",
        "name": "dataFormat",
        "type": "string",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "LRN",
    "category": "normalization",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "depth_radius",
        "name": "radius",
        "type": "number",
        "defaultValue": 5
      },
      { "tfName": "bias", "name": "bias", "type": "number", "defaultValue": 1 },
      {
        "tfName": "alpha",
        "name": "alpha",
        "type": "number",
        "defaultValue": 1
      },
      {
        "tfName": "beta",
        "name": "beta",
        "type": "number",
        "defaultValue": 0.5
      }
    ]
  },
  {
    "tfOpName": "Softmax",
    "category": "normalization",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "LogSoftmax",
    "category": "normalization",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "SparseToDense",
    "category": "normalization",
    "inputs": [
      { "start": 0, "name": "sparseIndices", "type": "tensor" },
      { "start": 1, "name": "outputShape", "type": "number[]" },
      { "start": 2, "name": "sparseValues", "type": "tensor" },
      { "start": 3, "name": "defaultValue", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "validate_indices",
      "name": "validateIndices",
      "type": "bool",
      "defaultValue": true,
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/reduction.ts
var reduction_exports = {};
__export(reduction_exports, {
  json: () => json14
});
var json14 = [
  {
    "tfOpName": "Bincount",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "size", "type": "number" },
      { "start": 2, "name": "weights", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "DenseBincount",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "size", "type": "number" },
      { "start": 2, "name": "weights", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "binary_output", "name": "binaryOutput", "type": "bool" }]
  },
  {
    "tfOpName": "Max",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "Mean",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "Min",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "Sum",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "All",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "Any",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "ArgMax",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number" }
    ]
  },
  {
    "tfOpName": "ArgMin",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number" }
    ]
  },
  {
    "tfOpName": "Prod",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "keep_dims", "name": "keepDims", "type": "bool" }]
  },
  {
    "tfOpName": "Cumsum",
    "category": "reduction",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number" }
    ],
    "attrs": [
      { "tfName": "exclusive", "name": "exclusive", "type": "bool" },
      { "tfName": "reverse", "name": "reverse", "type": "bool" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/slice_join.ts
var slice_join_exports = {};
__export(slice_join_exports, {
  json: () => json15
});
var json15 = [
  {
    "tfOpName": "ConcatV2",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "end": -1, "name": "tensors", "type": "tensors" },
      { "start": -1, "name": "axis", "type": "number" }
    ],
    "attrs": [{ "tfName": "N", "name": "n", "type": "number", "defaultValue": 2 }]
  },
  {
    "tfOpName": "Concat",
    "category": "slice_join",
    "inputs": [
      { "start": 1, "end": 0, "name": "tensors", "type": "tensors" },
      { "start": 0, "name": "axis", "type": "number" }
    ],
    "attrs": [{ "tfName": "N", "name": "n", "type": "number", "defaultValue": 2 }]
  },
  {
    "tfOpName": "GatherV2",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "tensor" },
      { "start": 2, "name": "axis", "type": "number", "defaultValue": 0 }
    ],
    "attrs": [{
      "tfName": "batch_dims",
      "name": "batchDims",
      "type": "number",
      "defaultValue": 0
    }]
  },
  {
    "tfOpName": "Gather",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "validate_indices",
      "name": "validateIndices",
      "type": "bool",
      "notSupported": true
    }]
  },
  {
    "tfOpName": "Reverse",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "dims", "type": "bool[]" }
    ]
  },
  {
    "tfOpName": "ReverseV2",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "Slice",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "begin", "type": "number[]" },
      { "start": 2, "name": "size", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "StridedSlice",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "begin", "type": "number[]" },
      { "start": 2, "name": "end", "type": "number[]" },
      { "start": 3, "name": "strides", "type": "number[]" }
    ],
    "attrs": [
      {
        "tfName": "begin_mask",
        "name": "beginMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "end_mask",
        "name": "endMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "new_axis_mask",
        "name": "newAxisMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "ellipsis_mask",
        "name": "ellipsisMask",
        "type": "number",
        "defaultValue": 0
      },
      {
        "tfName": "shrink_axis_mask",
        "name": "shrinkAxisMask",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Pack",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "end": 0, "name": "tensors", "type": "tensors" }
    ],
    "attrs": [
      { "tfName": "axis", "name": "axis", "type": "number", "defaultValue": 0 }
    ]
  },
  {
    "tfOpName": "Unpack",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "tensor", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "axis", "name": "axis", "type": "number", "defaultValue": 0 },
      {
        "tfName": "num",
        "name": "num",
        "type": "number",
        "defaultValue": 0,
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "Tile",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "reps", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "Split",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "axis", "type": "number", "defaultValue": 0 },
      { "start": 1, "name": "x", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "num_split",
      "name": "numOrSizeSplits",
      "type": "number",
      "defaultValue": 1
    }]
  },
  {
    "tfOpName": "SplitV",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "numOrSizeSplits", "type": "number[]" },
      { "start": 2, "name": "axis", "type": "number", "defaultValue": 0 }
    ]
  },
  {
    "tfOpName": "ScatterNd",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "indices", "type": "tensor" },
      { "start": 1, "name": "values", "type": "tensor" },
      { "start": 2, "name": "shape", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "GatherNd",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "SparseToDense",
    "category": "slice_join",
    "inputs": [
      { "start": 0, "name": "sparseIndices", "type": "tensor" },
      { "start": 1, "name": "outputShape", "type": "number[]" },
      { "start": 2, "name": "sparseValues", "type": "tensor" },
      { "start": 3, "name": "defaultValue", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "validate_indices",
      "name": "validateIndices",
      "type": "bool",
      "defaultValue": false,
      "notSupported": true
    }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/sparse.ts
var sparse_exports = {};
__export(sparse_exports, {
  json: () => json16
});
var json16 = [
  {
    "tfOpName": "SparseFillEmptyRows",
    "category": "sparse",
    "inputs": [
      { "start": 0, "name": "indices", "type": "tensor" },
      { "start": 1, "name": "values", "type": "tensor" },
      { "start": 2, "name": "denseShape", "type": "tensor" },
      { "start": 3, "name": "defaultValue", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "SparseReshape",
    "category": "sparse",
    "inputs": [
      { "start": 0, "name": "inputIndices", "type": "tensor" },
      { "start": 1, "name": "inputShape", "type": "tensor" },
      { "start": 2, "name": "newShape", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "T", "name": "dtype", "type": "dtype", "notSupported": true }
    ]
  },
  {
    "tfOpName": "SparseSegmentMean",
    "category": "sparse",
    "inputs": [
      { "start": 0, "name": "data", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "tensor" },
      { "start": 2, "name": "segmentIds", "type": "tensor" }
    ]
  },
  {
    "tfOpName": "SparseSegmentSum",
    "category": "sparse",
    "inputs": [
      { "start": 0, "name": "data", "type": "tensor" },
      { "start": 1, "name": "indices", "type": "tensor" },
      { "start": 2, "name": "segmentIds", "type": "tensor" }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/spectral.ts
var spectral_exports = {};
__export(spectral_exports, {
  json: () => json17
});
var json17 = [
  {
    "tfOpName": "FFT",
    "category": "spectral",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "IFFT",
    "category": "spectral",
    "inputs": [{ "start": 0, "name": "x", "type": "tensor" }]
  },
  {
    "tfOpName": "RFFT",
    "category": "spectral",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      {
        "start": 1,
        "name": "fft_length",
        "type": "number",
        "notSupported": true
      }
    ]
  },
  {
    "tfOpName": "IRFFT",
    "category": "spectral",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      {
        "start": 1,
        "name": "fft_length",
        "type": "number",
        "notSupported": true
      }
    ]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/string.ts
var string_exports = {};
__export(string_exports, {
  json: () => json18
});
var json18 = [
  {
    "tfOpName": "StringNGrams",
    "category": "string",
    "inputs": [
      { "start": 0, "name": "data", "type": "tensor" },
      { "start": 1, "name": "dataSplits", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "separator", "name": "separator", "type": "string" },
      { "tfName": "ngram_widths", "name": "nGramWidths", "type": "number[]" },
      { "tfName": "left_pad", "name": "leftPad", "type": "string" },
      { "tfName": "right_pad", "name": "rightPad", "type": "string" },
      { "tfName": "pad_width", "name": "padWidth", "type": "number" },
      {
        "tfName": "preserve_short_sequences",
        "name": "preserveShortSequences",
        "type": "bool"
      }
    ],
    "outputs": ["ngrams", "ngrams_splits"]
  },
  {
    "tfOpName": "StringSplit",
    "category": "string",
    "inputs": [
      { "start": 0, "name": "input", "type": "tensor" },
      { "start": 1, "name": "delimiter", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "skip_empty", "name": "skipEmpty", "type": "bool" }],
    "outputs": ["indices", "values", "shape"]
  },
  {
    "tfOpName": "StringToHashBucketFast",
    "category": "string",
    "inputs": [
      { "start": 0, "name": "input", "type": "tensor" }
    ],
    "attrs": [{ "tfName": "num_buckets", "name": "numBuckets", "type": "number" }]
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/op_list/transformation.ts
var transformation_exports = {};
__export(transformation_exports, {
  json: () => json19
});
var json19 = [
  {
    "tfOpName": "Cast",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      {
        "tfName": "SrcT",
        "name": "sdtype",
        "type": "dtype",
        "notSupported": true
      },
      { "tfName": "DstT", "name": "dtype", "type": "dtype" }
    ]
  },
  {
    "tfOpName": "ExpandDims",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "axis", "type": "number" }
    ]
  },
  {
    "tfOpName": "MirrorPad",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "padding", "type": "number[]" }
    ],
    "attrs": [{ "tfName": "mode", "name": "mode", "type": "string" }]
  },
  {
    "tfOpName": "Pad",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "padding", "type": "number[]" }
    ],
    "attrs": [{
      "tfName": "constant_value",
      "name": "constantValue",
      "type": "number",
      "defaultValue": 0
    }]
  },
  {
    "tfOpName": "PadV2",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "padding", "type": "number[]" },
      {
        "start": 2,
        "name": "constantValue",
        "type": "number",
        "defaultValue": 0
      }
    ]
  },
  {
    "tfOpName": "Reshape",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "shape", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "Squeeze",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [{
      "tfName": "axis",
      "tfDeprecatedName": "squeeze_dims",
      "name": "axis",
      "type": "number[]"
    }]
  },
  {
    "tfOpName": "SpaceToBatchND",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "blockShape", "type": "number[]" },
      { "start": 2, "name": "paddings", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "BatchToSpaceND",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "blockShape", "type": "number[]" },
      { "start": 2, "name": "crops", "type": "number[]" }
    ]
  },
  {
    "tfOpName": "DepthToSpace",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" }
    ],
    "attrs": [
      { "tfName": "block_size", "name": "blockSize", "type": "number" },
      { "tfName": "data_format", "name": "dataFormat", "type": "string" }
    ]
  },
  {
    "tfOpName": "BroadcastTo",
    "category": "transformation",
    "inputs": [
      { "start": 0, "name": "x", "type": "tensor" },
      { "start": 1, "name": "shape", "type": "number[]" }
    ],
    "attrs": []
  }
];

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/operation_mapper.ts
var OperationMapper = class {
  static get Instance() {
    return this._instance || (this._instance = new this());
  }
  constructor() {
    const ops = [
      arithmetic_exports,
      basic_math_exports,
      control_exports,
      convolution_exports,
      creation_exports,
      dynamic_exports,
      evaluation_exports,
      graph_exports,
      hash_table_exports,
      image_exports,
      logical_exports,
      matrices_exports,
      normalization_exports,
      reduction_exports,
      slice_join_exports,
      sparse_exports,
      spectral_exports,
      string_exports,
      transformation_exports
    ];
    const mappersJson = [].concat(...ops.map((op3) => op3.json));
    this.opMappers = mappersJson.reduce((map, mapper) => {
      map[mapper.tfOpName] = mapper;
      return map;
    }, {});
  }
  transformGraph(graph2, signature = {}) {
    const tfNodes = graph2.node;
    const placeholders = [];
    const weights = [];
    const initNodes = [];
    const nodes = tfNodes.reduce((map, node) => {
      map[node.name] = this.mapNode(node);
      if (node.op.startsWith("Placeholder")) {
        placeholders.push(map[node.name]);
      } else if (node.op === "Const") {
        weights.push(map[node.name]);
      } else if (node.input == null || node.input.length === 0) {
        initNodes.push(map[node.name]);
      }
      return map;
    }, {});
    let inputs = [];
    const outputs = [];
    let inputNodeNameToKey = {};
    let outputNodeNameToKey = {};
    if (signature != null) {
      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);
      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);
    }
    const allNodes = Object.keys(nodes);
    allNodes.forEach((key) => {
      const node = nodes[key];
      node.inputNames.forEach((name, index) => {
        const [nodeName, , outputName] = getNodeNameAndIndex(name);
        const inputNode = nodes[nodeName];
        if (inputNode.outputs != null) {
          const outputIndex = inputNode.outputs.indexOf(outputName);
          if (outputIndex !== -1) {
            const inputName = `${nodeName}:${outputIndex}`;
            node.inputNames[index] = inputName;
          }
        }
        node.inputs.push(inputNode);
        inputNode.children.push(node);
      });
    });
    if (Object.keys(outputNodeNameToKey).length === 0) {
      allNodes.forEach((key) => {
        const node = nodes[key];
        if (node.children.length === 0) {
          outputs.push(node);
        }
      });
    } else {
      Object.keys(outputNodeNameToKey).forEach((name) => {
        const [nodeName] = getNodeNameAndIndex(name);
        const node = nodes[nodeName];
        if (node != null) {
          node.signatureKey = outputNodeNameToKey[name];
          outputs.push(node);
        }
      });
    }
    if (Object.keys(inputNodeNameToKey).length > 0) {
      Object.keys(inputNodeNameToKey).forEach((name) => {
        const [nodeName] = getNodeNameAndIndex(name);
        const node = nodes[nodeName];
        if (node) {
          node.signatureKey = inputNodeNameToKey[name];
          inputs.push(node);
        }
      });
    } else {
      inputs = placeholders;
    }
    let functions = {};
    if (graph2.library != null && graph2.library.function != null) {
      functions = graph2.library.function.reduce((functions2, func2) => {
        functions2[func2.signature.name] = this.mapFunction(func2);
        return functions2;
      }, {});
    }
    const result = { nodes, inputs, outputs, weights, placeholders, signature, functions };
    if (initNodes.length > 0) {
      result.initNodes = initNodes;
    }
    return result;
  }
  mapSignatureEntries(entries) {
    return Object.keys(entries || {}).reduce((prev, curr) => {
      prev[entries[curr].name] = curr;
      return prev;
    }, {});
  }
  mapNode(node) {
    const mapper = getRegisteredOp(node.op) || this.opMappers[node.op] || {};
    if (node.attr == null) {
      node.attr = {};
    }
    const newNode = {
      name: node.name,
      op: node.op,
      category: mapper.category,
      inputNames: (node.input || []).map((input2) => input2.startsWith("^") ? input2.substr(1) : input2),
      inputs: [],
      children: [],
      inputParams: {},
      attrParams: {},
      rawAttrs: node.attr,
      outputs: mapper.outputs
    };
    if (mapper.inputs != null) {
      newNode.inputParams = mapper.inputs.reduce((map, param) => {
        map[param.name] = {
          type: param.type,
          inputIndexStart: param.start,
          inputIndexEnd: param.end
        };
        return map;
      }, {});
    }
    if (mapper.attrs != null) {
      newNode.attrParams = mapper.attrs.reduce((map, param) => {
        const type = param.type;
        let value = void 0;
        switch (param.type) {
          case "string":
            value = getStringParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getStringParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "string[]":
            value = getStringArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getStringArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "number":
            value = getNumberParam(node.attr, param.tfName, param.defaultValue || 0);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getNumberParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "number[]":
            value = getNumericArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getNumericArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "bool":
            value = getBoolParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getBoolParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "bool[]":
            value = getBoolArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getBoolArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "shape":
            value = getTensorShapeParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getTensorShapeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "shape[]":
            value = getTensorShapeArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getTensorShapeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "dtype":
            value = getDtypeParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getDtypeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "dtype[]":
            value = getDtypeArrayParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getDtypeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "func":
            value = getFuncParam(node.attr, param.tfName, param.defaultValue);
            if (value === void 0 && !!param.tfDeprecatedName) {
              value = getFuncParam(node.attr, param.tfDeprecatedName, param.defaultValue);
            }
            break;
          case "tensor":
          case "tensors":
            break;
          default:
            throw new Error(`Unsupported param type: ${param.type} for op: ${node.op}`);
        }
        map[param.name] = { value, type };
        return map;
      }, {});
    }
    return newNode;
  }
  mapFunction(functionDef) {
    const tfNodes = functionDef.nodeDef;
    const placeholders = [];
    const weights = [];
    let nodes = {};
    if (tfNodes != null) {
      nodes = tfNodes.reduce((map, node) => {
        map[node.name] = this.mapNode(node);
        if (node.op === "Const") {
          weights.push(map[node.name]);
        }
        return map;
      }, {});
    }
    const inputs = [];
    const outputs = [];
    functionDef.signature.inputArg.forEach((arg) => {
      const [nodeName] = getNodeNameAndIndex(arg.name);
      const node = {
        name: nodeName,
        op: "Placeholder",
        inputs: [],
        inputNames: [],
        category: "graph",
        inputParams: {},
        attrParams: { dtype: { value: parseDtypeParam(arg.type), type: "dtype" } },
        children: []
      };
      node.signatureKey = arg.name;
      inputs.push(node);
      nodes[nodeName] = node;
    });
    const allNodes = Object.keys(nodes);
    allNodes.forEach((key) => {
      const node = nodes[key];
      node.inputNames.forEach((name, index) => {
        const [nodeName, , outputName] = getNodeNameAndIndex(name);
        const inputNode = nodes[nodeName];
        if (inputNode.outputs != null) {
          const outputIndex = inputNode.outputs.indexOf(outputName);
          if (outputIndex !== -1) {
            const inputName = `${nodeName}:${outputIndex}`;
            node.inputNames[index] = inputName;
          }
        }
        node.inputs.push(inputNode);
        inputNode.children.push(node);
      });
    });
    const returnNodeMap = functionDef.ret;
    functionDef.signature.outputArg.forEach((output) => {
      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);
      const node = nodes[nodeName];
      if (node != null) {
        node.defaultOutput = index;
        outputs.push(node);
      }
    });
    const signature = this.mapArgsToSignature(functionDef);
    return { nodes, inputs, outputs, weights, placeholders, signature };
  }
  mapArgsToSignature(functionDef) {
    return {
      methodName: functionDef.signature.name,
      inputs: functionDef.signature.inputArg.reduce((map, arg) => {
        map[arg.name] = this.mapArgToTensorInfo(arg);
        return map;
      }, {}),
      outputs: functionDef.signature.outputArg.reduce((map, arg) => {
        map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);
        return map;
      }, {})
    };
  }
  mapArgToTensorInfo(arg, nameMap2) {
    let name = arg.name;
    if (nameMap2 != null) {
      name = nameMap2[name];
    }
    return { name, dtype: arg.type };
  }
};
function decodeBase64(text) {
  const global2 = env2().global;
  if (typeof global2.atob !== "undefined") {
    return global2.atob(text);
  } else if (typeof Buffer !== "undefined") {
    return new Buffer(text, "base64").toString();
  } else {
    throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
  }
}
function parseStringParam(s, keepCase) {
  const value = Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);
  return keepCase ? value : value.toLowerCase();
}
function getStringParam(attrs, name, def, keepCase = false) {
  const param = attrs[name];
  if (param != null) {
    return parseStringParam(param.s, keepCase);
  }
  return def;
}
function getBoolParam(attrs, name, def) {
  const param = attrs[name];
  return param ? param.b : def;
}
function getNumberParam(attrs, name, def) {
  const param = attrs[name] || {};
  const value = param["i"] != null ? param["i"] : param["f"] != null ? param["f"] : def;
  return typeof value === "number" ? value : parseInt(value, 10);
}
function parseDtypeParam(value) {
  if (typeof value === "string") {
    value = DataType8[value];
  }
  switch (value) {
    case DataType8.DT_FLOAT:
      return "float32";
    case DataType8.DT_INT32:
    case DataType8.DT_INT64:
    case DataType8.DT_INT8:
    case DataType8.DT_UINT8:
      return "int32";
    case DataType8.DT_BOOL:
      return "bool";
    case DataType8.DT_DOUBLE:
      return "float32";
    case DataType8.DT_STRING:
      return "string";
    default:
      return null;
  }
}
function getFuncParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.func) {
    return param.func.name;
  }
  return def;
}
function getDtypeParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.type) {
    return parseDtypeParam(param.type);
  }
  return def;
}
function getDtypeArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.type) {
    return param.list.type.map((v) => parseDtypeParam(v));
  }
  return def;
}
function parseTensorShapeParam(shape) {
  if (shape.unknownRank) {
    return void 0;
  }
  if (shape.dim != null) {
    return shape.dim.map((dim) => typeof dim.size === "number" ? dim.size : parseInt(dim.size, 10));
  }
  return [];
}
function getTensorShapeParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.shape) {
    return parseTensorShapeParam(param.shape);
  }
  return def;
}
function getNumericArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param) {
    return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || []).map((v) => typeof v === "number" ? v : parseInt(v, 10));
  }
  return def;
}
function getStringArrayParam(attrs, name, def, keepCase = false) {
  const param = attrs[name];
  if (param && param.list && param.list.s) {
    return param.list.s.map((v) => {
      return parseStringParam(v, keepCase);
    });
  }
  return def;
}
function getTensorShapeArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.shape) {
    return param.list.shape.map((v) => {
      return parseTensorShapeParam(v);
    });
  }
  return def;
}
function getBoolArrayParam(attrs, name, def) {
  const param = attrs[name];
  if (param && param.list && param.list.b) {
    return param.list.b;
  }
  return def;
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/custom_op/node_value_impl.ts
var NodeValueImpl = class {
  constructor(node, tensorMap, context) {
    this.node = node;
    this.tensorMap = tensorMap;
    this.context = context;
    this.inputs = [];
    this.attrs = {};
    this.inputs = node.inputNames.map((name) => this.getInput(name));
    if (node.rawAttrs != null) {
      this.attrs = Object.keys(node.rawAttrs).reduce((attrs, key) => {
        attrs[key] = this.getAttr(key);
        return attrs;
      }, {});
    }
  }
  getInput(name) {
    return getTensor(name, this.tensorMap, this.context);
  }
  getAttr(name, defaultValue) {
    const value = this.node.rawAttrs[name];
    if (value.tensor != null) {
      return getTensor(name, this.tensorMap, this.context);
    }
    if (value.i != null || value.f != null) {
      return getNumberParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.s != null) {
      return getStringParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.b != null) {
      return getBoolParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.shape != null) {
      return getTensorShapeParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.type != null) {
      return getDtypeParam(this.node.rawAttrs, name, defaultValue);
    }
    if (value.list != null) {
      if (value.list.i != null || value.list.f != null) {
        return getNumericArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.s != null) {
        return getStringArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.shape != null) {
        return getTensorShapeArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.b != null) {
        return getBoolArrayParam(this.node.rawAttrs, name, defaultValue);
      }
      if (value.list.type != null) {
        return getDtypeArrayParam(this.node.rawAttrs, name, defaultValue);
      }
    }
    return defaultValue;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/arithmetic_executor.ts
var executeOp = (node, tensorMap, context) => {
  switch (node.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add": {
      return [add4(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "AddN": {
      return [addN2(getParamValue("tensors", node, tensorMap, context))];
    }
    case "FloorMod":
    case "Mod":
      return [mod2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    case "Mul":
      return [mul2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    case "RealDiv":
    case "Div": {
      return [div2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "DivNoNan": {
      return [divNoNan2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "FloorDiv": {
      return [floorDiv2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Sub": {
      return [sub2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Minimum": {
      return [minimum2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Maximum": {
      return [maximum2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Pow": {
      return [pow2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "SquaredDifference": {
      return [squaredDifference2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/basic_math_executor.ts
var executeOp2 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Abs":
    case "ComplexAbs":
      return [abs2(getParamValue("x", node, tensorMap, context))];
    case "Acos":
      return [acos2(getParamValue("x", node, tensorMap, context))];
    case "Acosh":
      return [acosh2(getParamValue("x", node, tensorMap, context))];
    case "Asin":
      return [asin2(getParamValue("x", node, tensorMap, context))];
    case "Asinh":
      return [asinh2(getParamValue("x", node, tensorMap, context))];
    case "Atan":
      return [atan3(getParamValue("x", node, tensorMap, context))];
    case "Atan2":
      return [atan22(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
    case "Atanh":
      return [atanh2(getParamValue("x", node, tensorMap, context))];
    case "Ceil":
      return [ceil2(getParamValue("x", node, tensorMap, context))];
    case "Complex":
      return [complex2(getParamValue("real", node, tensorMap, context), getParamValue("imag", node, tensorMap, context))];
    case "Cos":
      return [cos2(getParamValue("x", node, tensorMap, context))];
    case "Cosh":
      return [cosh2(getParamValue("x", node, tensorMap, context))];
    case "Elu":
      return [elu2(getParamValue("x", node, tensorMap, context))];
    case "Erf":
      return [erf2(getParamValue("x", node, tensorMap, context))];
    case "Exp":
      return [exp2(getParamValue("x", node, tensorMap, context))];
    case "Expm1": {
      return [expm12(getParamValue("x", node, tensorMap, context))];
    }
    case "Floor":
      return [floor2(getParamValue("x", node, tensorMap, context))];
    case "Log":
      return [log3(getParamValue("x", node, tensorMap, context))];
    case "Log1p": {
      return [log1p2(getParamValue("x", node, tensorMap, context))];
    }
    case "Imag":
      return [imag2(getParamValue("x", node, tensorMap, context))];
    case "Neg":
      return [neg2(getParamValue("x", node, tensorMap, context))];
    case "Reciprocal": {
      return [reciprocal2(getParamValue("x", node, tensorMap, context))];
    }
    case "Real":
      return [real2(getParamValue("x", node, tensorMap, context))];
    case "Relu":
      return [relu2(getParamValue("x", node, tensorMap, context))];
    case "Round": {
      return [round4(getParamValue("x", node, tensorMap, context))];
    }
    case "Selu":
      return [selu2(getParamValue("x", node, tensorMap, context))];
    case "Sigmoid":
      return [sigmoid2(getParamValue("x", node, tensorMap, context))];
    case "Sin":
      return [sin2(getParamValue("x", node, tensorMap, context))];
    case "Sign": {
      return [sign2(getParamValue("x", node, tensorMap, context))];
    }
    case "Sinh": {
      return [sinh2(getParamValue("x", node, tensorMap, context))];
    }
    case "Softplus": {
      return [softplus2(getParamValue("x", node, tensorMap, context))];
    }
    case "Sqrt": {
      return [sqrt2(getParamValue("x", node, tensorMap, context))];
    }
    case "Square": {
      return [square2(getParamValue("x", node, tensorMap, context))];
    }
    case "Tanh": {
      return [tanh4(getParamValue("x", node, tensorMap, context))];
    }
    case "Tan":
      return [tan2(getParamValue("x", node, tensorMap, context))];
    case "ClipByValue":
      return [clipByValue2(getParamValue("x", node, tensorMap, context), getParamValue("clipValueMin", node, tensorMap, context), getParamValue("clipValueMax", node, tensorMap, context))];
    case "Relu6":
      return [relu62(getParamValue("x", node, tensorMap, context))];
    case "Rsqrt":
      return [rsqrt2(getTensor(node.inputNames[0], tensorMap, context))];
    case "Prod":
      return [prod2(getParamValue("x", node, tensorMap, context), getParamValue("axes", node, tensorMap, context))];
    case "LeakyRelu":
      return [leakyRelu2(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
    case "Prelu":
      return [prelu2(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
    case "IsNan":
      return [isNaN3(getTensor(node.inputNames[0], tensorMap, context))];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/tensor_utils.ts
function assertShapesMatchAllowUndefinedSize(shapeA, shapeB, errorMessagePrefix = "") {
  if (typeof shapeA === "number" || typeof shapeB === "number") {
    return;
  }
  util_exports2.assert(shapeA.length === shapeB.length, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  for (let i = 0; i < shapeA.length; i++) {
    const dim0 = shapeA[i];
    const dim1 = shapeB[i];
    util_exports2.assert(dim0 < 0 || dim1 < 0 || dim0 === dim1, () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
  }
}
function fullDefinedShape(elementShape) {
  if (typeof elementShape === "number" || elementShape.some((dim) => dim < 0)) {
    return false;
  }
  return true;
}
function inferElementShape(listElementShape, tensors, elementShape) {
  let partialShape = mergeElementShape(listElementShape, elementShape);
  const notfullDefinedShape = !fullDefinedShape(partialShape);
  if (notfullDefinedShape && tensors.length === 0) {
    throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${partialShape}`);
  }
  if (notfullDefinedShape) {
    tensors.forEach((tensor3) => {
      partialShape = mergeElementShape(tensor3.shape, partialShape);
    });
  }
  if (!fullDefinedShape(partialShape)) {
    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);
  }
  return partialShape;
}
function mergeElementShape(elementShapeA, elementShapeB) {
  if (typeof elementShapeA === "number") {
    return elementShapeB;
  }
  if (typeof elementShapeB === "number") {
    return elementShapeA;
  }
  if (elementShapeA.length !== elementShapeB.length) {
    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${elementShapeB}`);
  }
  const result = [];
  for (let i = 0; i < elementShapeA.length; ++i) {
    const dim0 = elementShapeA[i];
    const dim1 = elementShapeB[i];
    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {
      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${elementShapeB}`);
    }
    result[i] = dim0 >= 0 ? dim0 : dim1;
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/tensor_array.ts
var TensorArray = class {
  constructor(name, dtype, maxSize, elementShape, identicalElementShapes, dynamicSize, clearAfterRead) {
    this.name = name;
    this.dtype = dtype;
    this.maxSize = maxSize;
    this.elementShape = elementShape;
    this.identicalElementShapes = identicalElementShapes;
    this.dynamicSize = dynamicSize;
    this.clearAfterRead = clearAfterRead;
    this.tensors = [];
    this.closed_ = false;
    this.idTensor = scalar2(0);
    keep2(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  get closed() {
    return this.closed_;
  }
  clearAndClose(keepIds) {
    this.tensors.forEach((tensor3) => {
      if (keepIds == null || !keepIds.has(tensor3.tensor.id)) {
        tensor3.tensor.dispose();
      }
    });
    this.tensors = [];
    this.closed_ = true;
    this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  read(index) {
    if (this.closed_) {
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    }
    if (index < 0 || index >= this.size()) {
      throw new Error(`Tried to read from index ${index}, but array size is: ${this.size()}`);
    }
    const tensorWithState = this.tensors[index];
    if (tensorWithState.cleared) {
      throw new Error(`TensorArray ${this.name}: Could not read index ${index} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
    }
    if (this.clearAfterRead) {
      tensorWithState.cleared = true;
    }
    tensorWithState.read = true;
    return tensorWithState.tensor;
  }
  readMany(indices) {
    return indices.map((index) => this.read(index));
  }
  write(index, tensor3) {
    if (this.closed_) {
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    }
    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {
      throw new Error(`Tried to write to index ${index}, but array is not resizeable and size is: ${this.maxSize}`);
    }
    const t = this.tensors[index] || {};
    if (tensor3.dtype !== this.dtype) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index},
          because the value dtype is ${tensor3.dtype}, but TensorArray dtype is ${this.dtype}.`);
    }
    if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0)) {
      this.elementShape = tensor3.shape;
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensor3.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${index}.`);
    if (t.read) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been read.`);
    }
    if (t.written) {
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been written.`);
    }
    t.tensor = tensor3;
    keep2(tensor3);
    t.written = true;
    this.tensors[index] = t;
  }
  writeMany(indices, tensors) {
    if (indices.length !== tensors.length) {
      throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${indices.length} is not the same as tensors size: ${tensors.length}.`);
    }
    indices.forEach((i, index) => this.write(i, tensors[index]));
  }
  gather(indices, dtype) {
    if (!!dtype && dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${dtype}`);
    }
    if (!indices) {
      indices = [];
      for (let i = 0; i < this.size(); i++) {
        indices.push(i);
      }
    } else {
      indices = indices.slice(0, this.size());
    }
    if (indices.length === 0) {
      return tensor2([], [0].concat(this.elementShape));
    }
    const tensors = this.readMany(indices);
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: ");
    return stack2(tensors, 0);
  }
  concat(dtype) {
    if (!!dtype && dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${dtype}`);
    }
    if (this.size() === 0) {
      return tensor2([], [0].concat(this.elementShape));
    }
    const indices = [];
    for (let i = 0; i < this.size(); i++) {
      indices.push(i);
    }
    const tensors = this.readMany(indices);
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${tensors[0].shape})`);
    return concat2(tensors, 0);
  }
  scatter(indices, tensor3) {
    if (tensor3.dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor3.dtype}`);
    }
    if (indices.length !== tensor3.shape[0]) {
      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor3.shape[0]}`);
    }
    const maxIndex = Math.max(...indices);
    if (!this.dynamicSize && maxIndex >= this.maxSize) {
      throw new Error(`Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);
    }
    this.writeMany(indices, unstack2(tensor3, 0));
  }
  split(length, tensor3) {
    if (tensor3.dtype !== this.dtype) {
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor3.dtype}`);
    }
    let totalLength = 0;
    const cumulativeLengths = length.map((len) => {
      totalLength += len;
      return totalLength;
    });
    if (totalLength !== tensor3.shape[0]) {
      throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor3.shape}`);
    }
    if (!this.dynamicSize && length.length !== this.maxSize) {
      throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${length.length}), and the TensorArray is not marked as dynamically resizeable`);
    }
    const elementPerRow = totalLength === 0 ? 0 : tensor3.size / totalLength;
    const tensors = [];
    tidy2(() => {
      tensor3 = reshape2(tensor3, [1, totalLength, elementPerRow]);
      for (let i = 0; i < length.length; ++i) {
        const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
        const indices2 = [0, previousLength, 0];
        const sizes = [1, length[i], elementPerRow];
        tensors[i] = reshape2(slice2(tensor3, indices2, sizes), this.elementShape);
      }
      return tensors;
    });
    const indices = [];
    for (let i = 0; i < length.length; i++) {
      indices[i] = i;
    }
    this.writeMany(indices, tensors);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/tensor_list.ts
var TensorList = class {
  constructor(tensors, elementShape, elementDtype, maxNumElements = -1) {
    this.tensors = tensors;
    this.elementShape = elementShape;
    this.elementDtype = elementDtype;
    if (tensors != null) {
      tensors.forEach((tensor3) => {
        if (elementDtype !== tensor3.dtype) {
          throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${tensor3.dtype}`);
        }
        assertShapesMatchAllowUndefinedSize(elementShape, tensor3.shape, "TensorList shape mismatch: ");
        keep2(tensor3);
      });
    }
    this.idTensor = scalar2(0);
    this.maxNumElements = maxNumElements;
    keep2(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  copy() {
    return new TensorList([...this.tensors], this.elementShape, this.elementDtype);
  }
  clearAndClose(keepIds) {
    this.tensors.forEach((tensor3) => {
      if (keepIds == null || !keepIds.has(tensor3.id)) {
        tensor3.dispose();
      }
    });
    this.tensors.length = 0;
    this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  stack(elementShape, elementDtype, numElements = -1) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (numElements !== -1 && this.tensors.length !== numElements) {
      throw new Error(`Operation expected a list with ${numElements} elements but got a list with ${this.tensors.length} elements.`);
    }
    assertShapesMatchAllowUndefinedSize(elementShape, this.elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    return tidy2(() => {
      const reshapedTensors = this.tensors.map((tensor3) => reshape2(tensor3, outputElementShape));
      return stack2(reshapedTensors, 0);
    });
  }
  popBack(elementShape, elementDtype) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (this.size() === 0) {
      throw new Error("Trying to pop from an empty list.");
    }
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    const tensor3 = this.tensors.pop();
    assertShapesMatchAllowUndefinedSize(tensor3.shape, elementShape, "TensorList shape mismatch: ");
    return reshape2(tensor3, outputElementShape);
  }
  pushBack(tensor3) {
    if (tensor3.dtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${tensor3.dtype}, but list elements ${this.elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(tensor3.shape, this.elementShape, "TensorList shape mismatch: ");
    if (this.maxNumElements === this.size()) {
      throw new Error(`Trying to push element into a full list.`);
    }
    keep2(tensor3);
    this.tensors.push(tensor3);
  }
  resize(size) {
    if (size < 0) {
      throw new Error(`TensorListResize expects size to be non-negative. Got: ${size}`);
    }
    if (this.maxNumElements !== -1 && size > this.maxNumElements) {
      throw new Error(`TensorListResize input size ${size} is greater maxNumElement ${this.maxNumElements}.`);
    }
    this.tensors.length = size;
  }
  getItem(elementIndex, elementShape, elementDtype) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    if (elementIndex < 0 || elementIndex > this.tensors.length) {
      throw new Error(`Trying to access element ${elementIndex} in a list with ${this.tensors.length} elements.`);
    }
    if (this.tensors[elementIndex] == null) {
      throw new Error(`element at index ${elementIndex} is null.`);
    }
    assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape, elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    return reshape2(this.tensors[elementIndex], outputElementShape);
  }
  setItem(elementIndex, tensor3) {
    if (tensor3.dtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${tensor3.dtype}, but list elements ${this.elementDtype}`);
    }
    if (elementIndex < 0 || this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {
      throw new Error(`Trying to set element ${elementIndex} in a list with max ${this.maxNumElements} elements.`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, tensor3.shape, "TensorList shape mismatch: ");
    keep2(tensor3);
    this.tensors[elementIndex] = tensor3;
  }
  gather(indices, elementDtype, elementShape) {
    if (elementDtype !== this.elementDtype) {
      throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
    indices = indices.slice(0, this.size());
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    if (indices.length === 0) {
      return tensor2([], [0].concat(outputElementShape));
    }
    return tidy2(() => {
      const tensors = indices.map((i) => reshape2(this.tensors[i], outputElementShape));
      return stack2(tensors, 0);
    });
  }
  concat(elementDtype, elementShape) {
    if (!!elementDtype && elementDtype !== this.elementDtype) {
      throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${elementDtype}`);
    }
    assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
    const outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
    if (this.size() === 0) {
      return tensor2([], [0].concat(outputElementShape));
    }
    return tidy2(() => {
      const tensors = this.tensors.map((t) => reshape2(t, outputElementShape));
      return concat2(tensors, 0);
    });
  }
};
function fromTensor(tensor3, elementShape, elementDtype) {
  const dtype = tensor3.dtype;
  if (tensor3.shape.length < 1) {
    throw new Error(`Tensor must be at least a vector, but saw shape: ${tensor3.shape}`);
  }
  if (tensor3.dtype !== elementDtype) {
    throw new Error(`Invalid data types; op elements ${tensor3.dtype}, but list elements ${elementDtype}`);
  }
  const tensorElementShape = tensor3.shape.slice(1);
  assertShapesMatchAllowUndefinedSize(tensorElementShape, elementShape, "TensorList shape mismatch: ");
  const tensorList = unstack2(tensor3);
  return new TensorList(tensorList, elementShape, dtype);
}
function reserve(elementShape, elementDtype, numElements) {
  return new TensorList([], elementShape, elementDtype, numElements);
}
function scatter(tensor3, indices, elementShape, numElements) {
  if (indices.length !== tensor3.shape[0]) {
    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor3.shape[0]}`);
  }
  const maxIndex = Math.max(...indices);
  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {
    throw new Error(`Max index must be < array size (${maxIndex}  vs. ${numElements})`);
  }
  const list = new TensorList([], elementShape, tensor3.dtype, numElements);
  const tensors = unstack2(tensor3, 0);
  indices.forEach((value, index) => {
    list.setItem(value, tensors[index]);
  });
  return list;
}
function split3(tensor3, length, elementShape) {
  let totalLength = 0;
  const cumulativeLengths = length.map((len) => {
    totalLength += len;
    return totalLength;
  });
  if (totalLength !== tensor3.shape[0]) {
    throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${totalLength}, and tensor's shape is: ${tensor3.shape}`);
  }
  const shapeWithoutFirstDim = tensor3.shape.slice(1);
  const outputElementShape = mergeElementShape(shapeWithoutFirstDim, elementShape);
  const elementPerRow = totalLength === 0 ? 0 : tensor3.size / totalLength;
  const tensors = tidy2(() => {
    const tensors2 = [];
    tensor3 = reshape2(tensor3, [1, totalLength, elementPerRow]);
    for (let i = 0; i < length.length; ++i) {
      const previousLength = i === 0 ? 0 : cumulativeLengths[i - 1];
      const indices = [0, previousLength, 0];
      const sizes = [1, length[i], elementPerRow];
      tensors2[i] = reshape2(slice2(tensor3, indices, sizes), outputElementShape);
    }
    tensor3.dispose();
    return tensors2;
  });
  const list = new TensorList([], elementShape, tensor3.dtype, length.length);
  for (let i = 0; i < tensors.length; i++) {
    list.setItem(i, tensors[i]);
  }
  return list;
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/control_executor.ts
var executeOp3 = async (node, tensorMap, context) => {
  switch (node.op) {
    case "If":
    case "StatelessIf": {
      const thenFunc = getParamValue("thenBranch", node, tensorMap, context);
      const elseFunc = getParamValue("elseBranch", node, tensorMap, context);
      const cond = getParamValue("cond", node, tensorMap, context);
      const args = getParamValue("args", node, tensorMap, context);
      const condValue = await cond.data();
      if (condValue[0]) {
        return context.functionMap[thenFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      } else {
        return context.functionMap[elseFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      }
    }
    case "While":
    case "StatelessWhile": {
      const bodyFunc = getParamValue("body", node, tensorMap, context);
      const condFunc = getParamValue("cond", node, tensorMap, context);
      const args = getParamValue("args", node, tensorMap, context);
      const condResult = await context.functionMap[condFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap);
      const argIds = args.map((tensor3) => tensor3.id);
      let condValue = await condResult[0].data();
      condResult.forEach((tensor3) => {
        if (!tensor3.kept && argIds.indexOf(tensor3.id) === -1) {
          tensor3.dispose();
        }
      });
      let result = args;
      while (condValue[0]) {
        const origResult = result;
        result = await context.functionMap[bodyFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
        const resultIds = result.map((tensor3) => tensor3.id);
        origResult.forEach((tensor3) => {
          if (!tensor3.kept && argIds.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
            tensor3.dispose();
          }
        });
        const condResult2 = await context.functionMap[condFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap);
        condValue = await condResult2[0].data();
        condResult2.forEach((tensor3) => {
          if (!tensor3.kept && argIds.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
            tensor3.dispose();
          }
        });
      }
      return result;
    }
    case "LoopCond": {
      const pred = getParamValue("pred", node, tensorMap, context);
      return [cloneTensor(pred)];
    }
    case "Switch": {
      const pred = getParamValue("pred", node, tensorMap, context);
      let data = getParamValue("data", node, tensorMap, context);
      if (!data.kept) {
        data = cloneTensor(data);
      }
      return (await pred.data())[0] ? [void 0, data] : [data, void 0];
    }
    case "Merge": {
      const inputName = node.inputNames.find((name) => getTensor(name, tensorMap, context) !== void 0);
      if (inputName) {
        const data = getTensor(inputName, tensorMap, context);
        return [cloneTensor(data)];
      }
      return void 0;
    }
    case "Enter": {
      const frameId = getParamValue("frameName", node, tensorMap, context);
      const data = getParamValue("tensor", node, tensorMap, context);
      context.enterFrame(frameId);
      return [cloneTensor(data)];
    }
    case "Exit": {
      const data = getParamValue("tensor", node, tensorMap, context);
      context.exitFrame();
      return [cloneTensor(data)];
    }
    case "NextIteration": {
      const data = getParamValue("tensor", node, tensorMap, context);
      context.nextIteration();
      return [cloneTensor(data)];
    }
    case "TensorArrayV3": {
      const size = getParamValue("size", node, tensorMap, context);
      const dtype = getParamValue("dtype", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const dynamicSize = getParamValue("dynamicSize", node, tensorMap, context);
      const clearAfterRead = getParamValue("clearAfterRead", node, tensorMap, context);
      const identicalElementShapes = getParamValue("identicalElementShapes", node, tensorMap, context);
      const name = getParamValue("name", node, tensorMap, context);
      const tensorArray = new TensorArray(name, dtype, size, elementShape, identicalElementShapes, dynamicSize, clearAfterRead);
      context.addTensorArray(tensorArray);
      return [tensorArray.idTensor, scalar2(1)];
    }
    case "TensorArrayWriteV3": {
      const id = getParamValue("tensorArrayId", node, tensorMap, context);
      const index = getParamValue("index", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const writeTensorArray = context.getTensorArray(id.id);
      writeTensorArray.write(index, writeTensor);
      return [writeTensorArray.idTensor];
    }
    case "TensorArrayReadV3": {
      const readId = getParamValue("tensorArrayId", node, tensorMap, context);
      const readIndex = getParamValue("index", node, tensorMap, context);
      const readTensorArray = context.getTensorArray(readId.id);
      return [readTensorArray.read(readIndex)];
    }
    case "TensorArrayGatherV3": {
      const gatherId = getParamValue("tensorArrayId", node, tensorMap, context);
      const gatherIndices = getParamValue("indices", node, tensorMap, context);
      const gatherDtype = getParamValue("dtype", node, tensorMap, context);
      const gatherTensorArray = context.getTensorArray(gatherId.id);
      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];
    }
    case "TensorArrayScatterV3": {
      const scatterId = getParamValue("tensorArrayId", node, tensorMap, context);
      const scatterIndices = getParamValue("indices", node, tensorMap, context);
      const scatterTensor = getParamValue("tensor", node, tensorMap, context);
      const scatterTensorArray = context.getTensorArray(scatterId.id);
      scatterTensorArray.scatter(scatterIndices, scatterTensor);
      return [scatterTensorArray.idTensor];
    }
    case "TensorArrayConcatV3": {
      const concatId = getParamValue("tensorArrayId", node, tensorMap, context);
      const concatTensorArray = context.getTensorArray(concatId.id);
      const concatDtype = getParamValue("dtype", node, tensorMap, context);
      return [concatTensorArray.concat(concatDtype)];
    }
    case "TensorArraySplitV3": {
      const splitId = getParamValue("tensorArrayId", node, tensorMap, context);
      const splitTensor = getParamValue("tensor", node, tensorMap, context);
      const lengths = getParamValue("lengths", node, tensorMap, context);
      const splitTensorArray = context.getTensorArray(splitId.id);
      splitTensorArray.split(lengths, splitTensor);
      return [splitTensorArray.idTensor];
    }
    case "TensorArraySizeV3": {
      const sizeId = getParamValue("tensorArrayId", node, tensorMap, context);
      const sizeTensorArray = context.getTensorArray(sizeId.id);
      return [scalar2(sizeTensorArray.size(), "int32")];
    }
    case "TensorArrayCloseV3": {
      const closeId = getParamValue("tensorArrayId", node, tensorMap, context);
      const closeTensorArray = context.getTensorArray(closeId.id);
      closeTensorArray.clearAndClose();
      return [closeTensorArray.idTensor];
    }
    case "TensorListSetItem": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const index = getParamValue("index", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      tensorList.setItem(index, writeTensor);
      return [tensorList.idTensor];
    }
    case "TensorListGetItem": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const readIndex = getParamValue("index", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDType = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.getItem(readIndex, elementShape, elementDType)];
    }
    case "TensorListScatterV2":
    case "TensorListScatter": {
      const scatterIndices = getParamValue("indices", node, tensorMap, context);
      const scatterTensor = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const numElements = getParamValue("numElements", node, tensorMap, context);
      const tensorList = scatter(scatterTensor, scatterIndices, elementShape, numElements);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListReserve":
    case "EmptyTensorList": {
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      let numElementsParam;
      if (node.op === "TensorListReserve") {
        numElementsParam = "numElements";
      } else {
        numElementsParam = "maxNumElements";
      }
      const numElements = getParamValue(numElementsParam, node, tensorMap, context);
      const tensorList = reserve(elementShape, elementDtype, numElements);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListGather": {
      const gatherId = getParamValue("tensorListId", node, tensorMap, context);
      const gatherIndices = getParamValue("indices", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(gatherId.id);
      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];
    }
    case "TensorListStack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const numElements = getParamValue("numElements", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.stack(elementShape, elementDtype, numElements)];
    }
    case "TensorListFromTensor": {
      const tensor3 = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDtype = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = fromTensor(tensor3, elementShape, elementDtype);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    case "TensorListConcat": {
      const concatId = getParamValue("tensorListId", node, tensorMap, context);
      const tensorList = context.getTensorList(concatId.id);
      const concatDtype = getParamValue("dtype", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      return [tensorList.concat(concatDtype, elementShape)];
    }
    case "TensorListPushBack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const writeTensor = getParamValue("tensor", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      tensorList.pushBack(writeTensor);
      return [tensorList.idTensor];
    }
    case "TensorListPopBack": {
      const idTensor = getParamValue("tensorListId", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const elementDType = getParamValue("elementDType", node, tensorMap, context);
      const tensorList = context.getTensorList(idTensor.id);
      return [tensorList.popBack(elementShape, elementDType)];
    }
    case "TensorListSplit": {
      const splitTensor = getParamValue("tensor", node, tensorMap, context);
      const elementShape = getParamValue("elementShape", node, tensorMap, context);
      const lengths = getParamValue("lengths", node, tensorMap, context);
      const tensorList = split3(splitTensor, lengths, elementShape);
      context.addTensorList(tensorList);
      return [tensorList.idTensor];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/convolution_executor.ts
function fusedConvAndDepthWiseParams(node, tensorMap, context) {
  const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
  const isBiasAdd = extraOp === "biasadd";
  const noBiasAdd = !isBiasAdd;
  const isPrelu = activationFunc === "prelu";
  const isBatchNorm = extraOp === "fusedbatchnorm";
  const numArgs = getParamValue("numArgs", node, tensorMap, context);
  if (isBiasAdd) {
    if (isPrelu && numArgs !== 2) {
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    }
    if (!isPrelu && isBiasAdd && numArgs !== 1) {
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
    }
  }
  if (isBatchNorm) {
    throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  }
  const stride = getParamValue("strides", node, tensorMap, context);
  const pad4 = getPadding(node, tensorMap, context);
  const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
  const dilations = getParamValue("dilations", node, tensorMap, context);
  let [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
  if (noBiasAdd) {
    preluArg = biasArg;
    biasArg = void 0;
  }
  const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
  return {
    stride,
    pad: pad4,
    dataFormat,
    dilations,
    biasArg,
    preluArg,
    activationFunc,
    leakyreluAlpha
  };
}
var executeOp4 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Conv1D": {
      const stride = getParamValue("stride", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilation = getParamValue("dilation", node, tensorMap, context);
      return [conv1d2(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), stride, pad4, dataFormat, dilation)];
    }
    case "Conv2D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getPadding(node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilations = getParamValue("dilations", node, tensorMap, context);
      return [conv2d3(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad4, dataFormat, [dilations[1], dilations[2]])];
    }
    case "_FusedConv2D": {
      const {
        stride,
        pad: pad4,
        dataFormat,
        dilations,
        biasArg,
        preluArg,
        activationFunc,
        leakyreluAlpha
      } = fusedConvAndDepthWiseParams(node, tensorMap, context);
      return [fused_ops_exports2.conv2d({
        x: getParamValue("x", node, tensorMap, context),
        filter: getParamValue("filter", node, tensorMap, context),
        strides: [stride[1], stride[2]],
        pad: pad4,
        dataFormat,
        dilations: [dilations[1], dilations[2]],
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    }
    case "FusedDepthwiseConv2dNative": {
      const {
        stride,
        pad: pad4,
        dataFormat,
        dilations,
        biasArg,
        preluArg,
        activationFunc,
        leakyreluAlpha
      } = fusedConvAndDepthWiseParams(node, tensorMap, context);
      return [fused_ops_exports2.depthwiseConv2d({
        x: getParamValue("x", node, tensorMap, context),
        filter: getParamValue("filter", node, tensorMap, context),
        strides: [stride[1], stride[2]],
        pad: pad4,
        dataFormat,
        dilations: [dilations[1], dilations[2]],
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    }
    case "Conv2DBackpropInput":
    case "Conv2dTranspose": {
      const shape = getParamValue("outputShape", node, tensorMap, context);
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getPadding(node, tensorMap, context);
      return [conv2dTranspose2(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), shape, [stride[1], stride[2]], pad4)];
    }
    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getPadding(node, tensorMap, context);
      const dilations = getParamValue("dilations", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      return [depthwiseConv2d3(getParamValue("input", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad4, dataFormat, [dilations[1], dilations[2]])];
    }
    case "Conv3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      const dilations = getParamValue("dilations", node, tensorMap, context);
      return [conv3d2(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2], stride[3]], pad4, dataFormat, [dilations[1], dilations[2], dilations[3]])];
    }
    case "AvgPool": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [avgPool2(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad4)];
    }
    case "MaxPool": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [maxPool2(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad4)];
    }
    case "MaxPoolWithArgmax": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      const includeBatchInIndex = getParamValue("includeBatchInIndex", node, tensorMap, context);
      const { result, indexes } = maxPoolWithArgmax2(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad4, includeBatchInIndex);
      return [result, indexes];
    }
    case "AvgPool3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [avgPool3d2(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad4)];
    }
    case "MaxPool3D": {
      const stride = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const kernelSize = getParamValue("kernelSize", node, tensorMap, context);
      return [maxPool3d2(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad4)];
    }
    case "Dilation2D": {
      const strides = getParamValue("strides", node, tensorMap, context);
      const pad4 = getParamValue("pad", node, tensorMap, context);
      const dilations = getParamValue("dilations", node, tensorMap, context);
      const strideHeight = strides[1];
      const strideWidth = strides[2];
      const dilationHeight = dilations[1];
      const dilationWidth = dilations[2];
      return [dilation2d2(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [strideHeight, strideWidth], pad4, [dilationHeight, dilationWidth], "NHWC")];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/creation_executor.ts
var executeOp5 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Fill": {
      const shape = getParamValue("shape", node, tensorMap, context);
      const dtype = getParamValue("dtype", node, tensorMap, context);
      const value = getParamValue("value", node, tensorMap, context);
      return [fill2(shape, value, dtype)];
    }
    case "LinSpace": {
      const start = getParamValue("start", node, tensorMap, context);
      const stop = getParamValue("stop", node, tensorMap, context);
      const num = getParamValue("num", node, tensorMap, context);
      return [linspace2(start, stop, num)];
    }
    case "Multinomial": {
      const logits = getParamValue("logits", node, tensorMap, context);
      const numSamples = getParamValue("numSamples", node, tensorMap, context);
      const seed = getParamValue("seed", node, tensorMap, context);
      return [multinomial2(logits, numSamples, seed)];
    }
    case "OneHot": {
      const indices = getParamValue("indices", node, tensorMap, context);
      const depth = getParamValue("depth", node, tensorMap, context);
      const onValue = getParamValue("onValue", node, tensorMap, context);
      const offValue = getParamValue("offValue", node, tensorMap, context);
      return [oneHot2(indices, depth, onValue, offValue)];
    }
    case "Ones": {
      return [ones4(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "OnesLike": {
      return [onesLike2(getParamValue("x", node, tensorMap, context))];
    }
    case "RandomUniform": {
      return [randomUniform2(getParamValue("shape", node, tensorMap, context), getParamValue("minval", node, tensorMap, context), getParamValue("maxval", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "Range": {
      const start = getParamValue("start", node, tensorMap, context);
      const stop = getParamValue("stop", node, tensorMap, context);
      const step6 = getParamValue("step", node, tensorMap, context);
      return [range2(start, stop, step6, getParamValue("dtype", node, tensorMap, context))];
    }
    case "TruncatedNormal": {
      const shape = getParamValue("shape", node, tensorMap, context);
      const mean5 = getParamValue("mean", node, tensorMap, context);
      const stdDev = getParamValue("stdDev", node, tensorMap, context);
      const seed = getParamValue("seed", node, tensorMap, context);
      return [truncatedNormal2(shape, mean5, stdDev, getParamValue("dtype", node, tensorMap, context), seed)];
    }
    case "Zeros": {
      return [zeros2(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "ZerosLike": {
      return [zerosLike2(getParamValue("x", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/dynamic_executor.ts
function nmsParams(node, tensorMap, context) {
  const boxes = getParamValue("boxes", node, tensorMap, context);
  const scores = getParamValue("scores", node, tensorMap, context);
  const maxOutputSize = getParamValue("maxOutputSize", node, tensorMap, context);
  const iouThreshold = getParamValue("iouThreshold", node, tensorMap, context);
  const scoreThreshold = getParamValue("scoreThreshold", node, tensorMap, context);
  const softNmsSigma = getParamValue("softNmsSigma", node, tensorMap, context);
  return {
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma
  };
}
var executeOp6 = async (node, tensorMap, context) => {
  switch (node.op) {
    case "NonMaxSuppressionV5": {
      const {
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma
      } = nmsParams(node, tensorMap, context);
      const result = await image2.nonMaxSuppressionWithScoreAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      return [result.selectedIndices, result.selectedScores];
    }
    case "NonMaxSuppressionV4": {
      const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
      const padToMaxOutputSize = getParamValue("padToMaxOutputSize", node, tensorMap, context);
      const result = await image2.nonMaxSuppressionPaddedAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
      return [result.selectedIndices, result.validOutputs];
    }
    case "NonMaxSuppressionV3":
    case "NonMaxSuppressionV2": {
      const { boxes, scores, maxOutputSize, iouThreshold, scoreThreshold } = nmsParams(node, tensorMap, context);
      return [await image2.nonMaxSuppressionAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold)];
    }
    case "Where": {
      const condition = cast2(getParamValue("condition", node, tensorMap, context), "bool");
      const result = [await whereAsync2(condition)];
      condition.dispose();
      return result;
    }
    case "ListDiff": {
      return setdiff1dAsync2(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context));
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/evaluation_executor.ts
var executeOp7 = (node, tensorMap, context) => {
  switch (node.op) {
    case "TopKV2": {
      const x = getParamValue("x", node, tensorMap, context);
      const k = getParamValue("k", node, tensorMap, context);
      const sorted = getParamValue("sorted", node, tensorMap, context);
      const result = topk2(x, k, sorted);
      return [result.values, result.indices];
    }
    case "Unique": {
      const x = getParamValue("x", node, tensorMap, context);
      const result = unique2(x);
      return [result.values, result.indices];
    }
    case "UniqueV2": {
      const x = getParamValue("x", node, tensorMap, context);
      const axis = getParamValue("axis", node, tensorMap, context);
      const result = unique2(x, axis);
      return [result.values, result.indices];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/graph_executor.ts
var executeOp8 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Const": {
      return tensorMap[node.name];
    }
    case "PlaceholderWithDefault":
      const def = getParamValue("default", node, tensorMap, context);
      return [getTensor(node.name, tensorMap, context) || def];
    case "Placeholder":
      return [getTensor(node.name, tensorMap, context)];
    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars": {
      const data2 = getParamValue("x", node, tensorMap, context);
      return [cloneTensor(data2)];
    }
    case "IdentityN":
      return getParamValue("x", node, tensorMap, context).map((t) => cloneTensor(t));
    case "Snapshot":
      const snapshot = getParamValue("x", node, tensorMap, context);
      return [cloneTensor(snapshot)];
    case "Shape":
      return [tensor1d2(getParamValue("x", node, tensorMap, context).shape, "int32")];
    case "ShapeN":
      return getParamValue("x", node, tensorMap, context).map((t) => tensor1d2(t.shape));
    case "Size":
      return [scalar2(getParamValue("x", node, tensorMap, context).size, "int32")];
    case "Rank":
      return [scalar2(getParamValue("x", node, tensorMap, context).rank, "int32")];
    case "NoOp":
      return [scalar2(1)];
    case "Print":
      const input2 = getParamValue("x", node, tensorMap, context);
      const data = getParamValue("data", node, tensorMap, context);
      const message = getParamValue("message", node, tensorMap, context);
      const summarize = getParamValue("summarize", node, tensorMap, context);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance.");
      console.log(message);
      for (let i = 0; i < data.length; i++) {
        console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));
      }
      return [input2];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/hash_table.ts
var HashTable = class {
  constructor(keyDType, valueDType) {
    this.keyDType = keyDType;
    this.valueDType = valueDType;
    this.handle = scalar2(0);
    this.tensorMap = new Map();
    keep2(this.handle);
  }
  get id() {
    return this.handle.id;
  }
  clearAndClose() {
    this.tensorMap.forEach((value) => value.dispose());
    this.tensorMap.clear();
    this.handle.dispose();
  }
  size() {
    return this.tensorMap.size;
  }
  tensorSize() {
    return scalar2(this.size(), "int32");
  }
  async import(keys, values) {
    this.checkKeyAndValueTensor(keys, values);
    const $keys = await keys.data();
    this.tensorMap.forEach((value) => value.dispose());
    this.tensorMap.clear();
    return tidy2(() => {
      const $values = unstack2(values);
      const keysLength = $keys.length;
      const valuesLength = $values.length;
      util_exports2.assert(keysLength === valuesLength, () => `The number of elements doesn't match, keys has ${keysLength} elements, the values has ${valuesLength} elements.`);
      for (let i = 0; i < keysLength; i++) {
        const key = $keys[i];
        const value = $values[i];
        keep2(value);
        this.tensorMap.set(key, value);
      }
      return this.handle;
    });
  }
  async find(keys, defaultValue) {
    this.checkKeyAndValueTensor(keys, defaultValue);
    const $keys = await keys.data();
    return tidy2(() => {
      const result = [];
      for (let i = 0; i < $keys.length; i++) {
        const key = $keys[i];
        const value = this.findWithDefault(key, defaultValue);
        result.push(value);
      }
      return stack2(result);
    });
  }
  findWithDefault(key, defaultValue) {
    const result = this.tensorMap.get(key);
    return result != null ? result : defaultValue;
  }
  checkKeyAndValueTensor(key, value) {
    if (key.dtype !== this.keyDType) {
      throw new Error(`Expect key dtype ${this.keyDType}, but got ${key.dtype}`);
    }
    if (value.dtype !== this.valueDType) {
      throw new Error(`Expect value dtype ${this.valueDType}, but got ${value.dtype}`);
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/hash_table_executor.ts
var executeOp9 = async (node, tensorMap, context, resourceManager) => {
  switch (node.op) {
    case "HashTable":
    case "HashTableV2": {
      const keyDType = getParamValue("keyDType", node, tensorMap, context);
      const valueDType = getParamValue("valueDType", node, tensorMap, context);
      const hashTable2 = new HashTable(keyDType, valueDType);
      resourceManager.addHashTable(node.name, hashTable2);
      return [hashTable2.handle];
    }
    case "LookupTableImport":
    case "LookupTableImportV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const keys = getParamValue("keys", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      const hashTable2 = resourceManager.getHashTableById(handle.id);
      return [await hashTable2.import(keys, values)];
    }
    case "LookupTableFind":
    case "LookupTableFindV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const keys = getParamValue("keys", node, tensorMap, context);
      const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
      const hashTable2 = resourceManager.getHashTableById(handle.id);
      return [await hashTable2.find(keys, defaultValue)];
    }
    case "LookupTableSize":
    case "LookupTableSizeV2": {
      const handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
      const hashTable2 = resourceManager.getHashTableById(handle.id);
      return [hashTable2.tensorSize()];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/image_executor.ts
var executeOp10 = (node, tensorMap, context) => {
  switch (node.op) {
    case "ResizeBilinear": {
      const images = getParamValue("images", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
      const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
      return [image2.resizeBilinear(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
    }
    case "ResizeNearestNeighbor": {
      const images = getParamValue("images", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      const alignCorners = getParamValue("alignCorners", node, tensorMap, context);
      const halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
      return [image2.resizeNearestNeighbor(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
    }
    case "CropAndResize": {
      const image4 = getParamValue("image", node, tensorMap, context);
      const boxes = getParamValue("boxes", node, tensorMap, context);
      const boxInd = getParamValue("boxInd", node, tensorMap, context);
      const cropSize = getParamValue("cropSize", node, tensorMap, context);
      const method = getParamValue("method", node, tensorMap, context);
      const extrapolationValue = getParamValue("extrapolationValue", node, tensorMap, context);
      return [image2.cropAndResize(image4, boxes, boxInd, cropSize, method, extrapolationValue)];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/logical_executor.ts
var executeOp11 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Equal": {
      return [equal2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "NotEqual": {
      return [notEqual2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Greater": {
      return [greater2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "GreaterEqual": {
      return [greaterEqual2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Less": {
      return [less2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LessEqual": {
      return [lessEqual2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LogicalAnd": {
      return [logicalAnd2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "LogicalNot": {
      return [logicalNot2(getParamValue("a", node, tensorMap, context))];
    }
    case "LogicalOr": {
      return [logicalOr2(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    case "Select":
    case "SelectV2": {
      return [where2(getParamValue("condition", node, tensorMap, context), getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/matrices_executor.ts
var executeOp12 = (node, tensorMap, context) => {
  switch (node.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [matMul3(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context), getParamValue("transposeA", node, tensorMap, context), getParamValue("transposeB", node, tensorMap, context))];
    case "Einsum":
      return [einsum2(getParamValue("equation", node, tensorMap, context), ...getParamValue("tensors", node, tensorMap, context))];
    case "Transpose":
      return [transpose2(getParamValue("x", node, tensorMap, context), getParamValue("perm", node, tensorMap, context))];
    case "_FusedMatMul":
      const [extraOp, activationFunc] = getParamValue("fusedOps", node, tensorMap, context);
      const isBiasAdd = extraOp === "biasadd";
      const isPrelu = activationFunc === "prelu";
      const numArgs = getParamValue("numArgs", node, tensorMap, context);
      const leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
      if (isBiasAdd) {
        if (isPrelu && numArgs !== 2) {
          throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        }
        if (!isPrelu && numArgs !== 1) {
          throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
        }
      }
      const [biasArg, preluArg] = getParamValue("args", node, tensorMap, context);
      return [fused_ops_exports2.matMul({
        a: getParamValue("a", node, tensorMap, context),
        b: getParamValue("b", node, tensorMap, context),
        transposeA: getParamValue("transposeA", node, tensorMap, context),
        transposeB: getParamValue("transposeB", node, tensorMap, context),
        bias: biasArg,
        activation: activationFunc,
        preluActivationWeights: preluArg,
        leakyreluAlpha
      })];
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/normalization_executor.ts
var executeOp13 = (node, tensorMap, context) => {
  switch (node.op) {
    case "FusedBatchNorm":
    case "FusedBatchNormV2": {
      return [batchNorm2(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
    }
    case "FusedBatchNormV3": {
      return [batchNorm2(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
    }
    case "LRN": {
      return [localResponseNormalization2(getParamValue("x", node, tensorMap, context), getParamValue("radius", node, tensorMap, context), getParamValue("bias", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context), getParamValue("beta", node, tensorMap, context))];
    }
    case "Softmax": {
      return [softmax2(getParamValue("x", node, tensorMap, context))];
    }
    case "LogSoftmax": {
      return [logSoftmax2(getParamValue("x", node, tensorMap, context))];
    }
    case "SparseToDense": {
      return [sparseToDense2(getParamValue("sparseIndices", node, tensorMap, context), getParamValue("outputShape", node, tensorMap, context), getParamValue("sparseValues", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/reduction_executor.ts
var executeOp14 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Max": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [max2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Mean": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [mean2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Min": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [min2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Sum": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [sum4(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "All": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [all2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Any": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [any2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "ArgMax": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [argMax2(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "ArgMin": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [argMin2(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Prod": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const keepDims = getParamValue("keepDims", node, tensorMap, context);
      return [prod2(getParamValue("x", node, tensorMap, context), axis, keepDims)];
    }
    case "Cumsum": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const exclusive = getParamValue("exclusive", node, tensorMap, context);
      const reverse6 = getParamValue("reverse", node, tensorMap, context);
      return [cumsum2(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse6)];
    }
    case "Bincount":
      const x = getParamValue("x", node, tensorMap, context);
      const weights = getParamValue("weights", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      return [bincount2(x, weights, size)];
    case "DenseBincount": {
      const x2 = getParamValue("x", node, tensorMap, context);
      const weights2 = getParamValue("weights", node, tensorMap, context);
      const size2 = getParamValue("size", node, tensorMap, context);
      const binaryOutput = getParamValue("binaryOutput", node, tensorMap, context);
      return [denseBincount2(x2, weights2, size2, binaryOutput)];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/slice_join_executor.ts
var executeOp15 = (node, tensorMap, context) => {
  switch (node.op) {
    case "ConcatV2":
    case "Concat": {
      const n = getParamValue("n", node, tensorMap, context);
      const axis = getParamValue("axis", node, tensorMap, context);
      let inputs = getParamValue("tensors", node, tensorMap, context);
      inputs = inputs.slice(0, n);
      return [concat2(inputs, axis)];
    }
    case "Gather": {
      const input2 = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [gather2(input2, cast2(indices, "int32"), 0)];
    }
    case "GatherV2": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const batchDims = getParamValue("batchDims", node, tensorMap, context);
      const input2 = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [gather2(input2, cast2(indices, "int32"), axis, batchDims)];
    }
    case "Reverse": {
      const dims = getParamValue("dims", node, tensorMap, context);
      const axis = [];
      for (let i = 0; i < dims.length; i++) {
        if (dims[i]) {
          axis.push(i);
        }
      }
      const input2 = getParamValue("x", node, tensorMap, context);
      return [reverse2(input2, axis)];
    }
    case "ReverseV2": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const input2 = getParamValue("x", node, tensorMap, context);
      return [reverse2(input2, axis)];
    }
    case "Slice": {
      const begin = getParamValue("begin", node, tensorMap, context);
      const size = getParamValue("size", node, tensorMap, context);
      return [slice2(getParamValue("x", node, tensorMap, context), begin, size)];
    }
    case "StridedSlice": {
      const begin = getParamValue("begin", node, tensorMap, context);
      const end = getParamValue("end", node, tensorMap, context);
      const strides = getParamValue("strides", node, tensorMap, context);
      const beginMask = getParamValue("beginMask", node, tensorMap, context);
      const endMask = getParamValue("endMask", node, tensorMap, context);
      const ellipsisMask = getParamValue("ellipsisMask", node, tensorMap, context);
      const newAxisMask = getParamValue("newAxisMask", node, tensorMap, context);
      const shrinkAxisMask = getParamValue("shrinkAxisMask", node, tensorMap, context);
      const tensor3 = getParamValue("x", node, tensorMap, context);
      return [stridedSlice2(tensor3, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask)];
    }
    case "Pack": {
      return tidy2(() => {
        const axis = getParamValue("axis", node, tensorMap, context);
        const tensors = getParamValue("tensors", node, tensorMap, context);
        const shape = tensors[0].shape;
        const squeezedShape = squeeze2(tensors[0]).shape;
        const mapped = tensors.map((tensor3) => {
          const sameShape = util_exports2.arraysEqual(tensor3.shape, shape);
          if (!sameShape && !util_exports2.arraysEqual(squeeze2(tensor3).shape, squeezedShape)) {
            throw new Error("the input tensors shape does not match");
          }
          return sameShape ? tensor3 : reshape2(tensor3, shape);
        });
        return [stack2(mapped, axis)];
      });
    }
    case "Unpack": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const tensor3 = getParamValue("tensor", node, tensorMap, context);
      return unstack2(tensor3, axis);
    }
    case "Tile": {
      const reps = getParamValue("reps", node, tensorMap, context);
      return [tile2(getParamValue("x", node, tensorMap, context), reps)];
    }
    case "Split":
    case "SplitV": {
      const axis = getParamValue("axis", node, tensorMap, context);
      const numOrSizeSplits = getParamValue("numOrSizeSplits", node, tensorMap, context);
      const tensor3 = getParamValue("x", node, tensorMap, context);
      return split2(tensor3, numOrSizeSplits, axis);
    }
    case "ScatterNd": {
      const indices = getParamValue("indices", node, tensorMap, context);
      const values = getParamValue("values", node, tensorMap, context);
      const shape = getParamValue("shape", node, tensorMap, context);
      return [scatterND2(indices, values, shape)];
    }
    case "GatherNd": {
      const x = getParamValue("x", node, tensorMap, context);
      const indices = getParamValue("indices", node, tensorMap, context);
      return [gatherND2(x, indices)];
    }
    case "SparseToDense": {
      const indices = getParamValue("sparseIndices", node, tensorMap, context);
      const shape = getParamValue("outputShape", node, tensorMap, context);
      const sparseValues = getParamValue("sparseValues", node, tensorMap, context);
      const defaultValue = getParamValue("defaultValue", node, tensorMap, context);
      return [sparseToDense2(indices, sparseValues, shape, sparseValues.dtype === defaultValue.dtype ? defaultValue : cast2(defaultValue, sparseValues.dtype))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/sparse_executor.ts
var executeOp16 = (node, tensorMap, context) => {
  switch (node.op) {
    case "SparseFillEmptyRows": {
      const {
        outputIndices,
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      } = sparse2.sparseFillEmptyRows(getParamValue("indices", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("denseShape", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context));
      return [
        outputIndices,
        outputValues,
        emptyRowIndicator,
        reverseIndexMap
      ];
    }
    case "SparseReshape": {
      const { outputIndices, outputShape } = sparse2.sparseReshape(getParamValue("inputIndices", node, tensorMap, context), getParamValue("inputShape", node, tensorMap, context), getParamValue("newShape", node, tensorMap, context));
      return [outputIndices, outputShape];
    }
    case "SparseSegmentMean": {
      const outputData = sparse2.sparseSegmentMean(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
      return [outputData];
    }
    case "SparseSegmentSum": {
      const outputData = sparse2.sparseSegmentSum(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
      return [outputData];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/spectral_executor.ts
var executeOp17 = (node, tensorMap, context) => {
  switch (node.op) {
    case "FFT": {
      return [fft2(getParamValue("x", node, tensorMap, context))];
    }
    case "IFFT": {
      return [ifft2(getParamValue("x", node, tensorMap, context))];
    }
    case "RFFT": {
      return [rfft2(getParamValue("x", node, tensorMap, context))];
    }
    case "IRFFT": {
      return [irfft2(getParamValue("x", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/string_executor.ts
var executeOp18 = (node, tensorMap, context) => {
  switch (node.op) {
    case "StringNGrams": {
      const { nGrams, nGramsSplits } = string2.stringNGrams(getParamValue("data", node, tensorMap, context), getParamValue("dataSplits", node, tensorMap, context), getParamValue("separator", node, tensorMap, context), getParamValue("nGramWidths", node, tensorMap, context), getParamValue("leftPad", node, tensorMap, context), getParamValue("rightPad", node, tensorMap, context), getParamValue("padWidth", node, tensorMap, context), getParamValue("preserveShortSequences", node, tensorMap, context));
      return [nGrams, nGramsSplits];
    }
    case "StringSplit": {
      const { indices, values, shape } = string2.stringSplit(getParamValue("input", node, tensorMap, context), getParamValue("delimiter", node, tensorMap, context), getParamValue("skipEmpty", node, tensorMap, context));
      return [indices, values, shape];
    }
    case "StringToHashBucketFast": {
      const output = string2.stringToHashBucketFast(getParamValue("input", node, tensorMap, context), getParamValue("numBuckets", node, tensorMap, context));
      return [output];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/executors/transformation_executor.ts
var executeOp19 = (node, tensorMap, context) => {
  switch (node.op) {
    case "Cast": {
      return [cast2(getParamValue("x", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
    }
    case "ExpandDims": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [expandDims2(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Squeeze": {
      const axis = getParamValue("axis", node, tensorMap, context);
      return [squeeze2(getParamValue("x", node, tensorMap, context), axis)];
    }
    case "Reshape": {
      return [reshape2(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
    }
    case "MirrorPad": {
      return [mirrorPad2(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("mode", node, tensorMap, context))];
    }
    case "PadV2":
    case "Pad": {
      return [pad2(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("constantValue", node, tensorMap, context))];
    }
    case "SpaceToBatchND": {
      const blockShape = getParamValue("blockShape", node, tensorMap, context);
      const paddings = getParamValue("paddings", node, tensorMap, context);
      return [spaceToBatchND2(getParamValue("x", node, tensorMap, context), blockShape, paddings)];
    }
    case "BatchToSpaceND": {
      const blockShape = getParamValue("blockShape", node, tensorMap, context);
      const crops = getParamValue("crops", node, tensorMap, context);
      return [batchToSpaceND2(getParamValue("x", node, tensorMap, context), blockShape, crops)];
    }
    case "DepthToSpace": {
      const blockSize = getParamValue("blockSize", node, tensorMap, context);
      const dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      return [depthToSpace2(getParamValue("x", node, tensorMap, context), blockSize, dataFormat)];
    }
    case "BroadcastTo": {
      return [broadcastTo2(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
    }
    default:
      throw TypeError(`Node type ${node.op} is not implemented`);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/operations/operation_executor.ts
function executeOp20(node, tensorMap, context, resourceManager) {
  const value = ((node2, tensorMap2, context2) => {
    switch (node2.category) {
      case "arithmetic":
        return tidy2(() => executeOp(node2, tensorMap2, context2));
      case "basic_math":
        return tidy2(() => executeOp2(node2, tensorMap2, context2));
      case "control":
        return executeOp3(node2, tensorMap2, context2);
      case "convolution":
        return tidy2(() => executeOp4(node2, tensorMap2, context2));
      case "creation":
        return tidy2(() => executeOp5(node2, tensorMap2, context2));
      case "dynamic":
        return executeOp6(node2, tensorMap2, context2);
      case "evaluation":
        return tidy2(() => executeOp7(node2, tensorMap2, context2));
      case "image":
        return tidy2(() => executeOp10(node2, tensorMap2, context2));
      case "graph":
        return tidy2(() => executeOp8(node2, tensorMap2, context2));
      case "logical":
        return tidy2(() => executeOp11(node2, tensorMap2, context2));
      case "matrices":
        return tidy2(() => executeOp12(node2, tensorMap2, context2));
      case "normalization":
        return tidy2(() => executeOp13(node2, tensorMap2, context2));
      case "reduction":
        return tidy2(() => executeOp14(node2, tensorMap2, context2));
      case "slice_join":
        return tidy2(() => executeOp15(node2, tensorMap2, context2));
      case "sparse":
        return tidy2(() => executeOp16(node2, tensorMap2, context2));
      case "spectral":
        return tidy2(() => executeOp17(node2, tensorMap2, context2));
      case "string":
        return tidy2(() => executeOp18(node2, tensorMap2, context2));
      case "transformation":
        return tidy2(() => executeOp19(node2, tensorMap2, context2));
      case "hash_table":
        return executeOp9(node2, tensorMap2, context2, resourceManager);
      case "custom":
        const opMapper = getRegisteredOp(node2.op);
        if (opMapper && opMapper.customExecutor) {
          return opMapper.customExecutor(new NodeValueImpl(node2, tensorMap2, context2));
        } else {
          throw TypeError(`Custom op ${node2.op} is not registered.`);
        }
      default:
        throw TypeError(`Unknown op '${node2.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
    }
  })(node, tensorMap, context);
  if (util_exports2.isPromise(value)) {
    return value.then((data) => [].concat(data));
  }
  return [].concat(value);
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/execution_context.ts
var ExecutionContext = class {
  constructor(weightMap = {}, tensorArrayMap = {}, tensorListMap = {}, functionMap = {}) {
    this.weightMap = weightMap;
    this.tensorArrayMap = tensorArrayMap;
    this.tensorListMap = tensorListMap;
    this.functionMap = functionMap;
    this.rootContext = { id: 0, frameName: "", iterationId: 0 };
    this.contexts = [this.rootContext];
    this.lastId = 0;
    this.generateCurrentContextIds();
  }
  newFrame(id, frameName) {
    return { id, frameName, iterationId: 0 };
  }
  set currentContext(contexts2) {
    if (this.contexts !== contexts2) {
      this.contexts = contexts2;
      this.generateCurrentContextIds();
    }
  }
  get currentContext() {
    return this.contexts;
  }
  get currentContextId() {
    return this._currentContextIds[0];
  }
  get currentContextIds() {
    return this._currentContextIds;
  }
  generateCurrentContextIds() {
    const names = [];
    for (let i = 0; i < this.contexts.length - 1; i++) {
      const contexts2 = this.contexts.slice(0, this.contexts.length - i);
      names.push(this.contextIdforContexts(contexts2));
    }
    names.push("");
    this._currentContextIds = names;
  }
  contextIdforContexts(contexts2) {
    return contexts2 ? contexts2.map((context) => context.id === 0 && context.iterationId === 0 ? "" : `${context.frameName}-${context.iterationId}`).join("/") : "";
  }
  enterFrame(frameId) {
    if (this.contexts) {
      this.lastId++;
      this.contexts = this.contexts.slice();
      this.contexts.push(this.newFrame(this.lastId, frameId));
      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));
    }
  }
  exitFrame() {
    if (this.contexts && this.contexts.length > 1) {
      this.contexts = this.contexts.slice();
      this.contexts.splice(-1);
      this.currentContextIds.shift();
    } else {
      throw new Error("Cannot exit frame, the context is empty");
    }
  }
  nextIteration() {
    if (this.contexts && this.contexts.length > 0) {
      this.contexts = this.contexts.slice();
      this.lastId++;
      const context = Object.assign({}, this.contexts[this.contexts.length - 1]);
      context.iterationId += 1;
      context.id = this.lastId;
      this.contexts.splice(-1, 1, context);
      this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    } else {
      throw new Error("Cannot increase frame iteration, the context is empty");
    }
  }
  getWeight(name) {
    return this.weightMap[name];
  }
  addTensorArray(tensorArray) {
    this.tensorArrayMap[tensorArray.id] = tensorArray;
  }
  getTensorArray(id) {
    return this.tensorArrayMap[id];
  }
  addTensorList(tensorList) {
    this.tensorListMap[tensorList.id] = tensorList;
  }
  getTensorList(id) {
    return this.tensorListMap[id];
  }
  dispose(keepIds) {
    for (const key in this.tensorArrayMap) {
      this.tensorArrayMap[key].clearAndClose(keepIds);
    }
    for (const key in this.tensorListMap) {
      this.tensorListMap[key].clearAndClose(keepIds);
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/model_analysis.ts
function getExecutionSubgraph(inputs, outputs, weightMap, initNodes) {
  const usedNodes = new Set();
  const missingInputs = [];
  let dynamicNode = null;
  let syncInputs = null;
  const seen = new Set();
  const inputNodeNames = Object.keys(inputs).map((name) => parseNodeName(name)[0]);
  let initNodeNames = [];
  if (initNodes != null) {
    initNodeNames = initNodes.map((node) => parseNodeName(node.name)[0]);
  }
  const frontier = [...outputs];
  while (frontier.length > 0) {
    const node = frontier.pop();
    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {
      if (dynamicNode == null) {
        dynamicNode = node;
        syncInputs = dynamicNode.children.map((child) => child.name).filter((name) => usedNodes.has(name));
      }
    }
    usedNodes.add(node.name);
    if (weightMap[node.name] != null) {
      continue;
    }
    if (inputNodeNames.indexOf(node.name) !== -1) {
      continue;
    }
    if (initNodeNames.indexOf(node.name) !== -1) {
      continue;
    }
    if (node.inputs.length === 0) {
      missingInputs.push(node.name);
      continue;
    }
    node.inputs.forEach((input2) => {
      if (seen.has(input2.name)) {
        return;
      }
      seen.add(input2.name);
      frontier.push(input2);
    });
  }
  return { inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs };
}
function getNodesInTopologicalOrder(graph2, weightMap, executionInfo) {
  const { usedNodes, inputs } = executionInfo;
  const frontier = [];
  const inputNodes = Object.keys(inputs).map((name) => parseNodeName(name)[0]).map((name) => graph2.nodes[name]);
  const initNodes = graph2.initNodes;
  inputNodes.forEach((input2) => {
    if (usedNodes.has(input2.name)) {
      frontier.push(input2);
    }
  });
  graph2.weights.forEach((weight) => {
    if (usedNodes.has(weight.name)) {
      frontier.push(weight);
    }
  });
  if (initNodes != null) {
    initNodes.forEach((node) => {
      if (usedNodes.has(node.name)) {
        frontier.push(node);
      }
    });
  }
  const seen = new Set();
  const orderedNodes = [];
  while (frontier.length > 0) {
    const node = frontier.pop();
    seen.add(node.name);
    if (!weightMap[node.name]) {
      orderedNodes.push(node);
    }
    node.children.forEach((child) => {
      if (!seen.has(child.name) && usedNodes.has(child.name) && child.inputs.every((input2) => seen.has(input2.name))) {
        frontier.push(child);
      }
    });
  }
  return orderedNodes;
}
var CONTROL_FLOW_OPS = [
  "Switch",
  "Merge",
  "Enter",
  "Exit",
  "NextIteration",
  "StatelessIf",
  "StatelessWhile",
  "if",
  "While"
];
var DYNAMIC_SHAPE_OPS = [
  "NonMaxSuppressionV2",
  "NonMaxSuppressionV3",
  "NonMaxSuppressionV5",
  "Where"
];
var HASH_TABLE_OPS = [
  "HashTable",
  "HashTableV2",
  "LookupTableImport",
  "LookupTableImportV2",
  "LookupTableFind",
  "LookupTableFindV2",
  "LookupTableSize",
  "LookupTableSizeV2"
];
function isControlFlow(node) {
  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;
}
function isDynamicShape(node) {
  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;
}
function isHashTable(node) {
  return HASH_TABLE_OPS.indexOf(node.op) >= 0;
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/graph_executor.ts
var GraphExecutor = class {
  constructor(graph2, parent) {
    this.graph = graph2;
    this.parent = parent;
    this.compiledMap = new Map();
    this._weightMap = {};
    this.SEPERATOR = ",";
    this._functions = {};
    this._functionExecutorMap = {};
    this._outputs = graph2.outputs;
    this._inputs = graph2.inputs;
    this._initNodes = graph2.initNodes;
    this._signature = graph2.signature;
    this._functions = graph2.functions;
    if (graph2.functions != null) {
      Object.keys(graph2.functions).forEach((name) => {
        this._functionExecutorMap[name] = new GraphExecutor(graph2.functions[name], this);
      });
    }
  }
  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }
  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }
  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }
  set weightMap(weightMap) {
    const weightIds = Object.keys(weightMap).map((key) => weightMap[key].map((tensor3) => tensor3.id));
    this._weightIds = [].concat(...weightIds);
    this._weightMap = weightMap;
  }
  set resourceManager(resourceManager) {
    this._resourceManager = resourceManager;
  }
  get inputs() {
    return this._inputs.map((node) => {
      return {
        name: node.name,
        shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
        dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
      };
    });
  }
  get outputs() {
    return this._outputs.map((node) => {
      return {
        name: node.name,
        shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
        dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
      };
    });
  }
  get inputNodes() {
    return this._inputs.map((node) => node.signatureKey || node.name);
  }
  get outputNodes() {
    return this._outputs.map((node) => {
      const name = node.signatureKey || node.name;
      return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;
    });
  }
  get functions() {
    return Object.keys(this._functions).reduce((map, key) => {
      map[key] = this._functions[key].signature;
      return map;
    }, {});
  }
  getCompilationKey(inputs, outputs) {
    const sortedInputs = inputs.map((node) => node.name).sort();
    const sortedOutputs = outputs.map((node) => node.name).sort();
    return sortedInputs.join(this.SEPERATOR) + "--" + sortedOutputs.join(this.SEPERATOR);
  }
  compile(inputs, outputs) {
    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);
    const { missingInputs, dynamicNode, syncInputs } = executionInfo;
    if (dynamicNode != null) {
      throw new Error(`This execution contains the node '${dynamicNode.name}', which has the dynamic op '${dynamicNode.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${syncInputs}]`);
    }
    if (missingInputs.length > 0) {
      const outNames = outputs.map((n) => n.name);
      const inNames = Object.keys(inputs);
      throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs [${inNames}]. Missing the following inputs: [${missingInputs}]`);
    }
    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);
  }
  execute(inputs, outputs) {
    inputs = this.mapInputs(inputs);
    const names = Object.keys(inputs).sort();
    this.checkInputs(inputs);
    this.checkInputShapeAndType(inputs);
    outputs = this.mapOutputs(outputs);
    this.checkOutputs(outputs);
    const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
    const outputNodeNames = outputs.map((name) => parseNodeName(name)[0]);
    let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
    if (outputNodes.length === 0) {
      outputNodes = this._outputs;
    }
    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);
    let orderedNodes = this.compiledMap.get(compilationKey);
    if (orderedNodes == null) {
      orderedNodes = this.compile(inputs, outputNodes);
      this.compiledMap.set(compilationKey, orderedNodes);
    }
    const tensorArrayMap = {};
    const tensorListMap = {};
    return tidy2(() => {
      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);
      const tensorsMap = { ...this.weightMap };
      Object.keys(inputs).forEach((name) => {
        const [nodeName, index] = parseNodeName(name);
        const tensors = [];
        tensors[index] = inputs[name];
        tensorsMap[nodeName] = tensors;
      });
      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
      const intermediateTensorConsumerCount = {};
      for (let i = 0; i < orderedNodes.length; i++) {
        const node = orderedNodes[i];
        if (!tensorsMap[node.name]) {
          const tensors = executeOp20(node, tensorsMap, context, this._resourceManager);
          if (util_exports2.isPromise(tensors)) {
            throw new Error(`The execution of the op '${node.op}' returned a promise. Please use model.executeAsync() instead.`);
          }
          tensorsMap[node.name] = tensors;
          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);
        }
      }
      if (this.parent == null) {
        context.dispose(tensorsToKeep);
      }
      return outputs.map((name) => getTensor(name, tensorsMap, context));
    });
  }
  getFrozenTensorIds(tensorMap) {
    const ids = [].concat.apply([], Object.keys(tensorMap).map((key) => tensorMap[key]).map((tensors) => tensors.map((tensor3) => tensor3.id)));
    return new Set(ids);
  }
  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {
    if (node.category === "control" || outputNames.indexOf(nodeName) !== -1) {
      return;
    }
    tensorMap[nodeName].forEach((tensor3) => {
      if (tensor3 != null) {
        intermediateTensorConsumerCount[tensor3.id] = (intermediateTensorConsumerCount[tensor3.id] || 0) + node.children.length;
      }
    });
    node.inputs.forEach((input2) => {
      if (input2.category !== "control") {
        const tensors = getTensorsForCurrentContenxt(input2.name, tensorMap, context);
        if (tensors != null) {
          tensors.forEach((tensor3) => {
            if (tensor3 && !tensor3.kept && !tensorsToKeep.has(tensor3.id)) {
              const count2 = intermediateTensorConsumerCount[tensor3.id];
              if (count2 === 1) {
                tensor3.dispose();
                delete intermediateTensorConsumerCount[tensor3.id];
              } else if (count2 != null) {
                intermediateTensorConsumerCount[tensor3.id]--;
              }
            }
          });
        }
      }
    });
  }
  async executeAsync(inputs, outputs) {
    return this._executeAsync(inputs, outputs);
  }
  async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {
    if (!isFunctionExecution) {
      inputs = this.mapInputs(inputs);
      this.checkInputs(inputs);
      this.checkInputShapeAndType(inputs);
      outputs = this.mapOutputs(outputs);
      this.checkOutputs(outputs);
    }
    const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);
    const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);
    const results = outputs.map((name) => getTensor(name, tensorMap, context));
    const outputIds = results.map((t) => t.id);
    const inputIds = Object.keys(inputs).map((name) => inputs[name].id);
    const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);
    Object.keys(tensorMap).forEach((key) => {
      const tensorArray = tensorMap[key];
      tensorArray.forEach((tensor3) => {
        if (tensor3 && !tensor3.kept && !tensor3.isDisposed && !keepIds.has(tensor3.id)) {
          tensor3.dispose();
        }
      });
    });
    if (this.parent == null) {
      context.dispose(keepIds);
    }
    return results;
  }
  async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {
    const mappedInputs = inputs.reduce((map, tensor3, index) => {
      map[this.inputs[index].name] = tensor3;
      return map;
    }, {});
    return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);
  }
  async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {
    const names = Object.keys(inputs);
    const inputNodes = names.map((name) => this.graph.nodes[parseNodeName(name)[0]]);
    const outputNodeNames = outputNames.map((name) => parseNodeName(name)[0]);
    let outputNodes = outputNodeNames.map((name) => this.graph.nodes[name]);
    if (outputNodes.length === 0) {
      outputNodes = this._outputs;
    }
    const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);
    const stack3 = [
      ...inputNodes,
      ...this.graph.weights,
      ...this._initNodes || []
    ].map((node) => {
      return { node, contexts: context.currentContext };
    });
    const tensorsMap = { ...this.weightMap };
    Object.keys(inputs).forEach((name) => {
      const [nodeName, index] = parseNodeName(name);
      const tensors = [];
      tensors[index] = inputs[name];
      tensorsMap[nodeName] = tensors;
    });
    const intermediateTensorConsumerCount = {};
    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
    const added = {};
    while (stack3.length > 0) {
      const promises = this.processStack(inputNodes, stack3, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);
      await Promise.all(promises);
    }
    if (dynamicNode == null && !isFunctionExecution) {
      console.warn(`This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.`);
    }
    const missingOutputs = outputNodes.filter((node) => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map((node) => node.name);
    if (missingOutputs.length > 0) {
      let alternativeMsg = "";
      if (dynamicNode != null) {
        alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${syncInputs}]`;
      }
      throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided inputs [${names}]. Consider providing the following inputs: [${missingInputs}]. ${alternativeMsg}`);
    }
    return tensorsMap;
  }
  processStack(inputNodes, stack3, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {
    const promises = [];
    while (stack3.length > 0) {
      const item = stack3.pop();
      context.currentContext = item.contexts;
      let nodeName = "";
      if (item.node.op === "Enter" && getParamValue("isConstant", item.node, tensorMap, context)) {
        [nodeName] = getNodeNameAndIndex(item.node.name, context);
      }
      if (tensorMap[item.node.name] == null) {
        const tensors = executeOp20(item.node, tensorMap, context, this._resourceManager);
        if (!nodeName) {
          [nodeName] = getNodeNameAndIndex(item.node.name, context);
        }
        const currentContext = context.currentContext;
        if (util_exports2.isPromise(tensors)) {
          promises.push(tensors.then((t) => {
            tensorMap[nodeName] = t;
            context.currentContext = currentContext;
            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);
            this.processChildNodes(item.node, stack3, context, tensorMap, added, usedNodes);
            return t;
          }));
        } else {
          tensorMap[nodeName] = tensors;
          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);
          this.processChildNodes(item.node, stack3, context, tensorMap, added, usedNodes);
        }
      } else {
        this.processChildNodes(item.node, stack3, context, tensorMap, added, usedNodes);
      }
    }
    return promises;
  }
  processChildNodes(node, stack3, context, tensorMap, added, usedNodes) {
    node.children.forEach((childNode) => {
      const [nodeName] = getNodeNameAndIndex(childNode.name, context);
      if (added[nodeName] || !usedNodes.has(childNode.name)) {
        return;
      }
      if (childNode.op === "Merge") {
        if (childNode.inputNames.some((name) => {
          return !!getTensor(name, tensorMap, context);
        })) {
          added[nodeName] = true;
          stack3.push({ contexts: context.currentContext, node: childNode });
        }
      } else if (childNode.inputNames.every((name) => {
        return !!getTensor(name, tensorMap, context);
      })) {
        added[nodeName] = true;
        stack3.push({ contexts: context.currentContext, node: childNode });
      }
    });
  }
  dispose() {
    Object.keys(this.weightMap).forEach((key) => this.weightMap[key].forEach((tensor3) => tensor3.dispose()));
  }
  checkInputShapeAndType(inputs) {
    Object.keys(inputs).forEach((name) => {
      const input2 = inputs[name];
      const [nodeName] = parseNodeName(name);
      const node = this.graph.nodes[nodeName];
      if (node.attrParams["shape"] && node.attrParams["shape"].value) {
        const shape = node.attrParams["shape"].value;
        const match = shape.length === input2.shape.length && input2.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);
        util_exports2.assert(match, () => `The shape of dict['${node.name}'] provided in model.execute(dict) must be [${shape}], but was [${input2.shape}]`);
      }
      if (node.attrParams["dtype"] && node.attrParams["dtype"].value) {
        util_exports2.assert(input2.dtype === node.attrParams["dtype"].value, () => `The dtype of dict['${node.name}'] provided in model.execute(dict) must be ${node.attrParams["dtype"].value}, but was ${input2.dtype}`);
      }
    });
  }
  mapInputs(inputs) {
    const result = {};
    for (const inputName in inputs) {
      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {
        const tensor3 = this._signature.inputs[inputName];
        result[tensor3.name] = inputs[inputName];
      } else {
        result[inputName] = inputs[inputName];
      }
    }
    return result;
  }
  checkInputs(inputs) {
    const notInGraph = Object.keys(inputs).filter((name) => {
      const [nodeName] = parseNodeName(name);
      return this.graph.nodes[nodeName] == null;
    });
    if (notInGraph.length > 0) {
      throw new Error(`The dict provided in model.execute(dict) has keys: [${notInGraph}] that are not part of graph`);
    }
  }
  mapOutputs(outputs) {
    return outputs.map((name) => {
      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {
        const tensor3 = this._signature.outputs[name];
        return tensor3.name;
      }
      return name;
    }, {});
  }
  checkOutputs(outputs) {
    outputs.forEach((name) => {
      const [normalizedName] = parseNodeName(name);
      if (!this.graph.nodes[normalizedName]) {
        throw new Error(`The output '${name}' is not found in the graph`);
      }
    });
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/resource_manager.ts
var ResourceManager = class {
  constructor(hashTableNameToHandle = {}, hashTableMap = {}) {
    this.hashTableNameToHandle = hashTableNameToHandle;
    this.hashTableMap = hashTableMap;
  }
  addHashTable(name, hashTable2) {
    this.hashTableNameToHandle[name] = hashTable2.handle;
    this.hashTableMap[hashTable2.id] = hashTable2;
  }
  getHashTableHandleByName(name) {
    return this.hashTableNameToHandle[name];
  }
  getHashTableById(id) {
    return this.hashTableMap[id];
  }
  dispose() {
    for (const key in this.hashTableMap) {
      this.hashTableMap[key].clearAndClose();
      delete this.hashTableMap[key];
    }
    for (const name in this.hashTableNameToHandle) {
      this.hashTableNameToHandle[name].dispose();
      delete this.hashTableNameToHandle[name];
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/executor/graph_model.ts
var TFHUB_SEARCH_PARAM = "?tfjs-format=file";
var DEFAULT_MODEL_NAME = "model.json";
var GraphModel = class {
  constructor(modelUrl, loadOptions = {}) {
    this.modelUrl = modelUrl;
    this.loadOptions = loadOptions;
    this.version = "n/a";
    if (loadOptions == null) {
      this.loadOptions = {};
    }
    this.resourceManager = new ResourceManager();
  }
  get modelVersion() {
    return this.version;
  }
  get inputNodes() {
    return this.executor.inputNodes;
  }
  get outputNodes() {
    return this.executor.outputNodes;
  }
  get inputs() {
    return this.executor.inputs;
  }
  get outputs() {
    return this.executor.outputs;
  }
  get weights() {
    return this.executor.weightMap;
  }
  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }
  get modelSignature() {
    return this.signature;
  }
  findIOHandler() {
    const path = this.modelUrl;
    if (path.load != null) {
      this.handler = path;
    } else if (this.loadOptions.requestInit != null) {
      this.handler = io_exports2.browserHTTPRequest(path, this.loadOptions);
    } else {
      const handlers = io_exports2.getLoadHandlers(path, this.loadOptions);
      if (handlers.length === 0) {
        handlers.push(io_exports2.browserHTTPRequest(path, this.loadOptions));
      } else if (handlers.length > 1) {
        throw new Error(`Found more than one (${handlers.length}) load handlers for URL '${[path]}'`);
      }
      this.handler = handlers[0];
    }
  }
  async load() {
    this.findIOHandler();
    if (this.handler.load == null) {
      throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    }
    const artifacts = await this.handler.load();
    return this.loadSync(artifacts);
  }
  loadSync(artifacts) {
    this.artifacts = artifacts;
    const graph2 = this.artifacts.modelTopology;
    let signature;
    if (this.artifacts.userDefinedMetadata != null && this.artifacts.userDefinedMetadata.signature != null) {
      signature = this.artifacts.userDefinedMetadata.signature;
    } else {
      signature = this.artifacts.signature;
    }
    this.signature = signature;
    this.version = `${graph2.versions.producer}.${graph2.versions.minConsumer}`;
    const weightMap = io_exports2.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);
    this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(graph2, this.signature));
    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);
    this.executor.resourceManager = this.resourceManager;
    if (artifacts.modelInitializer != null && artifacts.modelInitializer.node != null) {
      const initializer = OperationMapper.Instance.transformGraph(artifacts.modelInitializer);
      this.initializer = new GraphExecutor(initializer);
      this.initializer.weightMap = this.executor.weightMap;
      this.initializer.resourceManager = this.resourceManager;
      this.initializer.executeAsync({}, []);
    }
    return true;
  }
  async save(handlerOrURL, config) {
    if (typeof handlerOrURL === "string") {
      const handlers = io_exports2.getSaveHandlers(handlerOrURL);
      if (handlers.length === 0) {
        throw new Error(`Cannot find any save handlers for URL '${handlerOrURL}'`);
      } else if (handlers.length > 1) {
        throw new Error(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
      }
      handlerOrURL = handlers[0];
    }
    if (handlerOrURL.save == null) {
      throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    }
    return handlerOrURL.save(this.artifacts);
  }
  predict(inputs, config) {
    return this.execute(inputs, this.outputNodes);
  }
  normalizeInputs(inputs) {
    if (!(inputs instanceof Tensor4) && !Array.isArray(inputs)) {
      return inputs;
    }
    inputs = Array.isArray(inputs) ? inputs : [inputs];
    if (inputs.length !== this.inputNodes.length) {
      throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${inputs.length} input tensors.`);
    }
    return this.inputNodes.reduce((map, inputName, i) => {
      map[inputName] = inputs[i];
      return map;
    }, {});
  }
  normalizeOutputs(outputs) {
    outputs = outputs || this.outputNodes;
    return !Array.isArray(outputs) ? [outputs] : outputs;
  }
  execute(inputs, outputs) {
    inputs = this.normalizeInputs(inputs);
    outputs = this.normalizeOutputs(outputs);
    const result = this.executor.execute(inputs, outputs);
    return result.length > 1 ? result : result[0];
  }
  async executeAsync(inputs, outputs) {
    inputs = this.normalizeInputs(inputs);
    outputs = this.normalizeOutputs(outputs);
    const result = await this.executor.executeAsync(inputs, outputs);
    return result.length > 1 ? result : result[0];
  }
  convertTensorMapToTensorsMap(map) {
    return Object.keys(map).reduce((newMap, key) => {
      newMap[key] = [map[key]];
      return newMap;
    }, {});
  }
  dispose() {
    this.executor.dispose();
    if (this.initializer) {
      this.initializer.dispose();
    }
    this.resourceManager.dispose();
  }
};
async function loadGraphModel(modelUrl, options = {}) {
  if (modelUrl == null) {
    throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
  }
  if (options == null) {
    options = {};
  }
  if (options.fromTFHub) {
    if (modelUrl.load == null) {
      if (!modelUrl.endsWith("/")) {
        modelUrl = modelUrl + "/";
      }
      modelUrl = `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;
    }
  }
  const model2 = new GraphModel(modelUrl, options);
  await model2.load();
  return model2;
}

// node_modules/.pnpm/@tensorflow+tfjs-converter@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-converter/src/version.ts
var version12 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/index.ts
var src_exports = {};
__export(src_exports, {
  CSVDataset: () => CSVDataset,
  Dataset: () => Dataset,
  FileDataSource: () => FileDataSource,
  TextLineDataset: () => TextLineDataset,
  URLDataSource: () => URLDataSource,
  array: () => array,
  csv: () => csv,
  func: () => func,
  generator: () => generator,
  microphone: () => microphone,
  version_data: () => version13,
  webcam: () => webcam,
  zip: () => zip
});

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/dataset.ts
var seedrandom4 = __toModule(require_seedrandom4());

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/lazy_iterator.ts
var seedrandom3 = __toModule(require_seedrandom4());

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/util/deep_map.ts
function deepMap(input2, mapFn) {
  return deepMapInternal(input2, mapFn);
}
function deepMapInternal(input2, mapFn, seen = new Map(), containedIn = new Set()) {
  if (input2 == null) {
    return null;
  }
  if (containedIn.has(input2)) {
    throw new Error("Circular references are not supported.");
  }
  if (seen.has(input2)) {
    return seen.get(input2);
  }
  const result = mapFn(input2);
  if (result.recurse && result.value !== null) {
    throw new Error("A deep map function may not return both a value and recurse=true.");
  }
  if (!result.recurse) {
    seen.set(input2, result.value);
    return result.value;
  } else if (isIterable3(input2)) {
    const mappedIterable = Array.isArray(input2) ? [] : {};
    containedIn.add(input2);
    for (const k in input2) {
      const child = input2[k];
      const childResult = deepMapInternal(child, mapFn, seen, containedIn);
      mappedIterable[k] = childResult;
    }
    containedIn.delete(input2);
    return mappedIterable;
  } else {
    throw new Error(`Can't recurse into non-iterable type: ${input2}`);
  }
}
function deepZip(inputs, zipFn = zipToList) {
  return deepZipInternal(inputs, zipFn);
}
function deepZipInternal(inputs, zipFn, containedIn = new Set()) {
  const input2 = inputs[0];
  if (containedIn.has(input2)) {
    throw new Error("Circular references are not supported.");
  }
  const result = zipFn(inputs);
  if (result.recurse && result.value !== null) {
    throw new Error("A deep zip function may not return both a value and recurse=true.");
  }
  if (!result.recurse) {
    return result.value;
  } else if (isIterable3(input2)) {
    const mappedIterable = Array.isArray(input2) ? [] : {};
    containedIn.add(input2);
    for (const k in input2) {
      const children = inputs.map((x) => x[k]);
      const childResult = deepZipInternal(children, zipFn, containedIn);
      mappedIterable[k] = childResult;
    }
    containedIn.delete(input2);
    return mappedIterable;
  } else {
    throw new Error(`Can't recurse into non-iterable type: ${input2}`);
  }
}
function zipToList(x) {
  if (x === null) {
    return null;
  }
  if (isIterable3(x[0])) {
    return { value: null, recurse: true };
  } else {
    return { value: x, recurse: false };
  }
}
async function deepMapAndAwaitAll(input2, mapFn) {
  const seen = new Map();
  deepMapInternal(input2, mapFn, seen);
  for (const key of Array.from(seen.keys())) {
    const value = seen.get(key);
    if (util_exports2.isPromise(value)) {
      const mappedValue = await value;
      seen.set(key, mappedValue);
    }
  }
  const result = deepMapInternal(input2, mapFn, seen);
  return result;
}
function isIterable3(obj) {
  return obj != null && !ArrayBuffer.isView(obj) && (Array.isArray(obj) || typeof obj === "object" && !(obj instanceof Tensor4));
}
function canTensorify(obj) {
  return obj == null || isPrimitive(obj) || Array.isArray(obj) || typeof obj === "object" && obj instanceof Tensor4 || util_exports2.isTypedArray(obj);
}
function isPrimitive(value) {
  return value === null || typeof value !== "object" && typeof value !== "function";
}

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/util/deep_clone.ts
function deepClone(container) {
  return deepMap(container, cloneIfTensor);
}
function cloneIfTensor(item) {
  if (item instanceof Tensor4) {
    return { value: item.clone(), recurse: false };
  } else if (isIterable3(item)) {
    return { value: null, recurse: true };
  } else {
    return { value: item, recurse: false };
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/util/ring_buffer.ts
var RingBuffer = class {
  constructor(capacity) {
    this.capacity = capacity;
    this.begin = 0;
    this.end = 0;
    if (capacity == null) {
      throw new RangeError("Can't create a ring buffer of unknown capacity.");
    }
    if (capacity < 1) {
      throw new RangeError("Can't create ring buffer of capacity < 1.");
    }
    this.data = new Array(capacity);
    this.doubledCapacity = 2 * capacity;
  }
  wrap(index) {
    while (index < 0) {
      index += this.doubledCapacity;
    }
    return index % this.doubledCapacity;
  }
  get(index) {
    if (index < 0) {
      throw new RangeError("Can't get item at a negative index.");
    }
    return this.data[index % this.capacity];
  }
  set(index, value) {
    if (index < 0) {
      throw new RangeError("Can't set item at a negative index.");
    }
    this.data[index % this.capacity] = value;
  }
  length() {
    let length = this.end - this.begin;
    if (length < 0) {
      length = this.doubledCapacity + length;
    }
    return length;
  }
  isFull() {
    return this.length() === this.capacity;
  }
  isEmpty() {
    return this.length() === 0;
  }
  push(value) {
    if (this.isFull()) {
      throw new RangeError("Ring buffer is full.");
    }
    this.set(this.end, value);
    this.end = this.wrap(this.end + 1);
  }
  pushAll(values) {
    for (const value of values) {
      this.push(value);
    }
  }
  pop() {
    if (this.isEmpty()) {
      throw new RangeError("Ring buffer is empty.");
    }
    this.end = this.wrap(this.end - 1);
    const result = this.get(this.end);
    this.set(this.end, void 0);
    return result;
  }
  unshift(value) {
    if (this.isFull()) {
      throw new RangeError("Ring buffer is full.");
    }
    this.begin = this.wrap(this.begin - 1);
    this.set(this.begin, value);
  }
  shift() {
    if (this.isEmpty()) {
      throw new RangeError("Ring buffer is empty.");
    }
    const result = this.get(this.begin);
    this.set(this.begin, void 0);
    this.begin = this.wrap(this.begin + 1);
    return result;
  }
  shuffleExcise(relativeIndex) {
    if (this.isEmpty()) {
      throw new RangeError("Ring buffer is empty.");
    }
    const index = this.wrap(this.begin + relativeIndex);
    const result = this.get(index);
    this.set(index, this.pop());
    return result;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/util/growing_ring_buffer.ts
var _GrowingRingBuffer = class extends RingBuffer {
  constructor() {
    super(_GrowingRingBuffer.INITIAL_CAPACITY);
  }
  isFull() {
    return false;
  }
  push(value) {
    if (super.isFull()) {
      this.expand();
    }
    super.push(value);
  }
  unshift(value) {
    if (super.isFull()) {
      this.expand();
    }
    super.unshift(value);
  }
  expand() {
    const newCapacity = this.capacity * 2;
    const newData = new Array(newCapacity);
    const len = this.length();
    for (let i = 0; i < len; i++) {
      newData[i] = this.get(this.wrap(this.begin + i));
    }
    this.data = newData;
    this.capacity = newCapacity;
    this.doubledCapacity = 2 * this.capacity;
    this.begin = 0;
    this.end = len;
  }
};
var GrowingRingBuffer = _GrowingRingBuffer;
GrowingRingBuffer.INITIAL_CAPACITY = 32;

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/lazy_iterator.ts
function iteratorFromItems(items) {
  return new ArrayIterator(items);
}
function iteratorFromFunction(func2) {
  return new FunctionCallIterator(func2);
}
function iteratorFromConcatenated(baseIterators, baseErrorHandler) {
  return new ChainedIterator(baseIterators, baseErrorHandler);
}
function iteratorFromZipped(iterators, mismatchMode = ZipMismatchMode.FAIL) {
  return new ZipIterator(iterators, mismatchMode);
}
var LazyIterator = class {
  async toArray() {
    const result = [];
    let x = await this.next();
    while (!x.done) {
      result.push(x.value);
      x = await this.next();
    }
    return result;
  }
  async toArrayForTest() {
    const stream = this.prefetch(100);
    const result = [];
    let x = await stream.next();
    while (!x.done) {
      result.push(x.value);
      x = await stream.next();
    }
    return result;
  }
  async resolveFully() {
    let x = await this.next();
    while (!x.done) {
      x = await this.next();
    }
  }
  async resolveWhile(predicate) {
    let x = await this.next();
    let shouldContinue = predicate(x.value);
    while (!x.done && shouldContinue) {
      x = await this.next();
      shouldContinue = predicate(x.value);
    }
  }
  handleErrors(handler) {
    return new ErrorHandlingLazyIterator(this, handler);
  }
  filter(predicate) {
    return new FilterIterator(this, predicate);
  }
  map(transform6) {
    return new MapIterator(this, transform6);
  }
  mapAsync(transform6) {
    return new AsyncMapIterator(this, transform6);
  }
  serialMapAsync(transform6) {
    return new AsyncMapIterator(this, transform6).serial();
  }
  flatmap(transform6) {
    return new FlatmapIterator(this, transform6);
  }
  async forEachAsync(f) {
    return this.map(f).resolveFully();
  }
  async serialForEach(f) {
    return this.serialMapAsync(f).resolveWhile((x) => x === true);
  }
  rowMajorBatch(batchSize, smallLastBatch = true) {
    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);
  }
  columnMajorBatch(batchSize, smallLastBatch = true, zipFn = zipToList) {
    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);
    return rowBatches.map((x) => deepZip(x, zipFn));
  }
  concatenate(iterator, baseErrorHandler) {
    return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);
  }
  take(count2) {
    if (count2 < 0 || count2 == null) {
      return this;
    }
    return new TakeIterator(this, count2);
  }
  skip(count2) {
    if (count2 < 0 || count2 == null) {
      return this;
    }
    return new SkipIterator(this, count2);
  }
  prefetch(bufferSize) {
    return new PrefetchIterator(this, bufferSize);
  }
  shuffle(windowSize, seed) {
    return new ShuffleIterator(this, windowSize, seed);
  }
  serial() {
    return new SerialIterator(this);
  }
};
var ArrayIterator = class extends LazyIterator {
  constructor(items) {
    super();
    this.items = items;
    this.trav = 0;
  }
  summary() {
    return `Array of ${this.items.length} items`;
  }
  async next() {
    if (this.trav >= this.items.length) {
      return { value: null, done: true };
    }
    const item = this.items[this.trav];
    this.trav++;
    return { value: deepClone(item), done: false };
  }
};
var FunctionCallIterator = class extends LazyIterator {
  constructor(nextFn) {
    super();
    this.nextFn = nextFn;
  }
  summary() {
    return `Function call`;
  }
  async next() {
    try {
      return this.nextFn();
    } catch (e) {
      e.message = `Error thrown while iterating through a dataset: ${e.message}`;
      throw e;
    }
  }
};
var SerialIterator = class extends LazyIterator {
  constructor(upstream) {
    super();
    this.upstream = upstream;
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Serial`;
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    return this.upstream.next();
  }
};
var SkipIterator = class extends LazyIterator {
  constructor(upstream, maxCount) {
    super();
    this.upstream = upstream;
    this.maxCount = maxCount;
    this.count = 0;
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Skip`;
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    while (this.count++ < this.maxCount) {
      const skipped = await this.upstream.next();
      if (skipped.done) {
        return skipped;
      }
      dispose2(skipped.value);
    }
    return this.upstream.next();
  }
};
var TakeIterator = class extends LazyIterator {
  constructor(upstream, maxCount) {
    super();
    this.upstream = upstream;
    this.maxCount = maxCount;
    this.count = 0;
  }
  summary() {
    return `${this.upstream.summary()} -> Take`;
  }
  async next() {
    if (this.count++ >= this.maxCount) {
      return { value: null, done: true };
    }
    return this.upstream.next();
  }
};
var RowMajorBatchIterator = class extends LazyIterator {
  constructor(upstream, batchSize, enableSmallLastBatch = true) {
    super();
    this.upstream = upstream;
    this.batchSize = batchSize;
    this.enableSmallLastBatch = enableSmallLastBatch;
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> RowMajorBatch`;
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    const batch = [];
    while (batch.length < this.batchSize) {
      const item = await this.upstream.next();
      if (item.done) {
        if (this.enableSmallLastBatch && batch.length > 0) {
          return { value: batch, done: false };
        }
        return { value: null, done: true };
      }
      batch.push(item.value);
    }
    return { value: batch, done: false };
  }
};
var FilterIterator = class extends LazyIterator {
  constructor(upstream, predicate) {
    super();
    this.upstream = upstream;
    this.predicate = predicate;
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Filter`;
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    while (true) {
      const item = await this.upstream.next();
      if (item.done || this.predicate(item.value)) {
        return item;
      }
      dispose2(item.value);
    }
  }
};
var MapIterator = class extends LazyIterator {
  constructor(upstream, transform6) {
    super();
    this.upstream = upstream;
    this.transform = transform6;
  }
  summary() {
    return `${this.upstream.summary()} -> Map`;
  }
  async next() {
    const item = await this.upstream.next();
    if (item.done) {
      return { value: null, done: true };
    }
    const inputTensors = tensor_util_exports2.getTensorsInContainer(item.value);
    const mapped = this.transform(item.value);
    const outputTensors = tensor_util_exports2.getTensorsInContainer(mapped);
    for (const t of inputTensors) {
      if (!tensor_util_exports2.isTensorInList(t, outputTensors)) {
        t.dispose();
      }
    }
    return { value: mapped, done: false };
  }
};
var ErrorHandlingLazyIterator = class extends LazyIterator {
  constructor(upstream, handler) {
    super();
    this.upstream = upstream;
    this.handler = handler;
    this.count = 0;
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> handleErrors`;
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    while (true) {
      try {
        return await this.upstream.next();
      } catch (e) {
        if (!this.handler(e)) {
          return { value: null, done: true };
        }
      }
    }
  }
};
var AsyncMapIterator = class extends LazyIterator {
  constructor(upstream, transform6) {
    super();
    this.upstream = upstream;
    this.transform = transform6;
  }
  summary() {
    return `${this.upstream.summary()} -> AsyncMap`;
  }
  async next() {
    const item = await this.upstream.next();
    if (item.done) {
      return { value: null, done: true };
    }
    const inputTensors = tensor_util_exports2.getTensorsInContainer(item.value);
    const mapped = await this.transform(item.value);
    const outputTensors = tensor_util_exports2.getTensorsInContainer(mapped);
    for (const t of inputTensors) {
      if (!tensor_util_exports2.isTensorInList(t, outputTensors)) {
        t.dispose();
      }
    }
    return { value: mapped, done: false };
  }
};
var OneToManyIterator = class extends LazyIterator {
  constructor() {
    super();
    this.outputQueue = new GrowingRingBuffer();
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  async serialNext() {
    while (this.outputQueue.length() === 0) {
      if (!await this.pump()) {
        return { value: null, done: true };
      }
    }
    return { value: this.outputQueue.shift(), done: false };
  }
};
var FlatmapIterator = class extends OneToManyIterator {
  constructor(upstream, transform6) {
    super();
    this.upstream = upstream;
    this.transform = transform6;
  }
  summary() {
    return `${this.upstream.summary()} -> Flatmap`;
  }
  async pump() {
    const item = await this.upstream.next();
    if (item.done) {
      return false;
    }
    const inputTensors = tensor_util_exports2.getTensorsInContainer(item.value);
    const mappedArray = this.transform(item.value);
    const outputTensors = tensor_util_exports2.getTensorsInContainer(mappedArray);
    this.outputQueue.pushAll(mappedArray);
    for (const t of inputTensors) {
      if (!tensor_util_exports2.isTensorInList(t, outputTensors)) {
        t.dispose();
      }
    }
    return true;
  }
};
var ChainedIterator = class extends LazyIterator {
  constructor(iterators, baseErrorHandler) {
    super();
    this.baseErrorHandler = baseErrorHandler;
    this.lastRead = null;
    this.iterator = null;
    this.moreIterators = iterators;
  }
  summary() {
    const upstreamSummaries = "TODO: fill in upstream of chained summaries";
    return `${upstreamSummaries} -> Chained`;
  }
  async next() {
    this.lastRead = this.readFromChain(this.lastRead);
    return this.lastRead;
  }
  async readFromChain(lastRead) {
    await lastRead;
    if (this.iterator == null) {
      const iteratorResult = await this.moreIterators.next();
      if (iteratorResult.done) {
        return { value: null, done: true };
      }
      this.iterator = iteratorResult.value;
      if (this.baseErrorHandler != null) {
        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);
      }
    }
    const itemResult = await this.iterator.next();
    if (itemResult.done) {
      this.iterator = null;
      return this.readFromChain(lastRead);
    }
    return itemResult;
  }
};
var ZipMismatchMode;
(function(ZipMismatchMode2) {
  ZipMismatchMode2[ZipMismatchMode2["FAIL"] = 0] = "FAIL";
  ZipMismatchMode2[ZipMismatchMode2["SHORTEST"] = 1] = "SHORTEST";
  ZipMismatchMode2[ZipMismatchMode2["LONGEST"] = 2] = "LONGEST";
})(ZipMismatchMode || (ZipMismatchMode = {}));
var ZipIterator = class extends LazyIterator {
  constructor(iterators, mismatchMode = 0) {
    super();
    this.iterators = iterators;
    this.mismatchMode = mismatchMode;
    this.count = 0;
    this.currentPromise = null;
  }
  summary() {
    const upstreamSummaries = "TODO: fill in upstream of zip summaries";
    return `{${upstreamSummaries}} -> Zip`;
  }
  async nextState(afterState) {
    await afterState;
    let numIterators = 0;
    let iteratorsDone = 0;
    function getNext(container) {
      if (container instanceof LazyIterator) {
        const result = container.next();
        return {
          value: result.then((x) => {
            numIterators++;
            if (x.done) {
              iteratorsDone++;
            }
            return x.value;
          }),
          recurse: false
        };
      } else {
        return { value: null, recurse: true };
      }
    }
    const mapped = await deepMapAndAwaitAll(this.iterators, getNext);
    if (numIterators === iteratorsDone) {
      return { value: null, done: true };
    }
    if (iteratorsDone > 0) {
      switch (this.mismatchMode) {
        case 0:
          throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);
        case 1:
          return { value: null, done: true };
        case 2:
        default:
      }
    }
    this.count++;
    return { value: mapped, done: false };
  }
  async next() {
    this.currentPromise = this.nextState(this.currentPromise);
    return this.currentPromise;
  }
};
var PrefetchIterator = class extends LazyIterator {
  constructor(upstream, bufferSize) {
    super();
    this.upstream = upstream;
    this.bufferSize = bufferSize;
    this.buffer = new RingBuffer(bufferSize);
  }
  summary() {
    return `${this.upstream.summary()} -> Prefetch`;
  }
  refill() {
    while (!this.buffer.isFull()) {
      const v = this.upstream.next();
      this.buffer.push(v);
    }
  }
  next() {
    this.refill();
    return this.buffer.shift();
  }
};
var ShuffleIterator = class extends PrefetchIterator {
  constructor(upstream, windowSize, seed) {
    super(upstream, windowSize);
    this.upstream = upstream;
    this.windowSize = windowSize;
    this.upstreamExhausted = false;
    this.random = seedrandom3.alea(seed || util_exports2.now().toString());
    this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    this.lastRead = this.lastRead.then(() => this.serialNext());
    return this.lastRead;
  }
  randomInt(max7) {
    return Math.floor(this.random() * max7);
  }
  chooseIndex() {
    return this.randomInt(this.buffer.length());
  }
  async serialNext() {
    if (!this.upstreamExhausted) {
      this.refill();
    }
    while (!this.buffer.isEmpty()) {
      const chosenIndex = this.chooseIndex();
      const result = await this.buffer.shuffleExcise(chosenIndex);
      if (result.done) {
        this.upstreamExhausted = true;
      } else {
        this.refill();
        return result;
      }
    }
    return { value: null, done: true };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/dataset.ts
var Dataset = class {
  constructor() {
    this.size = null;
  }
  batch(batchSize, smallLastBatch = true) {
    const base3 = this;
    util_exports2.assert(batchSize > 0, () => `batchSize needs to be positive, but it is
      ${batchSize}`);
    let size;
    if (this.size === Infinity || this.size == null) {
      size = this.size;
    } else if (smallLastBatch) {
      size = Math.ceil(this.size / batchSize);
    } else {
      size = Math.floor(this.size / batchSize);
    }
    return datasetFromIteratorFn(async () => {
      return (await base3.iterator()).columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat);
    }, size);
  }
  concatenate(dataset) {
    const base3 = this;
    let size;
    if (this.size === Infinity || dataset.size === Infinity) {
      size = Infinity;
    } else if (this.size != null && dataset.size != null) {
      size = this.size + dataset.size;
    } else {
      size = null;
    }
    return datasetFromIteratorFn(async () => (await base3.iterator()).concatenate(await dataset.iterator()), size);
  }
  filter(predicate) {
    const base3 = this;
    let size;
    if (this.size === Infinity) {
      size = Infinity;
    } else {
      size = null;
    }
    return datasetFromIteratorFn(async () => {
      return (await base3.iterator()).filter((x) => tidy2(() => predicate(x)));
    }, size);
  }
  async forEachAsync(f) {
    return (await this.iterator()).forEachAsync(f);
  }
  map(transform6) {
    const base3 = this;
    return datasetFromIteratorFn(async () => {
      return (await base3.iterator()).map((x) => tidy2(() => transform6(x)));
    }, this.size);
  }
  mapAsync(transform6) {
    const base3 = this;
    return datasetFromIteratorFn(async () => {
      return (await base3.iterator()).mapAsync(transform6);
    }, this.size);
  }
  prefetch(bufferSize) {
    if (bufferSize == null) {
      throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
    }
    const base3 = this;
    return datasetFromIteratorFn(async () => (await base3.iterator()).prefetch(bufferSize), this.size);
  }
  repeat(count2) {
    const base3 = this;
    let size;
    if (this.size != null && count2 > 0) {
      size = this.size * count2;
    } else if (count2 === 0) {
      size = 0;
    } else if (this.size != null && (count2 === void 0 || count2 < 0)) {
      size = Infinity;
    } else {
      size = null;
    }
    return datasetFromIteratorFn(async () => {
      const iteratorIterator = iteratorFromFunction(async () => ({ value: await base3.iterator(), done: false }));
      return iteratorFromConcatenated(iteratorIterator.take(count2));
    }, size);
  }
  skip(count2) {
    const base3 = this;
    let size;
    if (this.size != null && count2 >= 0 && this.size >= count2) {
      size = this.size - count2;
    } else if (this.size != null && (this.size < count2 || count2 === void 0 || count2 < 0)) {
      size = 0;
    } else {
      size = null;
    }
    return datasetFromIteratorFn(async () => (await base3.iterator()).skip(count2), size);
  }
  shuffle(bufferSize, seed, reshuffleEachIteration = true) {
    if (bufferSize == null || bufferSize < 0) {
      if (this.size == null) {
        throw new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.");
      } else {
        throw new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
      }
    }
    const base3 = this;
    const random = seedrandom4.alea(seed || util_exports2.now().toString());
    return datasetFromIteratorFn(async () => {
      let seed2 = random.int32();
      if (reshuffleEachIteration) {
        seed2 += random.int32();
      }
      return (await base3.iterator()).shuffle(bufferSize, seed2.toString());
    }, this.size);
  }
  take(count2) {
    const base3 = this;
    let size;
    if (this.size != null && this.size > count2) {
      size = count2;
    } else if (this.size != null && this.size <= count2) {
      size = this.size;
    } else {
      size = null;
    }
    return datasetFromIteratorFn(async () => (await base3.iterator()).take(count2), size);
  }
  async toArray() {
    if (this.size === Infinity) {
      throw new Error("Can not convert infinite data stream to array.");
    }
    return (await this.iterator()).toArray();
  }
  async toArrayForTest() {
    if (this.size === Infinity) {
      throw new Error("Can not convert infinite data stream to array.");
    }
    return (await this.iterator()).toArrayForTest();
  }
};
Dataset.MAX_BUFFER_SIZE = 1e4;
function datasetFromIteratorFn(iteratorFn, size = null) {
  return new class extends Dataset {
    constructor() {
      super(...arguments);
      this.size = size;
    }
    async iterator() {
      return iteratorFn();
    }
  }();
}
function array(items) {
  return datasetFromIteratorFn(async () => iteratorFromItems(items), items.length);
}
function zip(datasets) {
  if (!isIterable3(datasets)) {
    throw new Error("The argument to zip() must be an object or array.");
  }
  let size;
  if (Array.isArray(datasets)) {
    for (let i = 0; i < datasets.length; i++) {
      size = size == null ? datasets[i].size : Math.min(size, datasets[i].size);
    }
  } else if (datasets instanceof Object) {
    for (const ds in datasets) {
      size = size == null ? datasets[ds].size : Math.min(size, datasets[ds].size);
    }
  }
  return datasetFromIteratorFn(async () => {
    const streams = await deepMapAndAwaitAll(datasets, (d) => {
      if (d instanceof Dataset) {
        return { value: d.iterator(), recurse: false };
      } else if (isIterable3(d)) {
        return { value: null, recurse: true };
      } else {
        throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.");
      }
    });
    return iteratorFromZipped(streams, ZipMismatchMode.SHORTEST);
  }, size);
}
function deepBatchConcat(rows) {
  if (rows === null) {
    return null;
  }
  const exampleRow = rows[0];
  if (canTensorify(exampleRow)) {
    const value = batchConcat(rows);
    return { value, recurse: false };
  }
  return { value: null, recurse: true };
}
function batchConcat(arrays) {
  if (arrays.length === 0) {
    throw new Error("Can't make a batch of zero elements.");
  }
  if (arrays[0] instanceof Tensor4) {
    return stack2(arrays);
  } else {
    return tensor2(arrays);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/datasets/text_line_dataset.ts
var TextLineDataset = class extends Dataset {
  constructor(input2) {
    super();
    this.input = input2;
  }
  async iterator() {
    const inputIterator = await this.input.iterator();
    const utf8Iterator = inputIterator.decodeUTF8();
    const lineIterator = utf8Iterator.split("\n").map((line) => {
      if (line.endsWith("\r")) {
        line = line.slice(0, -1);
      }
      return line;
    });
    return lineIterator;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/datasets/csv_dataset.ts
var CODE_QUOTE = '"';
var STATE_OUT = Symbol("out");
var STATE_FIELD = Symbol("field");
var STATE_QUOTE = Symbol("quote");
var STATE_QUOTE_AFTER_QUOTE = Symbol("quoteafterquote");
var STATE_WITHIN_QUOTE_IN_QUOTE = Symbol("quoteinquote");
var CSVDataset = class extends Dataset {
  constructor(input2, csvConfig) {
    super();
    this.input = input2;
    this.hasHeader = true;
    this.fullColumnNames = null;
    this.columnNamesValidated = false;
    this.columnConfigs = null;
    this.configuredColumnsOnly = false;
    this.delimiter = ",";
    this.delimWhitespace = false;
    this.base = new TextLineDataset(input2);
    if (!csvConfig) {
      csvConfig = {};
    }
    this.hasHeader = csvConfig.hasHeader === false ? false : true;
    this.fullColumnNames = csvConfig.columnNames;
    this.columnConfigs = csvConfig.columnConfigs;
    this.configuredColumnsOnly = csvConfig.configuredColumnsOnly;
    if (csvConfig.delimWhitespace) {
      util_exports2.assert(csvConfig.delimiter == null, () => "Delimiter should not be provided when delimWhitespace is true.");
      this.delimWhitespace = true;
      this.delimiter = " ";
    } else {
      this.delimiter = csvConfig.delimiter ? csvConfig.delimiter : ",";
    }
  }
  async columnNames() {
    if (!this.columnNamesValidated) {
      await this.setColumnNames();
    }
    return this.configuredColumnsOnly ? Object.keys(this.columnConfigs) : this.fullColumnNames;
  }
  async setColumnNames() {
    const columnNamesFromFile = await this.maybeReadHeaderLine();
    if (!this.fullColumnNames && !columnNamesFromFile) {
      throw new Error("Column names must be provided if there is no header line.");
    } else if (this.fullColumnNames && columnNamesFromFile) {
      util_exports2.assert(columnNamesFromFile.length === this.fullColumnNames.length, () => "The length of provided columnNames (" + this.fullColumnNames.length.toString() + ") does not match the length of the header line read from file (" + columnNamesFromFile.length.toString() + ").");
    }
    if (!this.fullColumnNames) {
      this.fullColumnNames = columnNamesFromFile;
    }
    const counts = this.fullColumnNames.reduce((countAcc, name) => {
      countAcc[name] = countAcc[name] + 1 || 1;
      return countAcc;
    }, {});
    const duplicateNames = Object.keys(counts).filter((name) => counts[name] > 1);
    util_exports2.assert(duplicateNames.length === 0, () => "Duplicate column names found: " + duplicateNames.toString());
    if (this.columnConfigs) {
      for (const key of Object.keys(this.columnConfigs)) {
        const index = this.fullColumnNames.indexOf(key);
        if (index === -1) {
          throw new Error('The key "' + key + '" provided in columnConfigs does not match any of the column names (' + this.fullColumnNames.toString() + ").");
        }
      }
    }
    this.columnNamesValidated = true;
  }
  async maybeReadHeaderLine() {
    if (this.hasHeader) {
      const iter = await this.base.iterator();
      const firstElement = await iter.next();
      if (firstElement.done) {
        throw new Error("No data was found for CSV parsing.");
      }
      const firstLine = firstElement.value;
      const headers = this.parseRow(firstLine, false);
      return headers;
    } else {
      return null;
    }
  }
  async iterator() {
    if (!this.columnNamesValidated) {
      await this.setColumnNames();
    }
    let lines = await this.base.iterator();
    if (this.hasHeader) {
      lines = lines.skip(1);
    }
    return lines.map((x) => this.makeDataElement(x));
  }
  makeDataElement(line) {
    const values = this.parseRow(line);
    const features = {};
    const labels = {};
    for (let i = 0; i < this.fullColumnNames.length; i++) {
      const key = this.fullColumnNames[i];
      const config = this.columnConfigs ? this.columnConfigs[key] : null;
      if (this.configuredColumnsOnly && !config) {
        continue;
      } else {
        const value = values[i];
        let parsedValue = null;
        if (value === "") {
          if (config && config.default !== void 0) {
            parsedValue = config.default;
          } else if (config && (config.required || config.isLabel)) {
            throw new Error(`Required column ${key} is empty in this line: ${line}`);
          } else {
            parsedValue = void 0;
          }
        } else {
          const valueAsNum = Number(value);
          if (isNaN(valueAsNum)) {
            if (config && config.dtype === "bool") {
              parsedValue = this.getBoolean(value);
            } else {
              parsedValue = value;
            }
          } else if (!config || !config.dtype) {
            parsedValue = valueAsNum;
          } else {
            switch (config.dtype) {
              case "float32":
                parsedValue = valueAsNum;
                break;
              case "int32":
                parsedValue = Math.floor(valueAsNum);
                break;
              case "bool":
                parsedValue = this.getBoolean(value);
                break;
              default:
                parsedValue = valueAsNum;
            }
          }
        }
        config && config.isLabel ? labels[key] = parsedValue : features[key] = parsedValue;
      }
    }
    if (Object.keys(labels).length === 0) {
      return features;
    } else {
      return { xs: features, ys: labels };
    }
  }
  getBoolean(value) {
    if (value === "1" || value.toLowerCase() === "true") {
      return 1;
    } else {
      return 0;
    }
  }
  parseRow(line, validateElementCount = true) {
    const result = [];
    let readOffset = 0;
    const readLength = line.length;
    let currentState = STATE_OUT;
    for (let i = 0; i < readLength; i++) {
      switch (currentState) {
        case STATE_OUT:
          switch (line.charAt(i)) {
            case CODE_QUOTE:
              readOffset = i + 1;
              currentState = STATE_QUOTE;
              break;
            case this.delimiter:
              readOffset = i + 1;
              if (this.delimiter === " " && this.delimWhitespace) {
                break;
              }
              result.push("");
              currentState = STATE_OUT;
              break;
            default:
              currentState = STATE_FIELD;
              readOffset = i;
              break;
          }
          break;
        case STATE_FIELD:
          switch (line.charAt(i)) {
            case this.delimiter:
              result.push(line.substring(readOffset, i));
              currentState = STATE_OUT;
              readOffset = i + 1;
              break;
            default:
          }
          break;
        case STATE_QUOTE:
          switch (line.charAt(i)) {
            case CODE_QUOTE:
              currentState = STATE_QUOTE_AFTER_QUOTE;
              break;
            default:
          }
          break;
        case STATE_QUOTE_AFTER_QUOTE:
          switch (line.charAt(i)) {
            case this.delimiter:
              result.push(line.substring(readOffset, i - 1));
              currentState = STATE_OUT;
              readOffset = i + 1;
              break;
            case CODE_QUOTE:
              currentState = STATE_QUOTE;
              break;
            default:
              currentState = STATE_WITHIN_QUOTE_IN_QUOTE;
              break;
          }
          break;
        case STATE_WITHIN_QUOTE_IN_QUOTE:
          switch (line.charAt(i)) {
            case CODE_QUOTE:
              currentState = STATE_QUOTE;
              break;
            default:
          }
          break;
        default:
      }
    }
    if (currentState === STATE_QUOTE_AFTER_QUOTE) {
      result.push(line.substring(readOffset, readLength - 1));
    } else {
      result.push(line.substring(readOffset));
    }
    if (validateElementCount && result.length !== this.fullColumnNames.length) {
      throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${result}`);
    }
    return result;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/microphone_iterator.ts
var MicrophoneIterator = class extends LazyIterator {
  constructor(microphoneConfig) {
    super();
    this.microphoneConfig = microphoneConfig;
    this.isClosed = false;
    this.fftSize = microphoneConfig.fftSize || 1024;
    const fftSizeLog2 = Math.log2(this.fftSize);
    if (this.fftSize < 0 || fftSizeLog2 < 4 || fftSizeLog2 > 14 || !Number.isInteger(fftSizeLog2)) {
      throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);
    }
    this.numFrames = microphoneConfig.numFramesPerSpectrogram || 43;
    this.sampleRateHz = microphoneConfig.sampleRateHz;
    this.columnTruncateLength = microphoneConfig.columnTruncateLength || this.fftSize;
    this.audioTrackConstraints = microphoneConfig.audioTrackConstraints;
    this.smoothingTimeConstant = microphoneConfig.smoothingTimeConstant || 0;
    this.includeSpectrogram = microphoneConfig.includeSpectrogram === false ? false : true;
    this.includeWaveform = microphoneConfig.includeWaveform === true ? true : false;
    if (!this.includeSpectrogram && !this.includeWaveform) {
      throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.");
    }
  }
  summary() {
    return `microphone`;
  }
  static async create(microphoneConfig = {}) {
    if (env2().get("IS_NODE")) {
      throw new Error("microphone API is only supported in browser environment.");
    }
    const microphoneIterator = new MicrophoneIterator(microphoneConfig);
    await microphoneIterator.start();
    return microphoneIterator;
  }
  async start() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: this.audioTrackConstraints == null ? true : this.audioTrackConstraints,
        video: false
      });
    } catch (e) {
      throw new Error(`Error thrown while initializing video stream: ${e.message}`);
    }
    if (!this.stream) {
      throw new Error("Could not obtain audio from microphone.");
    }
    const ctxConstructor = window.AudioContext || window.webkitAudioContext;
    this.audioContext = new ctxConstructor();
    if (!this.sampleRateHz) {
      this.sampleRateHz = this.audioContext.sampleRate;
    } else if (this.audioContext.sampleRate !== this.sampleRateHz) {
      throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`);
    }
    const streamSource = this.audioContext.createMediaStreamSource(this.stream);
    this.analyser = this.audioContext.createAnalyser();
    this.analyser.fftSize = this.fftSize * 2;
    this.analyser.smoothingTimeConstant = this.smoothingTimeConstant;
    streamSource.connect(this.analyser);
    this.freqData = new Float32Array(this.fftSize);
    this.timeData = new Float32Array(this.fftSize);
    return;
  }
  async next() {
    if (this.isClosed) {
      return { value: null, done: true };
    }
    let spectrogramTensor;
    let waveformTensor;
    const audioDataQueue = await this.getAudioData();
    if (this.includeSpectrogram) {
      const freqData = this.flattenQueue(audioDataQueue.freqDataQueue);
      spectrogramTensor = this.getTensorFromAudioDataArray(freqData, [this.numFrames, this.columnTruncateLength, 1]);
    }
    if (this.includeWaveform) {
      const timeData = this.flattenQueue(audioDataQueue.timeDataQueue);
      waveformTensor = this.getTensorFromAudioDataArray(timeData, [this.numFrames * this.fftSize, 1]);
    }
    return {
      value: { "spectrogram": spectrogramTensor, "waveform": waveformTensor },
      done: false
    };
  }
  async capture() {
    return (await this.next()).value;
  }
  async getAudioData() {
    const freqDataQueue = [];
    const timeDataQueue = [];
    let currentFrames = 0;
    return new Promise((resolve) => {
      const intervalID = setInterval(() => {
        if (this.includeSpectrogram) {
          this.analyser.getFloatFrequencyData(this.freqData);
          if (this.freqData[0] === -Infinity) {
            resolve({ freqDataQueue, timeDataQueue });
          }
          freqDataQueue.push(this.freqData.slice(0, this.columnTruncateLength));
        }
        if (this.includeWaveform) {
          this.analyser.getFloatTimeDomainData(this.timeData);
          timeDataQueue.push(this.timeData.slice());
        }
        if (++currentFrames === this.numFrames) {
          clearInterval(intervalID);
          resolve({ freqDataQueue, timeDataQueue });
        }
      }, this.fftSize / this.sampleRateHz * 1e3);
    });
  }
  stop() {
    if (!this.isClosed) {
      this.isClosed = true;
      this.analyser.disconnect();
      this.audioContext.close();
      if (this.stream != null && this.stream.getTracks().length > 0) {
        this.stream.getTracks()[0].stop();
      }
    }
  }
  toArray() {
    throw new Error("Can not convert infinite audio stream to array.");
  }
  getSampleRate() {
    return this.sampleRateHz;
  }
  flattenQueue(queue) {
    const frameSize = queue[0].length;
    const freqData = new Float32Array(queue.length * frameSize);
    queue.forEach((data, i) => freqData.set(data, i * frameSize));
    return freqData;
  }
  getTensorFromAudioDataArray(freqData, shape) {
    const vals = new Float32Array(util_exports2.sizeFromShape(shape));
    vals.set(freqData, vals.length - freqData.length);
    return tensor2(vals, shape);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/webcam_iterator.ts
var WebcamIterator = class extends LazyIterator {
  constructor(webcamVideoElement, webcamConfig) {
    super();
    this.webcamVideoElement = webcamVideoElement;
    this.webcamConfig = webcamConfig;
    this.isClosed = true;
    this.resize = false;
    if (this.needToResize()) {
      this.resize = true;
      this.cropSize = [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth];
      this.cropBoxInd = tensor1d2([0], "int32");
      if (this.webcamConfig.centerCrop) {
        const widthCroppingRatio = this.webcamConfig.resizeWidth * 1 / this.webcamVideoElement.width;
        const heightCroppingRatio = this.webcamConfig.resizeHeight * 1 / this.webcamVideoElement.height;
        const widthCropStart = (1 - widthCroppingRatio) / 2;
        const heightCropStart = (1 - heightCroppingRatio) / 2;
        const widthCropEnd = widthCropStart + widthCroppingRatio;
        const heightCropEnd = heightCroppingRatio + heightCropStart;
        this.cropBox = tensor2d2([heightCropStart, widthCropStart, heightCropEnd, widthCropEnd], [1, 4]);
      } else {
        this.cropBox = tensor2d2([0, 0, 1, 1], [1, 4]);
      }
    }
  }
  summary() {
    return `webcam`;
  }
  static async create(webcamVideoElement, webcamConfig = {}) {
    if (env2().get("IS_NODE")) {
      throw new Error("tf.data.webcam is only supported in browser environment.");
    }
    if (!webcamVideoElement) {
      webcamVideoElement = document.createElement("video");
      if (!webcamConfig.resizeWidth || !webcamConfig.resizeHeight) {
        throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");
      }
      webcamVideoElement.width = webcamConfig.resizeWidth;
      webcamVideoElement.height = webcamConfig.resizeHeight;
    }
    const webcamIterator = new WebcamIterator(webcamVideoElement, webcamConfig);
    await webcamIterator.start();
    return webcamIterator;
  }
  async start() {
    if (this.webcamConfig.facingMode) {
      util_exports2.assert(this.webcamConfig.facingMode === "user" || this.webcamConfig.facingMode === "environment", () => `Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);
    }
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        video: {
          deviceId: this.webcamConfig.deviceId,
          facingMode: this.webcamConfig.facingMode ? this.webcamConfig.facingMode : "user",
          width: this.webcamVideoElement.width,
          height: this.webcamVideoElement.height
        }
      });
    } catch (e) {
      e.message = `Error thrown while initializing video stream: ${e.message}`;
      throw e;
    }
    if (!this.stream) {
      throw new Error("Could not obtain video from webcam.");
    }
    try {
      this.webcamVideoElement.srcObject = this.stream;
    } catch (error) {
      console.log(error);
      this.webcamVideoElement.src = window.URL.createObjectURL(this.stream);
    }
    this.webcamVideoElement.play();
    this.isClosed = false;
    return new Promise((resolve) => {
      this.webcamVideoElement.onloadedmetadata = () => {
        resolve();
      };
    });
  }
  async next() {
    if (this.isClosed) {
      return { value: null, done: true };
    }
    let img;
    try {
      img = browser_exports2.fromPixels(this.webcamVideoElement);
    } catch (e) {
      throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(e)}`);
    }
    if (this.resize) {
      try {
        return { value: this.cropAndResizeFrame(img), done: false };
      } catch (e) {
        throw new Error(`Error thrown cropping the video: ${e.message}`);
      } finally {
        img.dispose();
      }
    } else {
      return { value: img, done: false };
    }
  }
  needToResize() {
    if (this.webcamConfig.resizeWidth && this.webcamConfig.resizeHeight && (this.webcamVideoElement.width !== this.webcamConfig.resizeWidth || this.webcamVideoElement.height !== this.webcamConfig.resizeHeight)) {
      return true;
    }
    return false;
  }
  cropAndResizeFrame(img) {
    return tidy2(() => {
      const expandedImage = expandDims2(cast2(img, "float32"), 0);
      let resizedImage;
      resizedImage = image2.cropAndResize(expandedImage, this.cropBox, this.cropBoxInd, this.cropSize, "bilinear");
      const shape = resizedImage.shape;
      return reshape2(resizedImage, shape.slice(1));
    });
  }
  async capture() {
    return (await this.next()).value;
  }
  stop() {
    const tracks = this.stream.getTracks();
    tracks.forEach((track) => track.stop());
    try {
      this.webcamVideoElement.srcObject = null;
    } catch (error) {
      console.log(error);
      this.webcamVideoElement.src = null;
    }
    this.isClosed = true;
  }
  toArray() {
    throw new Error("Can not convert infinite video stream to array.");
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/datasource.ts
var DataSource = class {
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/string_iterator.ts
var StringIterator = class extends LazyIterator {
  split(separator) {
    return new SplitIterator(this, separator);
  }
};
var SplitIterator = class extends StringIterator {
  constructor(upstream, separator) {
    super();
    this.upstream = upstream;
    this.impl = new SplitIteratorImpl(upstream, separator);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var SplitIteratorImpl = class extends OneToManyIterator {
  constructor(upstream, separator) {
    super();
    this.upstream = upstream;
    this.separator = separator;
    this.carryover = "";
  }
  summary() {
    return `${this.upstream.summary()} -> Split('${this.separator}')`;
  }
  async pump() {
    const chunkResult = await this.upstream.next();
    if (chunkResult.done) {
      if (this.carryover === "") {
        return false;
      }
      this.outputQueue.push(this.carryover);
      this.carryover = "";
      return true;
    }
    const lines = chunkResult.value.split(this.separator);
    lines[0] = this.carryover + lines[0];
    for (const line of lines.slice(0, -1)) {
      this.outputQueue.push(line);
    }
    this.carryover = lines[lines.length - 1];
    return true;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/byte_chunk_iterator.ts
var ByteChunkIterator = class extends LazyIterator {
  decodeUTF8() {
    return new Utf8Iterator(this);
  }
};
var Utf8Iterator = class extends StringIterator {
  constructor(upstream) {
    super();
    this.upstream = upstream;
    this.impl = new Utf8IteratorImpl(upstream);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var Utf8IteratorImpl = class extends OneToManyIterator {
  constructor(upstream) {
    super();
    this.upstream = upstream;
    if (env2().get("IS_BROWSER")) {
      this.decoder = new TextDecoder("utf-8");
    } else {
      const { StringDecoder } = require_string_decoder();
      this.decoder = new StringDecoder("utf8");
    }
  }
  summary() {
    return `${this.upstream.summary()} -> Utf8`;
  }
  async pump() {
    const chunkResult = await this.upstream.next();
    let chunk;
    if (chunkResult.done) {
      return false;
    } else {
      chunk = chunkResult.value;
    }
    let text;
    if (env2().get("IS_BROWSER")) {
      text = this.decoder.decode(chunk, { stream: true });
    } else {
      text = this.decoder.write(Buffer.from(chunk.buffer));
    }
    this.outputQueue.push(text);
    return true;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/file_chunk_iterator.ts
var FileChunkIterator = class extends ByteChunkIterator {
  constructor(file, options = {}) {
    super();
    this.file = file;
    this.options = options;
    util_exports2.assert(file instanceof Uint8Array || (env2().get("IS_BROWSER") ? file instanceof File || file instanceof Blob : false), () => "FileChunkIterator only supports File, Blob and Uint8Array right now.");
    this.offset = options.offset || 0;
    this.chunkSize = options.chunkSize || 1024 * 1024;
  }
  summary() {
    return `FileChunks ${this.file}`;
  }
  async next() {
    if (this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size)) {
      return { value: null, done: true };
    }
    const chunk = new Promise((resolve, reject) => {
      const end = this.offset + this.chunkSize;
      if (this.file instanceof Uint8Array) {
        resolve(new Uint8Array(this.file.slice(this.offset, end)));
      } else {
        const fileReader = new FileReader();
        fileReader.onload = (event) => {
          let data = fileReader.result;
          if (data instanceof ArrayBuffer) {
            data = new Uint8Array(data);
          }
          if (!(data instanceof Uint8Array)) {
            return reject(new TypeError("FileReader returned unknown type."));
          }
          resolve(data);
        };
        fileReader.onabort = (event) => {
          return reject(new Error("Aborted"));
        };
        fileReader.onerror = (event) => {
          return reject(new Error(event.type));
        };
        const slice6 = this.file.slice(this.offset, end);
        fileReader.readAsArrayBuffer(slice6);
      }
      this.offset = end;
    });
    return { value: await chunk, done: false };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/iterators/url_chunk_iterator.ts
async function urlChunkIterator(url, options = {}) {
  let urlString;
  let requestInit;
  if (typeof url === "string") {
    urlString = url;
  } else {
    urlString = url.url;
    requestInit = getRequestInitFromRequest(url);
  }
  const response = await util_exports2.fetch(urlString, requestInit);
  if (response.ok) {
    const uint8Array = new Uint8Array(await response.arrayBuffer());
    return new FileChunkIterator(uint8Array, options);
  } else {
    throw new Error(response.statusText);
  }
}
var getRequestInitFromRequest = (request) => {
  const init2 = {
    method: request.method,
    headers: request.headers,
    body: request.body,
    mode: request.mode,
    credentials: request.credentials,
    cache: request.cache,
    redirect: request.redirect,
    referrer: request.referrer,
    integrity: request.integrity
  };
  return init2;
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/util/source_util.ts
function isLocalPath(source) {
  return typeof source === "string" && source.substr(0, 7) === "file://";
}

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/sources/file_data_source.ts
var FileDataSource = class extends DataSource {
  constructor(input2, options = {}) {
    super();
    this.input = input2;
    this.options = options;
  }
  async iterator() {
    if (isLocalPath(this.input) && env2().get("IS_NODE")) {
      const fs = __require("fs");
      this.input = fs.readFileSync(this.input.substr(7));
    }
    return new FileChunkIterator(this.input, this.options);
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/sources/url_data_source.ts
var URLDataSource = class extends DataSource {
  constructor(url, fileOptions = {}) {
    super();
    this.url = url;
    this.fileOptions = fileOptions;
  }
  async iterator() {
    if (isLocalPath(this.url)) {
      return new FileDataSource(this.url, this.fileOptions).iterator();
    } else {
      return urlChunkIterator(this.url, this.fileOptions);
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/readers.ts
function csv(source, csvConfig = {}) {
  return new CSVDataset(new URLDataSource(source), csvConfig);
}
function func(f) {
  const iter = iteratorFromFunction(f);
  return datasetFromIteratorFn(async () => iter);
}
function generator(generator2) {
  return datasetFromIteratorFn(async () => {
    const gen = await generator2();
    return iteratorFromFunction(() => gen.next());
  });
}
async function webcam(webcamVideoElement, webcamConfig) {
  return WebcamIterator.create(webcamVideoElement, webcamConfig);
}
async function microphone(microphoneConfig) {
  return MicrophoneIterator.create(microphoneConfig);
}

// node_modules/.pnpm/@tensorflow+tfjs-data@3.7.0_2d23fca999276b6587569019c21cba8f/node_modules/@tensorflow/tfjs-data/src/version.ts
var version13 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/cpu_util.ts
function assertNotComplex(tensor3, opName) {
  if (!Array.isArray(tensor3)) {
    tensor3 = [tensor3];
  }
  tensor3.forEach((t) => {
    if (t != null) {
      util_exports2.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
    }
  });
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/backend_cpu.ts
var whereImpl3 = kernel_impls_exports2.whereImpl;
var _MathBackendCPU = class extends KernelBackend2 {
  constructor() {
    super();
    this.blockSize = 48;
    this.firstUse = true;
    this.data = new DataStorage2(this, engine2());
  }
  nextDataId() {
    return _MathBackendCPU.nextDataId++;
  }
  write(values, shape, dtype) {
    if (this.firstUse) {
      this.firstUse = false;
      if (env2().get("IS_NODE")) {
        backend_util_exports2.warn("\n============================\nHi there \u{1F44B}. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================");
      }
    }
    const dataId = { id: this.nextDataId() };
    this.data.set(dataId, { values, dtype, refCount: 1 });
    return dataId;
  }
  makeTensorInfo(shape, dtype, values) {
    let outId;
    if (dtype === "string" && values != null && values.length > 0 && util_exports2.isString(values[0])) {
      const encodedValues = values.map((d) => util_exports2.encodeString(d));
      outId = this.write(encodedValues, shape, dtype);
    } else {
      outId = this.write(values, shape, dtype);
    }
    return { dataId: outId, shape, dtype };
  }
  refCount(dataId) {
    if (this.data.has(dataId)) {
      const tensorData = this.data.get(dataId);
      return tensorData.refCount;
    }
    return 0;
  }
  incRef(dataId) {
    const tensorData = this.data.get(dataId);
    tensorData.refCount++;
  }
  decRef(dataId) {
    if (this.data.has(dataId)) {
      const tensorData = this.data.get(dataId);
      tensorData.refCount--;
    }
  }
  move(dataId, values, shape, dtype, refCount) {
    this.data.set(dataId, { values, dtype, refCount });
  }
  numDataIds() {
    return this.data.numDataIds();
  }
  async read(dataId) {
    return this.readSync(dataId);
  }
  readSync(dataId) {
    const { dtype, complexTensorInfos } = this.data.get(dataId);
    if (dtype === "complex64") {
      const realValues = this.readSync(complexTensorInfos.real.dataId);
      const imagValues = this.readSync(complexTensorInfos.imag.dataId);
      return backend_util_exports2.mergeRealAndImagArrays(realValues, imagValues);
    }
    return this.data.get(dataId).values;
  }
  bufferSync(t) {
    const data = this.readSync(t.dataId);
    let decodedData = data;
    if (t.dtype === "string") {
      try {
        decodedData = data.map((d) => util_exports2.decodeString(d));
      } catch (e) {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    }
    return buffer2(t.shape, t.dtype, decodedData);
  }
  makeOutput(values, shape, dtype) {
    const dataId = this.write(values, shape, dtype);
    return engine2().makeTensorFromDataId(dataId, shape, dtype, this);
  }
  disposeData(dataId, force = false) {
    if (this.data.has(dataId)) {
      this.data.get(dataId).refCount--;
      if (!force && this.data.get(dataId).refCount > 0) {
        return false;
      }
      const { complexTensorInfos } = this.data.get(dataId);
      if (complexTensorInfos != null) {
        this.disposeData(complexTensorInfos.real.dataId, true);
        this.disposeData(complexTensorInfos.imag.dataId, true);
      }
      this.data.delete(dataId);
    }
    return true;
  }
  disposeIntermediateTensorInfo(tensorInfo) {
    this.disposeData(tensorInfo.dataId);
  }
  async time(f) {
    const start = util_exports2.now();
    f();
    const kernelMs = util_exports2.now() - start;
    return { kernelMs };
  }
  memory() {
    return {
      unreliable: true,
      reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
    };
  }
  where(condition) {
    assertNotComplex([condition], "where");
    const condVals = this.readSync(condition.dataId);
    return whereImpl3(condition.shape, condVals);
  }
  dispose() {
  }
  floatPrecision() {
    return 32;
  }
  epsilon() {
    return super.epsilon();
  }
};
var MathBackendCPU = _MathBackendCPU;
MathBackendCPU.nextDataId = 0;

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/shared.ts
var shared_exports = {};
__export(shared_exports, {
  addImpl: () => addImpl,
  bincountImpl: () => bincountImpl,
  bincountReduceImpl: () => bincountReduceImpl,
  ceilImpl: () => ceilImpl,
  concatImpl: () => concatImpl,
  equalImpl: () => equalImpl,
  expImpl: () => expImpl,
  expm1Impl: () => expm1Impl,
  floorImpl: () => floorImpl,
  gatherNdImpl: () => gatherNdImpl,
  gatherV2Impl: () => gatherV2Impl,
  greaterEqualImpl: () => greaterEqualImpl,
  greaterImpl: () => greaterImpl,
  lessEqualImpl: () => lessEqualImpl,
  lessImpl: () => lessImpl,
  linSpaceImpl: () => linSpaceImpl,
  logImpl: () => logImpl,
  maxImpl: () => maxImpl,
  maximumImpl: () => maximumImpl,
  minimumImpl: () => minimumImpl,
  multiplyImpl: () => multiplyImpl,
  negImpl: () => negImpl,
  notEqualImpl: () => notEqualImpl,
  prodImpl: () => prodImpl,
  rangeImpl: () => rangeImpl,
  rsqrtImpl: () => rsqrtImpl,
  simpleAbsImpl: () => simpleAbsImpl,
  sliceImpl: () => sliceImpl,
  sparseFillEmptyRowsImpl: () => sparseFillEmptyRowsImpl,
  sparseReshapeImpl: () => sparseReshapeImpl,
  sparseSegmentReductionImpl: () => sparseSegmentReductionImpl,
  squaredDifferenceImpl: () => squaredDifferenceImpl,
  stridedSliceImpl: () => stridedSliceImpl,
  stringNGramsImpl: () => stringNGramsImpl,
  stringSplitImpl: () => stringSplitImpl,
  stringToHashBucketFastImpl: () => stringToHashBucketFastImpl,
  subImpl: () => subImpl,
  tileImpl: () => tileImpl,
  topKImpl: () => topKImpl,
  transposeImpl: () => transposeImpl,
  uniqueImpl: () => uniqueImpl
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Abs.ts
function simpleAbsImpl(vals) {
  const resultValues = new Float32Array(vals.length);
  for (let i = 0; i < vals.length; ++i) {
    resultValues[i] = Math.abs(vals[i]);
  }
  return resultValues;
}
var abs3 = (args) => {
  const { x } = args.inputs;
  const cpuBackend = args.backend;
  assertNotComplex(x, "abs");
  let resultValues = new Float32Array(util_exports2.sizeFromShape(x.shape));
  const values = cpuBackend.data.get(x.dataId).values;
  resultValues = simpleAbsImpl(values);
  return cpuBackend.makeOutput(resultValues, x.shape, "float32");
};
var absConfig = {
  kernelName: Abs2,
  backendName: "cpu",
  kernelFunc: abs3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/binary_impl.ts
function createSimpleBinaryKernelImpl(op3) {
  return (aShape, bShape, aVals, bVals, dtype) => {
    const newShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    const resultRank = newShape.length;
    const resultStrides = util_exports2.computeStrides(newShape);
    const resultSize = util_exports2.sizeFromShape(newShape);
    const result = util_exports2.getTypedArrayFromDType(dtype, resultSize);
    const aRank = aShape.length;
    const bRank = bShape.length;
    const aStrides = util_exports2.computeStrides(aShape);
    const bStrides = util_exports2.computeStrides(bShape);
    const aBroadcastDims = backend_util_exports2.getBroadcastDims(aShape, newShape);
    const bBroadcastDims = backend_util_exports2.getBroadcastDims(bShape, newShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < result.length; ++i) {
        result[i] = op3(aVals[i % aVals.length], bVals[i % bVals.length]);
      }
    } else {
      for (let i = 0; i < result.length; ++i) {
        const loc = util_exports2.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports2.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports2.locToIndex(bLoc, bRank, bStrides);
        result[i] = op3(aVals[aIndex], bVals[bIndex]);
      }
    }
    return [result, newShape];
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Complex.ts
function complex3(args) {
  const { inputs, backend: backend3 } = args;
  const { real: real6, imag: imag5 } = inputs;
  const realVals = backend3.data.get(real6.dataId).values;
  const imagVals = backend3.data.get(imag5.dataId).values;
  const complexInfo = backend3.makeTensorInfo(real6.shape, "complex64");
  const complex6 = backend3.data.get(complexInfo.dataId);
  complex6.complexTensorInfos = {
    real: backend3.makeTensorInfo(real6.shape, "float32", realVals),
    imag: backend3.makeTensorInfo(imag5.shape, "float32", imagVals)
  };
  return complexInfo;
}
var complexConfig = {
  kernelName: Complex2,
  backendName: "cpu",
  kernelFunc: complex3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/zeros_impl.ts
function zeros4(backend3, shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = zeros4(backend3, shape, "float32");
    const imag5 = zeros4(backend3, shape, "float32");
    return complex3({ inputs: { real: real6, imag: imag5 }, backend: backend3 });
  }
  const values = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(shape), dtype);
  return backend3.makeTensorInfo(shape, dtype, values);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Identity.ts
function identity2(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  backend3.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}
var identityConfig = {
  kernelName: Identity2,
  backendName: "cpu",
  kernelFunc: identity2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Real.ts
function real3(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const real6 = backend3.data.get(input2.dataId).complexTensorInfos.real;
  const realVal = backend3.data.get(real6.dataId).values;
  return backend3.makeTensorInfo(real6.shape, real6.dtype, realVal);
}
var realConfig = {
  kernelName: Real2,
  backendName: "cpu",
  kernelFunc: real3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Cast.ts
function cast4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity2({ inputs: { x }, backend: backend3 });
    }
    const zerosTensorInfo = zeros4(backend3, x.shape, x.dtype);
    const floatX = cast4({ inputs: { x }, backend: backend3, attrs: { dtype: "float32" } });
    const result = complex3({ inputs: { real: floatX, imag: zerosTensorInfo }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(zerosTensorInfo);
    backend3.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend3 });
    const result = cast4({ inputs: { x: realPart }, backend: backend3, attrs: { dtype } });
    backend3.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports2.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity2({ inputs: { x }, backend: backend3 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  if (dtype === "int32") {
    const values = backend3.data.get(x.dataId).values;
    const resultValues = Int32Array.from(values);
    return backend3.makeTensorInfo(x.shape, "int32", resultValues);
  }
  if (dtype === "bool") {
    const xVals = backend3.data.get(x.dataId).values;
    const zero = util_exports2.toTypedArray([0], x.dtype);
    const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(x.shape, [], xVals, zero, "bool");
    return backend3.makeTensorInfo(resultShape, "bool", resultData);
  }
  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
}
var castConfig = {
  kernelName: Cast2,
  backendName: "cpu",
  kernelFunc: cast4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/binary_utils.ts
function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
  if (complexImpl == null) {
    return ({ inputs, backend: backend3 }) => {
      const { a, b } = inputs;
      const cpuBackend = backend3;
      assertNotComplex([a, b], name);
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(aVals) : aVals;
      const decodedBVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(bVals) : bVals;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    };
  }
  return ({ inputs, backend: backend3 }) => {
    const { a, b } = inputs;
    const cpuBackend = backend3;
    if (a.dtype === "complex64" || b.dtype === "complex64") {
      const $aComplex = cast4({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
      const aReal = $aComplexVals.complexTensorInfos.real;
      const aImag = $aComplexVals.complexTensorInfos.imag;
      const aRealVals = cpuBackend.data.get(aReal.dataId).values;
      const aImagVals = cpuBackend.data.get(aImag.dataId).values;
      const $bComplex = cast4({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
      const bReal = $bComplexVals.complexTensorInfos.real;
      const bImag = $bComplexVals.complexTensorInfos.imag;
      const bRealVals = cpuBackend.data.get(bReal.dataId).values;
      const bImagVals = cpuBackend.data.get(bImag.dataId).values;
      const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
      const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
      const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
      const result = complex3({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
      cpuBackend.disposeIntermediateTensorInfo($aComplex);
      cpuBackend.disposeIntermediateTensorInfo($bComplex);
      cpuBackend.disposeIntermediateTensorInfo(resultReal);
      cpuBackend.disposeIntermediateTensorInfo(resultImag);
      return result;
    } else {
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    }
  };
}
function createComplexBinaryKernelImpl(op3) {
  return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
    const resultShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    const resultSize = util_exports2.sizeFromShape(resultShape);
    const resultRank = resultShape.length;
    const resultStrides = util_exports2.computeStrides(resultShape);
    const resultRealVals = util_exports2.getTypedArrayFromDType("float32", resultSize);
    const resultImagVals = util_exports2.getTypedArrayFromDType("float32", resultSize);
    const aBroadcastDims = backend_util_exports2.getBroadcastDims(aShape, resultShape);
    const bBroadcastDims = backend_util_exports2.getBroadcastDims(bShape, resultShape);
    const aVals = backend_util_exports2.mergeRealAndImagArrays(aRealVals, aImagVals);
    const bVals = backend_util_exports2.mergeRealAndImagArrays(bRealVals, bImagVals);
    const aRank = aShape.length;
    const aStrides = util_exports2.computeStrides(aShape);
    const bRank = bShape.length;
    const bStrides = util_exports2.computeStrides(bShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < resultRealVals.length; i++) {
        const aIdx = i % aVals.length;
        const bIdx = i % bVals.length;
        const result = op3(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
        resultRealVals[i] = result.real;
        resultImagVals[i] = result.imag;
      }
    } else {
      for (let i = 0; i < resultRealVals.length; i++) {
        const loc = util_exports2.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports2.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports2.locToIndex(bLoc, bRank, bStrides);
        const opResult = op3(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
        resultRealVals[i] = opResult.real;
        resultImagVals[i] = opResult.imag;
      }
    }
    return [resultRealVals, resultImagVals, resultShape];
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Add.ts
var addImpl = createSimpleBinaryKernelImpl((a, b) => a + b);
var addComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return { real: aReal + bReal, imag: aImag + bImag };
});
var add6 = binaryKernelFunc(Add2, addImpl, addComplexImpl);
var addConfig = {
  kernelName: Add2,
  backendName: "cpu",
  kernelFunc: add6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Bincount_impl.ts
function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
  const weightsSize = util_exports2.sizeFromShape(weightsShape);
  const outVals = util_exports2.makeZerosTypedArray(size, weightsDtype);
  for (let i = 0; i < xVals.length; i++) {
    const value = xVals[i];
    if (value < 0) {
      throw new Error("Input x must be non-negative!");
    }
    if (value >= size) {
      continue;
    }
    if (weightsSize > 0) {
      outVals[value] += weightsVals[i];
    } else {
      outVals[value] += 1;
    }
  }
  return outVals;
}
function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput = false) {
  const numRows = xBuf.shape[0];
  const numCols = xBuf.shape[1];
  const outBuf = buffer2([numRows, size], weightsBuf.dtype);
  for (let i = 0; i < numRows; i++) {
    for (let j = 0; j < numCols; j++) {
      const value = xBuf.get(i, j);
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size) {
        continue;
      }
      if (binaryOutput) {
        outBuf.set(1, i, value);
      } else {
        if (weightsBuf.size > 0) {
          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
        } else {
          outBuf.set(outBuf.get(i, value) + 1, i, value);
        }
      }
    }
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/unary_impl.ts
function createSimpleUnaryImpl(op3) {
  return (values, dtype, attrs) => {
    const newValues = util_exports2.getTypedArrayFromDType(dtype, values.length);
    for (let i = 0; i < values.length; ++i) {
      newValues[i] = op3(values[i], attrs);
    }
    return newValues;
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/unary_utils.ts
function unaryKernelFunc(name, op3, dtype) {
  return ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    assertNotComplex(x, name);
    if (x.dtype === "string" || dtype === "string") {
      throw new Error("unaryKernelFunc does not support string input/output");
    }
    const cpuBackend = backend3;
    const values = cpuBackend.data.get(x.dataId).values;
    const xSize = util_exports2.sizeFromShape(x.shape);
    const $dtype = dtype || x.dtype;
    const newValues = util_exports2.getArrayFromDType($dtype, xSize);
    for (let i = 0; i < xSize; ++i) {
      newValues[i] = op3(values[i], attrs);
    }
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}
function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
  return ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    assertNotComplex(x, name);
    if (x.dtype === "string" || dtype === "string") {
      throw new Error("unaryKernelFunc does not support string input/output");
    }
    const cpuBackend = backend3;
    const values = cpuBackend.data.get(x.dataId).values;
    const $dtype = dtype || x.dtype;
    const newValues = unaryImpl(values, $dtype, attrs);
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Ceil.ts
var ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));
var ceil3 = unaryKernelFuncFromImpl(Ceil2, ceilImpl);
var ceilConfig = {
  kernelName: Ceil2,
  backendName: "cpu",
  kernelFunc: ceil3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Concat_impl.ts
function concatImpl(inputs, outShape, dtype, simplyConcat) {
  const outVals = util_exports2.getArrayFromDType(dtype, util_exports2.sizeFromShape(outShape));
  if (simplyConcat && dtype !== "string") {
    let offset = 0;
    inputs.forEach((input2) => {
      const size = util_exports2.sizeFromShape(input2.shape);
      outVals.set(input2.vals, offset);
      offset += size;
    });
  } else {
    let colOffset = 0;
    inputs.forEach((input2) => {
      const decodedData = dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(input2.vals) : input2.vals;
      let tIdx = 0;
      for (let row = 0; row < input2.shape[0]; ++row) {
        const resIdx = row * outShape[1] + colOffset;
        for (let col = 0; col < input2.shape[1]; ++col) {
          outVals[resIdx + col] = decodedData[tIdx++];
        }
      }
      colOffset += input2.shape[1];
    });
  }
  return outVals;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Equal.ts
var equalImpl = createSimpleBinaryKernelImpl((a, b) => a === b ? 1 : 0);
var equal3 = binaryKernelFunc(Equal2, equalImpl, null, "bool");
var equalConfig = {
  kernelName: Equal2,
  backendName: "cpu",
  kernelFunc: equal3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Exp.ts
var expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));
var exp3 = unaryKernelFuncFromImpl(Exp2, expImpl);
var expConfig = {
  kernelName: Exp2,
  backendName: "cpu",
  kernelFunc: exp3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Expm1.ts
var expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));
var expm13 = unaryKernelFuncFromImpl(Expm12, expm1Impl);
var expm1Config = {
  kernelName: Expm12,
  backendName: "cpu",
  kernelFunc: expm13
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Floor.ts
var floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));
var floor3 = unaryKernelFuncFromImpl(Floor2, floorImpl);
var floorConfig = {
  kernelName: Floor2,
  backendName: "cpu",
  kernelFunc: floor3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/GatherNd_Impl.ts
function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
  const outBuf = buffer2([numSlices, sliceSize], dtype);
  for (let i = 0; i < numSlices; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      flattenIndex += dim * strides[j];
      index.push(dim);
    }
    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      outBuf.values[i * sliceSize + k] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
    }
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/GatherV2_impl.ts
function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
  const outBuf = buffer2(flattenOutputShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const newLoc = outBuf.indexToLoc(i);
    const originalLoc = newLoc.slice();
    const batchIdx = originalLoc[0];
    const indicesIdx = originalLoc[2];
    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
    originalLoc[2] = indicesBuf.values[indicesIndex];
    const originalIndex = xBuf.locToIndex(originalLoc);
    outBuf.values[i] = xBuf.values[originalIndex];
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Greater.ts
var greaterImpl = createSimpleBinaryKernelImpl((a, b) => a > b ? 1 : 0);
var greater4 = binaryKernelFunc(Greater2, greaterImpl, null, "bool");
var greaterConfig = {
  kernelName: Greater2,
  backendName: "cpu",
  kernelFunc: greater4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/GreaterEqual.ts
var greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => a >= b ? 1 : 0);
var greaterEqual3 = binaryKernelFunc(GreaterEqual2, greaterEqualImpl, null, "bool");
var greaterEqualConfig = {
  kernelName: GreaterEqual2,
  backendName: "cpu",
  kernelFunc: greaterEqual3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Less.ts
var lessImpl = createSimpleBinaryKernelImpl((a, b) => a < b ? 1 : 0);
var less4 = binaryKernelFunc(Less2, lessImpl, null, "bool");
var lessConfig = {
  kernelName: Less2,
  backendName: "cpu",
  kernelFunc: less4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LessEqual.ts
var lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => a <= b ? 1 : 0);
var lessEqual3 = binaryKernelFunc(LessEqual2, lessEqualImpl, null, "bool");
var lessEqualConfig = {
  kernelName: LessEqual2,
  backendName: "cpu",
  kernelFunc: lessEqual3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LinSpace_impl.ts
function linSpaceImpl(start, stop, num) {
  const step6 = (stop - start) / (num - 1);
  const values = util_exports2.makeZerosTypedArray(num, "float32");
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step6;
  }
  return values;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Log.ts
var logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));
var log5 = unaryKernelFuncFromImpl(Log2, logImpl);
var logConfig = {
  kernelName: Log2,
  backendName: "cpu",
  kernelFunc: log5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Max_impl.ts
function maxImpl(aVals, reduceSize, outShape, dtype) {
  const vals = util_exports2.getTypedArrayFromDType(dtype, util_exports2.sizeFromShape(outShape));
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max7 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value > max7) {
        max7 = value;
      }
    }
    vals[i] = max7;
  }
  return vals;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Maximum.ts
var maximumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.max(aValue, bValue));
var maximum4 = binaryKernelFunc(Maximum2, maximumImpl);
var maximumConfig = {
  kernelName: Maximum2,
  backendName: "cpu",
  kernelFunc: maximum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Minimum.ts
var minimumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.min(aValue, bValue));
var minimum4 = binaryKernelFunc(Minimum2, minimumImpl);
var minimumConfig = {
  kernelName: Minimum2,
  backendName: "cpu",
  kernelFunc: minimum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Multiply.ts
var multiplyImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue * bValue);
var multiplyComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return {
    real: aReal * bReal - aImag * bImag,
    imag: aReal * bImag + aImag * bReal
  };
});
var multiply2 = binaryKernelFunc(Multiply2, multiplyImpl, multiplyComplexImpl);
var multiplyConfig = {
  kernelName: Multiply2,
  backendName: "cpu",
  kernelFunc: multiply2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Neg.ts
function negImpl(xVals, xShape, xDtype) {
  const minusOne = util_exports2.createScalarValue(-1, xDtype);
  return multiplyImpl([], xShape, minusOne, xVals, xDtype);
}
function neg3(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  assertNotComplex(x, "neg");
  const xVals = backend3.data.get(x.dataId).values;
  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);
  return backend3.makeTensorInfo(newShape, x.dtype, res);
}
var negConfig = {
  kernelName: Neg2,
  backendName: "cpu",
  kernelFunc: neg3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/NotEqual.ts
var notEqualImpl = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0);
var notEqual3 = binaryKernelFunc(NotEqual2, notEqualImpl, null, "bool");
var notEqualConfig = {
  kernelName: NotEqual2,
  backendName: "cpu",
  kernelFunc: notEqual3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Transpose_impl.ts
function transposeImpl(xVals, xShape, dtype, perm, newShape) {
  const xRank = xShape.length;
  const xSize = util_exports2.sizeFromShape(xShape);
  const xStrides = util_exports2.computeStrides(xShape);
  const newStrides = util_exports2.computeStrides(newShape);
  const result = util_exports2.getTypedArrayFromDType(dtype, util_exports2.sizeFromShape(newShape));
  for (let i = 0; i < xSize; ++i) {
    const loc = util_exports2.indexToLoc(i, xRank, xStrides);
    const newLoc = new Array(loc.length);
    for (let i2 = 0; i2 < newLoc.length; i2++) {
      newLoc[i2] = loc[perm[i2]];
    }
    const newIndex = util_exports2.locToIndex(newLoc, xRank, newStrides);
    result[newIndex] = xVals[i];
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Transpose.ts
function transpose3(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x } = inputs;
  const { perm } = attrs;
  assertNotComplex(x, "transpose");
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  const values = backend3.data.get(x.dataId).values;
  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
  const dataId = backend3.write(result, newShape, x.dtype);
  return { dataId, shape: newShape, dtype: x.dtype };
}
var transposeConfig = {
  kernelName: Transpose2,
  backendName: "cpu",
  kernelFunc: transpose3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Prod.ts
function prodImpl(xShape, xDtype, xVals, reductionAxes) {
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(xShape, reductionAxes);
  const outDtype = upcastType2(xDtype, "int32");
  const outVals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(outShape), outDtype);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  for (let i = 0; i < outVals.length; ++i) {
    const offset = i * reduceSize;
    let prod6 = 1;
    for (let j = 0; j < reduceSize; ++j) {
      prod6 *= xVals[offset + j];
    }
    outVals[i] = prod6;
  }
  return { outVals, outShape, outDtype };
}
function prod3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "prod");
  const xRank = x.shape.length;
  const axes = util_exports2.parseAxisParam(axis, x.shape);
  const permutation = backend_util_exports2.getAxesPermutation(axes, xRank);
  let reductionAxes = axes;
  let permutedX = x;
  const intermediateTensorInfos = [];
  if (permutation != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutation } });
    intermediateTensorInfos.push(permutedX);
    reductionAxes = backend_util_exports2.getInnerMostAxes(reductionAxes.length, xRank);
  }
  const xVals = backend3.data.get(permutedX.dataId).values;
  const { outVals, outShape, outDtype } = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);
  let resultShape = outShape;
  if (keepDims) {
    resultShape = backend_util_exports2.expandShapeToKeepDim(outShape, axes);
  }
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return backend3.makeTensorInfo(resultShape, outDtype, outVals);
}
var prodConfig = {
  kernelName: Prod2,
  backendName: "cpu",
  kernelFunc: prod3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Range_impl.ts
function rangeImpl(start, stop, step6, dtype) {
  const sameStartStop = start === stop;
  const increasingRangeNegativeStep = start < stop && step6 < 0;
  const decreasingRangePositiveStep = stop < start && step6 > 1;
  if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
    return util_exports2.makeZerosTypedArray(0, dtype);
  }
  const numElements = Math.abs(Math.ceil((stop - start) / step6));
  const values = util_exports2.makeZerosTypedArray(numElements, dtype);
  if (stop < start && step6 === 1) {
    step6 = -1;
  }
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step6;
  }
  return values;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Rsqrt.ts
var rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));
var rsqrt3 = unaryKernelFuncFromImpl(Rsqrt2, rsqrtImpl);
var rsqrtConfig = {
  kernelName: Rsqrt2,
  backendName: "cpu",
  kernelFunc: rsqrt3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Slice.ts
function sliceImpl(vals, begin, size, shape, dtype) {
  const isContinous = slice_util_exports2.isSliceContinous(shape, begin, size);
  const length = util_exports2.sizeFromShape(size);
  const xStrides = util_exports2.computeStrides(shape);
  if (isContinous) {
    const flatOffset = slice_util_exports2.computeFlatOffset(begin, xStrides);
    if (dtype === "string") {
      return vals.slice(flatOffset, flatOffset + length);
    }
    return vals.subarray(flatOffset, flatOffset + length);
  }
  const decodedData = dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(vals) : vals;
  const inBuf = buffer2(shape, dtype, decodedData);
  const outBuf = buffer2(size, dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.map((idx, j) => idx + begin[j]);
    outBuf.set(inBuf.get(...inLoc), ...outLoc);
  }
  if (dtype === "string") {
    return backend_util_exports2.fromStringArrayToUint8(outBuf.values);
  }
  return outBuf.values;
}
function slice3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { begin, size } = attrs;
  assertNotComplex(x, "slice");
  const [$begin, $size] = slice_util_exports2.parseSliceParams(x, begin, size);
  slice_util_exports2.assertParamsValid(x, $begin, $size);
  const vals = backend3.data.get(x.dataId).values;
  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
  return backend3.makeTensorInfo($size, x.dtype, outVals);
}
var sliceConfig = {
  kernelName: Slice2,
  backendName: "cpu",
  kernelFunc: slice3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseFillEmptyRows_impl.ts
function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
  const indicesCount = indicesShape[0];
  const denseRows = denseShape[0];
  const emptyRowIndicator = new Array(denseRows);
  const reverseIndexMap = new Array(indicesCount);
  const rank = indicesShape[1];
  if (denseRows === 0) {
    if (indicesCount !== 0) {
      throw new Error(`Received SparseTensor with denseShape[0] = 0 but
         indices.shape[0] = ${indicesCount}`);
    }
    const outputIndices = util_exports2.getArrayFromDType(indicesDType, 0);
    const outputValues = util_exports2.getArrayFromDType(valuesDType, 0);
    return [
      outputIndices,
      [0, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
  let rowsAreOrdered = true;
  let lastIndicesRow = 0;
  const csrOffset = new Array(denseRows).fill(0);
  for (let i = 0; i < indicesCount; ++i) {
    const row = indices[i * rank];
    if (row < 0) {
      throw new Error(`indices(${i}, 0) is invalid: ${row} < 0`);
    }
    if (row >= denseRows) {
      throw new Error(`indices(${i}, 0) is invalid: ${row} >= ${denseRows}`);
    }
    ++csrOffset[row];
    rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
    lastIndicesRow = row;
  }
  let allRowsFull = true;
  for (let row = 0; row < denseRows; ++row) {
    const rowEmpty = csrOffset[row] === 0;
    emptyRowIndicator[row] = rowEmpty;
    allRowsFull = allRowsFull && !rowEmpty;
    csrOffset[row] = Math.max(csrOffset[row], 1);
    if (row > 0) {
      csrOffset[row] += csrOffset[row - 1];
    }
  }
  if (allRowsFull && rowsAreOrdered) {
    const outputIndices = indices;
    const outputValues = values;
    for (let i = 0; i < indicesCount; ++i) {
      reverseIndexMap[i] = i;
    }
    return [
      outputIndices,
      [indicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  } else {
    const fullIndicesCount = csrOffset[denseRows - 1];
    const outputIndices = util_exports2.getArrayFromDType(indicesDType, fullIndicesCount * rank);
    const outputValues = util_exports2.getArrayFromDType(valuesDType, fullIndicesCount);
    const filledCount = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      const offset = filledCount[row];
      const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
      filledCount[row]++;
      for (let j = 0; j < rank; ++j) {
        outputIndices[outputI * rank + j] = indices[i * rank + j];
      }
      outputValues[outputI] = values[i];
      reverseIndexMap[i] = outputI;
    }
    for (let row = 0; row < denseRows; ++row) {
      const rowCount = filledCount[row];
      if (rowCount === 0) {
        const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
        outputIndices[startingIndex * rank + 0] = row;
        for (let col = 1; col < rank; ++col) {
          outputIndices[startingIndex * rank + col] = 0;
        }
        outputValues[startingIndex] = defaultValue;
      }
    }
    return [
      outputIndices,
      [fullIndicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseReshape_impl.ts
function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
  const denseSize = util_exports2.sizeFromShape(inputShape);
  const nnz = inputIndicesShape[0];
  const outputRank = targetShape.length;
  const outputShape = [];
  let product = 1;
  let unknownIndex = -1;
  for (let d = 0; d < outputRank; ++d) {
    const size = targetShape[d];
    if (size === -1) {
      if (unknownIndex !== -1) {
        throw new Error(`only one output dimension may be -1, not both ${unknownIndex} and ${d}`);
      }
      unknownIndex = d;
      outputShape.push(1);
    } else {
      if (size < 0) {
        throw new Error(`size ${d} must be non-negative, not ${size}`);
      }
      product *= size;
      outputShape.push(size);
    }
  }
  if (unknownIndex !== -1) {
    if (product <= 0) {
      throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");
    }
    const missing = Math.trunc(denseSize / product);
    if (product * missing !== denseSize) {
      throw new Error(`Input to reshape is a SparseTensor with ${denseSize}
          dense values, but the requested shape requires a multiple of ${product}. inputShape=${inputShape} outputShape= ${outputShape}`);
    }
    outputShape[unknownIndex] = missing;
  }
  const outputSize = util_exports2.sizeFromShape(outputShape);
  if (outputSize !== denseSize) {
    throw new Error(`Input to reshape is a tensor with ${denseSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`);
  }
  const inputRank = inputShape.length;
  const inputStrides = [];
  if (inputRank > 0) {
    inputStrides[inputRank - 1] = 1;
    for (let d = inputRank - 2; d >= 0; --d) {
      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
    }
  }
  const outputStrides = [];
  if (outputRank > 0) {
    outputStrides[outputRank - 1] = 1;
    for (let d = outputRank - 2; d >= 0; --d) {
      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
    }
  }
  const newIndices = util_exports2.getArrayFromDType(inputDType, nnz * outputRank);
  for (let i = 0; i < nnz; ++i) {
    let id = 0;
    for (let j = 0; j < inputRank; ++j) {
      id += inputIndices[i * inputRank + j] * inputStrides[j];
    }
    for (let j = 0; j < outputRank; ++j) {
      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
      id %= outputStrides[j];
    }
  }
  return [newIndices, [nnz, outputRank], outputShape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseSegmentReduction_impl.ts
function sparseSegmentReductionImpl(input2, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
  const numIndices = indices.length;
  if (numIndices !== segmentIds.length) {
    throw new Error(`segmentIds and indices should have same size.`);
  }
  const inputFlat = [inputShape[0], input2.length / inputShape[0]];
  const numCol = inputFlat[1];
  const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
  const outputRows = lastSegmentIdPlusOne;
  if (outputRows < 0) {
    throw new Error(`segment ids must be >= 0`);
  }
  const outputShape = inputShape.slice();
  outputShape[0] = outputRows;
  const outputLength = outputShape.reduce((product, value) => product * value, 1);
  const output = util_exports2.getArrayFromDType(inputDType, outputLength);
  if (numIndices === 0) {
    if (outputRows > 0) {
      output.fill(defaultValue);
    }
    return [output, outputShape];
  }
  if (outputRows <= 0) {
    throw new Error(`segment ids must be >= 0`);
  }
  let start = 0, end = 1;
  let uninitializedIndex = 0;
  let outIndex = segmentIds[start];
  while (true) {
    let nextIndex = 0;
    if (end < numIndices) {
      nextIndex = segmentIds[end];
      if (outIndex === nextIndex) {
        ++end;
        continue;
      }
      if (outIndex >= nextIndex) {
        throw new Error(`segment ids are not increasing`);
      }
    }
    if (outIndex < 0 || outIndex >= outputRows) {
      throw new Error(`Segment id ${outIndex} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`);
    }
    if (outIndex > uninitializedIndex) {
      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
    }
    for (let i = start; i < end; ++i) {
      const index = indices[i];
      if (index < 0 || index >= inputFlat[0]) {
        throw new Error(`Bad: indices[${i}] == ${indices[i]} out of range [0, ${inputFlat[0]})`);
      }
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] += input2[index * numCol + j];
      }
    }
    if (isMean) {
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] /= end - start;
      }
    }
    start = end;
    ++end;
    uninitializedIndex = outIndex + 1;
    outIndex = nextIndex;
    if (end > numIndices) {
      break;
    }
  }
  if (uninitializedIndex < outputRows) {
    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
  }
  return [output, outputShape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SquaredDifference.ts
var squaredDifferenceImpl = createSimpleBinaryKernelImpl((a, b) => {
  const diff = a - b;
  return diff * diff;
});
var squaredDifference3 = binaryKernelFunc(SquaredDifference2, squaredDifferenceImpl);
var squaredDifferenceConfig = {
  kernelName: SquaredDifference2,
  backendName: "cpu",
  kernelFunc: squaredDifference3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StridedSlice_impl.ts
function stridedSliceImpl(outShape, xBuf, strides, begin) {
  const outBuf = buffer2(outShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; i++) {
    const loc = outBuf.indexToLoc(i);
    const newLoc = new Array(loc.length);
    for (let j = 0; j < newLoc.length; j++) {
      newLoc[j] = loc[j] * strides[j] + begin[j];
    }
    outBuf.set(xBuf.get(...newLoc), ...loc);
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts
var StringNGramsOp = class {
  constructor(separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
    this.separator = util_exports2.encodeString(separator);
    this.nGramWidths = nGramWidths;
    this.leftPad = util_exports2.encodeString(leftPad);
    this.rightPad = util_exports2.encodeString(rightPad3);
    this.padWidth = padWidth;
    this.preserveShort = preserveShortSequences;
  }
  getPadWidth(nGramWidth) {
    return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
  }
  getNumNGrams(length, nGramWidth) {
    const padWidth = this.getPadWidth(nGramWidth);
    return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
  }
  createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
      const padWidth = this.getPadWidth(nGramWidth);
      const leftPadding = Math.max(0, padWidth - nGramIndex);
      const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
      const numTokens = nGramWidth - (leftPadding + rightPadding);
      const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
      let nGramSize = 0;
      nGramSize += leftPadding * this.leftPad.length;
      for (let n = 0; n < numTokens; ++n) {
        nGramSize += data[dataStartIndex + n].length;
      }
      nGramSize += rightPadding * this.rightPad.length;
      const numSeparators = leftPadding + rightPadding + numTokens - 1;
      nGramSize += numSeparators * this.separator.length;
      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
      const nGram = output[outputStartIndex + nGramIndex];
      let nextNGramIndex = 0;
      const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
      for (let n = 0; n < leftPadding; ++n) {
        appendToNGram(this.leftPad);
        appendToNGram(this.separator);
      }
      for (let n = 0; n < numTokens - 1; ++n) {
        appendToNGram(data[dataStartIndex + n]);
        appendToNGram(this.separator);
      }
      if (numTokens > 0) {
        appendToNGram(data[dataStartIndex + numTokens - 1]);
        for (let n = 0; n < rightPadding; ++n) {
          appendToNGram(this.separator);
          appendToNGram(this.rightPad);
        }
      } else {
        for (let n = 0; n < rightPadding - 1; ++n) {
          appendToNGram(this.rightPad);
          appendToNGram(this.separator);
        }
        appendToNGram(this.rightPad);
      }
    }
  }
  compute(data, splits) {
    const inputDataSize = data.length;
    const splitsSize = splits.length;
    if (splitsSize > 0) {
      let prevSplit = splits[0];
      if (prevSplit !== 0) {
        throw new Error(`First split value must be 0, got ${prevSplit}`);
      }
      for (let i = 1; i < splitsSize; ++i) {
        let validSplits = splits[i] >= prevSplit;
        validSplits = validSplits && splits[i] <= inputDataSize;
        if (!validSplits) {
          throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
        }
        prevSplit = splits[i];
      }
      if (prevSplit !== inputDataSize) {
        throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
      }
    }
    const numBatchItems = splitsSize - 1;
    const nGramsSplits = util_exports2.getArrayFromDType("int32", splitsSize);
    if (inputDataSize === 0 || splitsSize === 0) {
      const empty = new Array(inputDataSize);
      for (let i = 0; i <= numBatchItems; ++i) {
        nGramsSplits[i] = 0;
      }
      return [empty, nGramsSplits];
    }
    nGramsSplits[0] = 0;
    for (let i = 1; i <= numBatchItems; ++i) {
      const length = splits[i] - splits[i - 1];
      let numNGrams = 0;
      this.nGramWidths.forEach((nGramWidth) => {
        numNGrams += this.getNumNGrams(length, nGramWidth);
      });
      if (this.preserveShort && length > 0 && numNGrams === 0) {
        numNGrams = 1;
      }
      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
    }
    const nGrams = new Array(nGramsSplits[numBatchItems]);
    for (let i = 0; i < numBatchItems; ++i) {
      const splitIndex = splits[i];
      let outputStartIdx = nGramsSplits[i];
      this.nGramWidths.forEach((nGramWidth) => {
        const length = splits[i + 1] - splits[i];
        const numNGrams = this.getNumNGrams(length, nGramWidth);
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
        outputStartIdx += numNGrams;
      });
      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
        const dataLength = splits[i + 1] - splits[i];
        if (dataLength === 0) {
          continue;
        }
        const nGramWidth = dataLength + 2 * this.padWidth;
        const numNGrams = 1;
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
      }
    }
    return [nGrams, nGramsSplits];
  }
};
function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
  return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences).compute(data, dataSplits);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringSplit_impl.ts
function split4(str, delimiters, skipEmpty) {
  if (!str.length) {
    return [];
  }
  if (delimiters.length === 0) {
    const result2 = new Array(str.length);
    for (let i = 0; i < str.length; ++i) {
      result2[i] = str.subarray(i, i + 1);
    }
    return result2;
  }
  if (delimiters.length === 1) {
    const delimiter = delimiters[0];
    const result2 = [];
    let f = str.indexOf(delimiter);
    while (f !== -1) {
      const token = str.subarray(0, f);
      if (!skipEmpty || token.length !== 0) {
        result2.push(token);
      }
      str = str.subarray(f + 1);
      f = str.indexOf(delimiter);
    }
    if (!skipEmpty || str.length !== 0) {
      result2.push(str);
    }
    return result2;
  }
  const result = [];
  let tokenStart = 0;
  for (let i = 0; i < str.length + 1; i++) {
    if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
      const token = str.subarray(tokenStart, i);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      tokenStart = i + 1;
    }
  }
  return result;
}
function stringSplitImpl(input2, delimiter, skipEmpty) {
  const batchSize = input2.length;
  const tokens = [];
  let outputSize = 0;
  let maxNumEntries = 0;
  const numIndices = new Array(batchSize);
  for (let i = 0; i < batchSize; ++i) {
    const parts = split4(input2[i], delimiter, skipEmpty);
    const nEntries = parts.length;
    numIndices[i] = nEntries;
    outputSize += nEntries;
    maxNumEntries = Math.max(maxNumEntries, nEntries);
    tokens.push(...parts);
  }
  const indices = util_exports2.getArrayFromDType("int32", outputSize * 2);
  const values = new Array(outputSize);
  const shape = [batchSize, maxNumEntries];
  let c = 0;
  for (let i = 0; i < batchSize; ++i) {
    for (let j = 0; j < numIndices[i]; ++j) {
      indices[c * 2] = i;
      indices[c * 2 + 1] = j;
      values[c] = tokens[c];
      ++c;
    }
  }
  return [indices, values, shape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts
function stringToHashBucketFastImpl(input2, numBuckets) {
  const output = util_exports2.getArrayFromDType("int32", input2.length);
  for (let i = 0; i < input2.length; ++i) {
    output[i] = util_exports2.fingerPrint64(input2[i]).modulo(numBuckets).getLowBitsUnsigned();
  }
  return output;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sub.ts
var subImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue - bValue);
var subComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
  return { real: aReal - bReal, imag: aImag - bImag };
});
var sub3 = binaryKernelFunc(Sub2, subImpl, subComplexImpl);
var subConfig = {
  kernelName: Sub2,
  backendName: "cpu",
  kernelFunc: sub3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Tile_impl.ts
function tileImpl(xBuf, reps) {
  const newShape = new Array(xBuf.rank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = xBuf.shape[i] * reps[i];
  }
  const result = buffer2(newShape, xBuf.dtype);
  for (let i = 0; i < result.values.length; ++i) {
    const newLoc = result.indexToLoc(i);
    const originalLoc = new Array(xBuf.rank);
    for (let j = 0; j < originalLoc.length; j++) {
      originalLoc[j] = newLoc[j] % xBuf.shape[j];
    }
    const originalIndex = xBuf.locToIndex(originalLoc);
    result.values[i] = xBuf.values[originalIndex];
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/TopK_impl.ts
function topKImpl(x, xShape, xDtype, k, sorted) {
  const lastDim = xShape[xShape.length - 1];
  const [batch, size] = [x.length / lastDim, lastDim];
  const allTopKVals = util_exports2.getTypedArrayFromDType(xDtype, batch * k);
  const allTopKIndices = util_exports2.getTypedArrayFromDType("int32", batch * k);
  for (let b = 0; b < batch; b++) {
    const offset = b * size;
    const vals = x.subarray(offset, offset + size);
    const valAndInd = [];
    for (let i = 0; i < vals.length; i++) {
      valAndInd.push({ value: vals[i], index: i });
    }
    valAndInd.sort((a, b2) => b2.value - a.value);
    const outOffset = b * k;
    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
    for (let i = 0; i < k; i++) {
      topKVals[i] = valAndInd[i].value;
      topKIndices[i] = valAndInd[i].index;
    }
  }
  const outputShape = xShape.slice();
  outputShape[outputShape.length - 1] = k;
  return [
    buffer2(outputShape, xDtype, allTopKVals),
    buffer2(outputShape, "int32", allTopKIndices)
  ];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Unique_impl.ts
function uniqueImpl(values, axis, shape, dtype) {
  const $axis = util_exports2.parseAxisParam(axis, shape)[0];
  const newShape = [1, shape[0], 1];
  for (let i = 0; i < $axis; i++) {
    newShape[0] *= shape[i];
  }
  newShape[1] = shape[$axis];
  for (let i = $axis + 1; i < shape.length; i++) {
    newShape[2] *= shape[i];
  }
  const uniqueElements = {};
  const indices = new Int32Array(shape[$axis]);
  const inputBuffer = new TensorBuffer2(newShape, dtype, values);
  const uniqueIndices = [];
  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
  for (let i = 0; i < shape[$axis]; i++) {
    let element;
    if (is1DTensor) {
      element = values[i].toString();
    } else {
      const axisValues = [];
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          axisValues.push(inputBuffer.get(m, i, n));
        }
      }
      element = axisValues.join(",");
    }
    if (uniqueElements[element] !== void 0) {
      indices[i] = uniqueElements[element];
    } else {
      const uniqueIndex = Object.keys(uniqueElements).length;
      uniqueElements[element] = uniqueIndex;
      indices[i] = uniqueIndex;
      uniqueIndices.push(i);
    }
  }
  const outputTmpShape = newShape.slice();
  outputTmpShape[1] = Object.keys(uniqueElements).length;
  const outputBuffer = new TensorBuffer2(outputTmpShape, dtype);
  uniqueIndices.forEach((uniqueElementIndex, i) => {
    for (let m = 0; m < newShape[0]; m++) {
      for (let n = 0; n < newShape[2]; n++) {
        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
      }
    }
  });
  const outputShape = shape.slice();
  outputShape[$axis] = outputTmpShape[1];
  return {
    outputValues: outputBuffer.values,
    outputShape,
    indices
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/version.ts
var version14 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/base.ts
registerBackend2("cpu", () => new MathBackendCPU(), 1);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Elu.ts
var elu5 = unaryKernelFunc(Elu2, (xi) => xi >= 0 ? xi : Math.exp(xi) - 1);
var eluConfig = {
  kernelName: Elu2,
  backendName: "cpu",
  kernelFunc: elu5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LeakyRelu.ts
function leakyRelu3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { alpha } = attrs;
  assertNotComplex([x], "leakyRelu");
  const xSize = util_exports2.sizeFromShape(x.shape);
  const xVals = backend3.data.get(x.dataId).values;
  const outVals = util_exports2.getTypedArrayFromDType("float32", xSize);
  for (let i = 0; i < xVals.length; i++) {
    outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];
  }
  return backend3.makeTensorInfo(x.shape, "float32", outVals);
}
var leakyReluConfig = {
  kernelName: LeakyRelu2,
  backendName: "cpu",
  kernelFunc: leakyRelu3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Prelu.ts
var preluImpl = createSimpleBinaryKernelImpl((xValue, aValue) => xValue < 0 ? aValue * xValue : xValue);
function prelu4(args) {
  const { inputs, backend: backend3 } = args;
  const { x, alpha } = inputs;
  assertNotComplex([x, alpha], "prelu");
  const aVals = backend3.data.get(x.dataId).values;
  const bVals = backend3.data.get(alpha.dataId).values;
  const [resultData, resultShape] = preluImpl(x.shape, alpha.shape, aVals, bVals, x.dtype);
  return backend3.makeTensorInfo(resultShape, x.dtype, resultData);
}
var preluConfig = {
  kernelName: Prelu2,
  backendName: "cpu",
  kernelFunc: prelu4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Relu.ts
var relu3 = unaryKernelFunc(Relu2, (xi) => Math.max(0, xi));
var reluConfig = {
  kernelName: Relu2,
  backendName: "cpu",
  kernelFunc: relu3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Relu6.ts
var relu63 = unaryKernelFunc(Relu62, (xi) => Math.min(Math.max(0, xi), 6));
var relu6Config = {
  kernelName: Relu62,
  backendName: "cpu",
  kernelFunc: relu63
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sigmoid.ts
var sigmoid3 = unaryKernelFunc(Sigmoid2, (xi) => 1 / (1 + Math.exp(-xi)));
var sigmoidConfig = {
  kernelName: Sigmoid2,
  backendName: "cpu",
  kernelFunc: sigmoid3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/fused_utils.ts
function applyActivation3(backend3, x, activation2, preluActivationWeights, leakyreluAlpha) {
  if (activation2 === "linear") {
    return identity2({ inputs: { x }, backend: backend3 });
  } else if (activation2 === "relu") {
    return relu3({ inputs: { x }, backend: backend3 });
  } else if (activation2 === "elu") {
    return elu5({ inputs: { x }, backend: backend3 });
  } else if (activation2 === "relu6") {
    return relu63({ inputs: { x }, backend: backend3 });
  } else if (activation2 === "prelu") {
    return prelu4({ inputs: { x, alpha: preluActivationWeights }, backend: backend3 });
  } else if (activation2 === "leakyrelu") {
    return leakyRelu3({ inputs: { x }, backend: backend3, attrs: { alpha: leakyreluAlpha } });
  } else if (activation2 === "sigmoid") {
    return sigmoid3({ inputs: { x }, backend: backend3 });
  }
  throw new Error(`Activation ${activation2} has not been implemented for the CPU backend.`);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Reshape.ts
function reshape4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const xSize = util_exports2.sizeFromShape(x.shape);
  const $shape = util_exports2.inferFromImplicitShape(shape, xSize);
  const $xSize = util_exports2.sizeFromShape($shape);
  util_exports2.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
  backend3.incRef(x.dataId);
  const xData = backend3.data.get(x.dataId);
  if (xData.complexTensorInfos != null) {
    const real6 = xData.complexTensorInfos.real;
    const imag5 = xData.complexTensorInfos.imag;
    real6.shape = $shape;
    imag5.shape = $shape;
  }
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig = {
  kernelName: Reshape2,
  backendName: "cpu",
  kernelFunc: reshape4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/BatchMatMul.ts
function batchMatMul(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  assertNotComplex([a, b], "matMul");
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports2.sizeFromShape(outerDimsA);
  const batchDimB = util_exports2.sizeFromShape(outerDimsB);
  const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;
  util_exports2.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);
  const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports2.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape4({ inputs: { x: a }, backend: backend3, attrs: { shape: a3dShape } });
  const b3d = reshape4({ inputs: { x: b }, backend: backend3, attrs: { shape: b3dShape } });
  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
  const batchDim = Math.max(batchDimA, batchDimB);
  const a3dValues = backend3.data.get(a3d.dataId).values;
  const b3dValues = backend3.data.get(b3d.dataId).values;
  const a3dStrides = util_exports2.computeStrides(a3d.shape);
  const b3dStrides = util_exports2.computeStrides(b3d.shape);
  const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];
  const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];
  const size = leftDim * rightDim;
  const result = buffer2([batchDim, leftDim, rightDim], a3d.dtype);
  const resVals = result.values;
  const blockSize = backend3.blockSize;
  for (let bi = 0; bi < batchDim; bi++) {
    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {
      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {
        for (let k03 = 0; k03 < sharedDim; k03 += blockSize) {
          const iBlock = Math.min(i0 + blockSize, leftDim);
          const jBlock = Math.min(j0 + blockSize, rightDim);
          const kBlock = Math.min(k03 + blockSize, sharedDim);
          for (let i = i0; i < iBlock; i++) {
            for (let j = j0; j < jBlock; j++) {
              let sum8 = 0;
              for (let k = k03; k < kBlock; k++) {
                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;
                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;
                const aVal = a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];
                const bVal = b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];
                sum8 += aVal * bVal;
              }
              resVals[bi * size + (i * rightDim + j)] += sum8;
            }
          }
        }
      }
    }
  }
  backend3.disposeIntermediateTensorInfo(a3d);
  backend3.disposeIntermediateTensorInfo(b3d);
  return backend3.makeTensorInfo(outShape, result.dtype, result.values);
}
var batchMatMulConfig = {
  kernelName: BatchMatMul2,
  backendName: "cpu",
  kernelFunc: batchMatMul
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/_FusedMatMul.ts
function _fusedMatMul(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  const { transposeA, transposeB, activation: activation2, leakyreluAlpha } = attrs;
  let current;
  let addRes;
  let activationRes;
  const intermediates = [];
  const matMulRes = batchMatMul({ inputs: { a, b }, attrs: { transposeA, transposeB }, backend: backend3 });
  current = matMulRes;
  if (bias) {
    addRes = add6({ inputs: { a: current, b: bias }, backend: backend3 });
    intermediates.push(current);
    current = addRes;
  }
  if (activation2) {
    activationRes = applyActivation3(backend3, current, activation2, preluActivationWeights, leakyreluAlpha);
    intermediates.push(current);
    current = activationRes;
  }
  for (const i of intermediates) {
    backend3.disposeIntermediateTensorInfo(i);
  }
  return current;
}
var _fusedMatMulConfig = {
  kernelName: _FusedMatMul2,
  backendName: "cpu",
  kernelFunc: _fusedMatMul
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Acos.ts
var acos3 = unaryKernelFunc(Acos2, (xi) => Math.acos(xi));
var acosConfig = {
  kernelName: Acos2,
  backendName: "cpu",
  kernelFunc: acos3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Acosh.ts
var acosh3 = unaryKernelFunc(Acosh2, (xi) => Math.acosh(xi));
var acoshConfig = {
  kernelName: Acosh2,
  backendName: "cpu",
  kernelFunc: acosh3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/AddN.ts
function addN3(args) {
  const { inputs, backend: backend3 } = args;
  const tensors = inputs;
  assertNotComplex(inputs, "addN");
  const vals = tensors.map((t) => backend3.data.get(t.dataId).values);
  const outBuf = buffer2(tensors[0].shape, tensors[0].dtype);
  const outVals = outBuf.values;
  for (let i = 0; i < tensors.length; i++) {
    const currVals = vals[i];
    for (let j = 0; j < outVals.length; j++) {
      outVals[j] += currVals[j];
    }
  }
  return backend3.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var addNConfig = {
  kernelName: AddN2,
  backendName: "cpu",
  kernelFunc: addN3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/All.ts
function all3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "all");
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("all", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const vals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(outShape), $x.dtype);
  const aVals = backend3.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let all6 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      all6 = all6 && value;
    }
    vals[i] = all6;
  }
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo($x);
  }
  const result = backend3.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: expandedShape } });
    backend3.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var allConfig = {
  kernelName: All2,
  backendName: "cpu",
  kernelFunc: all3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Any.ts
function any3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "any");
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("any", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const vals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(outShape), $x.dtype);
  const aVals = backend3.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let anyVal = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      anyVal = anyVal || value;
    }
    vals[i] = anyVal;
  }
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo($x);
  }
  const result = backend3.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: expandedShape } });
    backend3.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var anyConfig = {
  kernelName: Any2,
  backendName: "cpu",
  kernelFunc: any3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ArgMax.ts
function argMax3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  assertNotComplex(x, "argMax");
  let axes = util_exports2.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, $x.shape.length);
  }
  axes = [axes[0]];
  backend_util_exports2.assertAxesAreInnerMostDims("argMax", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes($x.shape, axes);
  const outSize = util_exports2.sizeFromShape(outShape);
  const vals = util_exports2.makeZerosTypedArray(outSize, "int32");
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const aVals = backend3.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max7 = aVals[offset];
    let maxIndex = 0;
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (value > max7) {
        max7 = value;
        maxIndex = j;
      }
    }
    vals[i] = maxIndex;
  }
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return backend3.makeTensorInfo(outShape, "int32", vals);
}
var argMaxConfig = {
  kernelName: ArgMax2,
  backendName: "cpu",
  kernelFunc: argMax3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ArgMin.ts
function argMin3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  assertNotComplex(x, "argMin");
  let axes = util_exports2.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, $x.shape.length);
  }
  axes = [axes[0]];
  backend_util_exports2.assertAxesAreInnerMostDims("argMin", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes($x.shape, axes);
  const outSize = util_exports2.sizeFromShape(outShape);
  const vals = util_exports2.makeZerosTypedArray(outSize, "int32");
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const aVals = backend3.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let min7 = aVals[offset];
    let minIndex = 0;
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (value < min7) {
        min7 = value;
        minIndex = j;
      }
    }
    vals[i] = minIndex;
  }
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return backend3.makeTensorInfo(outShape, "int32", vals);
}
var argMinConfig = {
  kernelName: ArgMin2,
  backendName: "cpu",
  kernelFunc: argMin3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Asin.ts
var asin3 = unaryKernelFunc(Asin2, (xi) => Math.asin(xi));
var asinConfig = {
  kernelName: Asin2,
  backendName: "cpu",
  kernelFunc: asin3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Asinh.ts
var asinh3 = unaryKernelFunc(Asinh2, (xi) => Math.asinh(xi));
var asinhConfig = {
  kernelName: Asinh2,
  backendName: "cpu",
  kernelFunc: asinh3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Atan.ts
var atan4 = unaryKernelFunc(Atan3, (xi) => Math.atan(xi));
var atanConfig = {
  kernelName: Atan3,
  backendName: "cpu",
  kernelFunc: atan4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Atan2.ts
var atan2Impl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.atan2(aValue, bValue));
var atan23 = binaryKernelFunc(Atan22, atan2Impl);
var atan2Config = {
  kernelName: Atan22,
  backendName: "cpu",
  kernelFunc: atan23
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Atanh.ts
var atanh3 = unaryKernelFunc(Atanh2, (xi) => Math.atanh(xi));
var atanhConfig = {
  kernelName: Atanh2,
  backendName: "cpu",
  kernelFunc: atanh3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/pool_utils.ts
function pool3(xValues, xShape, dtype, strides, convInfo, poolType) {
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
  const output = buffer2(convInfo.outShape, dtype);
  const outputVals = output.values;
  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];
  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];
  const outputColStrides = convInfo.outShape[3];
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const outputBatchOffset = b * outputBatchStrides;
    const inputBatchOffset = b * strides[0];
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const xRCorner = yR * strideHeight - padTop;
        const xRMin = Math.max(0, xRCorner);
        const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const xCCorner = yC * strideWidth - padLeft;
          const xCMin = Math.max(0, xCCorner);
          const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
          let minMaxValue = initialValue;
          let avgValue = 0;
          let count2 = 0;
          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
            const xROffset = inputBatchOffset + xR * strides[1];
            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
              const xCOffset = xROffset + xC * strides[2];
              const pixel = xValues[xCOffset + d];
              if (poolType === "max" && pixel > minMaxValue) {
                minMaxValue = pixel;
              } else if (poolType === "avg") {
                avgValue += pixel;
                count2++;
              }
            }
            if (isNaN(minMaxValue)) {
              break;
            }
          }
          const outputOffset = outputRowOffset + yC * outputColStrides + d;
          outputVals[outputOffset] = poolType === "avg" ? avgValue / count2 : minMaxValue;
        }
      }
    }
  }
  return output;
}
function maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions = false, includeBatchInIndex = false) {
  const maxPositions = buffer2(convInfo.outShape, "int32");
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const xBuf = buffer2(xShape, dtype, xValues);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const xRCorner = yR * strideHeight - padTop;
        let xRMin = xRCorner;
        while (xRMin < 0) {
          xRMin += dilationHeight;
        }
        const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const xCCorner = yC * strideWidth - padLeft;
          let xCMin = xCCorner;
          while (xCMin < 0) {
            xCMin += dilationWidth;
          }
          const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
          let maxValue = Number.NEGATIVE_INFINITY;
          let maxPosition = -1;
          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
            const wR = xR - xRCorner;
            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
              const wC = xC - xCCorner;
              const pixel = xBuf.get(b, xR, xC, d);
              if (pixel > maxValue) {
                maxValue = pixel;
                if (flattenPositions) {
                  maxPosition = includeBatchInIndex ? ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) * convInfo.inChannels + d : (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;
                } else {
                  maxPosition = wR * effectiveFilterWidth + wC;
                }
              }
            }
          }
          maxPositions.set(maxPosition, b, yR, yC, d);
        }
      }
    }
  }
  return maxPositions;
}
function pool3d2(xValues, xShape, dtype, strides, convInfo, poolType) {
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = convInfo.padInfo.front;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
  const output = buffer2(convInfo.outShape, dtype);
  const outputVals = output.values;
  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
  const outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
  const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];
  const outputColStrides = convInfo.outShape[4];
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    const outputBatchOffset = batch * outputBatchStrides;
    const inputBatchOffset = batch * strides[0];
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
        const xDepthCorner = yDepth * strideDepth - padFront;
        let xDepthMin = xDepthCorner;
        while (xDepthMin < 0) {
          xDepthMin += dilationDepth;
        }
        const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
        const outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;
        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
          const xRowCorner = yRow * strideHeight - padTop;
          let xRowMin = xRowCorner;
          while (xRowMin < 0) {
            xRowMin += dilationHeight;
          }
          const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
          const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;
          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
            const xColCorner = yCol * strideWidth - padLeft;
            let xColMin = xColCorner;
            while (xColMin < 0) {
              xColMin += dilationWidth;
            }
            const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
            const outputColOffset = outputRowOffset + yCol * outputColStrides;
            let minMaxValue = initialValue;
            let avgValue = 0;
            let count2 = 0;
            for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
              const xDepthOffset = inputBatchOffset + xDepth * strides[1];
              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                const xRowOffset = xDepthOffset + xRow * strides[2];
                for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                  const xColOffset = xRowOffset + xCol * strides[3];
                  const pixel = xValues[xColOffset + channel];
                  if (poolType === "max" && pixel > minMaxValue) {
                    minMaxValue = pixel;
                  } else if (poolType === "avg") {
                    avgValue += pixel;
                    count2++;
                  }
                  if (isNaN(minMaxValue)) {
                    break;
                  }
                }
                if (isNaN(minMaxValue)) {
                  break;
                }
              }
              if (isNaN(minMaxValue)) {
                break;
              }
            }
            const outputOffset = outputColOffset + channel;
            outputVals[outputOffset] = poolType === "avg" ? avgValue / count2 : minMaxValue;
          }
        }
      }
    }
  }
  return output;
}
function maxPool3dPositions(xBuf, convInfo) {
  const maxPositions = buffer2(convInfo.outShape, "int32");
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = convInfo.padInfo.front;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
        const xDepthCorner = yDepth * strideDepth - padFront;
        let xDepthMin = xDepthCorner;
        while (xDepthMin < 0) {
          xDepthMin += dilationDepth;
        }
        const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
          const xRowCorner = yRow * strideHeight - padTop;
          let xRowMin = xRowCorner;
          while (xRowMin < 0) {
            xRowMin += dilationHeight;
          }
          const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
            const xColCorner = yCol * strideWidth - padLeft;
            let xColMin = xColCorner;
            while (xColMin < 0) {
              xColMin += dilationWidth;
            }
            const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
            let maxValue = Number.NEGATIVE_INFINITY;
            let maxPosition = -1;
            for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
              const wDepth = xDepth - xDepthCorner;
              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                const wRow = xRow - xRowCorner;
                for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                  const wCol = xCol - xColCorner;
                  const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);
                  if (pixel >= maxValue) {
                    maxValue = pixel;
                    maxPosition = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterHeight + wCol;
                  }
                }
              }
            }
            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);
          }
        }
      }
    }
  }
  return maxPositions;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/AvgPool.ts
function avgPool3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  assertNotComplex(x, "avgPool");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  let res;
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports2.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    res = identity2({ inputs: { x }, backend: backend3 });
  } else {
    const xValues = backend3.data.get(x.dataId).values;
    const strides2 = util_exports2.computeStrides(x.shape);
    const buffer3 = pool3(xValues, x.shape, x.dtype, strides2, convInfo, "avg");
    res = backend3.makeTensorInfo(convInfo.outShape, x.dtype, buffer3.values);
  }
  return res;
}
var avgPoolConfig = {
  kernelName: AvgPool2,
  backendName: "cpu",
  kernelFunc: avgPool3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/AvgPool3D.ts
function avgPool3D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat } = attrs;
  assertNotComplex(x, "avgPool3d");
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode, dataFormat);
  const xValues = backend3.data.get(x.dataId).values;
  const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports2.computeStrides(x.shape), convInfo, "avg");
  return backend3.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
}
var avgPool3DConfig = {
  kernelName: AvgPool3D2,
  backendName: "cpu",
  kernelFunc: avgPool3D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/AvgPool3DGrad.ts
function avgPool3DGrad(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  assertNotComplex([dy, input2], "avgPool3DGrad");
  const convInfo = backend_util_exports2.computePool3DInfo(input2.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterDepth = convInfo.filterDepth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer2(input2.shape, "float32");
  const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
  const dyBuf = backend3.bufferSync(dy);
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
            const dyDepthCorner = dxDepth - padFront;
            const dyRowCorner = dxRow - padTop;
            const dyColCorner = dxCol - padLeft;
            let dotProd = 0;
            for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
              if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                continue;
              }
              for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                const dyRow = (dyRowCorner + wRow) / strideHeight;
                if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                  continue;
                }
                for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                  const dyCol = (dyColCorner + wCol) / strideWidth;
                  if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                    continue;
                  }
                  const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  dotProd += pixel;
                }
              }
            }
            dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var avgPool3DGradConfig2 = {
  kernelName: AvgPool3DGrad2,
  backendName: "cpu",
  kernelFunc: avgPool3DGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/AvgPoolGrad.ts
function avgPoolGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  assertNotComplex([dy, input2], "avgPoolGrad");
  const { filterSize, strides, pad: pad4 } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4);
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer2(x.shape, "float32");
  const avgMultiplier = 1 / (filterHeight * filterWidth);
  const dyData = backend3.data.get(dy.dataId).values;
  const dyBuf = buffer2(dy.shape, "float32", dyData);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
          const dyRCorner = dxR - padTop;
          const dyCCorner = dxC - padLeft;
          let dotProd = 0;
          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
            const dyR = (dyRCorner + wR) / strideHeight;
            if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
              continue;
            }
            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
              const dyC = (dyCCorner + wC) / strideWidth;
              if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                continue;
              }
              const pixel = dyBuf.get(b, dyR, dyC, d);
              dotProd += pixel;
            }
          }
          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var avgPoolGradConfig2 = {
  kernelName: AvgPoolGrad2,
  backendName: "cpu",
  kernelFunc: avgPoolGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/BatchNorm.ts
function batchNorm3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, scale: scale2, offset, mean: mean5, variance } = inputs;
  util_exports2.assert(mean5.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  util_exports2.assert(offset == null || mean5.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  util_exports2.assert(scale2 == null || mean5.shape.length === scale2.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  assertNotComplex([x, mean5, variance, scale2, offset], "batchNorm");
  let { varianceEpsilon } = attrs;
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const xVals = backend3.data.get(x.dataId).values;
  const mVals = backend3.data.get(mean5.dataId).values;
  const varVals = backend3.data.get(variance.dataId).values;
  const sVals = scale2 ? backend3.data.get(scale2.dataId).values : new Float32Array([1]);
  const offVals = offset ? backend3.data.get(offset.dataId).values : new Float32Array([0]);
  const outVals = new Float32Array(xVals.length);
  const offValsLength = offVals.length;
  const sValsLength = sVals.length;
  const varValsLength = varVals.length;
  const mValsLength = mVals.length;
  let offi = 0;
  let mi = 0;
  let si = 0;
  let vi = 0;
  for (let i = 0; i < xVals.length; ++i) {
    outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);
    if (offi >= offValsLength) {
      offi = 0;
    }
    if (mi >= mValsLength) {
      mi = 0;
    }
    if (si >= sValsLength) {
      si = 0;
    }
    if (vi >= varValsLength) {
      vi = 0;
    }
  }
  return backend3.makeTensorInfo(x.shape, x.dtype, outVals);
}
var batchNormConfig = {
  kernelName: FusedBatchNorm2,
  backendName: "cpu",
  kernelFunc: batchNorm3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/BatchToSpaceND.ts
function batchToSpaceND3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockShape, crops } = attrs;
  assertNotComplex([x], "batchToSpaceND");
  const prod6 = blockShape.reduce((a, b) => a * b);
  const reshaped = backend_util_exports2.getReshaped(x.shape, blockShape, prod6);
  const permuted = backend_util_exports2.getPermuted(reshaped.length, blockShape.length);
  const reshapedPermuted = backend_util_exports2.getReshapedPermuted(x.shape, blockShape, prod6);
  const sliceBeginCoords = backend_util_exports2.getSliceBeginCoords(crops, blockShape.length);
  const sliceSize = backend_util_exports2.getSliceSize(reshapedPermuted, crops, blockShape.length);
  const xReshaped = reshape4({ inputs: { x }, backend: backend3, attrs: { shape: reshaped } });
  const xTransposed = transpose3({ inputs: { x: xReshaped }, backend: backend3, attrs: { perm: permuted } });
  const xTransposedReshaped = reshape4({ inputs: { x: xTransposed }, backend: backend3, attrs: { shape: reshapedPermuted } });
  const result = slice3({
    inputs: { x: xTransposedReshaped },
    backend: backend3,
    attrs: { begin: sliceBeginCoords, size: sliceSize }
  });
  backend3.disposeIntermediateTensorInfo(xReshaped);
  backend3.disposeIntermediateTensorInfo(xTransposed);
  backend3.disposeIntermediateTensorInfo(xTransposedReshaped);
  return result;
}
var batchToSpaceNDConfig = {
  kernelName: BatchToSpaceND2,
  backendName: "cpu",
  kernelFunc: batchToSpaceND3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Bincount.ts
function bincount3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, weights } = inputs;
  const { size } = attrs;
  const xVals = backend3.data.get(x.dataId).values;
  const weightsVals = backend3.data.get(weights.dataId).values;
  const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
  return backend3.makeTensorInfo([size], weights.dtype, outVals);
}
var bincountConfig = {
  kernelName: Bincount2,
  backendName: "cpu",
  kernelFunc: bincount3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Clip.ts
var clip = unaryKernelFunc(ClipByValue2, (xi, attrs) => {
  const clipAttrs = attrs;
  if (xi > clipAttrs.clipValueMax) {
    return clipAttrs.clipValueMax;
  }
  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;
});
var clipConfig = {
  kernelName: ClipByValue2,
  backendName: "cpu",
  kernelFunc: clip
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ComplexAbs.ts
var complexAbs = (args) => {
  const { x } = args.inputs;
  const cpuBackend = args.backend;
  const resultValues = new Float32Array(util_exports2.sizeFromShape(x.shape));
  const complexVals = cpuBackend.data.get(x.dataId);
  const real6 = complexVals.complexTensorInfos.real;
  const imag5 = complexVals.complexTensorInfos.imag;
  const realVals = cpuBackend.data.get(real6.dataId).values;
  const imagVals = cpuBackend.data.get(imag5.dataId).values;
  for (let i = 0; i < realVals.length; i++) {
    const real7 = realVals[i];
    const imag6 = imagVals[i];
    resultValues[i] = Math.hypot(real7, imag6);
  }
  return cpuBackend.makeOutput(resultValues, x.shape, "float32");
};
var complexAbsConfig = {
  kernelName: ComplexAbs2,
  backendName: "cpu",
  kernelFunc: complexAbs
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Imag.ts
function imag3(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const imag5 = backend3.data.get(input2.dataId).complexTensorInfos.imag;
  const imagVal = backend3.data.get(imag5.dataId).values;
  return backend3.makeTensorInfo(imag5.shape, imag5.dtype, imagVal);
}
var imagConfig = {
  kernelName: Imag2,
  backendName: "cpu",
  kernelFunc: imag3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Concat.ts
function concat3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { axis } = attrs;
  const $axis = util_exports2.parseAxisParam(axis, inputs[0].shape)[0];
  let outShape = backend_util_exports2.computeOutShape(inputs.map((t) => t.shape), $axis);
  if (util_exports2.sizeFromShape(outShape) === 0) {
    return backend3.makeTensorInfo(outShape, inputs[0].dtype, []);
  }
  const $inputs = inputs.filter((t) => util_exports2.sizeFromShape(t.shape) > 0);
  if ($inputs.length === 1) {
    return identity2({ inputs: { x: $inputs[0] }, backend: backend3 });
  }
  const shapes = $inputs.map((t) => t.shape);
  backend_util_exports2.assertParamsConsistent(shapes, $axis);
  if ($inputs[0].dtype === "complex64") {
    const reals = $inputs.map((t) => real3({ inputs: { input: t }, backend: backend3 }));
    const imags = $inputs.map((t) => imag3({ inputs: { input: t }, backend: backend3 }));
    const realConcated = concat3({ inputs: reals, backend: backend3, attrs: { axis: $axis } });
    const imagConcated = concat3({ inputs: imags, backend: backend3, attrs: { axis: $axis } });
    const result = complex3({ inputs: { real: realConcated, imag: imagConcated }, backend: backend3 });
    reals.forEach((r) => backend3.disposeIntermediateTensorInfo(r));
    imags.forEach((i) => backend3.disposeIntermediateTensorInfo(i));
    backend3.disposeIntermediateTensorInfo(realConcated);
    backend3.disposeIntermediateTensorInfo(imagConcated);
    return result;
  }
  const inputs2D = $inputs.map((t) => {
    const innerSize = util_exports2.sizeFromShape(t.shape.slice($axis));
    const shape = [-1, innerSize];
    return reshape4({ inputs: { x: t }, backend: backend3, attrs: { shape } });
  });
  const inputsValShapes = inputs2D.map((t) => {
    return { vals: backend3.data.get(t.dataId).values, shape: t.shape };
  });
  outShape = backend_util_exports2.computeOutShape(inputs2D.map((t) => t.shape), 1);
  const simplyConcat = inputs2D[0].shape[0] === 1;
  const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
  const finalOutShape = backend_util_exports2.computeOutShape($inputs.map((t) => t.shape), $axis);
  const outInfo = backend3.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);
  inputs2D.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return outInfo;
}
var concatConfig = {
  kernelName: Concat2,
  backendName: "cpu",
  kernelFunc: concat3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv2D.ts
function conv2D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dataFormat, dilations, dimRoundingMode } = attrs;
  assertNotComplex([x, filter], "conv2d");
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode, false, $dataFormat);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const padLeft = convInfo.padInfo.left;
  const padTop = convInfo.padInfo.top;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const y = new TensorBuffer2(convInfo.outShape, x.dtype);
  const xStrides = util_exports2.computeStrides(x.shape);
  const filterStrides = util_exports2.computeStrides(filter.shape);
  const xBatchStride = xStrides[0];
  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];
  const xColStride = isChannelsLast ? xStrides[2] : 1;
  const xChannelStride = isChannelsLast ? 1 : xStrides[1];
  const yBatchStride = y.strides[0];
  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];
  const yColStride = isChannelsLast ? y.strides[2] : 1;
  const yChannelStride = isChannelsLast ? 1 : y.strides[1];
  const xVals = backend3.data.get(x.dataId).values;
  const wVals = backend3.data.get(filter.dataId).values;
  const yVals = y.values;
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xBatchStride;
    const yOffset1 = b * yBatchStride;
    for (let yR = 0; yR < convInfo.outHeight; ++yR) {
      const yOffset2 = yOffset1 + yR * yRowStride;
      const xRCorner = yR * convInfo.strideHeight - padTop;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const xR = xRCorner + wR * dilationHeight;
        if (xR < 0 || xR >= convInfo.inHeight) {
          continue;
        }
        const wOffset1 = wR * filterStrides[0];
        const xOffset2 = xOffset1 + xR * xRowStride;
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const yOffset3 = yOffset2 + yC * yColStride;
          const xCCorner = yC * convInfo.strideWidth - padLeft;
          for (let wC = 0; wC < filterWidth; ++wC) {
            const xC = xCCorner + wC * dilationWidth;
            if (xC < 0 || xC >= convInfo.inWidth) {
              continue;
            }
            const wOffset2 = wOffset1 + wC * filterStrides[1];
            const xOffset3 = xOffset2 + xC * xColStride;
            let wOffset3 = wOffset2;
            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
              const xVal = xVals[xOffset3 + d1 * xChannelStride];
              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                yVals[yOffset3 + d2 * yChannelStride] += xVal * wVals[wOffset3 + d2];
              }
              wOffset3 += convInfo.outChannels;
            }
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(y.shape, y.dtype, yVals);
}
var conv2DConfig = {
  kernelName: Conv2D2,
  backendName: "cpu",
  kernelFunc: conv2D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv2DBackpropFilter.ts
function conv2DBackpropFilter3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad4, dataFormat, dimRoundingMode, filterShape } = attrs;
  assertNotComplex([x, dy], "conv2dBackpropFilter");
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filterShape, strides, 1, pad4, dimRoundingMode, false, $dataFormat);
  const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const dW = new TensorBuffer2(convInfo.filterShape, "float32");
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  const xVals = backend3.data.get(x.dataId).values;
  const dyVals = backend3.data.get(dy.dataId).values;
  const xBuf = new TensorBuffer2(x.shape, x.dtype, xVals);
  const dyBuf = new TensorBuffer2(dy.shape, dy.dtype, dyVals);
  for (let wR = 0; wR < filterHeight; ++wR) {
    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
    const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
    for (let wC = 0; wC < filterWidth; ++wC) {
      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
      const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
          let dotProd = 0;
          for (let b = 0; b < convInfo.batchSize; ++b) {
            for (let yR = yRMin; yR < yRMax; ++yR) {
              const xR = wR + yR * strideHeight - topPad;
              for (let yC = yCMin; yC < yCMax; ++yC) {
                const xC = wC + yC * strideWidth - leftPad;
                if (isChannelsLast) {
                  dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                } else {
                  dotProd += xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);
                }
              }
            }
          }
          dW.set(dotProd, wR, wC, d1, d2);
        }
      }
    }
  }
  return backend3.makeTensorInfo(dW.shape, dW.dtype, dW.values);
}
var conv2DBackpropFilterConfig = {
  kernelName: Conv2DBackpropFilter2,
  backendName: "cpu",
  kernelFunc: conv2DBackpropFilter3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv2DBackpropInput.ts
function conv2DBackpropInput3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { inputShape, strides, pad: pad4, dataFormat, dimRoundingMode } = attrs;
  assertNotComplex([dy, filter], "conv2dBackpropInput");
  const filterStrides = util_exports2.computeStrides(filter.shape);
  const dyStrides = util_exports2.computeStrides(dy.shape);
  let $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad4, dimRoundingMode, false, $dataFormat);
  const dx = new TensorBuffer2(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const dyValues = backend3.data.get(dy.dataId).values;
  const fltValues = backend3.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2] = filterStrides;
  const {
    batchSize,
    filterHeight,
    filterWidth,
    inChannels,
    inHeight,
    inWidth,
    outChannels,
    outHeight,
    outWidth,
    strideHeight,
    strideWidth
  } = convInfo;
  $dataFormat = convInfo.dataFormat;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  const isChannelsLast = $dataFormat === "channelsLast";
  const xBatchStride = dx.strides[0];
  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];
  const xColStride = isChannelsLast ? dx.strides[2] : 1;
  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];
  const yBatchStride = dyStrides[0];
  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
  const yColStride = isChannelsLast ? dyStrides[2] : 1;
  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xR = 0; xR < inHeight; ++xR) {
        const xRCorner = xR - topPad;
        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
        const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
        for (let xC = 0; xC < inWidth; ++xC) {
          const xCCorner = xC - leftPad;
          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
          const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
          let dotProd = 0;
          for (let yR = xRMin; yR < yRMax; ++yR) {
            const wR = yR * strideHeight - xRCorner;
            for (let yC = xCMin; yC < yCMax; ++yC) {
              const wC = yC * strideWidth - xCCorner;
              const dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;
              const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
              for (let d2 = 0; d2 < outChannels; ++d2) {
                const pixel = dyValues[dyOffset + yChannelStride * d2];
                const weight = fltValues[fltOffset + d2];
                dotProd += pixel * weight;
              }
            }
          }
          const dxOffset = xBatchStride * b + xRowStride * xR + xColStride * xC + xChannelStride * d1;
          dxValues[dxOffset] = dotProd;
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var conv2DBackpropInputConfig = {
  kernelName: Conv2DBackpropInput2,
  backendName: "cpu",
  kernelFunc: conv2DBackpropInput3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv3D.ts
function conv3D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dilations } = attrs;
  assertNotComplex([x, filter], "conv3d");
  const convInfo = backend_util_exports2.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad4);
  const {
    filterDepth,
    filterHeight,
    filterWidth,
    dilationDepth,
    dilationHeight,
    dilationWidth,
    padInfo
  } = convInfo;
  const padFront = padInfo.front;
  const padLeft = padInfo.left;
  const padTop = padInfo.top;
  const y = new TensorBuffer2(convInfo.outShape, x.dtype);
  const xVals = backend3.data.get(x.dataId).values;
  const wVals = backend3.data.get(filter.dataId).values;
  const yVals = y.values;
  const xStrides = util_exports2.computeStrides(x.shape);
  const filterStrides = util_exports2.computeStrides(filter.shape);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xStrides[0];
    const yOffset1 = b * y.strides[0];
    for (let yF = 0; yF < convInfo.outDepth; ++yF) {
      const yOffset2 = yOffset1 + yF * y.strides[1];
      const xFCorner = yF * convInfo.strideDepth - padFront;
      for (let wF = 0; wF < filterDepth; ++wF) {
        const xF = xFCorner + wF * dilationDepth;
        if (xF < 0 || xF >= convInfo.inDepth) {
          continue;
        }
        const wOffset1 = wF * filterStrides[0];
        const xOffset2 = xOffset1 + xF * xStrides[1];
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const yOffset3 = yOffset2 + yR * y.strides[2];
          const xRCorner = yR * convInfo.strideHeight - padTop;
          for (let wR = 0; wR < filterHeight; ++wR) {
            const xR = xRCorner + wR * dilationHeight;
            if (xR < 0 || xR >= convInfo.inHeight) {
              continue;
            }
            const wOffset2 = wOffset1 + wR * filterStrides[1];
            const xOffset3 = xOffset2 + xR * xStrides[2];
            for (let yC = 0; yC < convInfo.outWidth; ++yC) {
              const yOffset4 = yOffset3 + yC * convInfo.outChannels;
              const xCCorner = yC * convInfo.strideWidth - padLeft;
              for (let wC = 0; wC < filterWidth; ++wC) {
                const xC = xCCorner + wC * dilationWidth;
                if (xC < 0 || xC >= convInfo.inWidth) {
                  continue;
                }
                const wOffset3 = wOffset2 + wC * filterStrides[2];
                const xOffset4 = xOffset3 + xC * convInfo.inChannels;
                let wOffset4 = wOffset3;
                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                  const xVal = xVals[xOffset4 + d1];
                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];
                  }
                  wOffset4 += convInfo.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(y.shape, y.dtype, y.values);
}
var conv3DConfig = {
  kernelName: Conv3D2,
  backendName: "cpu",
  kernelFunc: conv3D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv3DBackpropFilterV2.ts
function conv3DBackpropFilterV2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad4, filterShape } = attrs;
  assertNotComplex([x, dy], "conv3dBackpropFilterV2");
  const xStrides = util_exports2.computeStrides(x.shape);
  const dyStrides = util_exports2.computeStrides(dy.shape);
  const convInfo = backend_util_exports2.computeConv3DInfo(x.shape, filterShape, strides, 1, pad4);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterDepth = convInfo.filterDepth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dw = new TensorBuffer2(convInfo.filterShape, "float32");
  const dwValues = dw.values;
  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;
  const dyValues = backend3.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
  const xValues = backend3.data.get(x.dataId).values;
  const [xS0, xS1, xS2, xS3] = xStrides;
  const frontPad = convInfo.padInfo.front;
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  for (let wF = 0; wF < filterDepth; ++wF) {
    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));
    const yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);
    const wOffset1 = wF * dwS0;
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      const wOffset2 = wR * dwS1 + wOffset1;
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        const wOffset3 = wC * dwS2 + wOffset2;
        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
          const wOffset4 = d1 * dwS3 + wOffset3;
          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
            let dotProd = 0;
            for (let b = 0; b < convInfo.batchSize; ++b) {
              const xOffset1 = b * xS0;
              const yOffset1 = b * dyS0;
              for (let yF = yFMin; yF < yFMax; ++yF) {
                const xF = wF + yF * strideDepth - frontPad;
                const xOffset2 = xF * xS1 + xOffset1;
                const yOffset2 = yF * dyS1 + yOffset1;
                for (let yR = yRMin; yR < yRMax; ++yR) {
                  const xR = wR + yR * strideHeight - topPad;
                  const xOffset3 = xR * xS2 + xOffset2;
                  const yOffset3 = yR * dyS2 + yOffset2;
                  for (let yC = yCMin; yC < yCMax; ++yC) {
                    const xC = wC + yC * strideWidth - leftPad;
                    const xOffset4 = xC * xS3 + xOffset3;
                    const yOffset4 = yC * dyS3 + yOffset3;
                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];
                  }
                }
              }
            }
            dwValues[wOffset4 + d2] = dotProd;
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(dw.shape, dw.dtype, dw.values);
}
var conv3DBackpropFilterV2Config = {
  kernelName: Conv3DBackpropFilterV22,
  backendName: "cpu",
  kernelFunc: conv3DBackpropFilterV2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Conv3DBackpropInputV2.ts
function conv3DBackpropInputV2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { pad: pad4, strides, inputShape } = attrs;
  assertNotComplex([dy], "conv3dBackpropInputV2");
  const dyStrides = util_exports2.computeStrides(dy.shape);
  const filterStrides = util_exports2.computeStrides(filter.shape);
  const convInfo = backend_util_exports2.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad4);
  const dx = new TensorBuffer2(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;
  const dyValues = backend3.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
  const fltValues = backend3.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;
  const {
    batchSize,
    filterDepth,
    filterHeight,
    filterWidth,
    inChannels,
    inDepth,
    inHeight,
    inWidth,
    outChannels,
    outDepth,
    outHeight,
    outWidth,
    strideDepth,
    strideHeight,
    strideWidth
  } = convInfo;
  const frontPad = filterDepth - 1 - convInfo.padInfo.front;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xF = 0; xF < inDepth; ++xF) {
        const xFCorner = xF - frontPad;
        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));
        const yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yF = xFMin; yF < yFMax; ++yF) {
              const wF = yF * strideDepth - xFCorner;
              for (let yR = xRMin; yR < yRMax; ++yR) {
                const wR = yR * strideHeight - xRCorner;
                for (let yC = xCMin; yC < yCMax; ++yC) {
                  const wC = yC * strideWidth - xCCorner;
                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;
                  const fltOffset = fltS0 * (filterDepth - 1 - wF) + fltS1 * (filterHeight - 1 - wR) + fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;
                  for (let d2 = 0; d2 < outChannels; ++d2) {
                    const pixel = dyValues[dyOffset + d2];
                    const weight = fltValues[fltOffset + d2];
                    dotProd += pixel * weight;
                  }
                }
              }
            }
            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] = dotProd;
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var conv3DBackpropInputV2Config = {
  kernelName: Conv3DBackpropInputV22,
  backendName: "cpu",
  kernelFunc: conv3DBackpropInputV2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Cos.ts
var cos3 = unaryKernelFunc(Cos2, (xi) => Math.cos(xi));
var cosConfig = {
  kernelName: Cos2,
  backendName: "cpu",
  kernelFunc: cos3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Cosh.ts
var cosh3 = unaryKernelFunc(Cosh2, (xi) => Math.cosh(xi));
var coshConfig = {
  kernelName: Cosh2,
  backendName: "cpu",
  kernelFunc: cosh3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/CropAndResize.ts
function cropAndResize3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { image: image4, boxes, boxInd } = inputs;
  const { cropSize, method, extrapolationValue } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  const numBoxes = boxes.shape[0];
  const [cropHeight, cropWidth] = cropSize;
  const output = buffer2([numBoxes, cropHeight, cropWidth, numChannels], "float32");
  const boxVals = backend3.data.get(boxes.dataId).values;
  const boxIndVals = backend3.data.get(boxInd.dataId).values;
  const imageVals = backend3.data.get(image4.dataId).values;
  const inStride = util_exports2.computeStrides(image4.shape);
  const outStride = util_exports2.computeStrides(output.shape);
  for (let b = 0; b < numBoxes; b++) {
    const startInd = b * 4;
    const y1 = boxVals[startInd];
    const x1 = boxVals[startInd + 1];
    const y2 = boxVals[startInd + 2];
    const x2 = boxVals[startInd + 3];
    const bInd = boxIndVals[b];
    if (bInd >= batch) {
      continue;
    }
    const heightScale = cropHeight > 1 ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;
    const widthScale = cropWidth > 1 ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;
    for (let y = 0; y < cropHeight; y++) {
      const yInd = cropHeight > 1 ? y1 * (imageHeight - 1) + y * heightScale : 0.5 * (y1 + y2) * (imageHeight - 1);
      if (yInd < 0 || yInd > imageHeight - 1) {
        for (let x = 0; x < cropWidth; x++) {
          for (let c = 0; c < numChannels; c++) {
            const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[ind] = extrapolationValue;
          }
        }
        continue;
      }
      if (method === "bilinear") {
        const topInd = Math.floor(yInd);
        const bottomInd = Math.ceil(yInd);
        const yLerp = yInd - topInd;
        for (let x = 0; x < cropWidth; x++) {
          const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
          if (xInd < 0 || xInd > imageWidth - 1) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
            continue;
          }
          const leftInd = Math.floor(xInd);
          const rightInd = Math.ceil(xInd);
          const xLerp = xInd - leftInd;
          for (let c = 0; c < numChannels; c++) {
            let ind = c + leftInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
            const topLeft = imageVals[ind];
            ind = c + rightInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
            const topRight = imageVals[ind];
            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
            const bottomLeft = imageVals[ind];
            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
            const bottomRight = imageVals[ind];
            const top = topLeft + (topRight - topLeft) * xLerp;
            const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;
            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[ind] = top + (bottom - top) * yLerp;
          }
        }
      } else {
        for (let x = 0; x < cropWidth; ++x) {
          const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
          if (xInd < 0 || xInd > imageWidth - 1) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
            continue;
          }
          const closestX = Math.round(xInd);
          const closestY = Math.round(yInd);
          for (let c = 0; c < numChannels; c++) {
            const inInd = c + closestX * inStride[2] + closestY * inStride[1] + bInd * inStride[0];
            const outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[outInd] = imageVals[inInd];
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(output.shape, output.dtype, output.values);
}
var cropAndResizeConfig = {
  kernelName: CropAndResize2,
  backendName: "cpu",
  kernelFunc: cropAndResize3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Cumsum.ts
function cumsum3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse6 } = attrs;
  assertNotComplex(x, "cumsum");
  const permutation = backend_util_exports2.getAxesPermutation([axis], x.shape.length);
  let $x = x;
  if (permutation != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports2.getInnerMostAxes(1, x.shape.length)[0];
  if (permutedAxis !== $x.shape.length - 1) {
    throw new Error(`backend.cumsum in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
  }
  const resultDtype = upcastType2($x.dtype, "int32");
  const vals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape($x.shape), resultDtype);
  const aVals = backend3.data.get($x.dataId).values;
  const finalDim = $x.shape[$x.shape.length - 1];
  const indexAdjuster = reverse6 ? (i, j) => i + finalDim - j - 1 : (i, j) => i + j;
  for (let i = 0; i < aVals.length; i += finalDim) {
    for (let j = 0; j < finalDim; j++) {
      const idx = indexAdjuster(i, j);
      if (j === 0) {
        vals[idx] = exclusive ? 0 : aVals[idx];
      } else {
        const prevIdx = indexAdjuster(i, j - 1);
        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];
      }
    }
  }
  const result = backend3.makeTensorInfo($x.shape, resultDtype, vals);
  if (permutation != null) {
    const reversePermutation = backend_util_exports2.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose3({ inputs: { x: result }, backend: backend3, attrs: { perm: reversePermutation } });
    backend3.disposeIntermediateTensorInfo(result);
    backend3.disposeIntermediateTensorInfo($x);
    return reverseTransposedResult;
  }
  return result;
}
var cumsumConfig = {
  kernelName: Cumsum2,
  backendName: "cpu",
  kernelFunc: cumsum3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/DenseBincount.ts
function denseBincount3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, weights } = inputs;
  const { size, binaryOutput } = attrs;
  if (x.shape.length === 1) {
    const xVals = backend3.data.get(x.dataId).values;
    const weightsVals = backend3.data.get(weights.dataId).values;
    const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
    return backend3.makeTensorInfo([size], weights.dtype, outVals);
  } else if (x.shape.length === 2) {
    const xBuf = backend3.bufferSync(x);
    const weightsBuf = backend3.bufferSync(weights);
    const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);
    return backend3.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
}
var denseBincountConfig = {
  kernelName: DenseBincount2,
  backendName: "cpu",
  kernelFunc: denseBincount3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/DepthToSpace.ts
function depthToSpace3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  util_exports2.assert(dataFormat === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${dataFormat}`);
  util_exports2.assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
  const batchSize = x.shape[0];
  const inputHeight = x.shape[1];
  const inputWidth = x.shape[2];
  const inputDepth = x.shape[3];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const xValues = backend3.data.get(x.dataId).values;
  const result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);
  let outputIdx = 0;
  for (let b = 0; b < batchSize; ++b) {
    for (let h = 0; h < outputHeight; ++h) {
      const inH = Math.floor(h / blockSize);
      const offsetH = h % blockSize;
      for (let w = 0; w < outputWidth; ++w) {
        const inW = Math.floor(w / blockSize);
        const offsetW = w % blockSize;
        const offsetD = (offsetH * blockSize + offsetW) * outputDepth;
        for (let d = 0; d < outputDepth; ++d) {
          const inD = d + offsetD;
          const inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));
          result[outputIdx++] = xValues[inputIdx];
        }
      }
    }
  }
  return backend3.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);
}
var depthToSpaceConfig = {
  kernelName: DepthToSpace2,
  backendName: "cpu",
  kernelFunc: depthToSpace3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/DepthwiseConv2dNative.ts
function depthwiseConv2dNative(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dilations, dimRoundingMode } = attrs;
  assertNotComplex([x, filter], "depthwiseConv2DNative");
  const xStrides = util_exports2.computeStrides(x.shape);
  const filterStrides = util_exports2.computeStrides(filter.shape);
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad4, dimRoundingMode, true);
  const { filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo } = convInfo;
  const padLeft = padInfo.left;
  const padTop = padInfo.top;
  const chMul = convInfo.outChannels / convInfo.inChannels;
  const y = new TensorBuffer2(convInfo.outShape, x.dtype);
  const xVals = backend3.data.get(x.dataId).values;
  const wVals = backend3.data.get(filter.dataId).values;
  const yVals = y.values;
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xStrides[0];
    const yOffset1 = b * y.strides[0];
    for (let yR = 0; yR < convInfo.outHeight; ++yR) {
      const yOffset2 = yOffset1 + yR * y.strides[1];
      const xRCorner = yR * convInfo.strideHeight - padTop;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const xR = xRCorner + wR * dilationHeight;
        if (xR < 0 || xR >= convInfo.inHeight) {
          continue;
        }
        const wOffset1 = wR * filterStrides[0];
        const xOffset2 = xOffset1 + xR * xStrides[1];
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const yOffset3 = yOffset2 + yC * y.strides[2];
          const xCCorner = yC * convInfo.strideWidth - padLeft;
          for (let wC = 0; wC < filterWidth; ++wC) {
            const xC = xCCorner + wC * dilationWidth;
            if (xC < 0 || xC >= convInfo.inWidth) {
              continue;
            }
            const wOffset2 = wOffset1 + wC * filterStrides[1];
            const xOffset3 = xOffset2 + xC * convInfo.inChannels;
            let yOffset4 = yOffset3;
            let wOffset3 = wOffset2;
            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
              const xVal = xVals[xOffset3 + d1];
              for (let q = 0; q < chMul; ++q) {
                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];
              }
              yOffset4 += chMul;
              wOffset3 += chMul;
            }
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(y.shape, y.dtype, y.values);
}
var depthwiseConv2dNativeConfig = {
  kernelName: DepthwiseConv2dNative2,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNative
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts
function depthwiseConv2dNativeBackpropFilter3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, dilations, pad: pad4, dimRoundingMode, filterShape } = attrs;
  assertNotComplex([x, dy], "depthwiseConv2dNativeBackpropFilter");
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad4, dimRoundingMode, true);
  const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
  const dW = new TensorBuffer2(convInfo.filterShape, "float32");
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  const chMul = convInfo.outChannels / convInfo.inChannels;
  const xVals = backend3.data.get(x.dataId).values;
  const xBuf = new TensorBuffer2(x.shape, x.dtype, xVals);
  const dyVals = backend3.data.get(dy.dataId).values;
  const dyBuf = new TensorBuffer2(dy.shape, dy.dtype, dyVals);
  for (let wR = 0; wR < filterHeight; ++wR) {
    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
    const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
    for (let wC = 0; wC < filterWidth; ++wC) {
      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
      const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
        const d1 = Math.trunc(d2 / chMul);
        const dm = d2 % chMul;
        let dotProd = 0;
        for (let b = 0; b < convInfo.batchSize; ++b) {
          for (let yR = yRMin; yR < yRMax; ++yR) {
            const xR = wR + yR * strideHeight - topPad;
            for (let yC = yCMin; yC < yCMax; ++yC) {
              const xC = wC + yC * strideWidth - leftPad;
              dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
            }
          }
        }
        dW.set(dotProd, wR, wC, d1, dm);
      }
    }
  }
  return backend3.makeTensorInfo(dW.shape, dW.dtype, dW.values);
}
var depthwiseConv2dNativeBackpropFilterConfig = {
  kernelName: DepthwiseConv2dNativeBackpropFilter2,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropFilter3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropInput.ts
function depthwiseConv2dNativeBackpropInput3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, dilations, pad: pad4, dimRoundingMode, inputShape } = attrs;
  assertNotComplex([dy, filter], "depthwiseConv2DNativeBackpropInput");
  const dyStrides = util_exports2.computeStrides(dy.shape);
  const filterStrides = util_exports2.computeStrides(filter.shape);
  const convInfo = backend_util_exports2.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad4, dimRoundingMode, true);
  const dx = new TensorBuffer2(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const [dxS0, dxS1, dxS2] = dx.strides;
  const dyValues = backend3.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2] = dyStrides;
  const fltValues = backend3.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2] = filterStrides;
  const {
    batchSize,
    filterHeight,
    filterWidth,
    inChannels,
    inHeight,
    inWidth,
    outChannels,
    outHeight,
    outWidth,
    strideHeight,
    strideWidth
  } = convInfo;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  const chMul = outChannels / inChannels;
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xR = 0; xR < inHeight; ++xR) {
        const xRCorner = xR - topPad;
        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
        const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
        for (let xC = 0; xC < inWidth; ++xC) {
          const xCCorner = xC - leftPad;
          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
          const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
          let dotProd = 0;
          for (let yR = xRMin; yR < yRMax; ++yR) {
            const wR = yR * strideHeight - xRCorner;
            for (let yC = xCMin; yC < yCMax; ++yC) {
              const wC = yC * strideWidth - xCCorner;
              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;
              const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
              for (let dm = 0; dm < chMul; ++dm) {
                const d2 = d1 * chMul + dm;
                const pixel = dyValues[dyOffset + d2];
                const weight = fltValues[fltOffset + dm];
                dotProd += pixel * weight;
              }
            }
          }
          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var depthwiseConv2dNativeBackpropInputConfig = {
  kernelName: DepthwiseConv2dNativeBackpropInput2,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropInput3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Diag.ts
function diag3(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  const xSize = util_exports2.sizeFromShape(x.shape);
  const xVals = backend3.data.get(x.dataId).values;
  const outBuf = buffer2([xSize, xSize], x.dtype);
  const vals = outBuf.values;
  for (let i = 0; i < xVals.length; i++) {
    vals[i * xSize + i] = xVals[i];
  }
  const outShape = [...x.shape, ...x.shape];
  return backend3.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);
}
var diagConfig = {
  kernelName: Diag2,
  backendName: "cpu",
  kernelFunc: diag3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Dilation2D.ts
var dilation2dConfig = {
  kernelName: Dilation2D2,
  backendName: "cpu",
  kernelFunc: ({ inputs, backend: backend3, attrs }) => {
    const { x, filter } = inputs;
    const { strides, pad: pad4, dilations } = attrs;
    const cpuBackend = backend3;
    const xVals = cpuBackend.data.get(x.dataId).values;
    const xRank = x.shape.length;
    const filterVals = cpuBackend.data.get(filter.dataId).values;
    const filterRank = filter.shape.length;
    const {
      batchSize,
      inHeight,
      inWidth,
      inChannels,
      outHeight,
      outWidth,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      dilationHeight,
      dilationWidth,
      outShape
    } = backend_util_exports2.computeDilation2DInfo(x.shape, filter.shape, strides, pad4, "NHWC", dilations);
    const outSize = util_exports2.sizeFromShape(outShape);
    const outRank = outShape.length;
    const outputVals = util_exports2.getArrayFromDType(x.dtype, outSize);
    for (let b = 0; b < batchSize; ++b) {
      for (let hOut = 0; hOut < outHeight; ++hOut) {
        const hBeg = hOut * strideHeight - padInfo.top;
        for (let wOut = 0; wOut < outWidth; ++wOut) {
          const wBeg = wOut * strideWidth - padInfo.left;
          for (let d = 0; d < inChannels; ++d) {
            let curVal = Number.MIN_SAFE_INTEGER;
            for (let h = 0; h < filterHeight; ++h) {
              const hIn = hBeg + h * dilationHeight;
              if (hIn >= 0 && hIn < inHeight) {
                for (let w = 0; w < filterWidth; ++w) {
                  const wIn = wBeg + w * dilationWidth;
                  if (wIn >= 0 && wIn < inWidth) {
                    const xIndex = util_exports2.locToIndex([b, hIn, wIn, d], xRank, util_exports2.computeStrides(x.shape));
                    const filterIndex = util_exports2.locToIndex([h, w, d], filterRank, util_exports2.computeStrides(filter.shape));
                    const val = xVals[xIndex] + filterVals[filterIndex];
                    if (val > curVal) {
                      curVal = val;
                    }
                  }
                }
              }
            }
            const outputIndex = util_exports2.locToIndex([b, hOut, wOut, d], outRank, util_exports2.computeStrides(outShape));
            outputVals[outputIndex] = curVal;
          }
        }
      }
    }
    const dataId = cpuBackend.write(util_exports2.toTypedArray(outputVals, x.dtype), outShape, x.dtype);
    return { dataId, shape: outShape, dtype: x.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Dilation2DBackpropFilter.ts
var dilation2dBackpropFilterConfig = {
  kernelName: Dilation2DBackpropFilter2,
  backendName: "cpu",
  kernelFunc: ({ inputs, backend: backend3, attrs }) => {
    const { x, filter, dy } = inputs;
    const { strides, pad: pad4, dilations } = attrs;
    const cpuBackend = backend3;
    const $x = util_exports2.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
    const $filter = util_exports2.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
    const {
      batchSize,
      inHeight,
      inWidth,
      inChannels,
      outHeight,
      outWidth,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      dilationHeight,
      dilationWidth,
      outShape
    } = backend_util_exports2.computeDilation2DInfo(x.shape, filter.shape, strides, pad4, "NHWC", dilations);
    util_exports2.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropFilter2}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
    const $dy = util_exports2.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
    const gradients = util_exports2.makeZerosNestedTypedArray(filter.shape, filter.dtype);
    for (let b = 0; b < batchSize; ++b) {
      for (let hOut = 0; hOut < outHeight; ++hOut) {
        const hBeg = hOut * strideHeight - padInfo.top;
        for (let wOut = 0; wOut < outWidth; ++wOut) {
          const wBeg = wOut * strideWidth - padInfo.left;
          for (let d = 0; d < inChannels; ++d) {
            let curVal = Number.MIN_SAFE_INTEGER;
            let hMax = 0;
            let wMax = 0;
            for (let h = 0; h < filterHeight; ++h) {
              const hIn = hBeg + h * dilationHeight;
              if (hIn >= 0 && hIn < inHeight) {
                for (let w = 0; w < filterWidth; ++w) {
                  const wIn = wBeg + w * dilationWidth;
                  if (wIn >= 0 && wIn < inWidth) {
                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                    if (val > curVal) {
                      curVal = val;
                      hMax = h;
                      wMax = w;
                    }
                  }
                }
              }
            }
            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];
          }
        }
      }
    }
    const dataId = cpuBackend.write(util_exports2.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);
    return { dataId, shape: filter.shape, dtype: filter.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Dilation2DBackpropInput.ts
var dilation2dBackpropInputConfig = {
  kernelName: Dilation2DBackpropInput2,
  backendName: "cpu",
  kernelFunc: ({ inputs, backend: backend3, attrs }) => {
    const { x, filter, dy } = inputs;
    const { strides, pad: pad4, dilations } = attrs;
    const cpuBackend = backend3;
    const $x = util_exports2.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
    const $filter = util_exports2.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
    const {
      batchSize,
      inHeight,
      inWidth,
      inChannels,
      outHeight,
      outWidth,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      dilationHeight,
      dilationWidth,
      outShape
    } = backend_util_exports2.computeDilation2DInfo(x.shape, filter.shape, strides, pad4, "NHWC", dilations);
    util_exports2.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput2}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
    const $dy = util_exports2.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
    const gradients = util_exports2.makeZerosNestedTypedArray(x.shape, x.dtype);
    for (let b = 0; b < batchSize; ++b) {
      for (let hOut = 0; hOut < outHeight; ++hOut) {
        const hBeg = hOut * strideHeight - padInfo.top;
        for (let wOut = 0; wOut < outWidth; ++wOut) {
          const wBeg = wOut * strideWidth - padInfo.left;
          for (let d = 0; d < inChannels; ++d) {
            let curVal = Number.MIN_SAFE_INTEGER;
            let hInMax = hBeg < 0 ? 0 : hBeg;
            let wInMax = wBeg < 0 ? 0 : wBeg;
            for (let h = 0; h < filterHeight; ++h) {
              const hIn = hBeg + h * dilationHeight;
              if (hIn >= 0 && hIn < inHeight) {
                for (let w = 0; w < filterWidth; ++w) {
                  const wIn = wBeg + w * dilationWidth;
                  if (wIn >= 0 && wIn < inWidth) {
                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                    if (val > curVal) {
                      curVal = val;
                      hInMax = hIn;
                      wInMax = wIn;
                    }
                  }
                }
              }
            }
            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];
          }
        }
      }
    }
    const dataId = cpuBackend.write(util_exports2.toTypedArray(gradients, x.dtype), x.shape, x.dtype);
    return { dataId, shape: x.shape, dtype: x.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sum.ts
function sum5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "sum");
  let $x;
  if (x.dtype === "bool") {
    $x = cast4({ inputs: { x }, backend: backend3, attrs: { dtype: "int32" } });
  } else {
    $x = identity2({ inputs: { x }, backend: backend3 });
  }
  const xRank = $x.shape.length;
  const axes = util_exports2.parseAxisParam(axis, $x.shape);
  const permutation = backend_util_exports2.getAxesPermutation(axes, xRank);
  let reductionAxes = axes;
  let permutedX = $x;
  if (permutation != null) {
    permutedX = transpose3({ inputs: { x: $x }, backend: backend3, attrs: { perm: permutation } });
    reductionAxes = backend_util_exports2.getInnerMostAxes(reductionAxes.length, xRank);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("sum", reductionAxes, permutedX.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(permutedX.shape, reductionAxes);
  const resultDtype = backend_util_exports2.upcastType(permutedX.dtype, "int32");
  let result = zeros4(backend3, outShape, resultDtype);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const vals = backend3.data.get(result.dataId).values;
  const aVals = backend3.data.get(permutedX.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let sum8 = 0;
    for (let j = 0; j < reduceSize; ++j) {
      sum8 += aVals[offset + j];
    }
    vals[i] = sum8;
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(result.shape, axes);
    const oldResult = result;
    result = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: newShape } });
    backend3.disposeIntermediateTensorInfo(oldResult);
  }
  backend3.disposeIntermediateTensorInfo($x);
  if (permutation != null) {
    backend3.disposeIntermediateTensorInfo(permutedX);
  }
  return result;
}
var sumConfig = {
  kernelName: Sum2,
  backendName: "cpu",
  kernelFunc: sum5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Einsum.ts
function einsum3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { equation } = attrs;
  const tensors = inputs;
  const { allDims, summedDims, idDims } = backend_util_exports2.decodeEinsumEquation(equation, tensors.length);
  backend_util_exports2.checkEinsumDimSizes(allDims.length, idDims, tensors);
  const { path, steps } = backend_util_exports2.getEinsumComputePath(summedDims, idDims);
  const nSteps = steps.length;
  let out = null;
  let numDimsRemaining = allDims.length;
  const tensorsToDispose = [];
  for (let i = 0; i < nSteps; ++i) {
    for (const idTerm of steps[i]) {
      const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports2.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
      let x;
      if (backend_util_exports2.isIdentityPermutation(perm)) {
        x = tensors[idTerm];
      } else {
        x = transpose3({ inputs: { x: tensors[idTerm] }, backend: backend3, attrs: { perm } });
        tensorsToDispose.push(x);
      }
      const targetShape = x.shape.slice();
      for (let k = 0; k < dimsToExpand.length; ++k) {
        targetShape.splice(dimsToExpand[k], 0, 1);
      }
      if (!util_exports2.arraysEqual(x.shape, targetShape)) {
        x = reshape4({ inputs: { x }, backend: backend3, attrs: { shape: targetShape } });
        tensorsToDispose.push(x);
      }
      if (out === null) {
        out = x;
      } else {
        out = multiply2({ inputs: { a: x, b: out }, backend: backend3 });
        tensorsToDispose.push(out);
      }
    }
    if (i < nSteps - 1) {
      if (path[i] >= 0) {
        out = sum5({
          inputs: { x: out },
          backend: backend3,
          attrs: {
            axis: path[i] - (allDims.length - numDimsRemaining),
            keepDims: false
          }
        });
        tensorsToDispose.push(out);
      }
      numDimsRemaining--;
    }
  }
  for (const tensorInfo of tensorsToDispose) {
    if (tensorInfo === out) {
      continue;
    }
    backend3.disposeIntermediateTensorInfo(tensorInfo);
  }
  return out;
}
var einsumConfig = {
  kernelName: Einsum2,
  backendName: "cpu",
  kernelFunc: einsum3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/EluGrad.ts
function eluGrad(args) {
  const { inputs, backend: backend3 } = args;
  const { dy, y } = inputs;
  assertNotComplex([dy, y], "eluGrad");
  const resultValues = new Float32Array(util_exports2.sizeFromShape(y.shape));
  const values = backend3.data.get(y.dataId).values;
  const dyValues = backend3.data.get(dy.dataId).values;
  for (let i = 0; i < values.length; ++i) {
    const v = values[i];
    if (v >= 1) {
      resultValues[i] = dyValues[i];
    } else {
      resultValues[i] = dyValues[i] * (v + 1);
    }
  }
  return backend3.makeTensorInfo(y.shape, "float32", resultValues);
}
var eluGradConfig2 = {
  kernelName: EluGrad2,
  backendName: "cpu",
  kernelFunc: eluGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Erf.ts
var p = backend_util_exports2.ERF_P;
var a1 = backend_util_exports2.ERF_A1;
var a2 = backend_util_exports2.ERF_A2;
var a3 = backend_util_exports2.ERF_A3;
var a4 = backend_util_exports2.ERF_A4;
var a5 = backend_util_exports2.ERF_A5;
var erf3 = unaryKernelFunc(Erf2, (xi) => {
  const sign5 = Math.sign(xi);
  const v = Math.abs(xi);
  const t = 1 / (1 + p * v);
  return sign5 * (1 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-v * v));
});
var erfConfig = {
  kernelName: Erf2,
  backendName: "cpu",
  kernelFunc: erf3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ExpandDims.ts
function expandDims4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { input: input2 } = inputs;
  const { dim } = attrs;
  const inputRank = input2.shape.length;
  const newShape = input2.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports2.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape4({ inputs: { x: input2 }, backend: backend3, attrs: { shape: newShape } });
}
var expandDimsConfig = {
  kernelName: ExpandDims2,
  backendName: "cpu",
  kernelFunc: expandDims4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/RealDiv.ts
var realDivImpl = createSimpleBinaryKernelImpl((a, b) => a / b);
var div3 = binaryKernelFunc(RealDiv2, realDivImpl);
var realDivConfig = {
  kernelName: RealDiv2,
  backendName: "cpu",
  kernelFunc: div3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/utils/fft_utils.ts
function fftBatch(input2, inverse, cpuBackend) {
  const inputShape = input2.shape;
  const batch = inputShape[0];
  const innerDim = inputShape[1];
  const inputVals = cpuBackend.data.get(input2.dataId);
  const real2D = inputVals.complexTensorInfos.real;
  const imag2D = inputVals.complexTensorInfos.imag;
  const resultShape = [batch, innerDim];
  const resultSize = util_exports2.sizeFromShape(resultShape);
  const resultReal = util_exports2.getTypedArrayFromDType("float32", resultSize);
  const resultImag = util_exports2.getTypedArrayFromDType("float32", resultSize);
  for (let b = 0; b < batch; b++) {
    const r = slice3({
      inputs: { x: real2D },
      backend: cpuBackend,
      attrs: { begin: [b, 0], size: [1, innerDim] }
    });
    const i = slice3({
      inputs: { x: imag2D },
      backend: cpuBackend,
      attrs: { begin: [b, 0], size: [1, innerDim] }
    });
    const input3 = complex3({ inputs: { real: r, imag: i }, backend: cpuBackend });
    const { real: real6, imag: imag5 } = fftImpl(input3, inverse, cpuBackend);
    const res = backend_util_exports2.mergeRealAndImagArrays(real6, imag5);
    for (let d = 0; d < innerDim; d++) {
      const c = backend_util_exports2.getComplexWithIndex(res, d);
      resultReal[b * innerDim + d] = c.real;
      resultImag[b * innerDim + d] = c.imag;
    }
    cpuBackend.disposeIntermediateTensorInfo(r);
    cpuBackend.disposeIntermediateTensorInfo(i);
    cpuBackend.disposeIntermediateTensorInfo(input3);
  }
  const $realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultReal);
  const $imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultImag);
  const result = complex3({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });
  cpuBackend.disposeIntermediateTensorInfo($realInfo);
  cpuBackend.disposeIntermediateTensorInfo($imagInfo);
  return result;
}
function fftImpl(input2, inverse, cpuBackend) {
  const inputSize = util_exports2.sizeFromShape(input2.shape);
  const inputVals = cpuBackend.data.get(input2.dataId);
  const realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;
  const imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;
  if (isExponentOf2(inputSize)) {
    const result = fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);
    const resultShape = [input2.shape[0], input2.shape[1]];
    if (inverse) {
      const realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.real);
      const imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.imag);
      const sizeInfo = cpuBackend.makeTensorInfo([], "float32", util_exports2.createScalarValue(inputSize, "float32"));
      const sizeInfoCopy = identity2({ inputs: { x: sizeInfo }, backend: cpuBackend });
      const divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });
      const divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });
      const divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;
      const divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;
      cpuBackend.disposeIntermediateTensorInfo(realInfo);
      cpuBackend.disposeIntermediateTensorInfo(imagInfo);
      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);
      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);
      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);
      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);
      return { real: divRealVals, imag: divImagVals };
    }
    return result;
  } else {
    const data = backend_util_exports2.mergeRealAndImagArrays(realVals, imagVals);
    const rawOutput = fourierTransformByMatmul(data, inputSize, inverse);
    return backend_util_exports2.splitRealAndImagArrays(rawOutput);
  }
}
function isExponentOf2(size) {
  return (size & size - 1) === 0;
}
function fftRadix2(realVals, imagVals, size, inverse, cpuBackend) {
  if (size === 1) {
    return { real: realVals, imag: imagVals };
  }
  const data = backend_util_exports2.mergeRealAndImagArrays(realVals, imagVals);
  const half = size / 2;
  const evenComplex = backend_util_exports2.complexWithEvenIndex(data);
  const evenRealVals = evenComplex.real;
  const evenImagVals = evenComplex.imag;
  const evenShape = [evenRealVals.length];
  const evenRealInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenRealVals);
  const evenImagInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenImagVals);
  const evenTensorInfo = complex3({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });
  const oddComplex = backend_util_exports2.complexWithOddIndex(data);
  const oddRealVals = oddComplex.real;
  const oddImagVals = oddComplex.imag;
  const oddShape = [oddRealVals.length];
  const oddRealInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddRealVals);
  const oddImagInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddImagVals);
  const oddTensorInfo = complex3({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });
  const $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);
  const $evenRealVals = $evenComplex.real;
  const $evenImagVals = $evenComplex.imag;
  const $evenShape = [$evenRealVals.length];
  const $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenRealVals);
  const $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenImagVals);
  const $evenTensorInfo = complex3({
    inputs: { real: $evenRealInfo, imag: $evenImagInfo },
    backend: cpuBackend
  });
  const $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);
  const $oddRealVals = $oddComplex.real;
  const $oddImagVals = $oddComplex.imag;
  const $oddShape = [$oddRealVals.length];
  const $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddRealVals);
  const $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddImagVals);
  const $oddTensorInfo = complex3({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });
  const e = backend_util_exports2.exponents(size, inverse);
  const eShape = [e.real.length];
  const eRealInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.real);
  const eImagInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.imag);
  const complexInfo = complex3({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });
  const exponentInfo = multiply2({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });
  const addPart = add6({
    inputs: { a: $evenTensorInfo, b: exponentInfo },
    backend: cpuBackend
  });
  const subPart = sub3({
    inputs: { a: $evenTensorInfo, b: exponentInfo },
    backend: cpuBackend
  });
  const addPartReal = real3({ inputs: { input: addPart }, backend: cpuBackend });
  const subPartReal = real3({ inputs: { input: subPart }, backend: cpuBackend });
  const addPartImag = imag3({ inputs: { input: addPart }, backend: cpuBackend });
  const subPartImag = imag3({ inputs: { input: subPart }, backend: cpuBackend });
  const $real = concat3({
    inputs: [addPartReal, subPartReal],
    backend: cpuBackend,
    attrs: { axis: 0 }
  });
  const $imag = concat3({
    inputs: [addPartImag, subPartImag],
    backend: cpuBackend,
    attrs: { axis: 0 }
  });
  const $realVals = cpuBackend.data.get($real.dataId).values;
  const $imagVals = cpuBackend.data.get($imag.dataId).values;
  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(complexInfo);
  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);
  cpuBackend.disposeIntermediateTensorInfo(addPart);
  cpuBackend.disposeIntermediateTensorInfo(subPart);
  cpuBackend.disposeIntermediateTensorInfo(addPartReal);
  cpuBackend.disposeIntermediateTensorInfo(addPartImag);
  cpuBackend.disposeIntermediateTensorInfo(subPartReal);
  cpuBackend.disposeIntermediateTensorInfo(subPartImag);
  cpuBackend.disposeIntermediateTensorInfo($real);
  cpuBackend.disposeIntermediateTensorInfo($imag);
  return { real: $realVals, imag: $imagVals };
}
function fourierTransformByMatmul(data, size, inverse) {
  const ret = new Float32Array(size * 2);
  for (let r = 0; r < size; r++) {
    let real6 = 0;
    let imag5 = 0;
    for (let c = 0; c < size; c++) {
      const e = backend_util_exports2.exponent(r * c, size, inverse);
      const term = backend_util_exports2.getComplexWithIndex(data, c);
      real6 += term.real * e.real - term.imag * e.imag;
      imag5 += term.real * e.imag + term.imag * e.real;
    }
    if (inverse) {
      real6 /= size;
      imag5 /= size;
    }
    backend_util_exports2.assignToTypedArray(ret, real6, imag5, r);
  }
  return ret;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/FFT.ts
function fft3(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const inputSize = util_exports2.sizeFromShape(input2.shape);
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape4({
    inputs: { x: input2 },
    backend: backend3,
    attrs: { shape: [batch, innerDimensionSize] }
  });
  const result = fftBatch(input2D, false, backend3);
  const resultReshaped = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: input2.shape } });
  backend3.disposeIntermediateTensorInfo(input2D);
  backend3.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var fftConfig = {
  kernelName: FFT2,
  backendName: "cpu",
  kernelFunc: fft3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Fill.ts
function fill3(args) {
  const { backend: backend3, attrs } = args;
  const { shape, value, dtype } = attrs;
  const $dtype = dtype || util_exports2.inferDtype(value);
  const values = util_exports2.getArrayFromDType($dtype, util_exports2.sizeFromShape(shape));
  fillValues(values, value, $dtype);
  return backend3.makeTensorInfo(shape, $dtype, values);
}
var fillConfig = {
  kernelName: Fill2,
  backendName: "cpu",
  kernelFunc: fill3
};
function fillValues(values, value, dtype) {
  if (dtype === "string") {
    values.fill(value);
  } else {
    values.fill(value);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/FlipLeftRight.ts
var flipLeftRightConfig = {
  kernelName: FlipLeftRight2,
  backendName: "cpu",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { image: image4 } = inputs;
    const cpuBackend = backend3;
    const output = util_exports2.getTypedArrayFromDType(image4.dtype, util_exports2.sizeFromShape(image4.shape));
    const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
    const imageVals = cpuBackend.data.get(image4.dataId).values;
    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
      for (let row = 0; row < imageHeight; row++) {
        const rowOffset = row * (imageWidth * numChannels);
        for (let col = 0; col < imageWidth; col++) {
          const colOffset = col * numChannels;
          for (let channel = 0; channel < numChannels; channel++) {
            const coords2 = [batch, row, col, channel];
            const x = coords2[2];
            const coordX = Math.round(imageWidth - x);
            const outIdx = batchOffset + rowOffset + colOffset + channel;
            let outputValue = imageVals[outIdx];
            if (coordX >= 0 && coordX < imageWidth) {
              const rotatedColOffset = coordX * numChannels;
              const imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;
              outputValue = imageVals[imageIdx];
            }
            output[outIdx] = outputValue;
          }
        }
      }
    }
    const dataId = cpuBackend.write(output, image4.shape, image4.dtype);
    return { dataId, shape: image4.shape, dtype: image4.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/FloorDiv.ts
var floorDivImpl = createSimpleBinaryKernelImpl((a, b) => Math.floor(a / b));
var floorDiv3 = binaryKernelFunc(FloorDiv2, floorDivImpl, null, "int32");
var floorDivConfig = {
  kernelName: FloorDiv2,
  backendName: "cpu",
  kernelFunc: floorDiv3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/FusedConv2D.ts
function fusedConv2D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  } = attrs;
  let result = conv2D({
    inputs: { x, filter },
    backend: backend3,
    attrs: { strides, pad: pad4, dataFormat, dilations, dimRoundingMode }
  });
  if (bias) {
    const resultOld = result;
    result = add6({ inputs: { a: result, b: bias }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(resultOld);
  }
  if (activation2) {
    const resultOld = result;
    result = applyActivation3(backend3, result, activation2, preluActivationWeights, leakyreluAlpha);
    backend3.disposeIntermediateTensorInfo(resultOld);
  }
  return result;
}
var fusedConv2DConfig = {
  kernelName: FusedConv2D2,
  backendName: "cpu",
  kernelFunc: fusedConv2D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/FusedDepthwiseConv2D.ts
function fusedDepthwiseConv2D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  } = attrs;
  let result = depthwiseConv2dNative({
    inputs: { x, filter },
    backend: backend3,
    attrs: { strides, pad: pad4, dataFormat, dilations, dimRoundingMode }
  });
  if (bias) {
    const oldResult = result;
    result = add6({ inputs: { a: result, b: bias }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(oldResult);
  }
  if (activation2) {
    const oldResult = result;
    result = applyActivation3(backend3, result, activation2, preluActivationWeights, leakyreluAlpha);
    backend3.disposeIntermediateTensorInfo(oldResult);
  }
  return result;
}
var fusedDepthwiseConv2DConfig = {
  kernelName: FusedDepthwiseConv2D2,
  backendName: "cpu",
  kernelFunc: fusedDepthwiseConv2D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/GatherNd.ts
function gatherNd(args) {
  const { inputs, backend: backend3 } = args;
  const { params, indices } = inputs;
  const paramsSize = util_exports2.sizeFromShape(params.shape);
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const [resultShape, numSlices, sliceSize, strides] = backend_util_exports2.prepareAndValidate(params, indices);
  if (numSlices === 0) {
    return backend3.makeTensorInfo(resultShape, params.dtype, []);
  }
  const indicesData = backend3.data.get(indices.dataId).values;
  const paramsBuf = backend3.bufferSync(params);
  const outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
  return backend3.makeTensorInfo(resultShape, params.dtype, outBuf.values);
}
var gatherNdConfig = {
  kernelName: GatherNd2,
  backendName: "cpu",
  kernelFunc: gatherNd
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/GatherV2.ts
function gatherV2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  assertNotComplex([x, indices], "gatherV2");
  let $batchDims = batchDims;
  if (batchDims == null) {
    $batchDims = 0;
  }
  const indicesSize = util_exports2.sizeFromShape(indices.shape);
  const parsedAxis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const shapeInfo = backend_util_exports2.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);
  const flattenX = reshape4({
    inputs: { x },
    backend: backend3,
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    }
  });
  const flattenIndex = reshape4({
    inputs: { x: indices },
    backend: backend3,
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
  });
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  const indicesBuf = backend3.bufferSync(flattenIndex);
  const xBuf = backend3.bufferSync(flattenX);
  const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);
  backend3.disposeIntermediateTensorInfo(flattenX);
  backend3.disposeIntermediateTensorInfo(flattenIndex);
  return backend3.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
}
var gatherV2Config = {
  kernelName: GatherV22,
  backendName: "cpu",
  kernelFunc: gatherV2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/IFFT.ts
function ifft3(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const inputSize = util_exports2.sizeFromShape(input2.shape);
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape4({
    inputs: { x: input2 },
    backend: backend3,
    attrs: { shape: [batch, innerDimensionSize] }
  });
  const result = fftBatch(input2D, true, backend3);
  const resultReshaped = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: input2.shape } });
  backend3.disposeIntermediateTensorInfo(input2D);
  backend3.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var ifftConfig = {
  kernelName: IFFT2,
  backendName: "cpu",
  kernelFunc: ifft3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/IsFinite.ts
var isFinite4 = unaryKernelFunc(IsFinite2, (xi) => Number.isFinite(xi) ? 1 : 0, "bool");
var isFiniteConfig = {
  kernelName: IsFinite2,
  backendName: "cpu",
  kernelFunc: isFinite4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/IsInf.ts
var isInf3 = unaryKernelFunc(IsInf2, (xi) => Math.abs(xi) === Infinity ? 1 : 0, "bool");
var isInfConfig = {
  kernelName: IsInf2,
  backendName: "cpu",
  kernelFunc: isInf3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/IsNaN.ts
var isNaN4 = unaryKernelFunc(IsNan2, (xi) => Number.isNaN(xi) ? 1 : 0, "bool");
var isNaNConfig = {
  kernelName: IsNan2,
  backendName: "cpu",
  kernelFunc: isNaN4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LinSpace.ts
function linSpace(args) {
  const { backend: backend3, attrs } = args;
  const { start, stop, num } = attrs;
  const outVals = linSpaceImpl(start, stop, num);
  return backend3.makeTensorInfo([outVals.length], "float32", outVals);
}
var linSpaceConfig = {
  kernelName: LinSpace2,
  backendName: "cpu",
  kernelFunc: linSpace
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Log1p.ts
var log1p3 = unaryKernelFunc(Log1p2, (xi) => Math.log1p(xi));
var log1pConfig = {
  kernelName: Log1p2,
  backendName: "cpu",
  kernelFunc: log1p3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LogicalAnd.ts
var logicalAndImpl = createSimpleBinaryKernelImpl((a, b) => a && b);
var logicalAnd3 = binaryKernelFunc(LogicalAnd2, logicalAndImpl, null, "bool");
var logicalAndConfig = {
  kernelName: LogicalAnd2,
  backendName: "cpu",
  kernelFunc: logicalAnd3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LogicalNot.ts
var logicalNot3 = unaryKernelFunc(LogicalNot2, (xi) => xi ? 0 : 1, "bool");
var logicalNotConfig = {
  kernelName: LogicalNot2,
  backendName: "cpu",
  kernelFunc: logicalNot3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LogicalOr.ts
var logicalOrImpl = createSimpleBinaryKernelImpl((a, b) => a || b);
var logicalOr3 = binaryKernelFunc(LogicalOr2, logicalOrImpl, null, "bool");
var logicalOrConfig = {
  kernelName: LogicalOr2,
  backendName: "cpu",
  kernelFunc: logicalOr3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LRN.ts
function lRN(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  assertNotComplex(x, "LRN");
  const channels = x.shape[3];
  const maxD = channels - 1;
  const xValues = backend3.data.get(x.dataId).values;
  const size = util_exports2.sizeFromShape(x.shape);
  const result = new Float32Array(size);
  function sumAcrossChannels(offset) {
    const currentChannel = offset % channels;
    let beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
    const endSumOffset = offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);
    let sum8 = 0;
    for (; beginSumOffset <= endSumOffset; beginSumOffset++) {
      const z = xValues[beginSumOffset];
      sum8 += z * z;
    }
    return sum8;
  }
  for (let offset = 0; offset < size; offset++) {
    const sum8 = sumAcrossChannels(offset);
    const val = xValues[offset] * Math.pow(bias + alpha * sum8, -beta);
    result[offset] = val;
  }
  return backend3.makeTensorInfo(x.shape, x.dtype, result);
}
var lRNConfig = {
  kernelName: LRN2,
  backendName: "cpu",
  kernelFunc: lRN
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/LRNGrad.ts
function lRNGrad(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, y, dy } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  assertNotComplex(dy, "LRNGrad");
  const dySize = util_exports2.sizeFromShape(dy.shape);
  const channels = dy.shape[3];
  const dyValues = backend3.data.get(dy.dataId).values;
  const xValues = backend3.data.get(x.dataId).values;
  const yValues = backend3.data.get(y.dataId).values;
  const result = new Float32Array(dySize);
  const size = dySize;
  for (let offset = 0; offset < size; offset++) {
    const currentChannel = offset % channels;
    const depthBegin = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
    const depthEnd = offset - currentChannel + Math.min(channels, currentChannel + depthRadius + 1);
    let norm3 = 0;
    for (let k = depthBegin; k < depthEnd; k++) {
      norm3 += Math.pow(xValues[k], 2);
    }
    norm3 = alpha * norm3 + bias;
    for (let k = depthBegin; k < depthEnd; k++) {
      let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm3;
      if (offset === k) {
        dyi += Math.pow(norm3, -beta);
      }
      dyi *= dyValues[offset];
      result[k] += dyi;
    }
  }
  return backend3.makeTensorInfo(dy.shape, x.dtype, result);
}
var lRNGradConfig = {
  kernelName: LRNGrad2,
  backendName: "cpu",
  kernelFunc: lRNGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Max.ts
function max4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { reductionIndices, keepDims } = attrs;
  const cpuBackend = backend3;
  let xShape = x.shape;
  const xRank = xShape.length;
  const origAxes = util_exports2.parseAxisParam(reductionIndices, xShape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let xVals = cpuBackend.data.get(x.dataId).values;
  if (permutedAxes != null) {
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = xShape[permutedAxes[i]];
    }
    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
    xShape = newShape;
  }
  assertNotComplex(x, "max");
  backend_util_exports2.assertAxesAreInnerMostDims("max", axes, xRank);
  const [maxOutShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(xShape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);
  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);
  let outShape = maxOutShape;
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(maxOutShape, origAxes);
    outShape = newShape;
  }
  return { dataId, shape: outShape, dtype: x.dtype };
}
var maxConfig = {
  kernelName: Max2,
  backendName: "cpu",
  kernelFunc: max4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPool.ts
function maxPool3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  assertNotComplex(x, "maxPool");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  let res;
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports2.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    res = identity2({ inputs: { x }, backend: backend3 });
  } else {
    const xValues = backend3.data.get(x.dataId).values;
    const strides2 = util_exports2.computeStrides(x.shape);
    const buffer3 = pool3(xValues, x.shape, x.dtype, strides2, convInfo, "max");
    res = backend3.makeTensorInfo(convInfo.outShape, x.dtype, buffer3.values);
  }
  return res;
}
var maxPoolConfig = {
  kernelName: MaxPool2,
  backendName: "cpu",
  kernelFunc: maxPool3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPool3D.ts
function maxPool3D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat } = attrs;
  assertNotComplex(x, "maxPool3d");
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode, dataFormat);
  const xValues = backend3.data.get(x.dataId).values;
  const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports2.computeStrides(x.shape), convInfo, "max");
  return backend3.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
}
var maxPool3DConfig = {
  kernelName: MaxPool3D2,
  backendName: "cpu",
  kernelFunc: maxPool3D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPool3DGrad.ts
function maxPool3DGrad(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  assertNotComplex([dy, input2], "maxPool3DGrad");
  const convInfo = backend_util_exports2.computePool3DInfo(input2.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const inputBuf = backend3.bufferSync(input2);
  const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer2(input2.shape, "float32");
  const dyBuf = backend3.bufferSync(dy);
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
            const dyDepthCorner = dxDepth - padFront;
            const dyRowCorner = dxRow - padTop;
            const dyColCorner = dxCol - padLeft;
            let dotProd = 0;
            for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
              if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                continue;
              }
              for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                const dyRow = (dyRowCorner + wRow) / strideHeight;
                if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                  continue;
                }
                for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                  const dyCol = (dyColCorner + wCol) / strideWidth;
                  if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                    continue;
                  }
                  const maxPos = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  const curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterWidth + wCol;
                  const mask = maxPos === curPos ? 1 : 0;
                  if (mask === 0) {
                    continue;
                  }
                  const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  dotProd += pixel * mask;
                }
              }
            }
            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);
          }
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var maxPool3DGradConfig2 = {
  kernelName: MaxPool3DGrad2,
  backendName: "cpu",
  kernelFunc: maxPool3DGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPoolGrad.ts
function maxPoolGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2, output } = inputs;
  const x = input2;
  assertNotComplex([input2, output], "maxPoolGrad");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const xValues = backend3.data.get(x.dataId).values;
  const maxPosBuf = buffer2(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer2(x.shape, "float32");
  const dyData = backend3.data.get(dy.dataId).values;
  const dyBuf = buffer2(dy.shape, "float32", dyData);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
          const dyRCorner = dxR - padTop;
          const dyCCorner = dxC - padLeft;
          let dotProd = 0;
          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
            const dyR = (dyRCorner + wR) / strideHeight;
            if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
              continue;
            }
            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
              const dyC = (dyCCorner + wC) / strideWidth;
              if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                continue;
              }
              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(b, dyR, dyC, d);
              const curPos = wR * effectiveFilterWidth + wC;
              const mask = maxPos === curPos ? 1 : 0;
              if (mask === 0) {
                continue;
              }
              const pixel = dyBuf.get(b, dyR, dyC, d);
              dotProd += pixel * mask;
            }
          }
          dx.set(dotProd, b, dxR, dxC, d);
        }
      }
    }
  }
  return backend3.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var maxPoolGradConfig2 = {
  kernelName: MaxPoolGrad2,
  backendName: "cpu",
  kernelFunc: maxPoolGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax_impl.ts
function maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {
  const strides = util_exports2.computeStrides(xShape);
  const maxPools = pool3(xValues, xShape, dtype, strides, convInfo, "max");
  const maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);
  return [maxPools.values, maxPositions.values];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax.ts
var maxPoolWithArgmaxConfig = {
  kernelName: MaxPoolWithArgmax2,
  backendName: "cpu",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    const { filterSize, strides, pad: pad4, includeBatchInIndex } = attrs;
    const cpuBackend = backend3;
    assertNotComplex(x, "MaxPoolWithArgmax");
    const values = cpuBackend.data.get(x.dataId).values;
    const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad4);
    const [pooled, indexes] = maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo);
    const pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);
    const indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);
    return [
      { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },
      { dataId: indexesDataId, shape: convInfo.outShape, dtype: "int32" }
    ];
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Mean.ts
function mean3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const axes = util_exports2.parseAxisParam(axis, x.shape);
  const shapes = backend_util_exports2.computeOutAndReduceShapes(x.shape, axes);
  const reduceShape = shapes[1];
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const toDispose = [];
  const reduceSizeScalar = backend3.makeTensorInfo([], "float32", new Float32Array([reduceSize]));
  toDispose.push(reduceSizeScalar);
  const $x = cast4({ inputs: { x }, backend: backend3, attrs: { dtype: "float32" } });
  toDispose.push($x);
  const res = div3({ inputs: { a: $x, b: reduceSizeScalar }, backend: backend3 });
  toDispose.push(res);
  const result = sum5({ inputs: { x: res }, backend: backend3, attrs: { axis, keepDims } });
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var meanConfig = {
  kernelName: Mean2,
  backendName: "cpu",
  kernelFunc: mean3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Min.ts
function min4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "min");
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("min", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const vals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(outShape), $x.dtype);
  const aVals = backend3.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let min7 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value < min7) {
        min7 = value;
      }
    }
    vals[i] = min7;
  }
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo($x);
  }
  const result = backend3.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: expandedShape } });
    backend3.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var minConfig = {
  kernelName: Min2,
  backendName: "cpu",
  kernelFunc: min4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/MirrorPad.ts
function mirrorPad3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { paddings, mode } = attrs;
  assertNotComplex(x, "mirrorPad");
  const outShape = paddings.map((p2, i) => p2[0] + x.shape[i] + p2[1]);
  const start = paddings.map((p2) => p2[0]);
  const end = paddings.map((p2, i) => p2[0] + x.shape[i]);
  const offset = mode === "reflect" ? 0 : 1;
  const xVals = backend3.data.get(x.dataId).values;
  const xRank = x.shape.length;
  const xStrides = util_exports2.computeStrides(x.shape);
  const resultSize = util_exports2.sizeFromShape(outShape);
  const resultRank = outShape.length;
  const resultStrides = util_exports2.computeStrides(outShape);
  const resVals = util_exports2.getTypedArrayFromDType(x.dtype, resultSize);
  for (let i = 0; i < resultSize; i++) {
    let coords2 = util_exports2.indexToLoc(i, resultRank, resultStrides);
    for (let i2 = 0; i2 < resultRank; i2++) {
      if (coords2[i2] < start[i2]) {
        coords2[i2] = start[i2] * 2 - coords2[i2] - offset;
      } else if (coords2[i2] >= end[i2]) {
        coords2[i2] = (end[i2] - 1) * 2 - coords2[i2] + offset;
      }
    }
    coords2 = coords2.map((c, i2) => c - start[i2]);
    const inIndex = util_exports2.locToIndex(coords2, xRank, xStrides);
    resVals[i] = xVals[inIndex];
  }
  const outId = backend3.write(resVals, outShape, x.dtype);
  return { dataId: outId, shape: outShape, dtype: x.dtype };
}
var mirrorPadConfig = {
  kernelName: MirrorPad2,
  backendName: "cpu",
  kernelFunc: mirrorPad3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Mod.ts
var modImpl = createSimpleBinaryKernelImpl((aValue, bValue) => {
  const rem = aValue % bValue;
  if (aValue < 0 && bValue < 0 || aValue >= 0 && bValue >= 0) {
    return rem;
  } else {
    return (rem + bValue) % bValue;
  }
});
var mod3 = binaryKernelFunc(Mod2, modImpl);
var modConfig = {
  kernelName: Mod2,
  backendName: "cpu",
  kernelFunc: mod3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Multinomial.ts
var seedrandom5 = __toModule(require_seedrandom2());

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Softmax.ts
function softmax4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { logits } = inputs;
  const { dim } = attrs;
  const logitsRank = logits.shape.length;
  let $dim = dim;
  if ($dim === -1) {
    $dim = logitsRank - 1;
  }
  if ($dim !== logitsRank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${logitsRank} and dim was ${$dim}`);
  }
  const axes = util_exports2.parseAxisParam([$dim], logits.shape);
  const maxLogit = max4({
    inputs: { x: logits },
    backend: backend3,
    attrs: { reductionIndices: axes, keepDims: false }
  });
  const expandedShape = backend_util_exports2.expandShapeToKeepDim(maxLogit.shape, axes);
  const maxLogitReshaped = reshape4({ inputs: { x: maxLogit }, backend: backend3, attrs: { shape: expandedShape } });
  const a = sub3({ inputs: { a: logits, b: maxLogitReshaped }, backend: backend3 });
  const b = exp3({ inputs: { x: a }, backend: backend3 });
  const sumExp = sum5({ inputs: { x: b }, backend: backend3, attrs: { axis: axes, keepDims: false } });
  const sumReshaped = reshape4({ inputs: { x: sumExp }, backend: backend3, attrs: { shape: expandedShape } });
  const result = div3({ inputs: { a: b, b: sumReshaped }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(maxLogit);
  backend3.disposeIntermediateTensorInfo(maxLogitReshaped);
  backend3.disposeIntermediateTensorInfo(a);
  backend3.disposeIntermediateTensorInfo(b);
  backend3.disposeIntermediateTensorInfo(sumExp);
  backend3.disposeIntermediateTensorInfo(sumReshaped);
  return result;
}
var softmaxConfig = {
  kernelName: Softmax2,
  backendName: "cpu",
  kernelFunc: softmax4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Multinomial.ts
function multinomial3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { logits } = inputs;
  const { numSamples, seed, normalized } = attrs;
  assertNotComplex(logits, "multinomial");
  const probabilities = normalized ? logits : softmax4({ inputs: { logits }, backend: backend3, attrs: { dim: -1 } });
  const batchSize = probabilities.shape[0];
  const numEvents = probabilities.shape[1];
  const probVals = backend3.data.get(probabilities.dataId).values;
  const resShape = [batchSize, numSamples];
  const resVals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(resShape), "int32");
  for (let b = 0; b < batchSize; ++b) {
    const offset = b * numEvents;
    const cdf = new Float32Array(numEvents - 1);
    cdf[0] = probVals[offset];
    for (let event = 1; event < cdf.length; ++event) {
      cdf[event] = cdf[event - 1] + probVals[offset + event];
    }
    const random = seedrandom5.alea(seed.toString());
    const outOffset = b * numSamples;
    for (let sampleId = 0; sampleId < numSamples; ++sampleId) {
      const r = random();
      resVals[outOffset + sampleId] = cdf.length;
      for (let event = 0; event < cdf.length; event++) {
        if (r < cdf[event]) {
          resVals[outOffset + sampleId] = event;
          break;
        }
      }
    }
  }
  if (!normalized) {
    backend3.disposeIntermediateTensorInfo(probabilities);
  }
  return backend3.makeTensorInfo(resShape, "int32", resVals);
}
var multinomialConfig = {
  kernelName: Multinomial2,
  backendName: "cpu",
  kernelFunc: multinomial3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/NonMaxSuppressionV3.ts
var nonMaxSuppressionV3Impl3 = kernel_impls_exports2.nonMaxSuppressionV3Impl;
function nonMaxSuppressionV3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
  assertNotComplex(boxes, "NonMaxSuppression");
  const boxesVals = backend3.data.get(boxes.dataId).values;
  const scoresVals = backend3.data.get(scores.dataId).values;
  const { selectedIndices } = nonMaxSuppressionV3Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  return backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
}
var nonMaxSuppressionV3Config = {
  kernelName: NonMaxSuppressionV32,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/NonMaxSuppressionV4.ts
var nonMaxSuppressionV4Impl3 = kernel_impls_exports2.nonMaxSuppressionV4Impl;
function nonMaxSuppressionV4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
  assertNotComplex(boxes, "NonMaxSuppressionPadded");
  const boxesVals = backend3.data.get(boxes.dataId).values;
  const scoresVals = backend3.data.get(scores.dataId).values;
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
  return [
    backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend3.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
  ];
}
var nonMaxSuppressionV4Config = {
  kernelName: NonMaxSuppressionV42,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/NonMaxSuppressionV5.ts
var nonMaxSuppressionV5Impl3 = kernel_impls_exports2.nonMaxSuppressionV5Impl;
function nonMaxSuppressionV5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
  assertNotComplex(boxes, "NonMaxSuppressionWithScore");
  const boxesVals = backend3.data.get(boxes.dataId).values;
  const scoresVals = backend3.data.get(scores.dataId).values;
  const maxOutputSizeVal = maxOutputSize;
  const iouThresholdVal = iouThreshold;
  const scoreThresholdVal = scoreThreshold;
  const softNmsSigmaVal = softNmsSigma;
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl3(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
  return [
    backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend3.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
  ];
}
var nonMaxSuppressionV5Config = {
  kernelName: NonMaxSuppressionV52,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/OneHot.ts
function oneHot3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { indices } = inputs;
  const { depth, onValue, offValue } = attrs;
  assertNotComplex(indices, "oneHot");
  const indicesSize = util_exports2.sizeFromShape(indices.shape);
  const res = new Float32Array(indicesSize * depth);
  res.fill(offValue);
  const indicesVal = backend3.data.get(indices.dataId).values;
  for (let event = 0; event < indicesSize; ++event) {
    if (indicesVal[event] >= 0 && indicesVal[event] < depth) {
      res[event * depth + indicesVal[event]] = onValue;
    }
  }
  return backend3.makeTensorInfo([...indices.shape, depth], "int32", res);
}
var oneHotConfig = {
  kernelName: OneHot2,
  backendName: "cpu",
  kernelFunc: oneHot3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ZerosLike.ts
function zerosLike3(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("zerosLike is not supported for string tensors");
  } else if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend3 });
    const r = zerosLike3({ inputs: { x: realPart }, backend: backend3 });
    const imagPart = imag3({ inputs: { input: x }, backend: backend3 });
    const i = zerosLike3({ inputs: { x: imagPart }, backend: backend3 });
    const result = complex3({ inputs: { real: r, imag: i }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(realPart);
    backend3.disposeIntermediateTensorInfo(r);
    backend3.disposeIntermediateTensorInfo(imagPart);
    backend3.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill3({ backend: backend3, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });
  }
}
var zerosLikeConfig = {
  kernelName: ZerosLike2,
  backendName: "cpu",
  kernelFunc: zerosLike3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/OnesLike.ts
function onesLike3(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("onesLike is not supported for string tensors");
  } else if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend3 });
    const r = onesLike3({ inputs: { x: realPart }, backend: backend3 });
    const imagPart = imag3({ inputs: { input: x }, backend: backend3 });
    const i = zerosLike3({ inputs: { x: imagPart }, backend: backend3 });
    const result = complex3({ inputs: { real: r, imag: i }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(realPart);
    backend3.disposeIntermediateTensorInfo(r);
    backend3.disposeIntermediateTensorInfo(imagPart);
    backend3.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill3({ backend: backend3, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });
  }
}
var onesLikeConfig = {
  kernelName: OnesLike2,
  backendName: "cpu",
  kernelFunc: onesLike3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Pack.ts
function pack(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims4({ inputs: { input: inputs[0] }, backend: backend3, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t) => {
    util_exports2.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
    util_exports2.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t) => {
    const expandedT = expandDims4({ inputs: { input: t }, backend: backend3, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat3({ inputs: expandedTensors, backend: backend3, attrs: { axis } });
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var packConfig = {
  kernelName: Pack2,
  backendName: "cpu",
  kernelFunc: pack
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/PadV2.ts
function padV2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { paddings, constantValue } = attrs;
  assertNotComplex(x, "pad");
  const outShape = paddings.map((p2, i) => p2[0] + x.shape[i] + p2[1]);
  const start = paddings.map((p2) => p2[0]);
  const xVals = backend3.data.get(x.dataId).values;
  const xSize = util_exports2.sizeFromShape(x.shape);
  const xRank = x.shape.length;
  const xStrides = util_exports2.computeStrides(x.shape);
  const resultSize = util_exports2.sizeFromShape(outShape);
  const resultRank = outShape.length;
  const resultStrides = util_exports2.computeStrides(outShape);
  const resVals = util_exports2.getTypedArrayFromDType(x.dtype, resultSize);
  if (constantValue !== 0) {
    resVals.fill(constantValue);
  }
  for (let i = 0; i < xSize; i++) {
    const coords2 = util_exports2.indexToLoc(i, xRank, xStrides);
    const outCoords = coords2.map((c, i2) => c + start[i2]);
    const outIndex = util_exports2.locToIndex(outCoords, resultRank, resultStrides);
    resVals[outIndex] = xVals[i];
  }
  const outId = backend3.write(resVals, outShape, x.dtype);
  return { dataId: outId, shape: outShape, dtype: x.dtype };
}
var padV2Config = {
  kernelName: PadV22,
  backendName: "cpu",
  kernelFunc: padV2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Pow.ts
var powImpl = createSimpleBinaryKernelImpl((a, b) => Math.pow(a, b));
var pow3 = binaryKernelFunc(Pow2, powImpl);
var powConfig = {
  kernelName: Pow2,
  backendName: "cpu",
  kernelFunc: pow3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Range.ts
function range4(args) {
  const { backend: backend3, attrs } = args;
  const { start, stop, dtype, step: step6 } = attrs;
  const values = rangeImpl(start, stop, step6, dtype);
  return backend3.makeTensorInfo([values.length], dtype, values);
}
var rangeConfig = {
  kernelName: Range2,
  backendName: "cpu",
  kernelFunc: range4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Reciprocal.ts
var reciprocal3 = unaryKernelFunc(Reciprocal2, (xi) => 1 / xi);
var reciprocalConfig = {
  kernelName: Reciprocal2,
  backendName: "cpu",
  kernelFunc: reciprocal3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ResizeBilinear.ts
function resizeBilinear3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  assertNotComplex(images, "resizeBilinear");
  const imagesStrides = util_exports2.computeStrides(images.shape);
  const [newHeight, newWidth] = size;
  const [batch, oldHeight, oldWidth, numChannels] = images.shape;
  const xValues = backend3.data.get(images.dataId).values;
  const result = new Float32Array(util_exports2.sizeFromShape([batch, newHeight, newWidth, numChannels]));
  const effectiveInputSize = [
    alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
    alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
  ];
  const effectiveOutputSize = [
    alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
    alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
  ];
  let outputIdx = 0;
  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
  for (let b = 0; b < batch; b++) {
    for (let r = 0; r < newHeight; r++) {
      let sourceFracRow;
      if (halfPixelCenters) {
        sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;
      } else {
        sourceFracRow = effectiveRowSizeRatio * r;
      }
      const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));
      const rowFrac = sourceFracRow - sourceRowFloor;
      const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));
      const topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];
      const botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];
      for (let c = 0; c < newWidth; c++) {
        let sourceFracCol;
        if (halfPixelCenters) {
          sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;
        } else {
          sourceFracCol = effectiveColSizeRatio * c;
        }
        const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));
        const colFrac = sourceFracCol - sourceColFloor;
        const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));
        const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];
        const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];
        const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];
        const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];
        for (let d = 0; d < numChannels; d++) {
          const topLeft = xValues[topLeftOffest + d];
          const bottomLeft = xValues[botLeftOffset + d];
          const topRight = xValues[topRightOffset + d];
          const bottomRight = xValues[botRightOffest + d];
          const top = topLeft + (topRight - topLeft) * colFrac;
          const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;
          const newValue = top + (bottom - top) * rowFrac;
          result[outputIdx++] = newValue;
        }
      }
    }
  }
  return backend3.makeTensorInfo([batch, newHeight, newWidth, numChannels], "float32", result);
}
var resizeBilinearConfig = {
  kernelName: ResizeBilinear2,
  backendName: "cpu",
  kernelFunc: resizeBilinear3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ResizeBilinearGrad.ts
function resizeBilinearGrad(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  assertNotComplex([dy, images], "resizeBilinearGrad");
  const imagesStrides = util_exports2.computeStrides(images.shape);
  const [batch, xHeight, xWidth, depth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const output = new Float32Array(batch * xHeight * xWidth * depth);
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const dyValues = backend3.data.get(dy.dataId).values;
  let offset = 0;
  for (let b = 0; b < batch; b++) {
    const bOffset = b * imagesStrides[0];
    for (let r = 0; r < yHeight; r++) {
      const dxR = r * heightScale;
      const topDxRIndex = Math.floor(dxR);
      const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);
      const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];
      const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];
      const dxRLerp = dxR - topDxRIndex;
      const inverseDxRLerp = 1 - dxRLerp;
      for (let c = 0; c < yWidth; c++) {
        const dxC = c * widthScale;
        const leftDxCIndex = Math.floor(dxC);
        const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);
        const dxCLerp = dxC - leftDxCIndex;
        const inverseDxCLerp = 1 - dxCLerp;
        const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];
        const topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];
        const bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];
        const bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];
        const inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;
        const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;
        const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;
        const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;
        for (let d = 0; d < depth; d++) {
          const dyVal = dyValues[offset++];
          output[topLeftRCOffset + d] += dyVal * inverseDxRLerpTimesInverseDxCLerp;
          output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;
          output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;
          output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;
        }
      }
    }
  }
  return backend3.makeTensorInfo([batch, xWidth, xHeight, depth], "float32", output);
}
var resizeBilinearGradConfig2 = {
  kernelName: ResizeBilinearGrad2,
  backendName: "cpu",
  kernelFunc: resizeBilinearGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ResizeNearestNeighbor.ts
function resizeNearestNeighbor3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  assertNotComplex(images, "resizeNearestNeighbor");
  const imagesStrides = util_exports2.computeStrides(images.shape);
  const [newHeight, newWidth] = size;
  const [batch, oldHeight, oldWidth, numChannels] = images.shape;
  const xValues = backend3.data.get(images.dataId).values;
  const output = new Float32Array(batch * newHeight * newWidth * numChannels);
  const effectiveInputSize = [
    alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
    alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
  ];
  const effectiveOutputSize = [
    alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
    alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
  ];
  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
  let outputOffset = 0;
  for (let b = 0; b < batch; b++) {
    const batchOffset = b * imagesStrides[0];
    for (let r = 0; r < newHeight; r++) {
      const sourceFracRow = halfPixelCenters ? effectiveRowSizeRatio * (r + 0.5) : effectiveRowSizeRatio * r;
      let sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
      if (halfPixelCenters) {
        sourceNearestRow = Math.max(0, sourceNearestRow);
      }
      const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];
      for (let c = 0; c < newWidth; c++) {
        const sourceFracCol = halfPixelCenters ? effectiveColSizeRatio * (c + 0.5) : effectiveColSizeRatio * c;
        let sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
        if (halfPixelCenters) {
          sourceNearestCol = Math.max(0, sourceNearestCol);
        }
        const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];
        for (let d = 0; d < numChannels; d++) {
          const newVal = xValues[colOffset + d];
          output[outputOffset++] = newVal;
        }
      }
    }
  }
  return backend3.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);
}
var resizeNearestNeighborConfig = {
  kernelName: ResizeNearestNeighbor2,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighbor3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ResizeNearestNeighborGrad.ts
function resizeNearestNeighborGrad(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  assertNotComplex([dy, images], "resizeNearestNeighborGrad");
  const imagesStrides = util_exports2.computeStrides(images.shape);
  const dyStrides = util_exports2.computeStrides(dy.shape);
  const [batch, xHeight, xWidth, depth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const output = new Float32Array(batch * xHeight * xWidth * depth);
  const dyValues = backend3.data.get(dy.dataId).values;
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const invHeightScale = 1 / heightScale;
  const invWidthScale = 1 / widthScale;
  const winHeight = Math.ceil(invHeightScale) * 2 + 2;
  const winWidth = Math.ceil(invWidthScale) * 2 + 2;
  for (let b = 0; b < batch; b++) {
    const batchOffset = b * imagesStrides[0];
    for (let r = 0; r < xHeight; r++) {
      const rowOffset = batchOffset + r * imagesStrides[1];
      const startRLerp = Math.floor(r * invHeightScale);
      const startDyR = Math.floor(startRLerp - winHeight / 2);
      for (let c = 0; c < xWidth; c++) {
        const colOffset = rowOffset + c * imagesStrides[2];
        const startCLerp = Math.floor(c * invWidthScale);
        const startDyC = Math.floor(startCLerp - winWidth / 2);
        for (let d = 0; d < depth; d++) {
          let accum = 0;
          for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {
            const dyR = dyRIndex + startDyR;
            if (dyR < 0 || dyR >= yHeight) {
              continue;
            }
            const dyROffset = batchOffset + dyR * dyStrides[1];
            const sourceFracRow = dyR * heightScale;
            const sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
            if (r !== sourceNearestRow) {
              continue;
            }
            for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {
              const dyC = dyCIndex + startDyC;
              if (dyC < 0 || dyC >= yWidth) {
                continue;
              }
              const dyCOffset = dyROffset + dyC * dyStrides[2];
              const sourceFracCol = dyC * widthScale;
              const sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
              if (c === sourceNearestCol) {
                accum += dyValues[dyCOffset + d];
              }
            }
          }
          output[colOffset + d] = accum;
        }
      }
    }
  }
  return backend3.makeTensorInfo(images.shape, images.dtype, output);
}
var resizeNearestNeighborGradConfig2 = {
  kernelName: ResizeNearestNeighborGrad2,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighborGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Reverse.ts
function reverse3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  assertNotComplex(x, "reverse");
  const xRank = x.shape.length;
  const $dims = util_exports2.parseAxisParam(dims, x.shape);
  if (xRank === 0) {
    return identity2({ inputs: { x }, backend: backend3 });
  }
  const outBuf = new TensorBuffer2(x.shape, x.dtype);
  const xBuf = backend3.bufferSync(x);
  for (let i = 0; i < outBuf.size; i++) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.slice();
    $dims.forEach((d) => inLoc[d] = x.shape[d] - 1 - inLoc[d]);
    outBuf.set(xBuf.get(...inLoc), ...outLoc);
  }
  return backend3.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var reverseConfig = {
  kernelName: Reverse2,
  backendName: "cpu",
  kernelFunc: reverse3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/RotateWithOffset.ts
var rotateWithOffsetConfig = {
  kernelName: RotateWithOffset2,
  backendName: "cpu",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { image: image4 } = inputs;
    const { radians, fillValue, center } = attrs;
    const cpuBackend = backend3;
    const output = util_exports2.getTypedArrayFromDType(image4.dtype, util_exports2.sizeFromShape(image4.shape));
    const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
    const [centerX, centerY] = backend_util_exports2.getImageCenter(center, imageHeight, imageWidth);
    const fullOpacityValue = 255;
    const sinFactor = Math.sin(radians);
    const cosFactor = Math.cos(radians);
    const imageVals = cpuBackend.data.get(image4.dataId).values;
    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
      for (let row = 0; row < imageHeight; row++) {
        const rowOffset = row * (imageWidth * numChannels);
        for (let col = 0; col < imageWidth; col++) {
          const colOffset = col * numChannels;
          for (let channel = 0; channel < numChannels; channel++) {
            const coords2 = [batch, row, col, channel];
            const x = coords2[2];
            const y = coords2[1];
            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;
            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;
            coordX = Math.round(coordX + centerX);
            coordY = Math.round(coordY + centerY);
            let outputValue = fillValue;
            if (typeof fillValue !== "number") {
              if (channel === 3) {
                outputValue = fullOpacityValue;
              } else {
                outputValue = fillValue[channel];
              }
            }
            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 && coordY < imageHeight) {
              const rotatedRowOffset = coordY * (imageWidth * numChannels);
              const rotatedColOffset = coordX * numChannels;
              const imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;
              outputValue = imageVals[imageIdx];
            }
            const outIdx = batchOffset + rowOffset + colOffset + channel;
            output[outIdx] = outputValue;
          }
        }
      }
    }
    const dataId = cpuBackend.write(output, image4.shape, image4.dtype);
    return { dataId, shape: image4.shape, dtype: image4.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Round.ts
var round5 = unaryKernelFunc(Round2, (xi) => {
  const base3 = Math.floor(xi);
  if (xi - base3 < 0.5) {
    return Math.floor(xi);
  } else if (xi - base3 > 0.5) {
    return Math.ceil(xi);
  } else {
    if (base3 % 2 === 0) {
      return base3;
    } else {
      return base3 + 1;
    }
  }
});
var roundConfig = {
  kernelName: Round2,
  backendName: "cpu",
  kernelFunc: round5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Scatter_impl.ts
function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
  const flattenShape = [outputSize / sliceSize, sliceSize];
  const indicesData = indices.values;
  const updatesData = updates.values;
  if (outputSize === 0) {
    return buffer2(shape, updates.dtype);
  }
  const outBuf = buffer2(flattenShape, updates.dtype);
  outBuf.values.fill(defaultValue);
  for (let i = 0; i < numUpdates; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      index.push(dim);
      flattenIndex += dim * strides[j];
    }
    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      if (sumDupeIndices) {
        outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
      } else {
        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
      }
    }
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/ScatterNd.ts
function scatterNd(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports2.calculateShapes(updates, indices, shape);
  const sumDupeIndices = true;
  const indicesBuf = backend3.bufferSync(indices);
  const updatesBuf = backend3.bufferSync(updates);
  const outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0, sumDupeIndices);
  return backend3.makeTensorInfo(shape, outBuf.dtype, outBuf.values);
}
var scatterNdConfig = {
  kernelName: ScatterNd2,
  backendName: "cpu",
  kernelFunc: scatterNd
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Select.ts
function select(args) {
  const { inputs, backend: backend3 } = args;
  const { condition, t, e } = inputs;
  assertNotComplex([condition, t, e], "select");
  const conditionRank = condition.shape.length;
  const values = backend3.data.get(condition.dataId).values;
  const tValues = backend3.data.get(t.dataId).values;
  const eValues = backend3.data.get(e.dataId).values;
  const resultDtype = upcastType2(t.dtype, e.dtype);
  const newValues = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(t.shape), resultDtype);
  let index = 0;
  const offset = conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ? 1 : util_exports2.sizeFromShape(t.shape.slice(1));
  for (let i = 0; i < values.length; i++) {
    for (let j = 0; j < offset; j++) {
      if (values[i] === 1) {
        newValues[index++] = tValues[i];
      } else {
        newValues[index++] = eValues[i];
      }
    }
  }
  return backend3.makeTensorInfo(t.shape, resultDtype, newValues);
}
var selectConfig = {
  kernelName: Select2,
  backendName: "cpu",
  kernelFunc: select
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Selu.ts
var scaleAlpha = backend_util_exports2.SELU_SCALEALPHA;
var scale = backend_util_exports2.SELU_SCALE;
var selu3 = unaryKernelFunc(Selu2, (xi) => {
  if (xi >= 0) {
    return scale * xi;
  } else {
    return scaleAlpha * (Math.exp(xi) - 1);
  }
});
var seluConfig = {
  kernelName: Selu2,
  backendName: "cpu",
  kernelFunc: selu3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sign.ts
var sign3 = unaryKernelFunc(Sign2, (xi) => {
  if (xi < 0) {
    return -1;
  } else if (xi > 0) {
    return 1;
  } else {
    return 0;
  }
});
var signConfig = {
  kernelName: Sign2,
  backendName: "cpu",
  kernelFunc: sign3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sin.ts
var sin3 = unaryKernelFunc(Sin2, (xi) => Math.sin(xi));
var sinConfig = {
  kernelName: Sin2,
  backendName: "cpu",
  kernelFunc: sin3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sinh.ts
var sinh3 = unaryKernelFunc(Sinh2, (xi) => Math.sinh(xi));
var sinhConfig = {
  kernelName: Sinh2,
  backendName: "cpu",
  kernelFunc: sinh3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Softplus.ts
var epsilon2 = 11920928955078125e-23;
var threshold3 = Math.log(epsilon2) + 2;
var softplus3 = unaryKernelFunc(Softplus2, (xi) => {
  const tooLarge = xi > -threshold3;
  const tooSmall = xi < threshold3;
  const expX = Math.exp(xi);
  let result;
  if (tooSmall) {
    result = expX;
  } else if (tooLarge) {
    result = xi;
  } else {
    result = Math.log(1 + expX);
  }
  return result;
});
var softplusConfig = {
  kernelName: Softplus2,
  backendName: "cpu",
  kernelFunc: softplus3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SpaceToBatchND.ts
function spaceToBatchND3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockShape, paddings } = attrs;
  assertNotComplex([x], "spaceToBatchND");
  const prod6 = util_exports2.sizeFromShape(blockShape);
  const completePaddings = [[0, 0]];
  completePaddings.push(...paddings);
  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
    completePaddings.push([0, 0]);
  }
  const paddedX = padV2Config.kernelFunc({
    inputs: { x },
    backend: backend3,
    attrs: { paddings: completePaddings, constantValue: 0 }
  });
  const reshapedPaddedShape = backend_util_exports2.getReshaped(paddedX.shape, blockShape, prod6, false);
  const permutedReshapedPaddedPermutation = backend_util_exports2.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
  const flattenShape = backend_util_exports2.getReshapedPermuted(paddedX.shape, blockShape, prod6, false);
  const reshapeInputs = { x: paddedX };
  const reshapeAttrs = { shape: reshapedPaddedShape };
  const paddedXReshaped = reshape4({ inputs: reshapeInputs, backend: backend3, attrs: reshapeAttrs });
  const transposeInputs = { x: paddedXReshaped };
  const transposeAttrs = { perm: permutedReshapedPaddedPermutation };
  const paddedXT = transpose3({ inputs: transposeInputs, backend: backend3, attrs: transposeAttrs });
  const resultReshapeInputs = { x: paddedXT };
  const resultReshapeAttrs = { shape: flattenShape };
  const result = reshape4({ inputs: resultReshapeInputs, backend: backend3, attrs: resultReshapeAttrs });
  backend3.disposeIntermediateTensorInfo(paddedX);
  backend3.disposeIntermediateTensorInfo(paddedXReshaped);
  backend3.disposeIntermediateTensorInfo(paddedXT);
  return result;
}
var spaceToBatchNDConfig = {
  kernelName: SpaceToBatchND2,
  backendName: "cpu",
  kernelFunc: spaceToBatchND3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseFillEmptyRows.ts
function sparseFillEmptyRows3(args) {
  const { inputs, backend: backend3 } = args;
  const { indices, values, denseShape, defaultValue } = inputs;
  if (denseShape.shape.length !== 1) {
    throw new Error(`Dense shape must be a vector, saw:
        ${denseShape.shape}`);
  }
  if (indices.shape.length !== 2) {
    throw new Error(`Indices must be a matrix, saw:
        ${indices.shape}`);
  }
  if (values.shape.length !== 1) {
    throw new Error(`Values must be a vector, saw:
        ${values.shape}`);
  }
  if (defaultValue.shape.length !== 0) {
    throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
  }
  const $indices = backend3.data.get(indices.dataId).values;
  const $values = backend3.data.get(values.dataId).values;
  const $denseShape = backend3.data.get(denseShape.dataId).values;
  const $defaultValue = backend3.data.get(defaultValue.dataId).values[0];
  const [
    outputIndices,
    outputIndicesShape,
    outputValues,
    emptyRowIndicator,
    reverseIndexMap
  ] = sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
  return [
    backend3.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
    backend3.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
    backend3.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
    backend3.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
  ];
}
var sparseFillEmptyRowsConfig = {
  kernelName: SparseFillEmptyRows2,
  backendName: "cpu",
  kernelFunc: sparseFillEmptyRows3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseReshape.ts
function sparseReshape3(args) {
  const { inputs, backend: backend3 } = args;
  const { inputIndices, inputShape, newShape } = inputs;
  if (inputIndices.shape.length !== 2) {
    throw new Error(`Input indices should be a matrix but received shape
        ${inputIndices.shape}`);
  }
  if (inputShape.shape.length !== 1) {
    throw new Error(`Input shape should be a vector but received shape
        ${inputShape.shape}`);
  }
  if (newShape.shape.length !== 1) {
    throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
  }
  const $inputShape = Array.from(backend3.data.get(inputShape.dataId).values);
  const $inputIndices = backend3.data.get(inputIndices.dataId).values;
  const targetShape = Array.from(backend3.data.get(newShape.dataId).values);
  const [newIndices, indicesShape, outputShape] = sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
  return [
    backend3.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
    backend3.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
  ];
}
var sparseReshapeConfig = {
  kernelName: SparseReshape2,
  backendName: "cpu",
  kernelFunc: sparseReshape3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseSegmentMean.ts
function sparseSegmentMean3(args) {
  const { inputs, backend: backend3 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
          ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
          ${segmentIds.shape}`);
  }
  const $data = backend3.data.get(data.dataId).values;
  const $indices = backend3.data.get(indices.dataId).values;
  const $segmentIds = backend3.data.get(segmentIds.dataId).values;
  const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true);
  return backend3.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentMeanConfig = {
  kernelName: SparseSegmentMean2,
  backendName: "cpu",
  kernelFunc: sparseSegmentMean3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseSegmentSum.ts
function sparseSegmentSum3(args) {
  const { inputs, backend: backend3 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
         ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
         ${segmentIds.shape}`);
  }
  const $data = backend3.data.get(data.dataId).values;
  const $indices = backend3.data.get(indices.dataId).values;
  const $segmentIds = backend3.data.get(segmentIds.dataId).values;
  const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds);
  return backend3.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentSumConfig = {
  kernelName: SparseSegmentSum2,
  backendName: "cpu",
  kernelFunc: sparseSegmentSum3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SparseToDense.ts
function sparseToDense3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { sparseIndices, sparseValues, defaultValue } = inputs;
  const { outputShape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports2.calculateShapes(sparseValues, sparseIndices, outputShape);
  const sumDupeIndices = false;
  const indicesBuf = backend3.bufferSync(sparseIndices);
  const updatesBuf = backend3.bufferSync(sparseValues);
  const $defaultValue = backend3.data.get(defaultValue.dataId).values[0];
  const outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
  return backend3.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
}
var sparseToDenseConfig = {
  kernelName: SparseToDense2,
  backendName: "cpu",
  kernelFunc: sparseToDense3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/SplitV.ts
function splitV(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports2.prepareSplitSize(x, numOrSizeSplits, $axis);
  const begin = new Array(x.shape.length).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const sliceSize = [...size];
    sliceSize[$axis] = s;
    const sliceT = slice3({ inputs: { x }, backend: backend3, attrs: { begin, size: sliceSize } });
    begin[$axis] += s;
    return sliceT;
  });
}
var splitVConfig = {
  kernelName: SplitV2,
  backendName: "cpu",
  kernelFunc: splitV
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Sqrt.ts
var sqrt3 = unaryKernelFunc(Sqrt2, (xi) => Math.sqrt(xi));
var sqrtConfig = {
  kernelName: Sqrt2,
  backendName: "cpu",
  kernelFunc: sqrt3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Square.ts
var squareConfig = {
  kernelName: Square2,
  backendName: "cpu",
  kernelFunc: ({ inputs, backend: backend3 }) => {
    const { x } = inputs;
    const cpuBackend = backend3;
    assertNotComplex(x, "square");
    const values = cpuBackend.data.get(x.dataId).values;
    const newValues = new Float32Array(values.length);
    for (let i = 0; i < values.length; ++i) {
      const value = values[i];
      newValues[i] = value * value;
    }
    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);
    return { dataId, shape: x.shape, dtype: x.dtype };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Step.ts
var step3 = unaryKernelFunc(Step2, (xi, attrs) => {
  const stepAttrs = attrs;
  if (isNaN(xi)) {
    return NaN;
  } else {
    return xi > 0 ? 1 : stepAttrs.alpha;
  }
});
var stepConfig = {
  kernelName: Step2,
  backendName: "cpu",
  kernelFunc: step3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StridedSlice.ts
function stridedSlice3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  } = attrs;
  assertNotComplex(x, "stridedSlice");
  const { nonStrided, $begin, $strides, size, newShape, outShape } = slice_util_exports2.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  const $x = reshape4({ inputs: { x }, backend: backend3, attrs: { shape: newShape } });
  let result;
  if (nonStrided) {
    const sliced = slice3({ inputs: { x: $x }, backend: backend3, attrs: { begin: $begin, size } });
    result = reshape4({ inputs: { x: sliced }, backend: backend3, attrs: { shape: outShape } });
    backend3.disposeIntermediateTensorInfo(sliced);
  } else if (outShape.some((axis) => axis === 0)) {
    result = backend3.makeTensorInfo(outShape, x.dtype, []);
  } else {
    const xBuf = backend3.bufferSync($x);
    const outBuf = stridedSliceImpl(outShape, xBuf, $strides, $begin);
    result = backend3.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  const resultReshaped = reshape4({ inputs: { x: result }, backend: backend3, attrs: { shape: outShape } });
  backend3.disposeIntermediateTensorInfo($x);
  backend3.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var stridedSliceConfig = {
  kernelName: StridedSlice2,
  backendName: "cpu",
  kernelFunc: stridedSlice3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringNGrams.ts
function stringNGrams3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const {
    separator,
    nGramWidths,
    leftPad,
    rightPad: rightPad3,
    padWidth,
    preserveShortSequences
  } = attrs;
  const { data, dataSplits } = inputs;
  const $data = backend3.data.get(data.dataId).values;
  const $dataSplits = backend3.data.get(dataSplits.dataId).values;
  const [nGrams, nGramsSplits] = stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences);
  return [
    backend3.makeTensorInfo([nGrams.length], "string", nGrams),
    backend3.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
  ];
}
var stringNGramsConfig = {
  kernelName: StringNGrams2,
  backendName: "cpu",
  kernelFunc: stringNGrams3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringSplit.ts
function stringSplit3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { skipEmpty } = attrs;
  const { input: input2, delimiter } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (input2.shape.length !== 1) {
    throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
  }
  if (delimiter.shape.length !== 0) {
    throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
  }
  const $input = backend3.data.get(input2.dataId).values;
  const $delimiter = backend3.data.get(delimiter.dataId).values[0];
  const [indices, values, shape] = stringSplitImpl($input, $delimiter, skipEmpty);
  const outputSize = values.length;
  return [
    backend3.makeTensorInfo([outputSize, 2], "int32", indices),
    backend3.makeTensorInfo([outputSize], "string", values),
    backend3.makeTensorInfo([2], "int32", new Int32Array(shape))
  ];
}
var stringSplitConfig = {
  kernelName: StringSplit2,
  backendName: "cpu",
  kernelFunc: stringSplit3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/StringToHashBucketFast.ts
function stringToHashBucketFast3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { numBuckets } = attrs;
  const { input: input2 } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const $input = backend3.data.get(input2.dataId).values;
  const output = stringToHashBucketFastImpl($input, numBuckets);
  return backend3.makeTensorInfo(input2.shape, "int32", output);
}
var stringToHashBucketFastConfig = {
  kernelName: StringToHashBucketFast2,
  backendName: "cpu",
  kernelFunc: stringToHashBucketFast3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Tan.ts
var tan3 = unaryKernelFunc(Tan2, (xi) => Math.tan(xi));
var tanConfig = {
  kernelName: Tan2,
  backendName: "cpu",
  kernelFunc: tan3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Tanh.ts
var tanh5 = unaryKernelFunc(Tanh2, (xi) => Math.tanh(xi));
var tanhConfig = {
  kernelName: Tanh2,
  backendName: "cpu",
  kernelFunc: tanh5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Tile.ts
function tile4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { reps } = attrs;
  assertNotComplex(x, "tile");
  const outBuf = tileImpl(backend3.bufferSync(x), reps);
  return backend3.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var tileConfig = {
  kernelName: Tile2,
  backendName: "cpu",
  kernelFunc: tile4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/TopK.ts
function topK(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { k, sorted } = attrs;
  assertNotComplex(x, "topk");
  const xVals = backend3.data.get(x.dataId).values;
  const [allTopKVals, allTopKIndices] = topKImpl(xVals, x.shape, x.dtype, k, sorted);
  return [
    backend3.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
    backend3.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
  ];
}
var topKConfig = {
  kernelName: TopK2,
  backendName: "cpu",
  kernelFunc: topK
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Transform.ts
function transform3(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { image: image4, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [batch, outHeight, outWidth, numChannels];
  const strides = util_exports2.computeStrides(image4.shape);
  const batchStride = strides[0];
  const rowStride = strides[1];
  const colStride = strides[2];
  const outVals = util_exports2.getTypedArrayFromDType(image4.dtype, util_exports2.sizeFromShape(outShape));
  outVals.fill(fillValue);
  const imageVals = backend3.data.get(image4.dataId).values;
  const transformVals = backend3.data.get(transforms.dataId).values;
  for (let b = 0; b < batch; ++b) {
    const transform6 = transforms.shape[0] === 1 ? transformVals : transformVals.subarray(b * 8, b * 8 + 8);
    for (let outY = 0; outY < outHeight; ++outY) {
      for (let outX = 0; outX < outWidth; ++outX) {
        for (let channel = 0; channel < numChannels; ++channel) {
          let val;
          const projection = transform6[6] * outX + transform6[7] * outY + 1;
          if (projection === 0) {
            continue;
          }
          const inX = (transform6[0] * outX + transform6[1] * outY + transform6[2]) / projection;
          const inY = (transform6[3] * outX + transform6[4] * outY + transform6[5]) / projection;
          const x = mapCoord(inX, imageWidth, fillMode);
          const y = mapCoord(inY, imageHeight, fillMode);
          switch (interpolation) {
            case "nearest":
              val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);
              break;
            case "bilinear":
              val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, b, y, x, channel, fillValue);
              break;
            default:
              throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${interpolation}`);
          }
          const ind = b * batchStride + outY * rowStride + outX * colStride + channel;
          outVals[ind] = val;
        }
      }
    }
    return backend3.makeTensorInfo(outShape, image4.dtype, outVals);
  }
  const dataId = backend3.write(outVals, outShape, image4.dtype);
  return { dataId, shape: image4.shape, dtype: image4.dtype };
}
var transformConfig = {
  kernelName: Transform2,
  backendName: "cpu",
  kernelFunc: transform3
};
function mapCoord(outCoord, len, mode) {
  switch (mode) {
    case "reflect":
      return mapCoordReflect(outCoord, len);
    case "wrap":
      return mapCoordWrap(outCoord, len);
    case "nearest":
      return mapCoordNearest(outCoord, len);
    case "constant":
    default:
      return mapCoordConstant(outCoord, len);
  }
}
function mapCoordReflect(outCoord, len) {
  let inCoord = outCoord;
  if (inCoord < 0) {
    if (len <= 1) {
      inCoord = 0;
    } else {
      const sz2 = 2 * len;
      if (inCoord < sz2) {
        inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;
      }
      inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;
    }
  } else if (inCoord > len - 1) {
    if (len <= 1) {
      inCoord = 0;
    } else {
      const sz2 = 2 * len;
      inCoord -= sz2 * Math.trunc(inCoord / sz2);
      if (inCoord >= len) {
        inCoord = sz2 - inCoord - 1;
      }
    }
  }
  return util_exports2.clamp(0, inCoord, len - 1);
}
function mapCoordWrap(outCoord, len) {
  let inCoord = outCoord;
  if (inCoord < 0) {
    if (len <= 1) {
      inCoord = 0;
    } else {
      const sz = len - 1;
      inCoord += len * (Math.trunc(-inCoord / sz) + 1);
    }
  } else if (inCoord > len - 1) {
    if (len <= 1) {
      inCoord = 0;
    } else {
      const sz = len - 1;
      inCoord -= len * Math.trunc(inCoord / sz);
    }
  }
  return util_exports2.clamp(0, inCoord, len - 1);
}
function mapCoordConstant(outCoord, len) {
  return outCoord;
}
function mapCoordNearest(outCoord, len) {
  return util_exports2.clamp(0, outCoord, len - 1);
}
function readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const ind = batch * batchStride + y * rowStride + x * colStride + channel;
  if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {
    return imageVals[ind];
  } else {
    return fillValue;
  }
}
function nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const $y = Math.round(y);
  const $x = Math.round(x);
  return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);
}
function bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const yFloor = Math.floor(y);
  const xFloor = Math.floor(x);
  const yCeil = yFloor + 1;
  const xCeil = xFloor + 1;
  const valueYFloor = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);
  const valueYCeil = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);
  return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Unique.ts
function unique4(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { axis } = attrs;
  const { x } = inputs;
  assertNotComplex(x, "unique");
  const values = backend3.data.get(x.dataId).values;
  const { outputValues, outputShape, indices } = uniqueImpl(values, axis, x.shape, x.dtype);
  return [
    backend3.makeTensorInfo(outputShape, x.dtype, outputValues),
    backend3.makeTensorInfo([indices.length], "int32", indices)
  ];
}
var uniqueConfig = {
  kernelName: Unique2,
  backendName: "cpu",
  kernelFunc: unique4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/Unpack.ts
function unpack(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const valueRank = value.shape.length;
  const num = value.shape[axis];
  const outShape = new Array(valueRank - 1);
  let outIndex = 0;
  for (let i = 0; i < valueRank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = value.shape[i];
    }
  }
  const begin = new Array(valueRank).fill(0);
  const size = value.shape.slice();
  size[axis] = 1;
  const res = new Array(num);
  for (let i = 0; i < res.length; i++) {
    begin[axis] = i;
    const tempRes = slice3({ inputs: { x: value }, backend: backend3, attrs: { begin, size } });
    res[i] = reshape4({ inputs: { x: tempRes }, backend: backend3, attrs: { shape: outShape } });
    backend3.disposeIntermediateTensorInfo(tempRes);
  }
  return res;
}
var unpackConfig = {
  kernelName: Unpack2,
  backendName: "cpu",
  kernelFunc: unpack
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/kernels/UnsortedSegmentSum.ts
function unsortedSegmentSum3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, segmentIds } = inputs;
  const { numSegments } = attrs;
  assertNotComplex(x, "unsortedSegmentSum");
  const xRank = x.shape.length;
  const segmentIdsRank = segmentIds.shape.length;
  const res = [];
  const intermediates = [];
  const numIters = xRank - segmentIdsRank;
  let $segmentIds = segmentIds;
  for (let i = 0; i < numIters; ++i) {
    const expanded = expandDims4({ inputs: { input: $segmentIds }, backend: backend3, attrs: { dim: i + 1 } });
    $segmentIds = expanded;
    intermediates.push(expanded);
  }
  for (let i = 0; i < numSegments; ++i) {
    const scalarValue = util_exports2.createScalarValue(i, "int32");
    const segmentId = backend3.makeTensorInfo([], "int32", scalarValue);
    const mask = equal3({ inputs: { a: segmentId, b: $segmentIds }, backend: backend3 });
    const maskCasted = cast4({ inputs: { x: mask }, backend: backend3, attrs: { dtype: "float32" } });
    const mul3 = multiply2({ inputs: { a: maskCasted, b: x }, backend: backend3 });
    const sumTensorInfo = sum5({ inputs: { x: mul3 }, backend: backend3, attrs: { axis: 0, keepDims: false } });
    res.push(sumTensorInfo);
    intermediates.push(segmentId);
    intermediates.push(mask);
    intermediates.push(maskCasted);
    intermediates.push(mul3);
    intermediates.push(sumTensorInfo);
  }
  const result = pack({ inputs: res, backend: backend3, attrs: { axis: 0 } });
  intermediates.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var unsortedSegmentSumConfig = {
  kernelName: UnsortedSegmentSum2,
  backendName: "cpu",
  kernelFunc: unsortedSegmentSum3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/src/register_all_kernels.ts
var kernelConfigs = [
  _fusedMatMulConfig,
  absConfig,
  acosConfig,
  acoshConfig,
  addConfig,
  addNConfig,
  allConfig,
  anyConfig,
  argMaxConfig,
  argMinConfig,
  asinConfig,
  asinhConfig,
  atanConfig,
  atan2Config,
  atanhConfig,
  avgPoolConfig,
  avgPool3DConfig,
  avgPool3DGradConfig2,
  avgPoolGradConfig2,
  batchMatMulConfig,
  batchNormConfig,
  batchToSpaceNDConfig,
  bincountConfig,
  castConfig,
  ceilConfig,
  clipConfig,
  complexConfig,
  complexAbsConfig,
  concatConfig,
  conv2DBackpropFilterConfig,
  conv2DBackpropInputConfig,
  conv2DConfig,
  conv3DBackpropFilterV2Config,
  conv3DBackpropInputV2Config,
  conv3DConfig,
  cosConfig,
  coshConfig,
  cropAndResizeConfig,
  cumsumConfig,
  denseBincountConfig,
  depthToSpaceConfig,
  depthwiseConv2dNativeConfig,
  depthwiseConv2dNativeBackpropFilterConfig,
  depthwiseConv2dNativeBackpropInputConfig,
  diagConfig,
  dilation2dConfig,
  dilation2dBackpropInputConfig,
  dilation2dBackpropFilterConfig,
  realDivConfig,
  einsumConfig,
  eluConfig,
  eluGradConfig2,
  equalConfig,
  erfConfig,
  expConfig,
  expandDimsConfig,
  expm1Config,
  fftConfig,
  fillConfig,
  flipLeftRightConfig,
  floorConfig,
  floorDivConfig,
  fusedConv2DConfig,
  fusedDepthwiseConv2DConfig,
  gatherNdConfig,
  gatherV2Config,
  greaterConfig,
  greaterEqualConfig,
  identityConfig,
  ifftConfig,
  imagConfig,
  isFiniteConfig,
  isInfConfig,
  isNaNConfig,
  leakyReluConfig,
  lessConfig,
  lessEqualConfig,
  linSpaceConfig,
  logConfig,
  log1pConfig,
  logicalAndConfig,
  logicalNotConfig,
  logicalOrConfig,
  lRNConfig,
  lRNGradConfig,
  maximumConfig,
  maxPoolConfig,
  maxPool3DConfig,
  maxPool3DGradConfig2,
  maxPoolGradConfig2,
  maxPoolWithArgmaxConfig,
  maxConfig,
  meanConfig,
  minConfig,
  minimumConfig,
  mirrorPadConfig,
  modConfig,
  multinomialConfig,
  multiplyConfig,
  negConfig,
  nonMaxSuppressionV3Config,
  nonMaxSuppressionV4Config,
  nonMaxSuppressionV5Config,
  notEqualConfig,
  oneHotConfig,
  onesLikeConfig,
  packConfig,
  padV2Config,
  powConfig,
  preluConfig,
  prodConfig,
  rangeConfig,
  realConfig,
  reciprocalConfig,
  reluConfig,
  relu6Config,
  reshapeConfig,
  resizeBilinearConfig,
  resizeBilinearGradConfig2,
  resizeNearestNeighborConfig,
  resizeNearestNeighborGradConfig2,
  reverseConfig,
  rotateWithOffsetConfig,
  roundConfig,
  rsqrtConfig,
  scatterNdConfig,
  selectConfig,
  seluConfig,
  sigmoidConfig,
  signConfig,
  sinConfig,
  sinhConfig,
  sliceConfig,
  softmaxConfig,
  softplusConfig,
  spaceToBatchNDConfig,
  sparseFillEmptyRowsConfig,
  sparseReshapeConfig,
  sparseSegmentMeanConfig,
  sparseSegmentSumConfig,
  sparseToDenseConfig,
  splitVConfig,
  sqrtConfig,
  squareConfig,
  squaredDifferenceConfig,
  stepConfig,
  stridedSliceConfig,
  stringNGramsConfig,
  stringSplitConfig,
  stringToHashBucketFastConfig,
  subConfig,
  sumConfig,
  tanConfig,
  tanhConfig,
  tileConfig,
  topKConfig,
  transposeConfig,
  transformConfig,
  uniqueConfig,
  unpackConfig,
  unsortedSegmentSumConfig,
  zerosLikeConfig
];
for (const kernelConfig of kernelConfigs) {
  registerKernel2(kernelConfig);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/webgl_util.ts
var webgl_util_exports = {};
__export(webgl_util_exports, {
  assertNotComplex: () => assertNotComplex2,
  bindCanvasToFramebuffer: () => bindCanvasToFramebuffer,
  bindColorTextureToFramebuffer: () => bindColorTextureToFramebuffer,
  bindTextureToProgramUniformSampler: () => bindTextureToProgramUniformSampler,
  bindTextureUnit: () => bindTextureUnit,
  bindVertexBufferToProgramAttribute: () => bindVertexBufferToProgramAttribute,
  callAndCheck: () => callAndCheck,
  canBeRepresented: () => canBeRepresented,
  createFragmentShader: () => createFragmentShader,
  createFramebuffer: () => createFramebuffer,
  createProgram: () => createProgram,
  createStaticIndexBuffer: () => createStaticIndexBuffer,
  createStaticVertexBuffer: () => createStaticVertexBuffer,
  createTexture: () => createTexture,
  createVertexShader: () => createVertexShader,
  getBatchDim: () => getBatchDim,
  getExtensionOrThrow: () => getExtensionOrThrow,
  getFramebufferErrorMessage: () => getFramebufferErrorMessage,
  getMaxTexturesInShader: () => getMaxTexturesInShader,
  getNumChannels: () => getNumChannels,
  getProgramUniformLocation: () => getProgramUniformLocation,
  getProgramUniformLocationOrThrow: () => getProgramUniformLocationOrThrow,
  getRowsCols: () => getRowsCols,
  getShapeAs3D: () => getShapeAs3D,
  getTextureShapeFromLogicalShape: () => getTextureShapeFromLogicalShape,
  getWebGLDisjointQueryTimerVersion: () => getWebGLDisjointQueryTimerVersion,
  getWebGLErrorMessage: () => getWebGLErrorMessage,
  getWebGLMaxTextureSize: () => getWebGLMaxTextureSize,
  hasExtension: () => hasExtension,
  isCapableOfRenderingToFloatTexture: () => isCapableOfRenderingToFloatTexture,
  isDownloadFloatTextureEnabled: () => isDownloadFloatTextureEnabled,
  isReshapeFree: () => isReshapeFree,
  isWebGLFenceEnabled: () => isWebGLFenceEnabled,
  isWebGLVersionEnabled: () => isWebGLVersionEnabled,
  linkProgram: () => linkProgram,
  resetMaxTextureSize: () => resetMaxTextureSize,
  resetMaxTexturesInShader: () => resetMaxTexturesInShader,
  unbindColorTextureFromFramebuffer: () => unbindColorTextureFromFramebuffer,
  unbindTextureUnit: () => unbindTextureUnit,
  validateFramebuffer: () => validateFramebuffer,
  validateProgram: () => validateProgram,
  validateTextureSize: () => validateTextureSize
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/canvas_util.ts
var contexts = {};
var WEBGL_ATTRIBUTES = {
  alpha: false,
  antialias: false,
  premultipliedAlpha: false,
  preserveDrawingBuffer: false,
  depth: false,
  stencil: false,
  failIfMajorPerformanceCaveat: true
};
function setWebGLContext(webGLVersion, gl) {
  contexts[webGLVersion] = gl;
}
function getWebGLContext(webGLVersion) {
  if (!(webGLVersion in contexts)) {
    const newCtx = getWebGLRenderingContext(webGLVersion);
    if (newCtx !== null) {
      contexts[webGLVersion] = newCtx;
    } else {
      console.log("Could not get context for WebGL version", webGLVersion);
      return null;
    }
  }
  const gl = contexts[webGLVersion];
  if (gl.isContextLost()) {
    delete contexts[webGLVersion];
    return getWebGLContext(webGLVersion);
  }
  gl.disable(gl.DEPTH_TEST);
  gl.disable(gl.STENCIL_TEST);
  gl.disable(gl.BLEND);
  gl.disable(gl.DITHER);
  gl.disable(gl.POLYGON_OFFSET_FILL);
  gl.disable(gl.SAMPLE_COVERAGE);
  gl.enable(gl.SCISSOR_TEST);
  gl.enable(gl.CULL_FACE);
  gl.cullFace(gl.BACK);
  return contexts[webGLVersion];
}
function createCanvas(webGLVersion) {
  if (typeof OffscreenCanvas !== "undefined" && webGLVersion === 2) {
    return new OffscreenCanvas(300, 150);
  } else if (typeof document !== "undefined") {
    return document.createElement("canvas");
  } else {
    throw new Error("Cannot create a canvas in this context");
  }
}
function getWebGLRenderingContext(webGLVersion) {
  if (webGLVersion !== 1 && webGLVersion !== 2) {
    throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  }
  const canvas = createCanvas(webGLVersion);
  canvas.addEventListener("webglcontextlost", (ev) => {
    ev.preventDefault();
    delete contexts[webGLVersion];
  }, false);
  if (webGLVersion === 1) {
    return canvas.getContext("webgl", WEBGL_ATTRIBUTES) || canvas.getContext("experimental-webgl", WEBGL_ATTRIBUTES);
  }
  return canvas.getContext("webgl2", WEBGL_ATTRIBUTES);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/tex_util.ts
var PackingScheme;
(function(PackingScheme2) {
  PackingScheme2[PackingScheme2["DENSE"] = 0] = "DENSE";
  PackingScheme2[PackingScheme2["SHARED_BATCH"] = 1] = "SHARED_BATCH";
})(PackingScheme || (PackingScheme = {}));
var TextureUsage;
(function(TextureUsage2) {
  TextureUsage2[TextureUsage2["RENDER"] = 0] = "RENDER";
  TextureUsage2[TextureUsage2["UPLOAD"] = 1] = "UPLOAD";
  TextureUsage2[TextureUsage2["PIXELS"] = 2] = "PIXELS";
  TextureUsage2[TextureUsage2["DOWNLOAD"] = 3] = "DOWNLOAD";
})(TextureUsage || (TextureUsage = {}));
var PhysicalTextureType;
(function(PhysicalTextureType2) {
  PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT16"] = 0] = "UNPACKED_FLOAT16";
  PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT32"] = 1] = "UNPACKED_FLOAT32";
  PhysicalTextureType2[PhysicalTextureType2["PACKED_4X1_UNSIGNED_BYTE"] = 2] = "PACKED_4X1_UNSIGNED_BYTE";
  PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT32"] = 3] = "PACKED_2X2_FLOAT32";
  PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT16"] = 4] = "PACKED_2X2_FLOAT16";
})(PhysicalTextureType || (PhysicalTextureType = {}));
function getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {
  return [columns, rows];
}
function getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {
  return matrixSize * channelsPerTexture;
}
function getDenseTexShape(shape) {
  const size = util_exports2.sizeFromShape(shape);
  const texelsNeeded = Math.ceil(size / 4);
  return util_exports2.sizeToSquarishShape(texelsNeeded);
}
function getPackedMatrixTextureShapeWidthHeight(rows, columns) {
  return [
    Math.max(1, Math.ceil(columns / 2)),
    Math.max(1, Math.ceil(rows / 2))
  ];
}
function getPackedRGBAArraySizeFromMatrixShape(rows, columns) {
  const [w, h] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return w * h * 4;
}
function getTextureConfig(gl, textureHalfFloatExtension) {
  const glany = gl;
  let internalFormatFloat;
  let internalFormatHalfFloat;
  let internalFormatPackedHalfFloat;
  let internalFormatPackedFloat;
  let textureFormatFloat;
  let downloadTextureFormat;
  let downloadUnpackNumChannels;
  let defaultNumChannels;
  let textureTypeHalfFloat;
  let textureTypeFloat;
  if (env2().getNumber("WEBGL_VERSION") === 2) {
    internalFormatFloat = glany.R32F;
    internalFormatHalfFloat = glany.R16F;
    internalFormatPackedHalfFloat = glany.RGBA16F;
    internalFormatPackedFloat = glany.RGBA32F;
    textureFormatFloat = glany.RED;
    downloadUnpackNumChannels = 4;
    defaultNumChannels = 1;
    textureTypeHalfFloat = glany.HALF_FLOAT;
    textureTypeFloat = glany.FLOAT;
  } else {
    internalFormatFloat = gl.RGBA;
    internalFormatHalfFloat = gl.RGBA;
    internalFormatPackedHalfFloat = gl.RGBA;
    internalFormatPackedFloat = glany.RGBA;
    textureFormatFloat = gl.RGBA;
    downloadUnpackNumChannels = 4;
    defaultNumChannels = 4;
    textureTypeHalfFloat = textureHalfFloatExtension != null ? textureHalfFloatExtension.HALF_FLOAT_OES : null;
    textureTypeFloat = gl.FLOAT;
  }
  downloadTextureFormat = gl.RGBA;
  return {
    internalFormatFloat,
    internalFormatHalfFloat,
    internalFormatPackedHalfFloat,
    internalFormatPackedFloat,
    textureFormatFloat,
    downloadTextureFormat,
    downloadUnpackNumChannels,
    defaultNumChannels,
    textureTypeHalfFloat,
    textureTypeFloat
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/webgl_util.ts
function callAndCheck(gl, func2) {
  const returnValue = func2();
  if (env2().getBool("DEBUG")) {
    checkWebGLError(gl);
  }
  return returnValue;
}
function checkWebGLError(gl) {
  const error = gl.getError();
  if (error !== gl.NO_ERROR) {
    throw new Error("WebGL Error: " + getWebGLErrorMessage(gl, error));
  }
}
var MIN_FLOAT16 = 596e-10;
var MAX_FLOAT16 = 65504;
function canBeRepresented(num) {
  if (env2().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || num === 0 || MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16) {
    return true;
  }
  return false;
}
function getWebGLErrorMessage(gl, status) {
  switch (status) {
    case gl.NO_ERROR:
      return "NO_ERROR";
    case gl.INVALID_ENUM:
      return "INVALID_ENUM";
    case gl.INVALID_VALUE:
      return "INVALID_VALUE";
    case gl.INVALID_OPERATION:
      return "INVALID_OPERATION";
    case gl.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";
    case gl.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";
    case gl.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";
    default:
      return `Unknown error code ${status}`;
  }
}
function getExtensionOrThrow(gl, extensionName) {
  return throwIfNull(gl, () => gl.getExtension(extensionName), 'Extension "' + extensionName + '" not supported on this browser.');
}
function createVertexShader(gl, vertexShaderSource) {
  const vertexShader = throwIfNull(gl, () => gl.createShader(gl.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  callAndCheck(gl, () => gl.shaderSource(vertexShader, vertexShaderSource));
  callAndCheck(gl, () => gl.compileShader(vertexShader));
  if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {
    console.log(gl.getShaderInfoLog(vertexShader));
    throw new Error("Failed to compile vertex shader.");
  }
  return vertexShader;
}
function createFragmentShader(gl, fragmentShaderSource) {
  const fragmentShader = throwIfNull(gl, () => gl.createShader(gl.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  callAndCheck(gl, () => gl.shaderSource(fragmentShader, fragmentShaderSource));
  callAndCheck(gl, () => gl.compileShader(fragmentShader));
  if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {
    logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));
    throw new Error("Failed to compile fragment shader.");
  }
  return fragmentShader;
}
var lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;
function logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {
  const lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);
  if (lineNumberRegexResult == null) {
    console.log(`Couldn't parse line number in error: ${shaderInfoLog}`);
    console.log(shaderSource);
    return;
  }
  const lineNumber = +lineNumberRegexResult[1];
  const shaderLines = shaderSource.split("\n");
  const pad4 = shaderLines.length.toString().length + 2;
  const linesWithLineNumbers = shaderLines.map((line, lineNumber2) => util_exports2.rightPad((lineNumber2 + 1).toString(), pad4) + line);
  let maxLineLength = 0;
  for (let i = 0; i < linesWithLineNumbers.length; i++) {
    maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);
  }
  const beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);
  const errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);
  const afterErrorLines = linesWithLineNumbers.slice(lineNumber);
  console.log(beforeErrorLines.join("\n"));
  console.log(shaderInfoLog.split("\n")[0]);
  console.log(`%c ${util_exports2.rightPad(errorLine[0], maxLineLength)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717");
  console.log(afterErrorLines.join("\n"));
}
function createProgram(gl) {
  return throwIfNull(gl, () => gl.createProgram(), "Unable to create WebGLProgram.");
}
function linkProgram(gl, program) {
  callAndCheck(gl, () => gl.linkProgram(program));
  if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {
    console.log(gl.getProgramInfoLog(program));
    throw new Error("Failed to link vertex and fragment shaders.");
  }
}
function validateProgram(gl, program) {
  callAndCheck(gl, () => gl.validateProgram(program));
  if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {
    console.log(gl.getProgramInfoLog(program));
    throw new Error("Shader program validation failed.");
  }
}
function createStaticVertexBuffer(gl, data) {
  const buffer3 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer3));
  callAndCheck(gl, () => gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW));
  return buffer3;
}
function createStaticIndexBuffer(gl, data) {
  const buffer3 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
  callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer3));
  callAndCheck(gl, () => gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW));
  return buffer3;
}
function getNumChannels() {
  if (env2().getNumber("WEBGL_VERSION") === 2) {
    return 1;
  }
  return 4;
}
function createTexture(gl) {
  return throwIfNull(gl, () => gl.createTexture(), "Unable to create WebGLTexture.");
}
function validateTextureSize(width, height) {
  const maxTextureSize = env2().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (width <= 0 || height <= 0) {
    const requested = `[${width}x${height}]`;
    throw new Error("Requested texture size " + requested + " is invalid.");
  }
  if (width > maxTextureSize || height > maxTextureSize) {
    const requested = `[${width}x${height}]`;
    const max7 = `[${maxTextureSize}x${maxTextureSize}]`;
    throw new Error("Requested texture size " + requested + " greater than WebGL maximum on this browser / GPU " + max7 + ".");
  }
}
function createFramebuffer(gl) {
  return throwIfNull(gl, () => gl.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}
function bindVertexBufferToProgramAttribute(gl, program, attribute, buffer3, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {
  const loc = gl.getAttribLocation(program, attribute);
  if (loc === -1) {
    return false;
  }
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer3));
  callAndCheck(gl, () => gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes));
  callAndCheck(gl, () => gl.enableVertexAttribArray(loc));
  return true;
}
function bindTextureUnit(gl, texture, textureUnit) {
  validateTextureUnit(gl, textureUnit);
  callAndCheck(gl, () => gl.activeTexture(gl.TEXTURE0 + textureUnit));
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
}
function unbindTextureUnit(gl, textureUnit) {
  validateTextureUnit(gl, textureUnit);
  callAndCheck(gl, () => gl.activeTexture(gl.TEXTURE0 + textureUnit));
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
}
function getProgramUniformLocationOrThrow(gl, program, uniformName) {
  return throwIfNull(gl, () => gl.getUniformLocation(program, uniformName), 'uniform "' + uniformName + '" not present in program.');
}
function getProgramUniformLocation(gl, program, uniformName) {
  return gl.getUniformLocation(program, uniformName);
}
function bindTextureToProgramUniformSampler(gl, texture, uniformSamplerLocation, textureUnit) {
  callAndCheck(gl, () => bindTextureUnit(gl, texture, textureUnit));
  callAndCheck(gl, () => gl.uniform1i(uniformSamplerLocation, textureUnit));
}
function bindCanvasToFramebuffer(gl) {
  callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, null));
  callAndCheck(gl, () => gl.viewport(0, 0, gl.canvas.width, gl.canvas.height));
  callAndCheck(gl, () => gl.scissor(0, 0, gl.canvas.width, gl.canvas.height));
}
function bindColorTextureToFramebuffer(gl, texture, framebuffer) {
  callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
  callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0));
}
function unbindColorTextureFromFramebuffer(gl, framebuffer) {
  callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
  callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0));
}
function validateFramebuffer(gl) {
  const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
  if (status !== gl.FRAMEBUFFER_COMPLETE) {
    throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage(gl, status));
  }
}
function getFramebufferErrorMessage(gl, status) {
  switch (status) {
    case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
    case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
    case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
    case gl.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";
    default:
      return `unknown error ${status}`;
  }
}
function throwIfNull(gl, returnTOrNull, failureMessage) {
  const tOrNull = callAndCheck(gl, () => returnTOrNull());
  if (tOrNull == null) {
    throw new Error(failureMessage);
  }
  return tOrNull;
}
function validateTextureUnit(gl, textureUnit) {
  const maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;
  const glTextureUnit = textureUnit + gl.TEXTURE0;
  if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {
    const textureUnitRange = `[gl.TEXTURE0, gl.TEXTURE${maxTextureUnit}]`;
    throw new Error(`textureUnit must be in ${textureUnitRange}.`);
  }
}
function getBatchDim(shape, dimsToSkip = 2) {
  return util_exports2.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));
}
function getRowsCols(shape) {
  if (shape.length === 0) {
    throw Error("Cannot get rows and columns of an empty shape array.");
  }
  return [
    shape.length > 1 ? shape[shape.length - 2] : 1,
    shape[shape.length - 1]
  ];
}
function getShapeAs3D(shape) {
  let shapeAs3D = [1, 1, 1];
  const isScalar = shape.length === 0 || shape.length === 1 && shape[0] === 1;
  if (!isScalar) {
    shapeAs3D = [getBatchDim(shape), ...getRowsCols(shape)];
  }
  return shapeAs3D;
}
function getTextureShapeFromLogicalShape(logShape, isPacked = false) {
  let maxTexSize = env2().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (isPacked) {
    maxTexSize = maxTexSize * 2;
    logShape = logShape.map((d, i) => i >= logShape.length - 2 ? util_exports2.nearestLargerEven(logShape[i]) : logShape[i]);
    if (logShape.length === 1) {
      logShape = [2, logShape[0]];
    }
  }
  if (logShape.length !== 2) {
    const squeezeResult = util_exports2.squeezeShape(logShape);
    logShape = squeezeResult.newShape;
  }
  let size = util_exports2.sizeFromShape(logShape);
  if (logShape.length <= 1 && size <= maxTexSize) {
    return [1, size];
  } else if (logShape.length === 2 && logShape[0] <= maxTexSize && logShape[1] <= maxTexSize) {
    return logShape;
  } else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize && logShape[2] <= maxTexSize) {
    return [logShape[0] * logShape[1], logShape[2]];
  } else if (logShape.length === 3 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] <= maxTexSize) {
    return [logShape[0], logShape[1] * logShape[2]];
  } else if (logShape.length === 4 && logShape[0] * logShape[1] * logShape[2] <= maxTexSize && logShape[3] <= maxTexSize) {
    return [logShape[0] * logShape[1] * logShape[2], logShape[3]];
  } else if (logShape.length === 4 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {
    return [logShape[0], logShape[1] * logShape[2] * logShape[3]];
  } else {
    if (isPacked) {
      const batchDim = getBatchDim(logShape);
      let rows = 2, cols = 2;
      if (logShape.length) {
        [rows, cols] = getRowsCols(logShape);
      }
      size = batchDim * (rows / 2) * (cols / 2);
      return util_exports2.sizeToSquarishShape(size).map((d) => d * 2);
    }
    return util_exports2.sizeToSquarishShape(size);
  }
}
function isEven(n) {
  return n % 2 === 0;
}
function isReshapeFree(shape1, shape2) {
  shape1 = shape1.slice(-2);
  shape2 = shape2.slice(-2);
  if (util_exports2.arraysEqual(shape1, shape2)) {
    return true;
  }
  if (!shape1.length || !shape2.length) {
    return true;
  }
  if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 || shape2[1] === 0) {
    return true;
  }
  if (shape1.length !== shape2.length) {
    const shape1Cols = shape1.slice(-1)[0];
    const shape2Cols = shape2.slice(-1)[0];
    if (shape1Cols === shape2Cols) {
      return true;
    }
    if (isEven(shape1Cols) && isEven(shape2Cols) && (shape1[0] === 1 || shape2[0] === 1)) {
      return true;
    }
  }
  return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);
}
var MAX_TEXTURE_SIZE;
var MAX_TEXTURES_IN_SHADER;
function getWebGLMaxTextureSize(webGLVersion) {
  if (MAX_TEXTURE_SIZE == null) {
    const gl = getWebGLContext(webGLVersion);
    MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);
  }
  return MAX_TEXTURE_SIZE;
}
function resetMaxTextureSize() {
  MAX_TEXTURE_SIZE = null;
}
function resetMaxTexturesInShader() {
  MAX_TEXTURES_IN_SHADER = null;
}
function getMaxTexturesInShader(webGLVersion) {
  if (MAX_TEXTURES_IN_SHADER == null) {
    const gl = getWebGLContext(webGLVersion);
    MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
  }
  return Math.min(16, MAX_TEXTURES_IN_SHADER);
}
function getWebGLDisjointQueryTimerVersion(webGLVersion) {
  if (webGLVersion === 0) {
    return 0;
  }
  let queryTimerVersion;
  const gl = getWebGLContext(webGLVersion);
  if (hasExtension(gl, "EXT_disjoint_timer_query_webgl2") && webGLVersion === 2) {
    queryTimerVersion = 2;
  } else if (hasExtension(gl, "EXT_disjoint_timer_query")) {
    queryTimerVersion = 1;
  } else {
    queryTimerVersion = 0;
  }
  return queryTimerVersion;
}
function hasExtension(gl, extensionName) {
  const ext = gl.getExtension(extensionName);
  return ext != null;
}
function isWebGLVersionEnabled(webGLVersion) {
  try {
    const gl = getWebGLContext(webGLVersion);
    if (gl != null) {
      return true;
    }
  } catch (e) {
    console.log("Error when getting WebGL context: ", e);
    return false;
  }
  return false;
}
function isCapableOfRenderingToFloatTexture(webGLVersion) {
  if (webGLVersion === 0) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  if (webGLVersion === 1) {
    if (!hasExtension(gl, "OES_texture_float")) {
      return false;
    }
  } else {
    if (!hasExtension(gl, "EXT_color_buffer_float")) {
      return false;
    }
  }
  const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
  return isFrameBufferComplete;
}
function isDownloadFloatTextureEnabled(webGLVersion) {
  if (webGLVersion === 0) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  if (webGLVersion === 1) {
    if (!hasExtension(gl, "OES_texture_float")) {
      return false;
    }
    if (!hasExtension(gl, "WEBGL_color_buffer_float")) {
      return false;
    }
  } else {
    if (hasExtension(gl, "EXT_color_buffer_float")) {
      return createFloatTextureAndBindToFramebuffer(gl);
    }
    const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
    if (hasExtension(gl, COLOR_BUFFER_HALF_FLOAT)) {
      const textureHalfFloatExtension = gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
      return createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension);
    }
    return false;
  }
  const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
  return isFrameBufferComplete;
}
function createFloatTextureAndBindToFramebuffer(gl) {
  const texConfig = getTextureConfig(gl);
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);
  const width = 1;
  const height = 1;
  gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeFloat, null);
  const frameBuffer = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
  const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
  gl.bindTexture(gl.TEXTURE_2D, null);
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.deleteTexture(texture);
  gl.deleteFramebuffer(frameBuffer);
  return isFrameBufferComplete;
}
function createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension) {
  const texConfig = getTextureConfig(gl, textureHalfFloatExtension);
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);
  const width = 1;
  const height = 1;
  gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatHalfFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeHalfFloat, null);
  const frameBuffer = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
  const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
  gl.bindTexture(gl.TEXTURE_2D, null);
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.deleteTexture(texture);
  gl.deleteFramebuffer(frameBuffer);
  return isFrameBufferComplete;
}
function isWebGLFenceEnabled(webGLVersion) {
  if (webGLVersion !== 2) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  const isEnabled = gl.fenceSync != null;
  return isEnabled;
}
function assertNotComplex2(tensor3, opName) {
  if (!Array.isArray(tensor3)) {
    tensor3 = [tensor3];
  }
  tensor3.forEach((t) => {
    if (t != null) {
      util_exports2.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the WebGL backend.`);
    }
  });
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/flags_webgl.ts
var ENV5 = env2();
ENV5.registerFlag("HAS_WEBGL", () => ENV5.getNumber("WEBGL_VERSION") > 0);
ENV5.registerFlag("WEBGL_VERSION", () => {
  if (isWebGLVersionEnabled(2)) {
    return 2;
  } else if (isWebGLVersionEnabled(1)) {
    return 1;
  }
  return 0;
});
ENV5.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
ENV5.registerFlag("WEBGL_BUFFER_SUPPORTED", () => ENV5.get("WEBGL_VERSION") === 2);
ENV5.registerFlag("WEBGL_CPU_FORWARD", () => true);
ENV5.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
ENV5.registerFlag("WEBGL_PACK", () => ENV5.getBool("HAS_WEBGL"));
ENV5.registerFlag("WEBGL_PACK_NORMALIZATION", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_CLIP", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_PACK_REDUCE", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_LAZILY_UNPACK", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_CONV_IM2COL", () => ENV5.getBool("WEBGL_PACK"));
ENV5.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => getWebGLMaxTextureSize(ENV5.getNumber("WEBGL_VERSION")));
ENV5.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => getMaxTexturesInShader(ENV5.getNumber("WEBGL_VERSION")));
ENV5.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  const webGLVersion = ENV5.getNumber("WEBGL_VERSION");
  if (webGLVersion === 0) {
    return 0;
  }
  return getWebGLDisjointQueryTimerVersion(webGLVersion);
});
ENV5.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ENV5.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !device_util_exports2.isMobile());
ENV5.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => isCapableOfRenderingToFloatTexture(ENV5.getNumber("WEBGL_VERSION")));
ENV5.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => {
  return ENV5.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ENV5.getBool("WEBGL_RENDER_FLOAT32_CAPABLE");
});
ENV5.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => isDownloadFloatTextureEnabled(ENV5.getNumber("WEBGL_VERSION")));
ENV5.registerFlag("WEBGL_FENCE_API_ENABLED", () => isWebGLFenceEnabled(ENV5.getNumber("WEBGL_VERSION")));
ENV5.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => {
  const useUniforms = ENV5.getBool("WEBGL_RENDER_FLOAT32_ENABLED");
  return useUniforms ? 4 : 0;
});
ENV5.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => {
  return -1;
}, (threshold4) => {
  if (threshold4 < 0 && threshold4 !== -1) {
    throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${threshold4}.`);
  }
});
ENV5.registerFlag("WEBGL_FLUSH_THRESHOLD", () => {
  return device_util_exports2.isMobile() && ENV5.getBool("IS_CHROME") ? 1 : -1;
}, (threshold4) => {
  if (threshold4 < 0 && threshold4 !== -1) {
    throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${threshold4}.`);
  }
});
ENV5.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/glsl_version.ts
function getGlslDifferences() {
  let version18;
  let attribute;
  let varyingVs;
  let varyingFs;
  let texture2D;
  let output;
  let defineOutput;
  let defineSpecialNaN;
  let defineSpecialInf;
  let defineRound;
  if (env2().getNumber("WEBGL_VERSION") === 2) {
    version18 = "#version 300 es";
    attribute = "in";
    varyingVs = "out";
    varyingFs = "in";
    texture2D = "texture";
    output = "outputColor";
    defineOutput = "out vec4 outputColor;";
    defineSpecialNaN = `
      bool isnan_custom(float val) {
        return (val > 0.0 || val < 0.0) ? false : val != 0.0;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    `;
    defineSpecialInf = ``;
    defineRound = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
  } else {
    version18 = "";
    attribute = "attribute";
    varyingVs = "varying";
    varyingFs = "varying";
    texture2D = "texture2D";
    output = "gl_FragColor";
    defineOutput = "";
    defineSpecialNaN = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `;
    defineSpecialInf = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `;
    defineRound = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
  }
  return {
    version: version18,
    attribute,
    varyingVs,
    varyingFs,
    texture2D,
    output,
    defineOutput,
    defineSpecialNaN,
    defineSpecialInf,
    defineRound
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/shader_compiler_util.ts
function getLogicalCoordinatesFromFlatIndex(coords2, shape, index = "index") {
  const strides = util_exports2.computeStrides(shape);
  return strides.map((stride, i) => {
    const line1 = `int ${coords2[i]} = ${index} / ${stride}`;
    const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * ${stride}` : `index -= ${coords2[i]} * ${stride}`;
    return `${line1}; ${line2};`;
  }).join("");
}
function getFlatIndexFrom3D(shape) {
  const strides = util_exports2.computeStrides(shape).map((d) => d.toString());
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${strides[0]} + coords.y * ${strides[1]} + coords.z;
  }
`;
}
var ENCODE_FLOAT_SNIPPET = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/decode_matrix_gpu.ts
var DecodeMatrixProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = false;
    this.packedOutput = true;
    this.outPackingScheme = PackingScheme.DENSE;
    const texShape = getDenseTexShape(outputShape);
    const glsl = getGlslDifferences();
    this.outputShape = outputShape;
    this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx *
          vec2(${texShape[0]}, ${texShape[1]}));
        int index = 4 * (resTexRC.x * ${texShape[1]} + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${glsl.output} = result;
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/decode_matrix_packed_gpu.ts
var DecodeMatrixPackedProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outPackingScheme = PackingScheme.DENSE;
    const texShape = getDenseTexShape(outputShape);
    const glsl = getGlslDifferences();
    this.outputShape = outputShape;
    this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx *
          vec2(${texShape[0]}, ${texShape[1]}));
        int index = 4 * (resTexRC.x * ${texShape[1]} + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${glsl.output} = result;
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/encode_float_gpu.ts
var EncodeFloatProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.outTexUsage = TextureUsage.DOWNLOAD;
    const glsl = getGlslDifferences();
    this.outputShape = outputShape;
    this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        float x = getAAtOutCoords();
        ${glsl.output} = encode_float(x);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/encode_float_packed_gpu.ts
var EncodeFloatPackedProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = false;
    this.outTexUsage = TextureUsage.DOWNLOAD;
    const glsl = getGlslDifferences();
    this.outputShape = outputShape;
    this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${glsl.output} = encode_float(x);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/encode_matrix_gpu.ts
var EncodeMatrixProgram = class {
  constructor(outputShape, texShape, inputIsUnsignedByte = false) {
    this.variableNames = ["A"];
    const glsl = getGlslDifferences();
    const [height, width] = texShape;
    this.outputShape = outputShape;
    let output = `result`;
    if (inputIsUnsignedByte) {
      output = `floor(result * 255. + 0.5)`;
    }
    this.userCode = `
      ${getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 coords = getOutputCoords();

        int flatIndex = getFlatIndex(coords);
        int offset = imod(flatIndex, 4);

        flatIndex = idiv(flatIndex, 4, 1.);

        int r = flatIndex / ${width};
        int c = imod(flatIndex, ${width});
        vec2 uv = (vec2(c, r) + halfCR) / vec2(${width}.0, ${height}.0);
        vec4 values = ${glsl.texture2D}(A, uv);

        float result;

        if(offset == 0) {
          result = values[0];
        } else if(offset == 1) {
          result = values[1];
        } else if(offset == 2) {
          result = values[2];
        } else {
          result = values[3];
        }

        ${glsl.output} = vec4(${output}, 0., 0., 0.);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/encode_matrix_packed_gpu.ts
var EncodeMatrixPackedProgram = class {
  constructor(outputShape, texShape, inputIsUnsignedByte = false) {
    this.variableNames = ["A"];
    this.packedInputs = false;
    this.packedOutput = true;
    const glsl = getGlslDifferences();
    const [height, width] = texShape;
    this.outputShape = outputShape;
    let mainLoop = "";
    let output = "result";
    if (inputIsUnsignedByte) {
      output = "floor(result * 255. + 0.5)";
    }
    for (let row = 0; row <= 1; row++) {
      for (let col = 0; col <= 1; col++) {
        const channel = row * 2 + col;
        mainLoop += `
          localCoords = coords;
          if(localCoords[2] + ${col} < ${outputShape[2]}) {
            localCoords[2] += ${col};
            if(localCoords[1] + ${row} < ${outputShape[1]}) {
              localCoords[1] += ${row};

              flatIndex = getFlatIndex(localCoords);
              offset = imod(flatIndex, 4);

              flatIndex = idiv(flatIndex, 4, 1.);

              r = flatIndex / ${width};
              c = imod(flatIndex, ${width});
              uv = (vec2(c, r) + halfCR) / vec2(${width}.0, ${height}.0);
              values = ${glsl.texture2D}(A, uv);

              if(offset == 0) {
                result[${channel}] = values[0];
              } else if(offset == 1) {
                result[${channel}] = values[1];
              } else if(offset == 2) {
                result[${channel}] = values[2];
              } else {
                result[${channel}] = values[3];
              }
            }
          }
        `;
      }
    }
    this.userCode = `
      ${getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 coords = getOutputCoords();

        vec4 result = vec4(0.);
        int flatIndex, r, c, offset;
        ivec3 localCoords;
        vec2 uv;
        vec4 values;

        ${mainLoop}

        ${glsl.output} = ${output};
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/gpgpu_util.ts
var gpgpu_util_exports = {};
__export(gpgpu_util_exports, {
  bindVertexProgramAttributeStreams: () => bindVertexProgramAttributeStreams,
  createBufferFromOutputTexture: () => createBufferFromOutputTexture,
  createFloat16MatrixTexture: () => createFloat16MatrixTexture,
  createFloat16PackedMatrixTexture: () => createFloat16PackedMatrixTexture,
  createFloat32MatrixTexture: () => createFloat32MatrixTexture,
  createIndexBuffer: () => createIndexBuffer,
  createPackedMatrixTexture: () => createPackedMatrixTexture,
  createUnsignedBytesMatrixTexture: () => createUnsignedBytesMatrixTexture,
  createVertexBuffer: () => createVertexBuffer,
  createVertexShader: () => createVertexShader2,
  downloadByteEncodedFloatMatrixFromOutputTexture: () => downloadByteEncodedFloatMatrixFromOutputTexture,
  downloadFloat32MatrixFromBuffer: () => downloadFloat32MatrixFromBuffer,
  downloadMatrixFromPackedOutputTexture: () => downloadMatrixFromPackedOutputTexture,
  downloadPackedMatrixFromBuffer: () => downloadPackedMatrixFromBuffer,
  getInternalFormatForFloat16MatrixTexture: () => getInternalFormatForFloat16MatrixTexture,
  getInternalFormatForFloat16PackedMatrixTexture: () => getInternalFormatForFloat16PackedMatrixTexture,
  getInternalFormatForFloat32MatrixTexture: () => getInternalFormatForFloat32MatrixTexture,
  getInternalFormatForPackedMatrixTexture: () => getInternalFormatForPackedMatrixTexture,
  getInternalFormatForUnsignedBytesMatrixTexture: () => getInternalFormatForUnsignedBytesMatrixTexture,
  uploadDenseMatrixToTexture: () => uploadDenseMatrixToTexture,
  uploadPixelDataToTexture: () => uploadPixelDataToTexture
});
function createVertexShader2(gl) {
  const glsl = getGlslDifferences();
  const vertexShaderSource = `${glsl.version}
    precision highp float;
    ${glsl.attribute} vec3 clipSpacePos;
    ${glsl.attribute} vec2 uv;
    ${glsl.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
  return createVertexShader(gl, vertexShaderSource);
}
function createVertexBuffer(gl) {
  const vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
  return createStaticVertexBuffer(gl, vertexArray);
}
function createIndexBuffer(gl) {
  const triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);
  return createStaticIndexBuffer(gl, triangleVertexIndices);
}
function createAndConfigureTexture(gl, width, height, internalFormat, textureFormat, textureType) {
  validateTextureSize(width, height);
  const texture = createTexture(gl);
  const tex2d = gl.TEXTURE_2D;
  callAndCheck(gl, () => gl.bindTexture(tex2d, texture));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST));
  callAndCheck(gl, () => gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null));
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
  return texture;
}
function getInternalFormatForFloat32MatrixTexture(textureConfig) {
  return textureConfig.internalFormatFloat;
}
function createFloat32MatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat32MatrixTexture(textureConfig), textureConfig.textureFormatFloat, gl.FLOAT);
}
function getInternalFormatForFloat16MatrixTexture(textureConfig) {
  return textureConfig.internalFormatHalfFloat;
}
function createFloat16MatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16MatrixTexture(textureConfig), textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);
}
function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig) {
  return textureConfig.downloadTextureFormat;
}
function createUnsignedBytesMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForUnsignedBytesMatrixTexture(textureConfig), gl.RGBA, gl.UNSIGNED_BYTE);
}
function getInternalFormatForPackedMatrixTexture(textureConfig) {
  return textureConfig.internalFormatPackedFloat;
}
function createPackedMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForPackedMatrixTexture(textureConfig), gl.RGBA, gl.FLOAT);
}
function getInternalFormatForFloat16PackedMatrixTexture(textureConfig) {
  return textureConfig.internalFormatPackedHalfFloat;
}
function createFloat16PackedMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16PackedMatrixTexture(textureConfig), gl.RGBA, textureConfig.textureTypeHalfFloat);
}
function bindVertexProgramAttributeStreams(gl, program, vertexBuffer) {
  const posOffset = 0;
  const uvOffset = 3 * 4;
  const stride = 3 * 4 + 2 * 4;
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer));
  const success = bindVertexBufferToProgramAttribute(gl, program, "clipSpacePos", vertexBuffer, 3, stride, posOffset);
  return success && bindVertexBufferToProgramAttribute(gl, program, "uv", vertexBuffer, 2, stride, uvOffset);
}
function uploadDenseMatrixToTexture(gl, texture, width, height, data, textureConfig) {
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
  let dataForUpload, texelDataType, internalFormat;
  if (data instanceof Uint8Array) {
    dataForUpload = new Uint8Array(width * height * 4);
    texelDataType = gl.UNSIGNED_BYTE;
    internalFormat = gl.RGBA;
  } else {
    dataForUpload = new Float32Array(width * height * 4);
    texelDataType = gl.FLOAT;
    internalFormat = textureConfig.internalFormatPackedFloat;
  }
  dataForUpload.set(data);
  callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, gl.RGBA, texelDataType, dataForUpload));
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
}
function uploadPixelDataToTexture(gl, texture, pixels) {
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
  if (pixels.data instanceof Uint8Array) {
    callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data));
  } else {
    callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels));
  }
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
}
function createBufferFromOutputTexture(gl2, rows, columns, textureConfig) {
  const buffer3 = gl2.createBuffer();
  callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3));
  const bytesPerFloat = 4;
  const valuesPerTexel = 4;
  const bufferSizeBytes = bytesPerFloat * valuesPerTexel * rows * columns;
  callAndCheck(gl2, () => gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ));
  callAndCheck(gl2, () => gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0));
  callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null));
  return buffer3;
}
function downloadFloat32MatrixFromBuffer(gl, buffer3, size) {
  const gl2 = gl;
  const downloadTarget = new Float32Array(size);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3);
  gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
  return downloadTarget;
}
function downloadByteEncodedFloatMatrixFromOutputTexture(gl, rows, columns, textureConfig) {
  const [w, h] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  const numChannels = 4;
  const downloadTarget = new Uint8Array(getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));
  callAndCheck(gl, () => gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget));
  return new Float32Array(downloadTarget.buffer);
}
function downloadPackedMatrixFromBuffer(gl, buffer3, batch, rows, cols, physicalRows, physicalCols, textureConfig) {
  const gl2 = gl;
  const downloadTarget = new Float32Array(getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer3);
  gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
  return downloadTarget;
}
function downloadMatrixFromPackedOutputTexture(gl, physicalRows, physicalCols) {
  const packedRGBA = new Float32Array(physicalRows * physicalCols * 4);
  callAndCheck(gl, () => gl.readPixels(0, 0, physicalCols, physicalRows, gl.RGBA, gl.FLOAT, packedRGBA));
  return packedRGBA;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/gpgpu_context.ts
var GPGPUContext = class {
  constructor(gl) {
    this.outputTexture = null;
    this.program = null;
    this.disposed = false;
    this.vertexAttrsAreBound = false;
    this.itemsToPoll = [];
    const glVersion = env2().getNumber("WEBGL_VERSION");
    if (gl != null) {
      this.gl = gl;
      setWebGLContext(glVersion, gl);
    } else {
      this.gl = getWebGLContext(glVersion);
    }
    let COLOR_BUFFER_FLOAT = "WEBGL_color_buffer_float";
    const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
    if (env2().getNumber("WEBGL_VERSION") === 1) {
      const TEXTURE_FLOAT = "OES_texture_float";
      const TEXTURE_HALF_FLOAT = "OES_texture_half_float";
      this.textureFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_FLOAT);
      if (hasExtension(this.gl, TEXTURE_HALF_FLOAT)) {
        this.textureHalfFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_HALF_FLOAT);
      } else if (env2().get("WEBGL_FORCE_F16_TEXTURES")) {
        throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      }
      this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
      if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
        this.colorBufferHalfFloatExtension = getExtensionOrThrow(this.gl, COLOR_BUFFER_HALF_FLOAT);
      } else if (env2().get("WEBGL_FORCE_F16_TEXTURES")) {
        throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      }
    } else {
      COLOR_BUFFER_FLOAT = "EXT_color_buffer_float";
      if (hasExtension(this.gl, COLOR_BUFFER_FLOAT)) {
        this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
      } else if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
        this.colorBufferHalfFloatExtension = this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
      } else {
        throw new Error("GL context does not support color renderable floats");
      }
    }
    this.vertexBuffer = createVertexBuffer(this.gl);
    this.indexBuffer = createIndexBuffer(this.gl);
    this.framebuffer = createFramebuffer(this.gl);
    this.textureConfig = getTextureConfig(this.gl, this.textureHalfFloatExtension);
  }
  get debug() {
    return env2().getBool("DEBUG");
  }
  dispose() {
    if (this.disposed) {
      return;
    }
    if (this.program != null) {
      console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.");
    }
    if (this.outputTexture != null) {
      console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    }
    const gl = this.gl;
    callAndCheck(gl, () => gl.finish());
    callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, null));
    callAndCheck(gl, () => gl.deleteFramebuffer(this.framebuffer));
    callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, null));
    callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null));
    callAndCheck(gl, () => gl.deleteBuffer(this.indexBuffer));
    this.disposed = true;
  }
  createFloat32MatrixTexture(rows, columns) {
    this.throwIfDisposed();
    return createFloat32MatrixTexture(this.gl, rows, columns, this.textureConfig);
  }
  createFloat16MatrixTexture(rows, columns) {
    this.throwIfDisposed();
    return createFloat16MatrixTexture(this.gl, rows, columns, this.textureConfig);
  }
  createUnsignedBytesMatrixTexture(rows, columns) {
    this.throwIfDisposed();
    return createUnsignedBytesMatrixTexture(this.gl, rows, columns, this.textureConfig);
  }
  uploadPixelDataToTexture(texture, pixels) {
    this.throwIfDisposed();
    uploadPixelDataToTexture(this.gl, texture, pixels);
  }
  uploadDenseMatrixToTexture(texture, width, height, data) {
    this.throwIfDisposed();
    uploadDenseMatrixToTexture(this.gl, texture, width, height, data, this.textureConfig);
  }
  createFloat16PackedMatrixTexture(rows, columns) {
    this.throwIfDisposed();
    return createFloat16PackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
  }
  createPackedMatrixTexture(rows, columns) {
    this.throwIfDisposed();
    return createPackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
  }
  deleteMatrixTexture(texture) {
    this.throwIfDisposed();
    if (this.outputTexture === texture) {
      unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
      this.outputTexture = null;
    }
    callAndCheck(this.gl, () => this.gl.deleteTexture(texture));
  }
  downloadByteEncodedFloatMatrixFromOutputTexture(texture, rows, columns) {
    return this.downloadMatrixDriver(texture, () => downloadByteEncodedFloatMatrixFromOutputTexture(this.gl, rows, columns, this.textureConfig));
  }
  downloadPackedMatrixFromBuffer(buffer3, batch, rows, columns, physicalRows, physicalCols) {
    return downloadPackedMatrixFromBuffer(this.gl, buffer3, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);
  }
  downloadFloat32MatrixFromBuffer(buffer3, size) {
    return downloadFloat32MatrixFromBuffer(this.gl, buffer3, size);
  }
  createBufferFromTexture(texture, rows, columns) {
    this.bindTextureToFrameBuffer(texture);
    const result = createBufferFromOutputTexture(this.gl, rows, columns, this.textureConfig);
    this.unbindTextureToFrameBuffer();
    return result;
  }
  createAndWaitForFence() {
    const fenceContext = this.createFence(this.gl);
    return this.pollFence(fenceContext);
  }
  createFence(gl) {
    let query;
    let isFencePassed;
    if (env2().getBool("WEBGL_FENCE_API_ENABLED")) {
      const gl2 = gl;
      const sync = gl2.fenceSync(gl2.SYNC_GPU_COMMANDS_COMPLETE, 0);
      gl.flush();
      isFencePassed = () => {
        const status = gl2.clientWaitSync(sync, 0, 0);
        return status === gl2.ALREADY_SIGNALED || status === gl2.CONDITION_SATISFIED;
      };
      query = sync;
    } else if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0) {
      query = this.beginQuery();
      this.endQuery();
      isFencePassed = () => this.isQueryAvailable(query, env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
    } else {
      isFencePassed = () => true;
    }
    return { query, isFencePassed };
  }
  downloadMatrixFromPackedTexture(texture, physicalRows, physicalCols) {
    return this.downloadMatrixDriver(texture, () => downloadMatrixFromPackedOutputTexture(this.gl, physicalRows, physicalCols));
  }
  createProgram(fragmentShaderSource) {
    this.throwIfDisposed();
    const gl = this.gl;
    const fragmentShader = createFragmentShader(gl, fragmentShaderSource);
    if (this.vertexShader == null) {
      this.vertexShader = createVertexShader2(gl);
    }
    const program = createProgram(gl);
    callAndCheck(gl, () => gl.attachShader(program, this.vertexShader));
    callAndCheck(gl, () => gl.attachShader(program, fragmentShader));
    linkProgram(gl, program);
    if (this.debug) {
      validateProgram(gl, program);
    }
    if (!this.vertexAttrsAreBound) {
      this.setProgram(program);
      this.vertexAttrsAreBound = bindVertexProgramAttributeStreams(gl, this.program, this.vertexBuffer);
    }
    return program;
  }
  deleteProgram(program) {
    this.throwIfDisposed();
    if (program === this.program) {
      this.program = null;
    }
    if (program != null) {
      callAndCheck(this.gl, () => this.gl.deleteProgram(program));
    }
  }
  setProgram(program) {
    this.throwIfDisposed();
    this.program = program;
    if (this.program != null && this.debug) {
      validateProgram(this.gl, this.program);
    }
    callAndCheck(this.gl, () => this.gl.useProgram(program));
  }
  getUniformLocation(program, uniformName, shouldThrow = true) {
    this.throwIfDisposed();
    if (shouldThrow) {
      return getProgramUniformLocationOrThrow(this.gl, program, uniformName);
    } else {
      return getProgramUniformLocation(this.gl, program, uniformName);
    }
  }
  getAttributeLocation(program, attribute) {
    this.throwIfDisposed();
    return callAndCheck(this.gl, () => this.gl.getAttribLocation(program, attribute));
  }
  getUniformLocationNoThrow(program, uniformName) {
    this.throwIfDisposed();
    return this.gl.getUniformLocation(program, uniformName);
  }
  setInputMatrixTexture(inputMatrixTexture, uniformLocation, textureUnit) {
    this.throwIfDisposed();
    this.throwIfNoProgram();
    bindTextureToProgramUniformSampler(this.gl, inputMatrixTexture, uniformLocation, textureUnit);
  }
  setOutputMatrixTexture(outputMatrixTexture, rows, columns) {
    this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);
  }
  setOutputPackedMatrixTexture(outputPackedMatrixTexture, rows, columns) {
    this.throwIfDisposed();
    const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
    this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);
  }
  setOutputMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
    this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);
  }
  setOutputPackedMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }
  debugValidate() {
    if (this.program != null) {
      validateProgram(this.gl, this.program);
    }
    validateFramebuffer(this.gl);
  }
  executeProgram() {
    this.throwIfDisposed();
    this.throwIfNoProgram();
    const gl = this.gl;
    if (this.debug) {
      this.debugValidate();
    }
    callAndCheck(gl, () => gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0));
  }
  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed();
    callAndCheck(this.gl, () => this.gl.finish());
  }
  getQueryTimerExtension() {
    if (this.disjointQueryTimerExtension == null) {
      this.disjointQueryTimerExtension = getExtensionOrThrow(this.gl, env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query");
    }
    return this.disjointQueryTimerExtension;
  }
  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }
  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }
  beginQuery() {
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const gl2 = this.gl;
      const ext2 = this.getQueryTimerExtensionWebGL2();
      const query2 = gl2.createQuery();
      gl2.beginQuery(ext2.TIME_ELAPSED_EXT, query2);
      return query2;
    }
    const ext = this.getQueryTimerExtensionWebGL1();
    const query = ext.createQueryEXT();
    ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);
    return query;
  }
  endQuery() {
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const gl2 = this.gl;
      const ext2 = this.getQueryTimerExtensionWebGL2();
      gl2.endQuery(ext2.TIME_ELAPSED_EXT);
      return;
    }
    const ext = this.getQueryTimerExtensionWebGL1();
    ext.endQueryEXT(ext.TIME_ELAPSED_EXT);
  }
  async waitForQueryAndGetTime(query) {
    await util_exports2.repeatedTry(() => this.disposed || this.isQueryAvailable(query, env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")));
    return this.getQueryTime(query, env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
  }
  getQueryTime(query, queryTimerVersion) {
    if (queryTimerVersion === 0) {
      return null;
    }
    if (queryTimerVersion === 2) {
      const gl2 = this.gl;
      const timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);
      return timeElapsedNanos / 1e6;
    } else {
      const ext = this.getQueryTimerExtensionWebGL1();
      const timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);
      return timeElapsedNanos / 1e6;
    }
  }
  isQueryAvailable(query, queryTimerVersion) {
    if (queryTimerVersion === 0) {
      return true;
    }
    if (queryTimerVersion === 2) {
      const gl2 = this.gl;
      const ext = this.getQueryTimerExtensionWebGL2();
      const available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);
      if (this.disjoint == null) {
        this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
      }
      return available && !this.disjoint;
    } else {
      const ext = this.getQueryTimerExtensionWebGL1();
      const available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);
      if (this.disjoint == null) {
        this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
      }
      return available && !this.disjoint;
    }
  }
  pollFence(fenceContext) {
    return new Promise((resolve) => {
      this.addItemToPoll(() => fenceContext.isFencePassed(), () => resolve());
    });
  }
  pollItems() {
    const index = linearSearchLastTrue(this.itemsToPoll.map((x) => x.isDoneFn));
    for (let i = 0; i <= index; ++i) {
      const { resolveFn } = this.itemsToPoll[i];
      resolveFn();
    }
    this.itemsToPoll = this.itemsToPoll.slice(index + 1);
  }
  addItemToPoll(isDoneFn, resolveFn) {
    this.itemsToPoll.push({ isDoneFn, resolveFn });
    if (this.itemsToPoll.length > 1) {
      return;
    }
    util_exports2.repeatedTry(() => {
      this.pollItems();
      return this.itemsToPoll.length === 0;
    });
  }
  bindTextureToFrameBuffer(texture) {
    this.throwIfDisposed();
    bindColorTextureToFramebuffer(this.gl, texture, this.framebuffer);
    if (this.debug) {
      validateFramebuffer(this.gl);
    }
  }
  unbindTextureToFrameBuffer() {
    if (this.outputTexture != null) {
      bindColorTextureToFramebuffer(this.gl, this.outputTexture, this.framebuffer);
      if (this.debug) {
        validateFramebuffer(this.gl);
      }
    } else {
      unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
    }
  }
  downloadMatrixDriver(texture, downloadAndDecode) {
    this.bindTextureToFrameBuffer(texture);
    const result = downloadAndDecode();
    this.unbindTextureToFrameBuffer();
    return result;
  }
  setOutputMatrixTextureDriver(outputMatrixTextureMaybePacked, width, height) {
    this.throwIfDisposed();
    const gl = this.gl;
    bindColorTextureToFramebuffer(gl, outputMatrixTextureMaybePacked, this.framebuffer);
    if (this.debug) {
      validateFramebuffer(gl);
    }
    this.outputTexture = outputMatrixTextureMaybePacked;
    callAndCheck(gl, () => gl.viewport(0, 0, width, height));
    callAndCheck(gl, () => gl.scissor(0, 0, width, height));
  }
  setOutputMatrixWriteRegionDriver(x, y, width, height) {
    this.throwIfDisposed();
    callAndCheck(this.gl, () => this.gl.scissor(x, y, width, height));
  }
  throwIfDisposed() {
    if (this.disposed) {
      throw new Error("Attempted to use disposed GPGPUContext.");
    }
  }
  throwIfNoProgram() {
    if (this.program == null) {
      throw new Error("No GPU program is currently set.");
    }
  }
};
function linearSearchLastTrue(arr) {
  let i = 0;
  for (; i < arr.length; ++i) {
    const isDone = arr[i]();
    if (!isDone) {
      break;
    }
  }
  return i - 1;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/shader_compiler.ts
var { getBroadcastDims: getBroadcastDims3 } = backend_util_exports2;
function makeShader(inputsInfo, outputShape, userCode, usesPackedTextures) {
  const prefixSnippets = [];
  inputsInfo.forEach((x) => {
    const size = util_exports2.sizeFromShape(x.shapeInfo.logicalShape);
    if (x.shapeInfo.isUniform) {
      prefixSnippets.push(`uniform float ${x.name}${size > 1 ? `[${size}]` : ""};`);
    } else {
      prefixSnippets.push(`uniform sampler2D ${x.name};`);
      prefixSnippets.push(`uniform int offset${x.name};`);
    }
  });
  const inputPrefixSnippet = prefixSnippets.join("\n");
  const inputSamplingSnippet = inputsInfo.map((x) => getInputSamplingSnippet(x, outputShape, usesPackedTextures)).join("\n");
  const outTexShape = outputShape.texShape;
  const glsl = getGlslDifferences();
  const floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);
  let outputSamplingSnippet;
  let floatTextureSetOutputSnippet;
  let shaderPrefix = getShaderPrefix(glsl);
  if (outputShape.isPacked) {
    outputSamplingSnippet = getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape);
    floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);
  } else {
    outputSamplingSnippet = getOutputSamplingSnippet(outputShape.logicalShape, outTexShape);
    floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);
  }
  if (usesPackedTextures) {
    shaderPrefix += SHADER_PACKED_PREFIX;
  }
  const source = [
    shaderPrefix,
    floatTextureSampleSnippet,
    floatTextureSetOutputSnippet,
    inputPrefixSnippet,
    outputSamplingSnippet,
    inputSamplingSnippet,
    userCode
  ].join("\n");
  return source;
}
function getSamplerFromInInfo(inInfo) {
  const shape = inInfo.shapeInfo.logicalShape;
  switch (shape.length) {
    case 0:
      return getSamplerScalar(inInfo);
    case 1:
      return getSampler1D(inInfo);
    case 2:
      return getSampler2D(inInfo);
    case 3:
      return getSampler3D(inInfo);
    case 4:
      return getSampler4D(inInfo);
    case 5:
      return getSampler5D(inInfo);
    case 6:
      return getSampler6D(inInfo);
    default:
      throw new Error(`${shape.length}-D input sampling is not yet supported`);
  }
}
function getPackedSamplerFromInInfo(inInfo) {
  const shape = inInfo.shapeInfo.logicalShape;
  switch (shape.length) {
    case 0:
      return getPackedSamplerScalar(inInfo);
    case 1:
      return getPackedSampler1D(inInfo);
    case 2:
      return getPackedSampler2D(inInfo);
    case 3:
      return getPackedSampler3D(inInfo);
    default:
      return getPackedSamplerND(inInfo);
  }
}
function getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures = false) {
  let res = "";
  if (usesPackedTextures) {
    res += getPackedSamplerFromInInfo(inInfo);
  } else {
    res += getSamplerFromInInfo(inInfo);
  }
  const inShape = inInfo.shapeInfo.logicalShape;
  const outShape = outShapeInfo.logicalShape;
  if (inShape.length <= outShape.length) {
    if (usesPackedTextures) {
      res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);
    } else {
      res += getSamplerAtOutputCoords(inInfo, outShapeInfo);
    }
  }
  return res;
}
function getPackedOutputSamplingSnippet(outShape, outTexShape) {
  switch (outShape.length) {
    case 0:
      return getOutputScalarCoords();
    case 1:
      return getOutputPacked1DCoords(outShape, outTexShape);
    case 2:
      return getOutputPacked2DCoords(outShape, outTexShape);
    case 3:
      return getOutputPacked3DCoords(outShape, outTexShape);
    default:
      return getOutputPackedNDCoords(outShape, outTexShape);
  }
}
function getOutputSamplingSnippet(outShape, outTexShape) {
  switch (outShape.length) {
    case 0:
      return getOutputScalarCoords();
    case 1:
      return getOutput1DCoords(outShape, outTexShape);
    case 2:
      return getOutput2DCoords(outShape, outTexShape);
    case 3:
      return getOutput3DCoords(outShape, outTexShape);
    case 4:
      return getOutput4DCoords(outShape, outTexShape);
    case 5:
      return getOutput5DCoords(outShape, outTexShape);
    case 6:
      return getOutput6DCoords(outShape, outTexShape);
    default:
      throw new Error(`${outShape.length}-D output sampling is not yet supported`);
  }
}
function getFloatTextureSampleSnippet(glsl) {
  return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${glsl.texture2D}(textureSampler, uv).r;
    }
  `;
}
function getFloatTextureSetRSnippet(glsl) {
  return `
    void setOutput(float val) {
      ${glsl.output} = vec4(val, 0, 0, 0);
    }
  `;
}
function getFloatTextureSetRGBASnippet(glsl) {
  return `
    void setOutput(vec4 val) {
      ${glsl.output} = val;
    }
  `;
}
function getShaderPrefix(glsl) {
  const SHADER_PREFIX = `${glsl.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${glsl.varyingFs} vec2 resultUV;
    ${glsl.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${glsl.defineSpecialNaN}
    ${glsl.defineSpecialInf}
    ${glsl.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${SAMPLE_1D_SNIPPET}
    ${SAMPLE_2D_SNIPPET}
    ${SAMPLE_3D_SNIPPET}
  `;
  return SHADER_PREFIX;
}
var SAMPLE_1D_SNIPPET = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var SAMPLE_2D_SNIPPET = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var SAMPLE_3D_SNIPPET = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var SHADER_PACKED_PREFIX = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
function getOutputScalarCoords() {
  return `
    int getOutputCoords() {
      return 0;
    }
  `;
}
function getOutputPacked1DCoords(shape, texShape) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (packedTexShape[0] === 1) {
    return `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${packedTexShape[1]}.0);
      }
    `;
  }
  if (packedTexShape[1] === 1) {
    return `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${packedTexShape[0]}.0);
      }
    `;
  }
  return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      return 2 * (resTexRC.x * ${packedTexShape[1]} + resTexRC.y);
    }
  `;
}
function getOutput1DCoords(shape, texShape) {
  if (texShape[0] === 1) {
    return `
      int getOutputCoords() {
        return int(resultUV.x * ${texShape[1]}.0);
      }
    `;
  }
  if (texShape[1] === 1) {
    return `
      int getOutputCoords() {
        return int(resultUV.y * ${texShape[0]}.0);
      }
    `;
  }
  return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      return resTexRC.x * ${texShape[1]} + resTexRC.y;
    }
  `;
}
function getOutputPacked3DCoords(shape, texShape) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texelsInLogicalRow = Math.ceil(shape[2] / 2);
  const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec3(b, r, c);
    }
  `;
}
function getOutput3DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
}
function getOutputPackedNDCoords(shape, texShape) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);
  const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);
  let texelsInBatchN = texelsInBatch;
  let batches = ``;
  let coords2 = "b, r, c";
  for (let b = 2; b < shape.length - 1; b++) {
    texelsInBatchN *= shape[shape.length - b - 1];
    batches = `
      int b${b} = index / ${texelsInBatchN};
      index -= b${b} * ${texelsInBatchN};
    ` + batches;
    coords2 = `b${b}, ` + coords2;
  }
  return `
    ivec${shape.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      ${batches}

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec${shape.length}(${coords2});
    }
  `;
}
function getOutput4DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2"], shape);
  return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec4(r, c, d, d2);
    }
  `;
}
function getOutput5DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3"], shape);
  return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${texShape[0]},
                             ${texShape[1]}));

      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
}
function getOutput6DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3", "d4"], shape);
  return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
}
function getOutputPacked2DCoords(shape, texShape) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (util_exports2.arraysEqual(shape, texShape)) {
    return `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      }
    `;
  }
  const texelsInLogicalRow = Math.ceil(shape[1] / 2);
  return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));

      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;
      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec2(r, c);
    }
  `;
}
function getOutput2DCoords(shape, texShape) {
  if (util_exports2.arraysEqual(shape, texShape)) {
    return `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${texShape[0]}, ${texShape[1]}));
      }
    `;
  }
  if (shape[1] === 1) {
    return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    `;
  }
  if (shape[0] === 1) {
    return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    `;
  }
  return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      int r = index / ${shape[1]};
      int c = index - r * ${shape[1]};
      return ivec2(r, c);
    }
  `;
}
function getFlatOffsetUniformName(texName) {
  return `offset${texName}`;
}
function getPackedSamplerScalar(inputInfo) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const glsl = getGlslDifferences();
  return `
    vec4 ${funcName}() {
      return ${glsl.texture2D}(${texName}, halfCR);
    }
  `;
}
function getSamplerScalar(inputInfo) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  if (inputInfo.shapeInfo.isUniform) {
    return `float ${funcName}() {return ${texName};}`;
  }
  const [texNumR, texNumC] = inputInfo.shapeInfo.texShape;
  if (texNumR === 1 && texNumC === 1) {
    return `
      float ${funcName}() {
        return sampleTexture(${texName}, halfCR);
      }
    `;
  }
  const [tNumR, tNumC] = inputInfo.shapeInfo.texShape;
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}() {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getPackedSampler1D(inputInfo) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const glsl = getGlslDifferences();
  return `
    vec4 ${funcName}(int index) {
      vec2 uv = packedUVfrom1D(
        ${packedTexShape[0]}, ${packedTexShape[1]}, index);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler1D(inputInfo) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int index) {
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texShape = inputInfo.shapeInfo.texShape;
  const tNumR = texShape[0];
  const tNumC = texShape[1];
  if (tNumC === 1 && tNumR === 1) {
    return `
      float ${funcName}(int index) {
        return sampleTexture(${texName}, halfCR);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  if (tNumC === 1) {
    return `
      float ${funcName}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / ${tNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (tNumR === 1) {
    return `
      float ${funcName}(int index) {
        vec2 uv = vec2((float(index + ${offset}) + 0.5) / ${tNumC}.0, 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  return `
    float ${funcName}(int index) {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getPackedSampler2D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const glsl = getGlslDifferences();
  if (texShape != null && util_exports2.arraysEqual(shape, texShape)) {
    return `
      vec4 ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);

        return ${glsl.texture2D}(${texName}, uv);
      }
    `;
  }
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const valuesPerRow = Math.ceil(shape[1] / 2);
  return `
    vec4 ${funcName}(int row, int col) {
      vec2 uv = packedUVfrom2D(${valuesPerRow}, ${packedTexShape[0]}, ${packedTexShape[1]}, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler2D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  if (texShape != null && util_exports2.arraysEqual(shape, texShape)) {
    const texNumR2 = texShape[0];
    const texNumC2 = texShape[1];
    return `
    float ${funcName}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC2}.0, ${texNumR2}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  const { newShape, keptDims } = util_exports2.squeezeShape(shape);
  const squeezedShape = newShape;
  if (squeezedShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["row", "col"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${shape[1]}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const offset = getFlatOffsetUniformName(texName);
  if (texNumC === 1) {
    return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  if (texNumR === 1) {
    return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${texNumC}.0, 0.5);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  return `
  float ${funcName}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${shape[1]} + col + ${offset};
    vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
    return sampleTexture(${texName}, uv);
  }
`;
}
function getPackedSampler3D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (shape[0] === 1) {
    const squeezedShape = shape.slice(1);
    const keptDims = [1, 2];
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["b", "row", "col"];
    return `
        ${getPackedSamplerFromInInfo(newInputInfo)}
        vec4 ${funcName}(int b, int row, int col) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
  }
  const texNumR = packedTexShape[0];
  const texNumC = packedTexShape[1];
  const valuesPerRow = Math.ceil(shape[2] / 2);
  const texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);
  const glsl = getGlslDifferences();
  return `
    vec4 ${funcName}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${texNumR}, ${texNumC}, ${texelsInBatch}, ${valuesPerRow}, b, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler3D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride0 = shape[1] * shape[2];
  const stride1 = shape[2];
  const { newShape, keptDims } = util_exports2.squeezeShape(shape);
  const squeezedShape = newShape;
  if (squeezedShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["row", "col", "depth"];
    return `
        ${getSamplerFromInInfo(newInputInfo)}
        float ${funcName}(int row, int col, int depth) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${stride0}, ${stride1}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  if (texNumC === stride0 && flatOffset == null) {
    return `
        float ${funcName}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${stride1}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${texNumC}.0, ${texNumR}.0);
          return sampleTexture(${texName}, uv);
        }
      `;
  }
  if (texNumC === stride1 && flatOffset == null) {
    return `
    float ${funcName}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${shape[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
      float ${funcName}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${stride0} + col * ${stride1} + depth + ${offset};
        vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
        return sampleTexture(${texName}, uv);
      }
  `;
}
function getPackedSamplerND(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const rank = shape.length;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texNumR = packedTexShape[0];
  const texNumC = packedTexShape[1];
  const valuesPerRow = Math.ceil(shape[rank - 1] / 2);
  let texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);
  let params = `int b, int row, int col`;
  let index = `b * ${texelsInBatch} + (row / 2) * ${valuesPerRow} + (col / 2)`;
  for (let b = 2; b < rank - 1; b++) {
    params = `int b${b}, ` + params;
    texelsInBatch *= shape[rank - b - 1];
    index = `b${b} * ${texelsInBatch} + ` + index;
  }
  const glsl = getGlslDifferences();
  return `
    vec4 ${funcName}(${params}) {
      int index = ${index};
      int texR = index / ${texNumC};
      int texC = index - texR * ${texNumC};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}, ${texNumR});
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler4D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride2 = shape[3];
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  const { newShape, keptDims } = util_exports2.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth, int depth2) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${stride0}, ${stride1}, ${stride2}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  if (texNumC === stride0 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${stride1}, ${stride2}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride2 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${shape[1] * shape[2]}, ${shape[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} +
          depth * ${stride2} + depth2;
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getSampler5D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride3 = shape[4];
  const stride2 = shape[3] * stride3;
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  const { newShape, keptDims } = util_exports2.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2", "depth3"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          depth3;
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  if (texNumC === stride0 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${stride1}, ${stride2}, ${stride3}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride3 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3]},
               ${shape[2] * shape[3]}, ${shape[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getSampler6D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const { newShape, keptDims } = util_exports2.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  const stride4 = shape[5];
  const stride3 = shape[4] * stride4;
  const stride2 = shape[3] * stride3;
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          dot(
            vec2(depth3, depth4),
            vec2(${stride4}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  if (texNumC === stride0 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${stride1}, ${stride2}, ${stride3}, ${stride4})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride4 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3] * shape[4]},
               ${shape[2] * shape[3] * shape[4]},
               ${shape[3] * shape[4]},
               ${shape[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 * ${stride4} + depth4 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getUniformSampler(inputInfo) {
  const texName = inputInfo.name;
  const inSize = util_exports2.sizeFromShape(inputInfo.shapeInfo.logicalShape);
  if (inSize < 2) {
    return `return ${texName};`;
  }
  return `
    for (int i = 0; i < ${inSize}; i++) {
      if (i == index) {
        return ${texName}[i];
      }
    }
  `;
}
function getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {
  const texName = inputInfo.name;
  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
  const funcName = "get" + texFuncSnippet + "AtOutCoords";
  const inRank = inputInfo.shapeInfo.logicalShape.length;
  const outRank = outShapeInfo.logicalShape.length;
  const broadcastDims = getBroadcastDims3(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
  const type = getCoordsDataType(outRank);
  const rankDiff = outRank - inRank;
  let coordsSnippet;
  const fields = ["x", "y", "z", "w", "u", "v"];
  if (inRank === 0) {
    coordsSnippet = "";
  } else if (outRank < 2 && broadcastDims.length >= 1) {
    coordsSnippet = "coords = 0;";
  } else {
    coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
  }
  let unpackedCoordsSnippet = "";
  if (outRank < 2 && inRank > 0) {
    unpackedCoordsSnippet = "coords";
  } else {
    unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
  }
  let output = `return outputValue;`;
  const inSize = util_exports2.sizeFromShape(inputInfo.shapeInfo.logicalShape);
  const isInputScalar = inSize === 1;
  const outSize = util_exports2.sizeFromShape(outShapeInfo.logicalShape);
  const isOutputScalar = outSize === 1;
  if (inRank === 1 && !isInputScalar && !isOutputScalar) {
    output = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
  } else if (isInputScalar && !isOutputScalar) {
    if (outRank === 1) {
      output = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      `;
    } else {
      output = `
        return vec4(outputValue.x);
      `;
    }
  } else if (broadcastDims.length) {
    const rows = inRank - 2;
    const cols = inRank - 1;
    if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {
      output = `return vec4(outputValue.x);`;
    } else if (broadcastDims.indexOf(rows) > -1) {
      output = `return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);`;
    } else if (broadcastDims.indexOf(cols) > -1) {
      output = `return vec4(outputValue.xx, outputValue.zz);`;
    }
  }
  return `
    vec4 ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      vec4 outputValue = get${texFuncSnippet}(${unpackedCoordsSnippet});
      ${output}
    }
  `;
}
function getSamplerAtOutputCoords(inputInfo, outShapeInfo) {
  const texName = inputInfo.name;
  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
  const funcName = "get" + texFuncSnippet + "AtOutCoords";
  const outTexShape = outShapeInfo.texShape;
  const inTexShape = inputInfo.shapeInfo.texShape;
  const inRank = inputInfo.shapeInfo.logicalShape.length;
  const outRank = outShapeInfo.logicalShape.length;
  if (!inputInfo.shapeInfo.isUniform && inRank === outRank && inputInfo.shapeInfo.flatOffset == null && util_exports2.arraysEqual(inTexShape, outTexShape)) {
    return `
      float ${funcName}() {
        return sampleTexture(${texName}, resultUV);
      }
    `;
  }
  const type = getCoordsDataType(outRank);
  const broadcastDims = getBroadcastDims3(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
  const rankDiff = outRank - inRank;
  let coordsSnippet;
  const fields = ["x", "y", "z", "w", "u", "v"];
  if (inRank === 0) {
    coordsSnippet = "";
  } else if (outRank < 2 && broadcastDims.length >= 1) {
    coordsSnippet = "coords = 0;";
  } else {
    coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
  }
  let unpackedCoordsSnippet = "";
  if (outRank < 2 && inRank > 0) {
    unpackedCoordsSnippet = "coords";
  } else {
    unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
  }
  return `
    float ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      return get${texFuncSnippet}(${unpackedCoordsSnippet});
    }
  `;
}
function getCoordsDataType(rank) {
  if (rank <= 1) {
    return "int";
  } else if (rank === 2) {
    return "ivec2";
  } else if (rank === 3) {
    return "ivec3";
  } else if (rank === 4) {
    return "ivec4";
  } else if (rank === 5) {
    return "ivec5";
  } else if (rank === 6) {
    return "ivec6";
  } else {
    throw Error(`GPU for rank ${rank} is not yet supported`);
  }
}
function squeezeInputInfo(inInfo, squeezedShape) {
  const newInputInfo = JSON.parse(JSON.stringify(inInfo));
  newInputInfo.shapeInfo.logicalShape = squeezedShape;
  return newInputInfo;
}
function getSqueezedParams(params, keptDims) {
  return keptDims.map((d) => params[d]).join(", ");
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/gpgpu_math.ts
function compileProgram(gpgpu, program, inputs, output) {
  const userCode = program.userCode;
  const inputInfos = inputs.map((input2, i) => {
    const shapeInfo = {
      logicalShape: input2.shape,
      texShape: input2.isUniform ? null : input2.texData.texShape,
      isUniform: input2.isUniform,
      isPacked: input2.isUniform ? false : input2.texData.isPacked,
      flatOffset: null
    };
    if (input2.texData != null && input2.texData.slice != null && input2.texData.slice.flatOffset > 0) {
      shapeInfo.flatOffset = input2.texData.slice.flatOffset;
    }
    return { name: program.variableNames[i], shapeInfo };
  });
  const inShapeInfos = inputInfos.map((x) => x.shapeInfo);
  const outShapeInfo = {
    logicalShape: output.shape,
    texShape: output.texData.texShape,
    isUniform: false,
    isPacked: output.texData.isPacked,
    flatOffset: null
  };
  const source = makeShader(inputInfos, outShapeInfo, userCode, program.packedInputs);
  const webGLProgram = gpgpu.createProgram(source);
  let infLoc = null;
  const nanLoc = gpgpu.getUniformLocation(webGLProgram, "NAN", false);
  if (env2().getNumber("WEBGL_VERSION") === 1) {
    infLoc = gpgpu.getUniformLocation(webGLProgram, "INFINITY", false);
  }
  const uniformLocations = {};
  for (let i = 0; i < program.variableNames.length; i++) {
    const varName = program.variableNames[i];
    const shouldThrow = false;
    uniformLocations[varName] = gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow);
    uniformLocations[`offset${varName}`] = gpgpu.getUniformLocation(webGLProgram, `offset${varName}`, shouldThrow);
  }
  return {
    program,
    source,
    webGLProgram,
    uniformLocations,
    inShapeInfos,
    outShapeInfo,
    infLoc,
    nanLoc
  };
}
function validateBinaryAndProgram(shapeInfos, inputs) {
  if (shapeInfos.length !== inputs.length) {
    throw Error(`Binary was compiled with ${shapeInfos.length} inputs, but was executed with ${inputs.length} inputs`);
  }
  shapeInfos.forEach((s, i) => {
    const shapeA = s.logicalShape;
    const input2 = inputs[i];
    const shapeB = input2.shape;
    if (!util_exports2.arraysEqual(shapeA, shapeB)) {
      throw Error(`Binary was compiled with different shapes than the current args. Shapes ${shapeA} and ${shapeB} must match`);
    }
    if (s.isUniform && input2.isUniform) {
      return;
    }
    const texShapeA = s.texShape;
    const texShapeB = input2.isUniform ? null : input2.texData.texShape;
    if (!util_exports2.arraysEqual(texShapeA, texShapeB)) {
      throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${texShapeA} and ${texShapeB} must match`);
    }
  });
}
function runProgram(gpgpu, binary, inputs, output, customSetup) {
  validateBinaryAndProgram(binary.inShapeInfos, inputs);
  validateBinaryAndProgram([binary.outShapeInfo], [output]);
  const outTex = output.texData.texture;
  const outTexShape = output.texData.texShape;
  if (output.texData.isPacked) {
    gpgpu.setOutputPackedMatrixTexture(outTex, outTexShape[0], outTexShape[1]);
  } else {
    gpgpu.setOutputMatrixTexture(outTex, outTexShape[0], outTexShape[1]);
  }
  gpgpu.setProgram(binary.webGLProgram);
  if (env2().getNumber("WEBGL_VERSION") === 1) {
    if (binary.infLoc !== null) {
      gpgpu.gl.uniform1f(binary.infLoc, Infinity);
    }
  }
  if (binary.nanLoc !== null) {
    gpgpu.gl.uniform1f(binary.nanLoc, NaN);
  }
  inputs.forEach((input2, i) => {
    const varName = binary.program.variableNames[i];
    const varLoc = binary.uniformLocations[varName];
    const varOffsetLoc = binary.uniformLocations[`offset${varName}`];
    if (varLoc == null) {
      return;
    }
    if (input2.isUniform) {
      if (util_exports2.sizeFromShape(input2.shape) < 2) {
        gpgpu.gl.uniform1f(varLoc, input2.uniformValues[0]);
      } else {
        let vals = input2.uniformValues;
        if (!(vals instanceof Float32Array)) {
          vals = new Float32Array(vals);
        }
        gpgpu.gl.uniform1fv(varLoc, vals);
      }
      return;
    }
    if (input2.texData.slice != null && varOffsetLoc != null) {
      gpgpu.gl.uniform1i(varOffsetLoc, input2.texData.slice.flatOffset);
    }
    gpgpu.setInputMatrixTexture(input2.texData.texture, varLoc, i);
  });
  if (customSetup != null) {
    customSetup(gpgpu, binary.webGLProgram);
  }
  gpgpu.executeProgram();
}
function makeShaderKey(program, inputs, output) {
  let keyInputs = "";
  inputs.concat(output).forEach((x) => {
    const hasOffset = x.texData != null && x.texData.slice != null && x.texData.slice.flatOffset > 0;
    const texShape = x.isUniform ? "uniform" : x.texData.texShape;
    keyInputs += `${x.shape}_${texShape}_${hasOffset}`;
  });
  const keyUserCode = program.userCode;
  let key = program.constructor.name;
  key += "_" + keyInputs + "_" + keyUserCode;
  return key;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/shared.js
var shared_exports2 = {};
__export(shared_exports2, {
  addImpl: () => addImpl2,
  bincountImpl: () => bincountImpl2,
  bincountReduceImpl: () => bincountReduceImpl2,
  ceilImpl: () => ceilImpl2,
  concatImpl: () => concatImpl2,
  equalImpl: () => equalImpl2,
  expImpl: () => expImpl2,
  expm1Impl: () => expm1Impl2,
  floorImpl: () => floorImpl2,
  gatherNdImpl: () => gatherNdImpl2,
  gatherV2Impl: () => gatherV2Impl2,
  greaterEqualImpl: () => greaterEqualImpl2,
  greaterImpl: () => greaterImpl2,
  lessEqualImpl: () => lessEqualImpl2,
  lessImpl: () => lessImpl2,
  linSpaceImpl: () => linSpaceImpl2,
  logImpl: () => logImpl2,
  maxImpl: () => maxImpl2,
  maximumImpl: () => maximumImpl2,
  minimumImpl: () => minimumImpl2,
  multiplyImpl: () => multiplyImpl2,
  negImpl: () => negImpl2,
  notEqualImpl: () => notEqualImpl2,
  prodImpl: () => prodImpl2,
  rangeImpl: () => rangeImpl2,
  rsqrtImpl: () => rsqrtImpl2,
  simpleAbsImpl: () => simpleAbsImpl2,
  sliceImpl: () => sliceImpl2,
  sparseFillEmptyRowsImpl: () => sparseFillEmptyRowsImpl2,
  sparseReshapeImpl: () => sparseReshapeImpl2,
  sparseSegmentReductionImpl: () => sparseSegmentReductionImpl2,
  squaredDifferenceImpl: () => squaredDifferenceImpl2,
  stridedSliceImpl: () => stridedSliceImpl2,
  stringNGramsImpl: () => stringNGramsImpl2,
  stringSplitImpl: () => stringSplitImpl2,
  stringToHashBucketFastImpl: () => stringToHashBucketFastImpl2,
  subImpl: () => subImpl2,
  tileImpl: () => tileImpl2,
  topKImpl: () => topKImpl2,
  transposeImpl: () => transposeImpl2,
  uniqueImpl: () => uniqueImpl2
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js
function assertNotComplex3(tensor3, opName) {
  if (!Array.isArray(tensor3)) {
    tensor3 = [tensor3];
  }
  tensor3.forEach((t) => {
    if (t != null) {
      util_exports2.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
    }
  });
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js
function simpleAbsImpl2(vals) {
  const resultValues = new Float32Array(vals.length);
  for (let i = 0; i < vals.length; ++i) {
    resultValues[i] = Math.abs(vals[i]);
  }
  return resultValues;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js
function createSimpleBinaryKernelImpl2(op3) {
  return (aShape, bShape, aVals, bVals, dtype) => {
    const newShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    const resultRank = newShape.length;
    const resultStrides = util_exports2.computeStrides(newShape);
    const resultSize = util_exports2.sizeFromShape(newShape);
    const result = util_exports2.getTypedArrayFromDType(dtype, resultSize);
    const aRank = aShape.length;
    const bRank = bShape.length;
    const aStrides = util_exports2.computeStrides(aShape);
    const bStrides = util_exports2.computeStrides(bShape);
    const aBroadcastDims = backend_util_exports2.getBroadcastDims(aShape, newShape);
    const bBroadcastDims = backend_util_exports2.getBroadcastDims(bShape, newShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < result.length; ++i) {
        result[i] = op3(aVals[i % aVals.length], bVals[i % bVals.length]);
      }
    } else {
      for (let i = 0; i < result.length; ++i) {
        const loc = util_exports2.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports2.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports2.locToIndex(bLoc, bRank, bStrides);
        result[i] = op3(aVals[aIndex], bVals[bIndex]);
      }
    }
    return [result, newShape];
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js
function complex4(args) {
  const { inputs, backend: backend3 } = args;
  const { real: real6, imag: imag5 } = inputs;
  const realVals = backend3.data.get(real6.dataId).values;
  const imagVals = backend3.data.get(imag5.dataId).values;
  const complexInfo = backend3.makeTensorInfo(real6.shape, "complex64");
  const complex6 = backend3.data.get(complexInfo.dataId);
  complex6.complexTensorInfos = {
    real: backend3.makeTensorInfo(real6.shape, "float32", realVals),
    imag: backend3.makeTensorInfo(imag5.shape, "float32", imagVals)
  };
  return complexInfo;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js
function zeros5(backend3, shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real6 = zeros5(backend3, shape, "float32");
    const imag5 = zeros5(backend3, shape, "float32");
    return complex4({ inputs: { real: real6, imag: imag5 }, backend: backend3 });
  }
  const values = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(shape), dtype);
  return backend3.makeTensorInfo(shape, dtype, values);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js
function identity3(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  backend3.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js
function real4(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const real6 = backend3.data.get(input2.dataId).complexTensorInfos.real;
  const realVal = backend3.data.get(real6.dataId).values;
  return backend3.makeTensorInfo(real6.shape, real6.dtype, realVal);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js
function cast5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity3({ inputs: { x }, backend: backend3 });
    }
    const zerosTensorInfo = zeros5(backend3, x.shape, x.dtype);
    const floatX = cast5({ inputs: { x }, backend: backend3, attrs: { dtype: "float32" } });
    const result = complex4({ inputs: { real: floatX, imag: zerosTensorInfo }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(zerosTensorInfo);
    backend3.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real4({ inputs: { input: x }, backend: backend3 });
    const result = cast5({ inputs: { x: realPart }, backend: backend3, attrs: { dtype } });
    backend3.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports2.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity3({ inputs: { x }, backend: backend3 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  if (dtype === "int32") {
    const values = backend3.data.get(x.dataId).values;
    const resultValues = Int32Array.from(values);
    return backend3.makeTensorInfo(x.shape, "int32", resultValues);
  }
  if (dtype === "bool") {
    const xVals = backend3.data.get(x.dataId).values;
    const zero = util_exports2.toTypedArray([0], x.dtype);
    const [resultData, resultShape] = createSimpleBinaryKernelImpl2((a, b) => a !== b ? 1 : 0)(x.shape, [], xVals, zero, "bool");
    return backend3.makeTensorInfo(resultShape, "bool", resultData);
  }
  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js
function binaryKernelFunc2(name, simpleImpl, complexImpl, dtype) {
  if (complexImpl == null) {
    return ({ inputs, backend: backend3 }) => {
      const { a, b } = inputs;
      const cpuBackend = backend3;
      assertNotComplex3([a, b], name);
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(aVals) : aVals;
      const decodedBVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(bVals) : bVals;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    };
  }
  return ({ inputs, backend: backend3 }) => {
    const { a, b } = inputs;
    const cpuBackend = backend3;
    if (a.dtype === "complex64" || b.dtype === "complex64") {
      const $aComplex = cast5({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
      const aReal = $aComplexVals.complexTensorInfos.real;
      const aImag = $aComplexVals.complexTensorInfos.imag;
      const aRealVals = cpuBackend.data.get(aReal.dataId).values;
      const aImagVals = cpuBackend.data.get(aImag.dataId).values;
      const $bComplex = cast5({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
      const bReal = $bComplexVals.complexTensorInfos.real;
      const bImag = $bComplexVals.complexTensorInfos.imag;
      const bRealVals = cpuBackend.data.get(bReal.dataId).values;
      const bImagVals = cpuBackend.data.get(bImag.dataId).values;
      const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
      const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
      const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
      const result = complex4({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
      cpuBackend.disposeIntermediateTensorInfo($aComplex);
      cpuBackend.disposeIntermediateTensorInfo($bComplex);
      cpuBackend.disposeIntermediateTensorInfo(resultReal);
      cpuBackend.disposeIntermediateTensorInfo(resultImag);
      return result;
    } else {
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    }
  };
}
function createComplexBinaryKernelImpl2(op3) {
  return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
    const resultShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    const resultSize = util_exports2.sizeFromShape(resultShape);
    const resultRank = resultShape.length;
    const resultStrides = util_exports2.computeStrides(resultShape);
    const resultRealVals = util_exports2.getTypedArrayFromDType("float32", resultSize);
    const resultImagVals = util_exports2.getTypedArrayFromDType("float32", resultSize);
    const aBroadcastDims = backend_util_exports2.getBroadcastDims(aShape, resultShape);
    const bBroadcastDims = backend_util_exports2.getBroadcastDims(bShape, resultShape);
    const aVals = backend_util_exports2.mergeRealAndImagArrays(aRealVals, aImagVals);
    const bVals = backend_util_exports2.mergeRealAndImagArrays(bRealVals, bImagVals);
    const aRank = aShape.length;
    const aStrides = util_exports2.computeStrides(aShape);
    const bRank = bShape.length;
    const bStrides = util_exports2.computeStrides(bShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < resultRealVals.length; i++) {
        const aIdx = i % aVals.length;
        const bIdx = i % bVals.length;
        const result = op3(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
        resultRealVals[i] = result.real;
        resultImagVals[i] = result.imag;
      }
    } else {
      for (let i = 0; i < resultRealVals.length; i++) {
        const loc = util_exports2.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports2.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports2.locToIndex(bLoc, bRank, bStrides);
        const opResult = op3(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
        resultRealVals[i] = opResult.real;
        resultImagVals[i] = opResult.imag;
      }
    }
    return [resultRealVals, resultImagVals, resultShape];
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js
var addImpl2 = createSimpleBinaryKernelImpl2((a, b) => a + b);
var addComplexImpl2 = createComplexBinaryKernelImpl2((aReal, aImag, bReal, bImag) => {
  return { real: aReal + bReal, imag: aImag + bImag };
});
var add7 = binaryKernelFunc2(Add2, addImpl2, addComplexImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js
function bincountImpl2(xVals, weightsVals, weightsDtype, weightsShape, size) {
  const weightsSize = util_exports2.sizeFromShape(weightsShape);
  const outVals = util_exports2.makeZerosTypedArray(size, weightsDtype);
  for (let i = 0; i < xVals.length; i++) {
    const value = xVals[i];
    if (value < 0) {
      throw new Error("Input x must be non-negative!");
    }
    if (value >= size) {
      continue;
    }
    if (weightsSize > 0) {
      outVals[value] += weightsVals[i];
    } else {
      outVals[value] += 1;
    }
  }
  return outVals;
}
function bincountReduceImpl2(xBuf, weightsBuf, size, binaryOutput = false) {
  const numRows = xBuf.shape[0];
  const numCols = xBuf.shape[1];
  const outBuf = buffer2([numRows, size], weightsBuf.dtype);
  for (let i = 0; i < numRows; i++) {
    for (let j = 0; j < numCols; j++) {
      const value = xBuf.get(i, j);
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size) {
        continue;
      }
      if (binaryOutput) {
        outBuf.set(1, i, value);
      } else {
        if (weightsBuf.size > 0) {
          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
        } else {
          outBuf.set(outBuf.get(i, value) + 1, i, value);
        }
      }
    }
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js
function createSimpleUnaryImpl2(op3) {
  return (values, dtype, attrs) => {
    const newValues = util_exports2.getTypedArrayFromDType(dtype, values.length);
    for (let i = 0; i < values.length; ++i) {
      newValues[i] = op3(values[i], attrs);
    }
    return newValues;
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js
function unaryKernelFuncFromImpl2(name, unaryImpl, dtype) {
  return ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    assertNotComplex3(x, name);
    if (x.dtype === "string" || dtype === "string") {
      throw new Error("unaryKernelFunc does not support string input/output");
    }
    const cpuBackend = backend3;
    const values = cpuBackend.data.get(x.dataId).values;
    const $dtype = dtype || x.dtype;
    const newValues = unaryImpl(values, $dtype, attrs);
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js
var ceilImpl2 = createSimpleUnaryImpl2((xi) => Math.ceil(xi));
var ceil4 = unaryKernelFuncFromImpl2(Ceil2, ceilImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js
function concatImpl2(inputs, outShape, dtype, simplyConcat) {
  const outVals = util_exports2.getArrayFromDType(dtype, util_exports2.sizeFromShape(outShape));
  if (simplyConcat && dtype !== "string") {
    let offset = 0;
    inputs.forEach((input2) => {
      const size = util_exports2.sizeFromShape(input2.shape);
      outVals.set(input2.vals, offset);
      offset += size;
    });
  } else {
    let colOffset = 0;
    inputs.forEach((input2) => {
      const decodedData = dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(input2.vals) : input2.vals;
      let tIdx = 0;
      for (let row = 0; row < input2.shape[0]; ++row) {
        const resIdx = row * outShape[1] + colOffset;
        for (let col = 0; col < input2.shape[1]; ++col) {
          outVals[resIdx + col] = decodedData[tIdx++];
        }
      }
      colOffset += input2.shape[1];
    });
  }
  return outVals;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js
var equalImpl2 = createSimpleBinaryKernelImpl2((a, b) => a === b ? 1 : 0);
var equal4 = binaryKernelFunc2(Equal2, equalImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js
var expImpl2 = createSimpleUnaryImpl2((xi) => Math.exp(xi));
var exp4 = unaryKernelFuncFromImpl2(Exp2, expImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js
var expm1Impl2 = createSimpleUnaryImpl2((xi) => Math.expm1(xi));
var expm14 = unaryKernelFuncFromImpl2(Expm12, expm1Impl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js
var floorImpl2 = createSimpleUnaryImpl2((xi) => Math.floor(xi));
var floor4 = unaryKernelFuncFromImpl2(Floor2, floorImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js
function gatherNdImpl2(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
  const outBuf = buffer2([numSlices, sliceSize], dtype);
  for (let i = 0; i < numSlices; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      flattenIndex += dim * strides[j];
      index.push(dim);
    }
    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      outBuf.values[i * sliceSize + k] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
    }
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js
function gatherV2Impl2(xBuf, indicesBuf, flattenOutputShape) {
  const outBuf = buffer2(flattenOutputShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const newLoc = outBuf.indexToLoc(i);
    const originalLoc = newLoc.slice();
    const batchIdx = originalLoc[0];
    const indicesIdx = originalLoc[2];
    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
    originalLoc[2] = indicesBuf.values[indicesIndex];
    const originalIndex = xBuf.locToIndex(originalLoc);
    outBuf.values[i] = xBuf.values[originalIndex];
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js
var greaterImpl2 = createSimpleBinaryKernelImpl2((a, b) => a > b ? 1 : 0);
var greater5 = binaryKernelFunc2(Greater2, greaterImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js
var greaterEqualImpl2 = createSimpleBinaryKernelImpl2((a, b) => a >= b ? 1 : 0);
var greaterEqual4 = binaryKernelFunc2(GreaterEqual2, greaterEqualImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js
var lessImpl2 = createSimpleBinaryKernelImpl2((a, b) => a < b ? 1 : 0);
var less5 = binaryKernelFunc2(Less2, lessImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js
var lessEqualImpl2 = createSimpleBinaryKernelImpl2((a, b) => a <= b ? 1 : 0);
var lessEqual4 = binaryKernelFunc2(LessEqual2, lessEqualImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js
function linSpaceImpl2(start, stop, num) {
  const step6 = (stop - start) / (num - 1);
  const values = util_exports2.makeZerosTypedArray(num, "float32");
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step6;
  }
  return values;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js
var logImpl2 = createSimpleUnaryImpl2((xi) => Math.log(xi));
var log6 = unaryKernelFuncFromImpl2(Log2, logImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js
function maxImpl2(aVals, reduceSize, outShape, dtype) {
  const vals = util_exports2.getTypedArrayFromDType(dtype, util_exports2.sizeFromShape(outShape));
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max7 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value > max7) {
        max7 = value;
      }
    }
    vals[i] = max7;
  }
  return vals;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js
var maximumImpl2 = createSimpleBinaryKernelImpl2((aValue, bValue) => Math.max(aValue, bValue));
var maximum5 = binaryKernelFunc2(Maximum2, maximumImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js
var minimumImpl2 = createSimpleBinaryKernelImpl2((aValue, bValue) => Math.min(aValue, bValue));
var minimum5 = binaryKernelFunc2(Minimum2, minimumImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js
var multiplyImpl2 = createSimpleBinaryKernelImpl2((aValue, bValue) => aValue * bValue);
var multiplyComplexImpl2 = createComplexBinaryKernelImpl2((aReal, aImag, bReal, bImag) => {
  return {
    real: aReal * bReal - aImag * bImag,
    imag: aReal * bImag + aImag * bReal
  };
});
var multiply3 = binaryKernelFunc2(Multiply2, multiplyImpl2, multiplyComplexImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js
function negImpl2(xVals, xShape, xDtype) {
  const minusOne = util_exports2.createScalarValue(-1, xDtype);
  return multiplyImpl2([], xShape, minusOne, xVals, xDtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js
var notEqualImpl2 = createSimpleBinaryKernelImpl2((a, b) => a !== b ? 1 : 0);
var notEqual4 = binaryKernelFunc2(NotEqual2, notEqualImpl2, null, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js
function transposeImpl2(xVals, xShape, dtype, perm, newShape) {
  const xRank = xShape.length;
  const xSize = util_exports2.sizeFromShape(xShape);
  const xStrides = util_exports2.computeStrides(xShape);
  const newStrides = util_exports2.computeStrides(newShape);
  const result = util_exports2.getTypedArrayFromDType(dtype, util_exports2.sizeFromShape(newShape));
  for (let i = 0; i < xSize; ++i) {
    const loc = util_exports2.indexToLoc(i, xRank, xStrides);
    const newLoc = new Array(loc.length);
    for (let i2 = 0; i2 < newLoc.length; i2++) {
      newLoc[i2] = loc[perm[i2]];
    }
    const newIndex = util_exports2.locToIndex(newLoc, xRank, newStrides);
    result[newIndex] = xVals[i];
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js
function prodImpl2(xShape, xDtype, xVals, reductionAxes) {
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(xShape, reductionAxes);
  const outDtype = upcastType2(xDtype, "int32");
  const outVals = util_exports2.makeZerosTypedArray(util_exports2.sizeFromShape(outShape), outDtype);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  for (let i = 0; i < outVals.length; ++i) {
    const offset = i * reduceSize;
    let prod6 = 1;
    for (let j = 0; j < reduceSize; ++j) {
      prod6 *= xVals[offset + j];
    }
    outVals[i] = prod6;
  }
  return { outVals, outShape, outDtype };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js
function rangeImpl2(start, stop, step6, dtype) {
  const sameStartStop = start === stop;
  const increasingRangeNegativeStep = start < stop && step6 < 0;
  const decreasingRangePositiveStep = stop < start && step6 > 1;
  if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
    return util_exports2.makeZerosTypedArray(0, dtype);
  }
  const numElements = Math.abs(Math.ceil((stop - start) / step6));
  const values = util_exports2.makeZerosTypedArray(numElements, dtype);
  if (stop < start && step6 === 1) {
    step6 = -1;
  }
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step6;
  }
  return values;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js
var rsqrtImpl2 = createSimpleUnaryImpl2((xi) => 1 / Math.sqrt(xi));
var rsqrt4 = unaryKernelFuncFromImpl2(Rsqrt2, rsqrtImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js
function sliceImpl2(vals, begin, size, shape, dtype) {
  const isContinous = slice_util_exports2.isSliceContinous(shape, begin, size);
  const length = util_exports2.sizeFromShape(size);
  const xStrides = util_exports2.computeStrides(shape);
  if (isContinous) {
    const flatOffset = slice_util_exports2.computeFlatOffset(begin, xStrides);
    if (dtype === "string") {
      return vals.slice(flatOffset, flatOffset + length);
    }
    return vals.subarray(flatOffset, flatOffset + length);
  }
  const decodedData = dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(vals) : vals;
  const inBuf = buffer2(shape, dtype, decodedData);
  const outBuf = buffer2(size, dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.map((idx, j) => idx + begin[j]);
    outBuf.set(inBuf.get(...inLoc), ...outLoc);
  }
  if (dtype === "string") {
    return backend_util_exports2.fromStringArrayToUint8(outBuf.values);
  }
  return outBuf.values;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js
function sparseFillEmptyRowsImpl2(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
  const indicesCount = indicesShape[0];
  const denseRows = denseShape[0];
  const emptyRowIndicator = new Array(denseRows);
  const reverseIndexMap = new Array(indicesCount);
  const rank = indicesShape[1];
  if (denseRows === 0) {
    if (indicesCount !== 0) {
      throw new Error(`Received SparseTensor with denseShape[0] = 0 but
         indices.shape[0] = ${indicesCount}`);
    }
    const outputIndices = util_exports2.getArrayFromDType(indicesDType, 0);
    const outputValues = util_exports2.getArrayFromDType(valuesDType, 0);
    return [
      outputIndices,
      [0, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
  let rowsAreOrdered = true;
  let lastIndicesRow = 0;
  const csrOffset = new Array(denseRows).fill(0);
  for (let i = 0; i < indicesCount; ++i) {
    const row = indices[i * rank];
    if (row < 0) {
      throw new Error(`indices(${i}, 0) is invalid: ${row} < 0`);
    }
    if (row >= denseRows) {
      throw new Error(`indices(${i}, 0) is invalid: ${row} >= ${denseRows}`);
    }
    ++csrOffset[row];
    rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
    lastIndicesRow = row;
  }
  let allRowsFull = true;
  for (let row = 0; row < denseRows; ++row) {
    const rowEmpty = csrOffset[row] === 0;
    emptyRowIndicator[row] = rowEmpty;
    allRowsFull = allRowsFull && !rowEmpty;
    csrOffset[row] = Math.max(csrOffset[row], 1);
    if (row > 0) {
      csrOffset[row] += csrOffset[row - 1];
    }
  }
  if (allRowsFull && rowsAreOrdered) {
    const outputIndices = indices;
    const outputValues = values;
    for (let i = 0; i < indicesCount; ++i) {
      reverseIndexMap[i] = i;
    }
    return [
      outputIndices,
      [indicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  } else {
    const fullIndicesCount = csrOffset[denseRows - 1];
    const outputIndices = util_exports2.getArrayFromDType(indicesDType, fullIndicesCount * rank);
    const outputValues = util_exports2.getArrayFromDType(valuesDType, fullIndicesCount);
    const filledCount = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      const offset = filledCount[row];
      const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
      filledCount[row]++;
      for (let j = 0; j < rank; ++j) {
        outputIndices[outputI * rank + j] = indices[i * rank + j];
      }
      outputValues[outputI] = values[i];
      reverseIndexMap[i] = outputI;
    }
    for (let row = 0; row < denseRows; ++row) {
      const rowCount = filledCount[row];
      if (rowCount === 0) {
        const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
        outputIndices[startingIndex * rank + 0] = row;
        for (let col = 1; col < rank; ++col) {
          outputIndices[startingIndex * rank + col] = 0;
        }
        outputValues[startingIndex] = defaultValue;
      }
    }
    return [
      outputIndices,
      [fullIndicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js
function sparseReshapeImpl2(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
  const denseSize = util_exports2.sizeFromShape(inputShape);
  const nnz = inputIndicesShape[0];
  const outputRank = targetShape.length;
  const outputShape = [];
  let product = 1;
  let unknownIndex = -1;
  for (let d = 0; d < outputRank; ++d) {
    const size = targetShape[d];
    if (size === -1) {
      if (unknownIndex !== -1) {
        throw new Error(`only one output dimension may be -1, not both ${unknownIndex} and ${d}`);
      }
      unknownIndex = d;
      outputShape.push(1);
    } else {
      if (size < 0) {
        throw new Error(`size ${d} must be non-negative, not ${size}`);
      }
      product *= size;
      outputShape.push(size);
    }
  }
  if (unknownIndex !== -1) {
    if (product <= 0) {
      throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");
    }
    const missing = Math.trunc(denseSize / product);
    if (product * missing !== denseSize) {
      throw new Error(`Input to reshape is a SparseTensor with ${denseSize}
          dense values, but the requested shape requires a multiple of ${product}. inputShape=${inputShape} outputShape= ${outputShape}`);
    }
    outputShape[unknownIndex] = missing;
  }
  const outputSize = util_exports2.sizeFromShape(outputShape);
  if (outputSize !== denseSize) {
    throw new Error(`Input to reshape is a tensor with ${denseSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`);
  }
  const inputRank = inputShape.length;
  const inputStrides = [];
  if (inputRank > 0) {
    inputStrides[inputRank - 1] = 1;
    for (let d = inputRank - 2; d >= 0; --d) {
      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
    }
  }
  const outputStrides = [];
  if (outputRank > 0) {
    outputStrides[outputRank - 1] = 1;
    for (let d = outputRank - 2; d >= 0; --d) {
      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
    }
  }
  const newIndices = util_exports2.getArrayFromDType(inputDType, nnz * outputRank);
  for (let i = 0; i < nnz; ++i) {
    let id = 0;
    for (let j = 0; j < inputRank; ++j) {
      id += inputIndices[i * inputRank + j] * inputStrides[j];
    }
    for (let j = 0; j < outputRank; ++j) {
      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
      id %= outputStrides[j];
    }
  }
  return [newIndices, [nnz, outputRank], outputShape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js
function sparseSegmentReductionImpl2(input2, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
  const numIndices = indices.length;
  if (numIndices !== segmentIds.length) {
    throw new Error(`segmentIds and indices should have same size.`);
  }
  const inputFlat = [inputShape[0], input2.length / inputShape[0]];
  const numCol = inputFlat[1];
  const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
  const outputRows = lastSegmentIdPlusOne;
  if (outputRows < 0) {
    throw new Error(`segment ids must be >= 0`);
  }
  const outputShape = inputShape.slice();
  outputShape[0] = outputRows;
  const outputLength = outputShape.reduce((product, value) => product * value, 1);
  const output = util_exports2.getArrayFromDType(inputDType, outputLength);
  if (numIndices === 0) {
    if (outputRows > 0) {
      output.fill(defaultValue);
    }
    return [output, outputShape];
  }
  if (outputRows <= 0) {
    throw new Error(`segment ids must be >= 0`);
  }
  let start = 0, end = 1;
  let uninitializedIndex = 0;
  let outIndex = segmentIds[start];
  while (true) {
    let nextIndex = 0;
    if (end < numIndices) {
      nextIndex = segmentIds[end];
      if (outIndex === nextIndex) {
        ++end;
        continue;
      }
      if (outIndex >= nextIndex) {
        throw new Error(`segment ids are not increasing`);
      }
    }
    if (outIndex < 0 || outIndex >= outputRows) {
      throw new Error(`Segment id ${outIndex} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`);
    }
    if (outIndex > uninitializedIndex) {
      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
    }
    for (let i = start; i < end; ++i) {
      const index = indices[i];
      if (index < 0 || index >= inputFlat[0]) {
        throw new Error(`Bad: indices[${i}] == ${indices[i]} out of range [0, ${inputFlat[0]})`);
      }
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] += input2[index * numCol + j];
      }
    }
    if (isMean) {
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] /= end - start;
      }
    }
    start = end;
    ++end;
    uninitializedIndex = outIndex + 1;
    outIndex = nextIndex;
    if (end > numIndices) {
      break;
    }
  }
  if (uninitializedIndex < outputRows) {
    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
  }
  return [output, outputShape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js
var squaredDifferenceImpl2 = createSimpleBinaryKernelImpl2((a, b) => {
  const diff = a - b;
  return diff * diff;
});
var squaredDifference4 = binaryKernelFunc2(SquaredDifference2, squaredDifferenceImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js
function stridedSliceImpl2(outShape, xBuf, strides, begin) {
  const outBuf = buffer2(outShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; i++) {
    const loc = outBuf.indexToLoc(i);
    const newLoc = new Array(loc.length);
    for (let j = 0; j < newLoc.length; j++) {
      newLoc[j] = loc[j] * strides[j] + begin[j];
    }
    outBuf.set(xBuf.get(...newLoc), ...loc);
  }
  return outBuf;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js
var StringNGramsOp2 = class {
  constructor(separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
    this.separator = util_exports2.encodeString(separator);
    this.nGramWidths = nGramWidths;
    this.leftPad = util_exports2.encodeString(leftPad);
    this.rightPad = util_exports2.encodeString(rightPad3);
    this.padWidth = padWidth;
    this.preserveShort = preserveShortSequences;
  }
  getPadWidth(nGramWidth) {
    return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
  }
  getNumNGrams(length, nGramWidth) {
    const padWidth = this.getPadWidth(nGramWidth);
    return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
  }
  createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
      const padWidth = this.getPadWidth(nGramWidth);
      const leftPadding = Math.max(0, padWidth - nGramIndex);
      const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
      const numTokens = nGramWidth - (leftPadding + rightPadding);
      const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
      let nGramSize = 0;
      nGramSize += leftPadding * this.leftPad.length;
      for (let n = 0; n < numTokens; ++n) {
        nGramSize += data[dataStartIndex + n].length;
      }
      nGramSize += rightPadding * this.rightPad.length;
      const numSeparators = leftPadding + rightPadding + numTokens - 1;
      nGramSize += numSeparators * this.separator.length;
      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
      const nGram = output[outputStartIndex + nGramIndex];
      let nextNGramIndex = 0;
      const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
      for (let n = 0; n < leftPadding; ++n) {
        appendToNGram(this.leftPad);
        appendToNGram(this.separator);
      }
      for (let n = 0; n < numTokens - 1; ++n) {
        appendToNGram(data[dataStartIndex + n]);
        appendToNGram(this.separator);
      }
      if (numTokens > 0) {
        appendToNGram(data[dataStartIndex + numTokens - 1]);
        for (let n = 0; n < rightPadding; ++n) {
          appendToNGram(this.separator);
          appendToNGram(this.rightPad);
        }
      } else {
        for (let n = 0; n < rightPadding - 1; ++n) {
          appendToNGram(this.rightPad);
          appendToNGram(this.separator);
        }
        appendToNGram(this.rightPad);
      }
    }
  }
  compute(data, splits) {
    const inputDataSize = data.length;
    const splitsSize = splits.length;
    if (splitsSize > 0) {
      let prevSplit = splits[0];
      if (prevSplit !== 0) {
        throw new Error(`First split value must be 0, got ${prevSplit}`);
      }
      for (let i = 1; i < splitsSize; ++i) {
        let validSplits = splits[i] >= prevSplit;
        validSplits = validSplits && splits[i] <= inputDataSize;
        if (!validSplits) {
          throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
        }
        prevSplit = splits[i];
      }
      if (prevSplit !== inputDataSize) {
        throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
      }
    }
    const numBatchItems = splitsSize - 1;
    const nGramsSplits = util_exports2.getArrayFromDType("int32", splitsSize);
    if (inputDataSize === 0 || splitsSize === 0) {
      const empty = new Array(inputDataSize);
      for (let i = 0; i <= numBatchItems; ++i) {
        nGramsSplits[i] = 0;
      }
      return [empty, nGramsSplits];
    }
    nGramsSplits[0] = 0;
    for (let i = 1; i <= numBatchItems; ++i) {
      const length = splits[i] - splits[i - 1];
      let numNGrams = 0;
      this.nGramWidths.forEach((nGramWidth) => {
        numNGrams += this.getNumNGrams(length, nGramWidth);
      });
      if (this.preserveShort && length > 0 && numNGrams === 0) {
        numNGrams = 1;
      }
      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
    }
    const nGrams = new Array(nGramsSplits[numBatchItems]);
    for (let i = 0; i < numBatchItems; ++i) {
      const splitIndex = splits[i];
      let outputStartIdx = nGramsSplits[i];
      this.nGramWidths.forEach((nGramWidth) => {
        const length = splits[i + 1] - splits[i];
        const numNGrams = this.getNumNGrams(length, nGramWidth);
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
        outputStartIdx += numNGrams;
      });
      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
        const dataLength = splits[i + 1] - splits[i];
        if (dataLength === 0) {
          continue;
        }
        const nGramWidth = dataLength + 2 * this.padWidth;
        const numNGrams = 1;
        this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
      }
    }
    return [nGrams, nGramsSplits];
  }
};
function stringNGramsImpl2(data, dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences) {
  return new StringNGramsOp2(separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences).compute(data, dataSplits);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js
function split5(str, delimiters, skipEmpty) {
  if (!str.length) {
    return [];
  }
  if (delimiters.length === 0) {
    const result2 = new Array(str.length);
    for (let i = 0; i < str.length; ++i) {
      result2[i] = str.subarray(i, i + 1);
    }
    return result2;
  }
  if (delimiters.length === 1) {
    const delimiter = delimiters[0];
    const result2 = [];
    let f = str.indexOf(delimiter);
    while (f !== -1) {
      const token = str.subarray(0, f);
      if (!skipEmpty || token.length !== 0) {
        result2.push(token);
      }
      str = str.subarray(f + 1);
      f = str.indexOf(delimiter);
    }
    if (!skipEmpty || str.length !== 0) {
      result2.push(str);
    }
    return result2;
  }
  const result = [];
  let tokenStart = 0;
  for (let i = 0; i < str.length + 1; i++) {
    if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
      const token = str.subarray(tokenStart, i);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      tokenStart = i + 1;
    }
  }
  return result;
}
function stringSplitImpl2(input2, delimiter, skipEmpty) {
  const batchSize = input2.length;
  const tokens = [];
  let outputSize = 0;
  let maxNumEntries = 0;
  const numIndices = new Array(batchSize);
  for (let i = 0; i < batchSize; ++i) {
    const parts = split5(input2[i], delimiter, skipEmpty);
    const nEntries = parts.length;
    numIndices[i] = nEntries;
    outputSize += nEntries;
    maxNumEntries = Math.max(maxNumEntries, nEntries);
    tokens.push(...parts);
  }
  const indices = util_exports2.getArrayFromDType("int32", outputSize * 2);
  const values = new Array(outputSize);
  const shape = [batchSize, maxNumEntries];
  let c = 0;
  for (let i = 0; i < batchSize; ++i) {
    for (let j = 0; j < numIndices[i]; ++j) {
      indices[c * 2] = i;
      indices[c * 2 + 1] = j;
      values[c] = tokens[c];
      ++c;
    }
  }
  return [indices, values, shape];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js
function stringToHashBucketFastImpl2(input2, numBuckets) {
  const output = util_exports2.getArrayFromDType("int32", input2.length);
  for (let i = 0; i < input2.length; ++i) {
    output[i] = util_exports2.fingerPrint64(input2[i]).modulo(numBuckets).getLowBitsUnsigned();
  }
  return output;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js
var subImpl2 = createSimpleBinaryKernelImpl2((aValue, bValue) => aValue - bValue);
var subComplexImpl2 = createComplexBinaryKernelImpl2((aReal, aImag, bReal, bImag) => {
  return { real: aReal - bReal, imag: aImag - bImag };
});
var sub4 = binaryKernelFunc2(Sub2, subImpl2, subComplexImpl2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js
function tileImpl2(xBuf, reps) {
  const newShape = new Array(xBuf.rank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = xBuf.shape[i] * reps[i];
  }
  const result = buffer2(newShape, xBuf.dtype);
  for (let i = 0; i < result.values.length; ++i) {
    const newLoc = result.indexToLoc(i);
    const originalLoc = new Array(xBuf.rank);
    for (let j = 0; j < originalLoc.length; j++) {
      originalLoc[j] = newLoc[j] % xBuf.shape[j];
    }
    const originalIndex = xBuf.locToIndex(originalLoc);
    result.values[i] = xBuf.values[originalIndex];
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js
function topKImpl2(x, xShape, xDtype, k, sorted) {
  const lastDim = xShape[xShape.length - 1];
  const [batch, size] = [x.length / lastDim, lastDim];
  const allTopKVals = util_exports2.getTypedArrayFromDType(xDtype, batch * k);
  const allTopKIndices = util_exports2.getTypedArrayFromDType("int32", batch * k);
  for (let b = 0; b < batch; b++) {
    const offset = b * size;
    const vals = x.subarray(offset, offset + size);
    const valAndInd = [];
    for (let i = 0; i < vals.length; i++) {
      valAndInd.push({ value: vals[i], index: i });
    }
    valAndInd.sort((a, b2) => b2.value - a.value);
    const outOffset = b * k;
    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
    for (let i = 0; i < k; i++) {
      topKVals[i] = valAndInd[i].value;
      topKIndices[i] = valAndInd[i].index;
    }
  }
  const outputShape = xShape.slice();
  outputShape[outputShape.length - 1] = k;
  return [
    buffer2(outputShape, xDtype, allTopKVals),
    buffer2(outputShape, "int32", allTopKIndices)
  ];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-cpu@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js
function uniqueImpl2(values, axis, shape, dtype) {
  const $axis = util_exports2.parseAxisParam(axis, shape)[0];
  const newShape = [1, shape[0], 1];
  for (let i = 0; i < $axis; i++) {
    newShape[0] *= shape[i];
  }
  newShape[1] = shape[$axis];
  for (let i = $axis + 1; i < shape.length; i++) {
    newShape[2] *= shape[i];
  }
  const uniqueElements = {};
  const indices = new Int32Array(shape[$axis]);
  const inputBuffer = new TensorBuffer2(newShape, dtype, values);
  const uniqueIndices = [];
  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
  for (let i = 0; i < shape[$axis]; i++) {
    let element;
    if (is1DTensor) {
      element = values[i].toString();
    } else {
      const axisValues = [];
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          axisValues.push(inputBuffer.get(m, i, n));
        }
      }
      element = axisValues.join(",");
    }
    if (uniqueElements[element] !== void 0) {
      indices[i] = uniqueElements[element];
    } else {
      const uniqueIndex = Object.keys(uniqueElements).length;
      uniqueElements[element] = uniqueIndex;
      indices[i] = uniqueIndex;
      uniqueIndices.push(i);
    }
  }
  const outputTmpShape = newShape.slice();
  outputTmpShape[1] = Object.keys(uniqueElements).length;
  const outputBuffer = new TensorBuffer2(outputTmpShape, dtype);
  uniqueIndices.forEach((uniqueElementIndex, i) => {
    for (let m = 0; m < newShape[0]; m++) {
      for (let n = 0; n < newShape[2]; n++) {
        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
      }
    }
  });
  const outputShape = shape.slice();
  outputShape[$axis] = outputTmpShape[1];
  return {
    outputValues: outputBuffer.values,
    outputShape,
    indices
  };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/shared.ts
var {
  addImpl: addImplCPU,
  bincountImpl: bincountImplCPU,
  bincountReduceImpl: bincountReduceImplCPU,
  ceilImpl: ceilImplCPU,
  concatImpl: concatImplCPU,
  equalImpl: equalImplCPU,
  expImpl: expImplCPU,
  expm1Impl: expm1ImplCPU,
  floorImpl: floorImplCPU,
  gatherNdImpl: gatherNdImplCPU,
  gatherV2Impl: gatherV2ImplCPU,
  greaterImpl: greaterImplCPU,
  greaterEqualImpl: greaterEqualImplCPU,
  lessImpl: lessImplCPU,
  lessEqualImpl: lessEqualImplCPU,
  linSpaceImpl: linSpaceImplCPU,
  logImpl: logImplCPU,
  maxImpl: maxImplCPU,
  maximumImpl: maximumImplCPU,
  minimumImpl: minimumImplCPU,
  multiplyImpl: multiplyImplCPU,
  negImpl: negImplCPU,
  notEqualImpl: notEqualImplCPU,
  prodImpl: prodImplCPU,
  rangeImpl: rangeImplCPU,
  rsqrtImpl: rsqrtImplCPU,
  simpleAbsImpl: simpleAbsImplCPU,
  sliceImpl: sliceImplCPU,
  sparseFillEmptyRowsImpl: sparseFillEmptyRowsImplCPU,
  sparseReshapeImpl: sparseReshapeImplCPU,
  sparseSegmentReductionImpl: sparseSegmentReductionImplCPU,
  stridedSliceImpl: stridedSliceImplCPU,
  stringNGramsImpl: stringNGramsImplCPU,
  stringSplitImpl: stringSplitImplCPU,
  stringToHashBucketFastImpl: stringToHashBucketFastImplCPU,
  subImpl: subImplCPU,
  tileImpl: tileImplCPU,
  topKImpl: topKImplCPU,
  transposeImpl: transposeImplCPU,
  uniqueImpl: uniqueImplCPU
} = shared_exports2;

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/packing_util.ts
function getVecChannels(name, rank) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, rank).map((d) => `${name}.${d}`);
}
function getChannels(name, rank) {
  if (rank === 1) {
    return [name];
  }
  return getVecChannels(name, rank);
}
function getSourceCoords(rank, dims) {
  if (rank === 1) {
    return "rc";
  }
  let coords2 = "";
  for (let i = 0; i < rank; i++) {
    coords2 += dims[i];
    if (i < rank - 1) {
      coords2 += ",";
    }
  }
  return coords2;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/pack_gpu.ts
var PackProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = false;
    this.packedOutput = true;
    this.outputShape = outputShape;
    const rank = outputShape.length;
    if (rank === 0) {
      this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
    } else {
      const channels = getChannels("rc", rank);
      const dtype = getCoordsDataType(rank);
      const outOfBoundsCondition = getOutOfBoundsCondition(rank, outputShape, channels);
      const setup46 = getSetup(rank, outputShape[outputShape.length - 1], outputShape[outputShape.length - 2], channels);
      const output = getOutput(outputShape, channels);
      this.userCode = `
        void main() {
          ${dtype} rc = getOutputCoords();

          if(${outOfBoundsCondition}) {
            setOutput(vec4(0));
          } else {
            ${setup46}

            setOutput(vec4(${output}));
          }
        }
      `;
    }
  }
};
function getSourceCoordsArr(rank, dims) {
  const coords2 = [];
  for (let row = 0; row <= 1; row++) {
    for (let col = 0; col <= 1; col++) {
      let coord = `${row === 0 ? "r" : "rp1"}, ${col === 0 ? "c" : "cp1"}`;
      for (let d = 2; d < rank; d++) {
        coord = `${dims[dims.length - 1 - d]},` + coord;
      }
      coords2.push(coord);
    }
  }
  return coords2;
}
function getOutOfBoundsCondition(rank, shape, dims) {
  if (rank === 1) {
    return `rc > ${shape[0]}`;
  }
  let cond = "";
  for (let i = rank - 2; i < rank; i++) {
    cond += `${dims[i]} >= ${shape[i]}`;
    if (i < rank - 1) {
      cond += "||";
    }
  }
  return cond;
}
function getSetup(rank, cols, rows, dims) {
  if (rank === 1) {
    return "";
  }
  const innerDims = dims.slice(-2);
  return `
    int r = ${innerDims[0]};
    int c = ${innerDims[1]};
    int rp1 = r + 1;
    int cp1 = c + 1;

    bool cEdge = cp1 >= ${cols};
    bool rEdge = rp1 >= ${rows};
  `;
}
function getOutput(shape, dims) {
  const rank = shape.length;
  const sourceCoords = getSourceCoordsArr(rank, dims);
  if (rank === 1) {
    return `getA(rc),
            rc + 1 >= ${shape[0]} ? 0. : getA(rc + 1),
            0, 0`;
  }
  return `getA(${sourceCoords[0]}),
          cEdge ? 0. : getA(${sourceCoords[1]}),
          rEdge ? 0. : getA(${sourceCoords[2]}),
          rEdge || cEdge ? 0. : getA(${sourceCoords[3]})`;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/reshape_packed_gpu.ts
var ReshapePackedProgram = class {
  constructor(outputShape, inputShape) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = outputShape;
    let mainLoop = ``;
    for (let i = 0; i < 4; i++) {
      let thisRC = `thisRC = rc;`;
      if (i % 2 === 1) {
        thisRC += `thisRC.z += 1;`;
      }
      if (i > 1) {
        thisRC += `thisRC.y += 1;`;
      }
      mainLoop += `
        ${thisRC}
        ${i > 0 ? `if(thisRC.y < rows && thisRC.z < cols){` : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${i}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${i > 0 ? "}" : ""}
      `;
    }
    this.userCode = `
      ${getReshapedInputCoords(inputShape)}
      ${getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${outputShape[1]};
        int cols = ${outputShape[2]};

        ${mainLoop}

        setOutput(result);
      }
    `;
  }
};
function getReshapedInputCoords(shape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
  return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/texture_manager.ts
var TextureManager = class {
  constructor(gpgpu) {
    this.gpgpu = gpgpu;
    this.numUsedTextures = 0;
    this.numFreeTextures = 0;
    this._numBytesAllocated = 0;
    this._numBytesFree = 0;
    this.freeTextures = {};
    this.logEnabled = false;
    this.usedTextures = {};
  }
  acquireTexture(shapeRC, usage, isPacked) {
    const physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);
    const shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);
    if (!(shapeKey in this.freeTextures)) {
      this.freeTextures[shapeKey] = [];
    }
    if (!(shapeKey in this.usedTextures)) {
      this.usedTextures[shapeKey] = [];
    }
    const texBytes = computeBytes(shapeRC, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
    if (this.freeTextures[shapeKey].length > 0) {
      this.numFreeTextures--;
      this.numUsedTextures++;
      this._numBytesFree -= texBytes;
      this.log();
      const newTexture2 = this.freeTextures[shapeKey].shift();
      this.usedTextures[shapeKey].push(newTexture2);
      return newTexture2;
    }
    let newTexture;
    if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT32) {
      newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);
    } else if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT16) {
      newTexture = this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);
    } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT32) {
      newTexture = this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);
    } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT16) {
      newTexture = this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);
    } else if (physicalTexType === PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {
      newTexture = this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);
    }
    this.usedTextures[shapeKey].push(newTexture);
    this.numUsedTextures++;
    this._numBytesAllocated += texBytes;
    this.log();
    return newTexture;
  }
  releaseTexture(texture, shape, logicalTexType, isPacked) {
    if (this.freeTextures == null) {
      return;
    }
    const physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);
    const shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);
    if (!(shapeKey in this.freeTextures)) {
      this.freeTextures[shapeKey] = [];
    }
    const texBytes = computeBytes(shape, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
    const deleteTexThreshold = env2().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
    if (deleteTexThreshold !== -1 && this._numBytesAllocated > deleteTexThreshold) {
      this.gpgpu.deleteMatrixTexture(texture);
      this._numBytesAllocated -= texBytes;
    } else {
      this.freeTextures[shapeKey].push(texture);
      this.numFreeTextures++;
      this._numBytesFree += texBytes;
    }
    this.numUsedTextures--;
    const texList = this.usedTextures[shapeKey];
    const texIndex = texList.indexOf(texture);
    if (texIndex < 0) {
      throw new Error("Cannot release a texture that was never provided by this texture manager");
    }
    texList.splice(texIndex, 1);
    this.log();
  }
  log() {
    if (!this.logEnabled) {
      return;
    }
    const total = this.numFreeTextures + this.numUsedTextures;
    console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${total})`);
    const freeRatio = this._numBytesFree / this._numBytesAllocated;
    console.log(`Bytes allocated: ${this._numBytesAllocated}`);
    console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * freeRatio)}%)`);
  }
  get numBytesAllocated() {
    return this._numBytesAllocated;
  }
  get numBytesFree() {
    return this._numBytesFree;
  }
  getNumUsedTextures() {
    return this.numUsedTextures;
  }
  getNumFreeTextures() {
    return this.numFreeTextures;
  }
  dispose() {
    if (this.freeTextures == null) {
      return;
    }
    for (const texShape in this.freeTextures) {
      this.freeTextures[texShape].forEach((tex) => {
        this.gpgpu.deleteMatrixTexture(tex);
      });
    }
    for (const texShape in this.usedTextures) {
      this.usedTextures[texShape].forEach((tex) => {
        this.gpgpu.deleteMatrixTexture(tex);
      });
    }
    this.freeTextures = null;
    this.usedTextures = null;
    this.numUsedTextures = 0;
    this.numFreeTextures = 0;
    this._numBytesAllocated = 0;
    this._numBytesFree = 0;
  }
};
function numBytesForInternalFormat(gl, internalFormat) {
  const glany = gl;
  if (internalFormat === glany.R32F) {
    return 4;
  } else if (internalFormat === glany.R16F) {
    return 2;
  } else if (internalFormat === glany.RGBA32F) {
    return 16;
  } else if (internalFormat === gl.RGBA) {
    return 16;
  } else if (internalFormat === glany.RGBA16F) {
    return 8;
  }
  throw new Error(`Unknown internal format ${internalFormat}`);
}
function computeBytes(shape, physicalTexType, gl, textureConfig, isPacked) {
  const internalFormat = internalFormatForPhysicalTexType(physicalTexType, textureConfig);
  let numElements;
  if (isPacked) {
    const [packedWidth, packedHeight] = getPackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
    numElements = packedWidth * packedHeight;
  } else {
    const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
    numElements = width * height;
  }
  const bytesPerElement3 = numBytesForInternalFormat(gl, internalFormat);
  return numElements * bytesPerElement3;
}
function internalFormatForPhysicalTexType(physicalTexType, textureConfig) {
  switch (physicalTexType) {
    case PhysicalTextureType.PACKED_2X2_FLOAT32:
      return getInternalFormatForPackedMatrixTexture(textureConfig);
    case PhysicalTextureType.PACKED_2X2_FLOAT16:
      return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);
    case PhysicalTextureType.UNPACKED_FLOAT32:
      return getInternalFormatForFloat32MatrixTexture(textureConfig);
    case PhysicalTextureType.UNPACKED_FLOAT16:
      return getInternalFormatForFloat16MatrixTexture(textureConfig);
    case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:
      return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);
    default:
      throw new Error(`Unknown physical texture type ${physicalTexType}`);
  }
}
function getPhysicalTextureForRendering(isPacked) {
  if (env2().getBool("WEBGL_RENDER_FLOAT32_ENABLED")) {
    if (isPacked) {
      return PhysicalTextureType.PACKED_2X2_FLOAT32;
    }
    return PhysicalTextureType.UNPACKED_FLOAT32;
  }
  if (isPacked) {
    return PhysicalTextureType.PACKED_2X2_FLOAT16;
  }
  return PhysicalTextureType.UNPACKED_FLOAT16;
}
function getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {
  if (logicalTexType === TextureUsage.UPLOAD) {
    return PhysicalTextureType.PACKED_2X2_FLOAT32;
  } else if (logicalTexType === TextureUsage.RENDER || logicalTexType == null) {
    return getPhysicalTextureForRendering(isPacked);
  } else if (logicalTexType === TextureUsage.DOWNLOAD || logicalTexType === TextureUsage.PIXELS) {
    return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;
  }
  throw new Error(`Unknown logical texture type ${logicalTexType}`);
}
function getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {
  return `${shapeRowsCol[0]}_${shapeRowsCol[1]}_${physicalTexType}_${isPacked}`;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/unaryop_gpu.ts
var UnaryOpProgram = class {
  constructor(aShape, opSnippet) {
    this.variableNames = ["A"];
    this.outputShape = aShape;
    this.userCode = `
      float unaryOperation(float x) {
        ${opSnippet}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var CHECK_NAN_SNIPPET = `if (isnan(x)) return x;`;
var LINEAR = `return x;`;
var ABS = `return abs(x);`;
var ELU2 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
var RELU = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
var RELU6 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var CLONE = "return x;";
var SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * x));`;

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/unaryop_packed_gpu.ts
var LINEAR2 = `return x;`;
var ELU3 = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var RELU2 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var RELU62 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var SIGMOID2 = `return 1.0 / (1.0 + exp(-1.0 * x));`;
var UnaryOpPackedProgram = class {
  constructor(aShape, opSnippet) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = aShape;
    this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${opSnippet}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/unpack_gpu.ts
var UnpackProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = false;
    this.outputShape = outputShape;
    const rank = outputShape.length;
    const channels = getChannels("rc", rank);
    const dtype = getCoordsDataType(rank);
    const sourceCoords = getSourceCoords(rank, channels);
    const innerDims = channels.slice(-2);
    const coords2 = rank <= 1 ? "rc" : `vec2(${innerDims.join(",")})`;
    this.userCode = `
      void main() {
        ${dtype} rc = getOutputCoords();
        vec4 packedInput = getA(${sourceCoords});

        setOutput(getChannel(packedInput, ${coords2}));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/backend_webgl.ts
var whereImpl4 = kernel_impls_exports2.whereImpl;
var EPSILON_FLOAT323 = 1e-7;
var EPSILON_FLOAT163 = 1e-4;
var binaryCaches = {};
function getBinaryCache(webGLVersion) {
  if (webGLVersion in binaryCaches) {
    return binaryCaches[webGLVersion];
  }
  binaryCaches[webGLVersion] = {};
  return binaryCaches[webGLVersion];
}
var CPU_HANDOFF_SIZE_THRESHOLD = env2().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
var BEFORE_PAGING_CONSTANT = 600;
function numMBBeforeWarning() {
  if (env2().global.screen == null) {
    return 1024;
  }
  return env2().global.screen.height * env2().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;
}
var _MathBackendWebGL = class extends KernelBackend2 {
  constructor(gpgpu) {
    super();
    this.pendingRead = new WeakMap();
    this.pendingDisposal = new WeakSet();
    this.dataRefCount = new WeakMap();
    this.numBytesInGPU = 0;
    this.uploadWaitMs = 0;
    this.downloadWaitMs = 0;
    this.lastGlFlushTime = 0;
    this.warnedAboutMemory = false;
    this.pendingDeletes = 0;
    this.disposed = false;
    if (!env2().getBool("HAS_WEBGL")) {
      throw new Error("WebGL is not supported on this device");
    }
    if (gpgpu == null) {
      const gl = getWebGLContext(env2().getNumber("WEBGL_VERSION"));
      this.binaryCache = getBinaryCache(env2().getNumber("WEBGL_VERSION"));
      this.gpgpu = new GPGPUContext(gl);
      this.canvas = gl.canvas;
      this.gpgpuCreatedLocally = true;
    } else {
      this.gpgpu = gpgpu;
      this.binaryCache = {};
      this.gpgpuCreatedLocally = false;
      this.canvas = gpgpu.gl.canvas;
    }
    this.textureManager = new TextureManager(this.gpgpu);
    this.numMBBeforeWarning = numMBBeforeWarning();
    this.texData = new DataStorage2(this, engine2());
  }
  nextDataId() {
    return _MathBackendWebGL.nextDataId++;
  }
  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }
  write(values, shape, dtype) {
    if (env2().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || env2().getBool("DEBUG")) {
      this.checkNumericalProblems(values);
    }
    if (dtype === "complex64" && values != null) {
      throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
    }
    const dataId = { id: this.nextDataId() };
    this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount: 1 });
    return dataId;
  }
  refCount(dataId) {
    if (this.texData.has(dataId)) {
      const tensorData = this.texData.get(dataId);
      return tensorData.refCount;
    }
    return 0;
  }
  incRef(dataId) {
    const texData = this.texData.get(dataId);
    texData.refCount++;
  }
  decRef(dataId) {
    if (this.texData.has(dataId)) {
      const texData = this.texData.get(dataId);
      texData.refCount--;
    }
  }
  move(dataId, values, shape, dtype, refCount) {
    if (env2().getBool("DEBUG")) {
      this.checkNumericalProblems(values);
    }
    if (dtype === "complex64") {
      throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
    }
    this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount });
  }
  disposeIntermediateTensorInfo(tensorInfo) {
    this.disposeData(tensorInfo.dataId);
  }
  readSync(dataId) {
    const texData = this.texData.get(dataId);
    const { values, dtype, complexTensorInfos, slice: slice6, shape, isPacked } = texData;
    if (slice6 != null) {
      let program;
      if (isPacked) {
        program = new UnaryOpPackedProgram(shape, CLONE);
      } else {
        program = new UnaryOpProgram(shape, CLONE);
      }
      const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
      const data = this.readSync(res.dataId);
      this.disposeIntermediateTensorInfo(res);
      return data;
    }
    if (values != null) {
      return this.convertAndCacheOnCPU(dataId);
    }
    if (dtype === "string") {
      return values;
    }
    const shouldTimeProgram = this.activeTimers != null;
    let start;
    if (shouldTimeProgram) {
      start = util_exports2.now();
    }
    let result;
    if (dtype === "complex64") {
      const realValues = this.readSync(complexTensorInfos.real.dataId);
      const imagValues = this.readSync(complexTensorInfos.imag.dataId);
      result = backend_util_exports2.mergeRealAndImagArrays(realValues, imagValues);
    } else {
      result = this.getValuesFromTexture(dataId);
    }
    if (shouldTimeProgram) {
      this.downloadWaitMs += util_exports2.now() - start;
    }
    return this.convertAndCacheOnCPU(dataId, result);
  }
  async read(dataId) {
    if (this.pendingRead.has(dataId)) {
      const subscribers2 = this.pendingRead.get(dataId);
      return new Promise((resolve) => subscribers2.push(resolve));
    }
    const texData = this.texData.get(dataId);
    const { values, shape, slice: slice6, dtype, complexTensorInfos, isPacked } = texData;
    if (slice6 != null) {
      let program;
      if (isPacked) {
        program = new UnaryOpPackedProgram(shape, CLONE);
      } else {
        program = new UnaryOpProgram(shape, CLONE);
      }
      const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
      const data = this.read(res.dataId);
      this.disposeIntermediateTensorInfo(res);
      return data;
    }
    if (values != null) {
      return this.convertAndCacheOnCPU(dataId);
    }
    if (!env2().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && env2().getNumber("WEBGL_VERSION") === 2) {
      throw new Error(`tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.`);
    }
    let buffer3 = null;
    let tmpDownloadTarget;
    if (dtype !== "complex64" && env2().get("WEBGL_BUFFER_SUPPORTED")) {
      tmpDownloadTarget = this.decode(dataId);
      const tmpData = this.texData.get(tmpDownloadTarget.dataId);
      buffer3 = this.gpgpu.createBufferFromTexture(tmpData.texture, ...getDenseTexShape(shape));
    }
    this.pendingRead.set(dataId, []);
    if (dtype !== "complex64") {
      await this.gpgpu.createAndWaitForFence();
    }
    let vals;
    if (dtype === "complex64") {
      const ps = await Promise.all([
        this.read(complexTensorInfos.real.dataId),
        this.read(complexTensorInfos.imag.dataId)
      ]);
      const realValues = ps[0];
      const imagValues = ps[1];
      vals = backend_util_exports2.mergeRealAndImagArrays(realValues, imagValues);
    } else if (buffer3 == null) {
      vals = this.getValuesFromTexture(dataId);
    } else {
      const size = util_exports2.sizeFromShape(shape);
      vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer3, size);
    }
    if (tmpDownloadTarget != null) {
      this.disposeIntermediateTensorInfo(tmpDownloadTarget);
    }
    const dTypeVals = this.convertAndCacheOnCPU(dataId, vals);
    const subscribers = this.pendingRead.get(dataId);
    this.pendingRead.delete(dataId);
    subscribers.forEach((resolve) => resolve(dTypeVals));
    if (this.pendingDisposal.has(dataId)) {
      this.pendingDisposal.delete(dataId);
      if (this.disposeData(dataId)) {
        engine2().removeDataId(dataId, this);
      }
      this.pendingDeletes--;
    }
    return dTypeVals;
  }
  bufferSync(t) {
    const data = this.readSync(t.dataId);
    let decodedData = data;
    if (t.dtype === "string") {
      try {
        decodedData = data.map((d) => util_exports2.decodeString(d));
      } catch (e) {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    }
    return buffer2(t.shape, t.dtype, decodedData);
  }
  checkNumericalProblems(values) {
    if (values == null) {
      return;
    }
    for (let i = 0; i < values.length; i++) {
      const num = values[i];
      if (!canBeRepresented(num)) {
        if (env2().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) {
          throw Error(`The value ${num} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);
        }
        throw Error(`The value ${num} cannot be represented on this device.`);
      }
    }
  }
  getValuesFromTexture(dataId) {
    const { shape, dtype, isPacked } = this.texData.get(dataId);
    const size = util_exports2.sizeFromShape(shape);
    if (env2().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      const tmpTarget = this.decode(dataId);
      const tmpData2 = this.texData.get(tmpTarget.dataId);
      const vals2 = this.gpgpu.downloadMatrixFromPackedTexture(tmpData2.texture, ...getDenseTexShape(shape)).subarray(0, size);
      this.disposeIntermediateTensorInfo(tmpTarget);
      return vals2;
    }
    const shouldUsePackedProgram = env2().getBool("WEBGL_PACK") && isPacked === true;
    const outputShape = shouldUsePackedProgram ? getShapeAs3D(shape) : shape;
    const program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);
    const output = this.runWebGLProgram(program, [{ shape: outputShape, dtype, dataId }], "float32");
    const tmpData = this.texData.get(output.dataId);
    const vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size);
    this.disposeIntermediateTensorInfo(output);
    return vals;
  }
  timerAvailable() {
    return env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }
  async time(f) {
    const oldActiveTimers = this.activeTimers;
    const newActiveTimers = [];
    let outerMostTime = false;
    if (this.programTimersStack == null) {
      this.programTimersStack = newActiveTimers;
      outerMostTime = true;
    } else {
      this.activeTimers.push(newActiveTimers);
    }
    this.activeTimers = newActiveTimers;
    f();
    const flattenedActiveTimerQueries = util_exports2.flatten(this.activeTimers.map((d) => d.query)).filter((d) => d != null);
    const flattenedActiveTimerNames = util_exports2.flatten(this.activeTimers.map((d) => d.name)).filter((d) => d != null);
    this.activeTimers = oldActiveTimers;
    if (outerMostTime) {
      this.programTimersStack = null;
    }
    const res = {
      uploadWaitMs: this.uploadWaitMs,
      downloadWaitMs: this.downloadWaitMs,
      kernelMs: null,
      wallMs: null
    };
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
      const kernelMs = await Promise.all(flattenedActiveTimerQueries);
      res["kernelMs"] = util_exports2.sum(kernelMs);
      res["getExtraProfileInfo"] = () => kernelMs.map((d, i) => ({ name: flattenedActiveTimerNames[i], ms: d })).map((d) => `${d.name}: ${d.ms}`).join(", ");
    } else {
      res["kernelMs"] = {
        error: "WebGL query timers are not supported in this environment."
      };
    }
    this.uploadWaitMs = 0;
    this.downloadWaitMs = 0;
    return res;
  }
  memory() {
    return {
      unreliable: false,
      numBytesInGPU: this.numBytesInGPU,
      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
      numBytesInGPUFree: this.textureManager.numBytesFree
    };
  }
  startTimer() {
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
      return this.gpgpu.beginQuery();
    }
    return { startMs: util_exports2.now(), endMs: null };
  }
  endTimer(query) {
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
      this.gpgpu.endQuery();
      return query;
    }
    query.endMs = util_exports2.now();
    return query;
  }
  async getQueryTime(query) {
    if (env2().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
      return this.gpgpu.waitForQueryAndGetTime(query);
    }
    const timerQuery = query;
    return timerQuery.endMs - timerQuery.startMs;
  }
  disposeData(dataId, force = false) {
    if (this.pendingDisposal.has(dataId)) {
      return false;
    }
    if (!this.texData.has(dataId)) {
      return true;
    }
    if (force) {
      this.texData.get(dataId).refCount = 0;
    } else {
      this.texData.get(dataId).refCount--;
    }
    if (!force && this.texData.get(dataId).refCount > 0) {
      return false;
    }
    if (this.pendingRead.has(dataId)) {
      this.pendingDisposal.add(dataId);
      this.pendingDeletes++;
      return false;
    }
    this.releaseGPUData(dataId);
    const { complexTensorInfos } = this.texData.get(dataId);
    if (complexTensorInfos != null) {
      this.disposeData(complexTensorInfos.real.dataId, force);
      this.disposeData(complexTensorInfos.imag.dataId, force);
    }
    this.texData.delete(dataId);
    return true;
  }
  releaseGPUData(dataId) {
    const { texture, dtype, texShape, usage, isPacked, slice: slice6 } = this.texData.get(dataId);
    const key = slice6 && slice6.origDataId || dataId;
    const refCount = this.dataRefCount.get(key);
    if (refCount > 1) {
      this.dataRefCount.set(key, refCount - 1);
    } else {
      this.dataRefCount.delete(key);
      if (texture != null) {
        this.numBytesInGPU -= this.computeBytes(texShape, dtype);
        this.textureManager.releaseTexture(texture, texShape, usage, isPacked);
      }
    }
    const texData = this.texData.get(dataId);
    texData.texture = null;
    texData.texShape = null;
    texData.isPacked = false;
    texData.slice = null;
  }
  getTexture(dataId) {
    this.uploadToGPU(dataId);
    return this.texData.get(dataId).texture;
  }
  getDataInfo(dataId) {
    return this.texData.get(dataId);
  }
  shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {
    return env2().getBool("WEBGL_CPU_FORWARD") && inputs.every((input2) => this.texData.get(input2.dataId).texture == null && util_exports2.sizeFromShape(input2.shape) < sizeThreshold);
  }
  getGPGPUContext() {
    return this.gpgpu;
  }
  where(condition) {
    backend_util_exports2.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    const condVals = condition.dataSync();
    return whereImpl4(condition.shape, condVals);
  }
  packedUnaryOp(x, op3, dtype) {
    const program = new UnaryOpPackedProgram(x.shape, op3);
    const outInfo = this.compileAndRun(program, [x], dtype);
    return engine2().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
  }
  abs(x) {
    if (this.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
      const outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);
      return this.makeOutput(x.shape, x.dtype, outValues);
    }
    if (env2().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
      return this.packedUnaryOp(x, ABS, x.dtype);
    }
    const program = new UnaryOpProgram(x.shape, ABS);
    const outInfo = this.compileAndRun(program, [x]);
    return engine2().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
  }
  makeTensorInfo(shape, dtype, values) {
    let dataId;
    if (dtype === "string" && values != null && values.length > 0 && util_exports2.isString(values[0])) {
      const encodedValues = values.map((d) => util_exports2.encodeString(d));
      dataId = this.write(encodedValues, shape, dtype);
    } else {
      dataId = this.write(values, shape, dtype);
    }
    this.texData.get(dataId).usage = null;
    return { dataId, shape, dtype };
  }
  makeOutput(shape, dtype, values) {
    const { dataId } = this.makeTensorInfo(shape, dtype, values);
    return engine2().makeTensorFromDataId(dataId, shape, dtype, this);
  }
  unpackTensor(input2) {
    const program = new UnpackProgram(input2.shape);
    return this.runWebGLProgram(program, [input2], input2.dtype);
  }
  packTensor(input2) {
    const program = new PackProgram(input2.shape);
    const preventEagerUnpackingOutput = true;
    return this.runWebGLProgram(program, [input2], input2.dtype, null, preventEagerUnpackingOutput);
  }
  packedReshape(input2, afterShape) {
    const input3DShape = [
      getBatchDim(input2.shape),
      ...getRowsCols(input2.shape)
    ];
    const input3D = {
      dtype: input2.dtype,
      shape: input3DShape,
      dataId: input2.dataId
    };
    const afterShapeAs3D = [
      getBatchDim(afterShape),
      ...getRowsCols(afterShape)
    ];
    const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
    const preventEagerUnpackingOfOutput = true;
    const output = this.runWebGLProgram(program, [input3D], input2.dtype, null, preventEagerUnpackingOfOutput);
    return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
  }
  decode(dataId) {
    const texData = this.texData.get(dataId);
    const { isPacked, shape, dtype } = texData;
    const shapeAs3D = getShapeAs3D(shape);
    let program;
    if (isPacked) {
      program = new DecodeMatrixPackedProgram(shapeAs3D);
    } else {
      program = new DecodeMatrixProgram(shapeAs3D);
    }
    const preventEagerUnpackingOfOutput = true;
    const out = this.runWebGLProgram(program, [{ shape: shapeAs3D, dtype, dataId }], dtype, null, preventEagerUnpackingOfOutput);
    return { dtype, shape, dataId: out.dataId };
  }
  runWebGLProgram(program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput = false) {
    const output = this.makeTensorInfo(program.outputShape, outputDtype);
    const outData = this.texData.get(output.dataId);
    if (program.packedOutput) {
      outData.isPacked = true;
    }
    if (program.outPackingScheme === PackingScheme.DENSE) {
      const texelShape = getDenseTexShape(program.outputShape);
      outData.texShape = texelShape.map((d) => d * 2);
    }
    if (program.outTexUsage != null) {
      outData.usage = program.outTexUsage;
    }
    if (util_exports2.sizeFromShape(output.shape) === 0) {
      outData.values = util_exports2.getTypedArrayFromDType(output.dtype, 0);
      return output;
    }
    const dataToDispose = [];
    const inputsData = inputs.map((input2) => {
      if (input2.dtype === "complex64") {
        throw new Error(`GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.`);
      }
      let texData = this.texData.get(input2.dataId);
      if (texData.texture == null) {
        if (!program.packedInputs && util_exports2.sizeFromShape(input2.shape) <= env2().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) {
          return {
            shape: input2.shape,
            texData: null,
            isUniform: true,
            uniformValues: texData.values
          };
        }
        if (program.packedInputs) {
          texData.isPacked = true;
          texData.shape = input2.shape;
        }
      } else if (!!texData.isPacked !== !!program.packedInputs) {
        input2 = texData.isPacked ? this.unpackTensor(input2) : this.packTensor(input2);
        dataToDispose.push(input2);
        texData = this.texData.get(input2.dataId);
      } else if (texData.isPacked && !isReshapeFree(texData.shape, input2.shape)) {
        const savedInput = input2;
        const targetShape = input2.shape;
        input2.shape = texData.shape;
        input2 = this.packedReshape(input2, targetShape);
        dataToDispose.push(input2);
        texData = this.texData.get(input2.dataId);
        savedInput.shape = targetShape;
      }
      this.uploadToGPU(input2.dataId);
      return { shape: input2.shape, texData, isUniform: false };
    });
    this.uploadToGPU(output.dataId);
    const outputData = { shape: output.shape, texData: outData, isUniform: false };
    const key = makeShaderKey(program, inputsData, outputData);
    const binary = this.getAndSaveBinary(key, () => {
      return compileProgram(this.gpgpu, program, inputsData, outputData);
    });
    const shouldTimeProgram = this.activeTimers != null;
    let query;
    if (shouldTimeProgram) {
      query = this.startTimer();
    }
    runProgram(this.gpgpu, binary, inputsData, outputData, customSetup);
    dataToDispose.forEach((info) => this.disposeIntermediateTensorInfo(info));
    if (shouldTimeProgram) {
      query = this.endTimer(query);
      this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });
    }
    const glFlushThreshold = env2().get("WEBGL_FLUSH_THRESHOLD");
    if (glFlushThreshold > 0) {
      const time2 = util_exports2.now();
      if (time2 - this.lastGlFlushTime > glFlushThreshold) {
        this.gpgpu.gl.flush();
        this.lastGlFlushTime = time2;
      }
    }
    if (!env2().getBool("WEBGL_LAZILY_UNPACK") && outData.isPacked && preventEagerUnpackingOfOutput === false) {
      const unpacked = this.unpackTensor(output);
      this.disposeIntermediateTensorInfo(output);
      return unpacked;
    }
    return output;
  }
  compileAndRun(program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput = false) {
    outputDtype = outputDtype || inputs[0].dtype;
    const outInfo = this.runWebGLProgram(program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput);
    return outInfo;
  }
  getAndSaveBinary(key, getBinary) {
    if (!(key in this.binaryCache)) {
      this.binaryCache[key] = getBinary();
    }
    return this.binaryCache[key];
  }
  getTextureManager() {
    return this.textureManager;
  }
  dispose() {
    if (this.disposed) {
      return;
    }
    if (!env2().getBool("IS_TEST")) {
      const allKeys = Object.keys(this.binaryCache);
      allKeys.forEach((key) => {
        this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram);
        delete this.binaryCache[key];
      });
    }
    this.textureManager.dispose();
    if (this.canvas != null && (typeof HTMLCanvasElement !== "undefined" && this.canvas instanceof HTMLCanvasElement)) {
      this.canvas.remove();
    } else {
      this.canvas = null;
    }
    if (this.gpgpuCreatedLocally) {
      this.gpgpu.program = null;
      this.gpgpu.dispose();
    }
    this.disposed = true;
  }
  floatPrecision() {
    if (this.floatPrecisionValue == null) {
      this.floatPrecisionValue = tidy2(() => {
        if (!env2().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
          const debugFlag = env2().getBool("DEBUG");
          env2().set("DEBUG", false);
          const underflowCheckValue = this.abs(scalar2(1e-8)).dataSync()[0];
          env2().set("DEBUG", debugFlag);
          if (underflowCheckValue > 0) {
            return 32;
          }
        }
        return 16;
      });
    }
    return this.floatPrecisionValue;
  }
  epsilon() {
    return this.floatPrecision() === 32 ? EPSILON_FLOAT323 : EPSILON_FLOAT163;
  }
  uploadToGPU(dataId) {
    const texData = this.texData.get(dataId);
    const { shape, dtype, values, texture, usage, isPacked } = texData;
    if (texture != null) {
      return;
    }
    const shouldTimeProgram = this.activeTimers != null;
    let start;
    if (shouldTimeProgram) {
      start = util_exports2.now();
    }
    let texShape = texData.texShape;
    if (texShape == null) {
      texShape = getTextureShapeFromLogicalShape(shape, isPacked);
      texData.texShape = texShape;
    }
    if (values != null) {
      const shapeAs3D = getShapeAs3D(shape);
      let program;
      let width = texShape[1], height = texShape[0];
      const isByteArray = values instanceof Uint8Array;
      if (isPacked) {
        [width, height] = getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]);
        program = new EncodeMatrixPackedProgram(shapeAs3D, [height, width], isByteArray);
      } else {
        program = new EncodeMatrixProgram(shapeAs3D, [height, width], isByteArray);
      }
      const tempDenseInputHandle = this.makeTensorInfo([height, width], dtype);
      if (isByteArray) {
        this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.PIXELS;
      } else {
        this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.UPLOAD;
      }
      this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);
      const preventEagerUnpacking = true;
      const encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, null, preventEagerUnpacking);
      const outputTexData = this.texData.get(encodedOutputTarget.dataId);
      texData.texture = outputTexData.texture;
      texData.texShape = outputTexData.texShape;
      texData.isPacked = outputTexData.isPacked;
      texData.usage = outputTexData.usage;
      this.disposeIntermediateTensorInfo(tempDenseInputHandle);
      this.texData.delete(encodedOutputTarget.dataId);
      texData.values = null;
      if (shouldTimeProgram) {
        this.uploadWaitMs += util_exports2.now() - start;
      }
    } else {
      const newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);
      texData.texture = newTexture;
    }
  }
  convertAndCacheOnCPU(dataId, float32Values) {
    const texData = this.texData.get(dataId);
    const { dtype } = texData;
    this.releaseGPUData(dataId);
    if (float32Values != null) {
      texData.values = float32ToTypedArray(float32Values, dtype);
    }
    return texData.values;
  }
  acquireTexture(texShape, texType, dtype, isPacked) {
    this.numBytesInGPU += this.computeBytes(texShape, dtype);
    if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
      const mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
      this.warnedAboutMemory = true;
      console.warn(`High memory usage in GPU: ${mb} MB, most likely due to a memory leak`);
    }
    return this.textureManager.acquireTexture(texShape, texType, isPacked);
  }
  computeBytes(shape, dtype) {
    return shape[0] * shape[1] * util_exports2.bytesPerElement(dtype);
  }
};
var MathBackendWebGL = _MathBackendWebGL;
MathBackendWebGL.nextDataId = 0;
function float32ToTypedArray(a, dtype) {
  if (dtype === "float32" || dtype === "complex64") {
    return a;
  } else if (dtype === "int32" || dtype === "bool") {
    const result = dtype === "int32" ? new Int32Array(a.length) : new Uint8Array(a.length);
    for (let i = 0; i < result.length; ++i) {
      result[i] = Math.round(a[i]);
    }
    return result;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/version.ts
var version15 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/webgl.ts
function forceHalfFloat() {
  env2().set("WEBGL_FORCE_F16_TEXTURES", true);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/base.ts
if (device_util_exports2.isBrowser()) {
  registerBackend2("webgl", () => new MathBackendWebGL(), 2);
}
var webgl = { forceHalfFloat };

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/binaryop_gpu.ts
var CHECK_NAN_SNIPPET2 = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
var BinaryOpProgram = class {
  constructor(op3, aShape, bShape) {
    this.variableNames = ["A", "B"];
    this.outputShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    this.userCode = `
      float binaryOperation(float a, float b) {
        ${op3}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/binaryop_packed_gpu.ts
var CHECK_NAN_SNIPPET3 = `
  result.r = isNaN.r > 0. ? NAN : result.r;
  result.g = isNaN.g > 0. ? NAN : result.g;
  result.b = isNaN.b > 0. ? NAN : result.b;
  result.a = isNaN.a > 0. ? NAN : result.a;
`;
var BinaryOpPackedProgram = class {
  constructor(op3, aShape, bShape, checkOutOfBounds = false) {
    this.variableNames = ["A", "B"];
    this.supportsBroadcasting = true;
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    const rank = this.outputShape.length;
    let checkOutOfBoundsString = "";
    if (checkOutOfBounds) {
      if (rank === 0 || util_exports2.sizeFromShape(this.outputShape) === 1) {
        checkOutOfBoundsString = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
      } else {
        const dtype = getCoordsDataType(rank);
        checkOutOfBoundsString = `
          ${dtype} coords = getOutputCoords();
        `;
        if (rank === 1) {
          checkOutOfBoundsString += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
        } else {
          const channels = getChannels("coords", rank);
          checkOutOfBoundsString += `
            bool nextRowOutOfBounds =
              (${channels[rank - 2]} + 1) >= ${this.outputShape[rank - 2]};
            bool nextColOutOfBounds =
              (${channels[rank - 1]} + 1) >= ${this.outputShape[rank - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
        }
      }
    }
    this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${op3}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${checkOutOfBoundsString}

        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Identity.ts
function identity4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  backend3.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}
var identityConfig2 = {
  kernelName: Identity2,
  backendName: "webgl",
  kernelFunc: identity4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Complex.ts
function complex5(args) {
  const { inputs, backend: backend3 } = args;
  const { real: real6, imag: imag5 } = inputs;
  const complexInfo = backend3.makeTensorInfo(real6.shape, "complex64");
  const complex6 = backend3.texData.get(complexInfo.dataId);
  const realTensorInfo = identity4({ inputs: { x: real6 }, backend: backend3 });
  const imagTensorInfo = identity4({ inputs: { x: imag5 }, backend: backend3 });
  complex6.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
  return complexInfo;
}
var complexConfig2 = {
  kernelName: Complex2,
  backendName: "webgl",
  kernelFunc: complex5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LeakyRelu.ts
var LEAKYRELU = `return (a < 0.) ? b * a : a;`;
var LEAKYRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function leakyRelu4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { alpha } = attrs;
  const $alpha = backend3.makeTensorInfo([], "float32", util_exports2.createScalarValue(alpha, "float32"));
  const program = env2().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(LEAKYRELU_PACKED, x.shape, $alpha.shape) : new BinaryOpProgram(LEAKYRELU, x.shape, $alpha.shape);
  const result = backend3.runWebGLProgram(program, [x, $alpha], x.dtype);
  backend3.disposeIntermediateTensorInfo($alpha);
  return result;
}
var leakyReluConfig2 = {
  kernelName: LeakyRelu2,
  backendName: "webgl",
  kernelFunc: leakyRelu4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Prelu.ts
var PRELU = `return (a < 0.) ? b * a : a;`;
var PRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function prelu5(args) {
  const { inputs, backend: backend3 } = args;
  const { x, alpha } = inputs;
  const program = env2().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(PRELU_PACKED, x.shape, alpha.shape) : new BinaryOpProgram(PRELU, x.shape, alpha.shape);
  return backend3.runWebGLProgram(program, [x, alpha], x.dtype);
}
var preluConfig2 = {
  kernelName: Prelu2,
  backendName: "webgl",
  kernelFunc: prelu5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/kernel_funcs_utils.ts
var CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;
var CHECK_NAN_SNIPPET_BINARY = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
var CHECK_NAN_SNIPPET_BINARY_PACKED = `
  result.r = isNaN.r > 0. ? NAN : result.r;
  result.g = isNaN.g > 0. ? NAN : result.g;
  result.b = isNaN.b > 0. ? NAN : result.b;
  result.a = isNaN.a > 0. ? NAN : result.a;
`;
function unaryKernelFunc2({ opSnippet, packedOpSnippet, cpuKernelImpl, dtype }) {
  return ({ inputs, backend: backend3 }) => {
    const { x } = inputs;
    const webglBackend = backend3;
    const $dtype = dtype || x.dtype;
    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
      const xData = webglBackend.texData.get(x.dataId);
      const outValues = cpuKernelImpl(xData.values, $dtype);
      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);
    }
    const shouldUsePackedProgram = env2().getBool("WEBGL_PACK_UNARY_OPERATIONS") && packedOpSnippet != null;
    let program;
    if (shouldUsePackedProgram) {
      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);
    } else {
      program = new UnaryOpProgram(x.shape, opSnippet);
    }
    return webglBackend.runWebGLProgram(program, [x], $dtype);
  };
}
function binaryKernelFunc3({
  opSnippet,
  packedOpSnippet,
  checkOutOfBounds = false,
  supportsComplex = false,
  cpuKernelImpl,
  dtype
}) {
  return ({ inputs, backend: backend3 }) => {
    const { a, b } = inputs;
    const webglBackend = backend3;
    if (supportsComplex && a.dtype === "complex64") {
      const aData = webglBackend.texData.get(a.dataId);
      const bData = webglBackend.texData.get(b.dataId);
      const [real6, imag5] = [
        [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
        [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
      ].map((complexParts) => {
        const [aPart, bPart] = complexParts;
        const aHandle = {
          dataId: aPart.dataId,
          dtype: aPart.dtype,
          shape: a.shape
        };
        const bHandle = {
          dataId: bPart.dataId,
          dtype: bPart.dtype,
          shape: b.shape
        };
        const program2 = new BinaryOpProgram(opSnippet, a.shape, b.shape);
        return webglBackend.runWebGLProgram(program2, [aHandle, bHandle], upcastType2(aPart.dtype, bPart.dtype));
      });
      const complexOutput = complex5({ inputs: { real: real6, imag: imag5 }, backend: webglBackend });
      webglBackend.disposeIntermediateTensorInfo(real6);
      webglBackend.disposeIntermediateTensorInfo(imag5);
      return complexOutput;
    }
    const $dtype = dtype || upcastType2(a.dtype, b.dtype);
    if ((a.dtype === "string" || b.dtype === "string" || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {
      const aVals = webglBackend.texData.get(a.dataId).values;
      const bVals = webglBackend.texData.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(aVals) : aVals;
      const decodedBVals = a.dtype === "string" ? backend_util_exports2.fromUint8ToStringArray(bVals) : bVals;
      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      const out = webglBackend.makeTensorInfo(outShape, $dtype);
      const outData = webglBackend.texData.get(out.dataId);
      outData.values = outValues;
      return out;
    }
    const shouldUsePackedProgram = env2().getBool("WEBGL_PACK_BINARY_OPERATIONS") && packedOpSnippet != null;
    let program;
    if (shouldUsePackedProgram) {
      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);
    } else {
      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);
    }
    return webglBackend.runWebGLProgram(program, [a, b], $dtype);
  };
}
function mapActivationToShaderProgram(activation2, packed = false) {
  if (activation2 === "linear") {
    if (packed) {
      return LINEAR2;
    }
    return LINEAR;
  } else if (activation2 === "relu") {
    if (packed) {
      return RELU2;
    }
    return RELU;
  } else if (activation2 === "elu") {
    if (packed) {
      return ELU3;
    }
    return ELU2;
  } else if (activation2 === "relu6") {
    if (packed) {
      return RELU62;
    }
    return RELU6;
  } else if (activation2 === "prelu") {
    if (packed) {
      return PRELU_PACKED;
    }
    return PRELU;
  } else if (activation2 === "leakyrelu") {
    if (packed) {
      return LEAKYRELU_PACKED;
    }
    return LEAKYRELU;
  } else if (activation2 === "sigmoid") {
    if (packed) {
      return SIGMOID2;
    }
    return SIGMOID;
  }
  throw new Error(`Activation ${activation2} has not been implemented for the WebGL backend.`);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/mulmat_packed_gpu.ts
var MatMulPackedProgram = class {
  constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, addBias = false, activation2 = null, hasPreluActivation = false, hasLeakyreluActivation = false) {
    this.variableNames = ["matrixA", "matrixB"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = outputShape;
    const sharedDim = transposeA ? aShape[1] : aShape[2];
    const sharedDimensionPacked = Math.ceil(sharedDim / 2);
    const aSample = transposeA ? "i * 2, rc.y" : "rc.y, i * 2";
    const bSample = transposeB ? "rc.z, i * 2" : "i * 2, rc.z";
    const aSwizzle = transposeA ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"];
    const bSwizzle = transposeB ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
    let activationSnippet = "", applyActivationSnippet = "";
    if (activation2) {
      if (hasPreluActivation) {
        activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation2}
        }`;
      } else if (hasLeakyreluActivation) {
        activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation2}
        }`;
      } else {
        activationSnippet = `vec4 activation(vec4 x) {
          ${activation2}
        }`;
      }
      applyActivationSnippet = `result = activation(result);`;
    }
    const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    if (hasLeakyreluActivation) {
      this.variableNames.push("leakyreluAlpha");
    }
    let batchASnippet = "rc.x";
    let batchBSnippet = "rc.x";
    if (aShape[0] < bShape[0]) {
      batchASnippet = `int(min(float(rc.x), ${aShape[0] - 1}.))`;
    } else if (bShape[0] < aShape[0]) {
      batchBSnippet = `int(min(float(rc.x), ${bShape[0] - 1}.))`;
    }
    this.userCode = `
      ${activationSnippet}

      const float sharedDimension = ${sharedDimensionPacked}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        for (int i = 0; i < ${sharedDimensionPacked}; i++) {
          int batchA = ${batchASnippet};
          int batchB = ${batchBSnippet};
          vec4 a = getMatrixA(batchA, ${aSample});
          vec4 b = getMatrixB(batchB, ${bSample});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${aSwizzle[0]} * ${bSwizzle[0]});
          result += (${aSwizzle[1]} * ${bSwizzle[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${addBiasSnippet}

        ${applyActivationSnippet}

        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/binaryop_complex_gpu.ts
var COMPLEX_MULTIPLY = {
  REAL: "return areal * breal - aimag * bimag;",
  IMAG: "return areal * bimag + aimag * breal;"
};
var BinaryOpComplexProgram = class {
  constructor(op3, aShape, bShape) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"];
    this.outputShape = backend_util_exports2.assertAndGetBroadcastShape(aShape, bShape);
    this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${op3}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Multiply.ts
var MUL = "return a * b;";
function multiply4(args) {
  const { inputs, backend: backend3 } = args;
  const { a, b } = inputs;
  const dtype = backend_util_exports2.upcastType(a.dtype, b.dtype);
  if (a.dtype === "complex64") {
    const aData = backend3.texData.get(a.dataId);
    const bData = backend3.texData.get(b.dataId);
    const realProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL, a.shape, b.shape);
    const imagProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);
    const inputs2 = [
      {
        dataId: aData.complexTensorInfos.real.dataId,
        dtype: aData.complexTensorInfos.real.dtype,
        shape: a.shape
      },
      {
        dataId: aData.complexTensorInfos.imag.dataId,
        dtype: aData.complexTensorInfos.imag.dtype,
        shape: a.shape
      },
      {
        dataId: bData.complexTensorInfos.real.dataId,
        dtype: bData.complexTensorInfos.real.dtype,
        shape: b.shape
      },
      {
        dataId: bData.complexTensorInfos.imag.dataId,
        dtype: bData.complexTensorInfos.imag.dtype,
        shape: b.shape
      }
    ];
    const realPart = backend3.runWebGLProgram(realProgram, inputs2, "float32");
    const imagPart = backend3.runWebGLProgram(imagProgram, inputs2, "float32");
    const complexOutput = complex5({ inputs: { real: realPart, imag: imagPart }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(realPart);
    backend3.disposeIntermediateTensorInfo(imagPart);
    return complexOutput;
  }
  if (backend3.shouldExecuteOnCPU([a, b])) {
    const aData = backend3.texData.get(a.dataId);
    const bData = backend3.texData.get(b.dataId);
    const [outValues, outShape] = multiplyImplCPU(a.shape, b.shape, aData.values, bData.values, dtype);
    const out = backend3.makeTensorInfo(outShape, dtype);
    const outData = backend3.texData.get(out.dataId);
    outData.values = outValues;
    return out;
  }
  let program;
  if (env2().getBool("WEBGL_PACK_BINARY_OPERATIONS")) {
    program = new BinaryOpPackedProgram(MUL, a.shape, b.shape);
  } else {
    program = new BinaryOpProgram(MUL, a.shape, b.shape);
  }
  return backend3.runWebGLProgram(program, [a, b], dtype);
}
var multiplyConfig2 = {
  kernelName: Multiply2,
  backendName: "webgl",
  kernelFunc: multiply4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/reshape.ts
function packedReshape(input2, afterShape, backend3) {
  const input3DShape = [
    getBatchDim(input2.shape),
    ...getRowsCols(input2.shape)
  ];
  const input3D = {
    dtype: input2.dtype,
    shape: input3DShape,
    dataId: input2.dataId
  };
  const afterShapeAs3D = [
    getBatchDim(afterShape),
    ...getRowsCols(afterShape)
  ];
  const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
  const preventEagerUnpackingOfOutput = true;
  const output = backend3.runWebGLProgram(program, [input3D], input2.dtype, null, preventEagerUnpackingOfOutput);
  return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Reshape.ts
function reshape5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const webglBackend = backend3;
  const xSize = util_exports2.sizeFromShape(x.shape);
  const $shape = util_exports2.inferFromImplicitShape(shape, xSize);
  const $xSize = util_exports2.sizeFromShape($shape);
  util_exports2.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
  const xTexData = webglBackend.texData.get(x.dataId);
  if (xTexData.isPacked && !isReshapeFree(x.shape, $shape) && !(xTexData.texture !== null && isReshapeFree(xTexData.shape, $shape))) {
    return packedReshape(x, $shape, webglBackend);
  }
  webglBackend.incRef(x.dataId);
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig2 = {
  kernelName: Reshape2,
  backendName: "webgl",
  kernelFunc: reshape5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/mean_gpu.ts
var MeanProgram = class {
  constructor(reduceInfo, divisor) {
    this.variableNames = ["x"];
    const { windowSize, batchSize, inSize, outSize } = reduceInfo;
    this.outputShape = [batchSize, outSize];
    const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
    const windowSizeVec4Remainder = windowSize % 4;
    let updateSnippet = `sumValue += dot(values, ones);`;
    if (divisor != null) {
      const denominator = 1 / divisor;
      updateSnippet = `sumValue += dot(values * ${util_exports2.isInt(denominator) ? denominator.toPrecision(2) : denominator}, ones);`;
    }
    let checkOutOfBounds = "";
    if (inSize % windowSize > 0) {
      checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return 0.0;
        }
      `;
    }
    this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${updateSnippet}
        }
        setOutput(sumValue);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/reduce_gpu.ts
var ReduceProgram = class {
  constructor(reduceInfo, reduceType) {
    this.variableNames = ["x"];
    const { windowSize, batchSize, inSize, outSize } = reduceInfo;
    this.outputShape = [batchSize, outSize];
    let initializationValue = "0.0";
    let compareOp = ``;
    if (reduceType === "prod") {
      initializationValue = "1.0";
    } else if (reduceType === "min") {
      initializationValue = "1.0 / 1e-20";
      compareOp = `min`;
    } else if (reduceType === "max") {
      initializationValue = "-1.0 / 1e-20";
      compareOp = `max`;
    }
    let returnValue = `${reduceType}(${reduceType}(${reduceType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    if (reduceType === "sum") {
      returnValue = `sumValue`;
    } else if (reduceType === "prod") {
      returnValue = `prodValue`;
    } else if (reduceType === "all") {
      returnValue = `allValue`;
    } else if (reduceType === "any") {
      returnValue = `anyValue`;
    }
    const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
    const windowSizeVec4Remainder = windowSize % 4;
    let updateSnippet = `
      if (${reduceType === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${reduceType === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
        if (${reduceType === "min"} || ${reduceType === "max"}) {
          minMaxValue = ${compareOp}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `;
    let vecType = `vec4`;
    if (reduceType === "all") {
      initializationValue = "1.0";
      updateSnippet = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `;
      vecType = `bvec4`;
    } else if (reduceType === "any") {
      initializationValue = "0.0";
      updateSnippet = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `;
      vecType = `bvec4`;
    }
    let checkOutOfBounds = "";
    if (inSize % windowSize > 0) {
      checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
    }
    this.userCode = `
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        vec4 minMaxValue = vec4(${initializationValue});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/reduce.ts
function getReductionStages(inShape) {
  const stages = [];
  while (stages.length === 0 || stages[stages.length - 1].outSize !== 1) {
    const outSize = stages.length ? stages[stages.length - 1].outSize : inShape[1];
    const windowSize = backend_util_exports2.computeOptimalWindowSize(outSize);
    stages.push({
      inSize: outSize,
      windowSize,
      outSize: Math.ceil(outSize / windowSize)
    });
  }
  return stages;
}
function reduce(x, dtype, reductionType, backend3) {
  const reductionStages = getReductionStages(x.shape);
  let result = x;
  for (let i = 0; i < reductionStages.length; i++) {
    const { inSize, windowSize, outSize } = reductionStages[i];
    let program;
    let previousResult;
    if (reductionType === "mean") {
      program = i === 0 ? new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, inSize) : new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize });
    } else {
      program = new ReduceProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, reductionType);
    }
    previousResult = result;
    result = backend3.runWebGLProgram(program, [result], dtype);
    if (previousResult.dataId !== x.dataId) {
      backend3.disposeIntermediateTensorInfo(previousResult);
    }
  }
  return result;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/transpose_gpu.ts
var TransposeProgram = class {
  constructor(aShape, newDim) {
    this.variableNames = ["A"];
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[newDim[i]];
    }
    this.outputShape = outputShape;
    this.rank = outputShape.length;
    const dtype = getCoordsDataType(this.rank);
    const switched = getSwitchedCoords(newDim);
    this.userCode = `
    void main() {
      ${dtype} resRC = getOutputCoords();
      setOutput(getA(${switched}));
    }
    `;
  }
};
function getSwitchedCoords(newDim) {
  const rank = newDim.length;
  if (rank > 6) {
    throw Error(`Transpose for rank ${rank} is not yet supported`);
  }
  const originalOrder = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"];
  const switchedCoords = new Array(rank);
  for (let i = 0; i < newDim.length; i++) {
    switchedCoords[newDim[i]] = originalOrder[i];
  }
  return switchedCoords.join();
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/transpose_packed_gpu.ts
var TransposePackedProgram = class {
  constructor(aShape, newDim) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[newDim[i]];
    }
    this.outputShape = outputShape;
    this.rank = outputShape.length;
    if (this.rank > 6) {
      throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
    }
    const dtype = getCoordsDataType(this.rank);
    const outputOrder = getVecChannels("rc", this.rank);
    const switchedOrder = new Array(this.rank);
    for (let i = 0; i < newDim.length; i++) {
      switchedOrder[newDim[i]] = outputOrder[i];
    }
    const innerDims = `vec2(${switchedOrder.slice(-2).join()})`;
    const nextColumn = `++${outputOrder[this.rank - 1]} < ${outputShape[this.rank - 1]}`;
    const getc = `getChannel(getA(${switchedOrder.join()}), ${innerDims})`;
    this.userCode = `
    void main() {
      ${dtype} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${getc};
      if(${nextColumn}) {
        result[1] = ${getc};
      }
      --${outputOrder[this.rank - 1]};
      if(++${outputOrder[this.rank - 2]} < ${outputShape[this.rank - 2]}) {
        result[2] = ${getc};
        if(${nextColumn}) {
          result[3] = ${getc};
        }
      }
      setOutput(result);
    }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Transpose_impl.ts
function transposeImpl3(x, perm, backend3) {
  const program = env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram(x.shape, perm) : new TransposeProgram(x.shape, perm);
  return backend3.runWebGLProgram(program, [x], x.dtype);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sum_impl.ts
function sumImpl(x, axis, keepDims, backend3) {
  const reductionIndices = axis;
  const xRank = x.shape.length;
  const origAxes = util_exports2.parseAxisParam(reductionIndices, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  const sumInputIsTransposed = permutedAxes != null;
  let sumInput = x;
  if (sumInputIsTransposed) {
    sumInput = transposeImpl3(x, permutedAxes, backend3);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("sum", axes, xRank);
  const [sumOutShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(sumInput.shape, axes);
  let outShape = sumOutShape;
  if (keepDims) {
    outShape = backend_util_exports2.expandShapeToKeepDim(sumOutShape, origAxes);
  }
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const xSize = util_exports2.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape5({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend: backend3 });
  const outType = sumOutType2(x.dtype);
  const reduced = reduce(reshapedInput, outType, "sum", backend3);
  const out = reshape5({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(reshapedInput);
  backend3.disposeIntermediateTensorInfo(reduced);
  if (sumInputIsTransposed) {
    backend3.disposeIntermediateTensorInfo(sumInput);
  }
  return out;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sum.ts
function sum6(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  return sumImpl(x, axis, keepDims, backend3);
}
var sumConfig2 = {
  kernelName: Sum2,
  backendName: "webgl",
  kernelFunc: sum6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Transpose.ts
function transpose5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { perm } = attrs;
  const webglBackend = backend3;
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  let out;
  if (webglBackend.shouldExecuteOnCPU([x])) {
    const xTexData = webglBackend.texData.get(x.dataId);
    const values = xTexData.values;
    const outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
    out = webglBackend.makeTensorInfo(newShape, x.dtype);
    const outData = webglBackend.texData.get(out.dataId);
    outData.values = outValues;
  } else {
    out = transposeImpl3(x, perm, webglBackend);
  }
  return out;
}
var transposeConfig2 = {
  kernelName: Transpose2,
  backendName: "webgl",
  kernelFunc: transpose5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/BatchMatMul_impl.ts
var MATMUL_SHARED_DIM_THRESHOLD = 1e3;
function batchMatMulImpl({
  a,
  b,
  transposeA,
  transposeB,
  backend: backend3,
  bias = null,
  preluActivationWeights = null,
  leakyreluAlpha = 0,
  activation: activation2 = null
}) {
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports2.sizeFromShape(outerDimsA);
  const batchDimB = util_exports2.sizeFromShape(outerDimsB);
  const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;
  util_exports2.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);
  const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports2.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape5({ inputs: { x: a }, backend: backend3, attrs: { shape: a3dShape } });
  const b3d = reshape5({ inputs: { x: b }, backend: backend3, attrs: { shape: b3dShape } });
  const intermediates = [a3d, b3d];
  const batchDim = Math.max(batchDimA, batchDimB);
  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation2 === "leakyrelu";
  const fusedActivation = activation2 != null ? mapActivationToShaderProgram(activation2, true) : null;
  const containsFusedOps = hasBias || hasPreluActivationWeights || hasLeakyreluAlpha || fusedActivation != null;
  let out;
  if ((outerShapeA === 1 || outerShapeB === 1) && sharedDim > MATMUL_SHARED_DIM_THRESHOLD && containsFusedOps === false) {
    let aVec = a3d;
    let bVec = b3d;
    if (transposeA) {
      aVec = transpose5({ inputs: { x: a3d }, backend: backend3, attrs: { perm: [0, 2, 1] } });
      intermediates.push(aVec);
    }
    if (transposeB) {
      bVec = transpose5({ inputs: { x: b3d }, backend: backend3, attrs: { perm: [0, 2, 1] } });
      intermediates.push(bVec);
    }
    const shouldReshapeA = outerShapeB !== 1;
    const shouldReshapeB = outerShapeB === 1;
    let aVec3d = aVec;
    if (shouldReshapeA) {
      aVec3d = reshape5({
        inputs: { x: aVec },
        backend: backend3,
        attrs: { shape: [batchDim, sharedDim, 1] }
      });
      intermediates.push(aVec3d);
    }
    const axis = outerShapeB === 1 ? 2 : 1;
    let bVec3d = bVec;
    if (shouldReshapeB) {
      bVec3d = reshape5({
        inputs: { x: bVec },
        backend: backend3,
        attrs: { shape: [batchDim, 1, sharedDim] }
      });
      intermediates.push(bVec3d);
    }
    const product = multiply4({ inputs: { a: aVec3d, b: bVec3d }, backend: backend3 });
    out = sum6({ inputs: { x: product }, backend: backend3, attrs: { axis, keepDims: true } });
    intermediates.push(product);
  } else {
    const dtype = upcastType2(a.dtype, b.dtype);
    const program = new MatMulPackedProgram(a3dShape, b3dShape, [batchDim, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const inputs = [a3d, b3d];
    if (bias != null) {
      inputs.push(bias);
    }
    if (hasPreluActivationWeights) {
      inputs.push(preluActivationWeights);
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend3.makeTensorInfo([], "float32", util_exports2.createScalarValue(leakyreluAlpha, "float32"));
      inputs.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    out = backend3.runWebGLProgram(program, inputs, dtype);
  }
  const outReshaped = reshape5({ inputs: { x: out }, backend: backend3, attrs: { shape: outShape } });
  intermediates.push(out);
  for (const i of intermediates) {
    backend3.disposeIntermediateTensorInfo(i);
  }
  return outReshaped;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/_FusedMatMul.ts
function _fusedMatMul2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  const { transposeA, transposeB, activation: activation2, leakyreluAlpha } = attrs;
  return batchMatMulImpl({
    a,
    b,
    transposeA,
    transposeB,
    backend: backend3,
    bias,
    preluActivationWeights,
    leakyreluAlpha,
    activation: activation2
  });
}
var _fusedMatMulConfig2 = {
  kernelName: _FusedMatMul2,
  backendName: "webgl",
  kernelFunc: _fusedMatMul2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Abs.ts
var ABS2 = `return abs(x);`;
function abs4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (backend3.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
    const xData = backend3.texData.get(x.dataId);
    const outValues = simpleAbsImplCPU(xData.values);
    return backend3.makeTensorInfo(x.shape, x.dtype, outValues);
  }
  let program;
  if (env2().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
    program = new UnaryOpPackedProgram(x.shape, ABS2);
  } else {
    program = new UnaryOpProgram(x.shape, ABS2);
  }
  return backend3.runWebGLProgram(program, [x], x.dtype);
}
var absConfig2 = {
  kernelName: Abs2,
  backendName: "webgl",
  kernelFunc: abs4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Acos.ts
var ACOS = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
var acos4 = unaryKernelFunc2({ opSnippet: ACOS });
var acosConfig2 = {
  kernelName: Acos2,
  backendName: "webgl",
  kernelFunc: acos4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Acosh.ts
var ACOSH = CHECK_NAN_SNIPPET + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
var acosh4 = unaryKernelFunc2({ opSnippet: ACOSH });
var acoshConfig2 = {
  kernelName: Acosh2,
  backendName: "webgl",
  kernelFunc: acosh4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Add.ts
var ADD = "return a + b;";
var addKernelFunc = binaryKernelFunc3({
  opSnippet: ADD,
  packedOpSnippet: ADD,
  supportsComplex: true,
  cpuKernelImpl: addImplCPU
});
var addConfig2 = {
  kernelName: Add2,
  backendName: "webgl",
  kernelFunc: addKernelFunc
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/addn_gpu.ts
var AddNProgram = class {
  constructor(outputShape, shapes) {
    this.outputShape = [];
    this.outputShape = outputShape;
    this.variableNames = shapes.map((_, i) => `T${i}`);
    const snippets = [];
    this.variableNames.forEach((variable3) => {
      snippets.push(`float v${variable3} = get${variable3}AtOutCoords();`);
    });
    const operation = this.variableNames.map((variable3) => {
      return `v${variable3}`;
    }).join(" + ");
    this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        float result = ${operation};
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/addn_packed_gpu.ts
var AddNPackedProgram = class {
  constructor(outputShape, shapes) {
    this.outputShape = [];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = outputShape;
    this.variableNames = shapes.map((_, i) => `T${i}`);
    const snippets = [];
    this.variableNames.forEach((variable3) => {
      snippets.push(`vec4 v${variable3} = get${variable3}AtOutCoords();`);
    });
    const operation = this.variableNames.map((variable3) => {
      return `v${variable3}`;
    }).join(" + ");
    this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        vec4 result = ${operation};
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/AddN.ts
function addN4(args) {
  const { inputs, backend: backend3 } = args;
  const tensors = inputs;
  if (tensors.length === 1) {
    return identity4({ inputs: { x: tensors[0] }, backend: backend3 });
  }
  if (tensors.length > env2().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    const midIndex = Math.floor(tensors.length / 2);
    const leftSide = addN4({ inputs: tensors.slice(0, midIndex), backend: backend3 });
    const rightSide = addN4({ inputs: tensors.slice(midIndex), backend: backend3 });
    return addN4({ inputs: [leftSide, rightSide], backend: backend3 });
  }
  const dtype = tensors.map((t) => t.dtype).reduce((d1, d2) => upcastType2(d1, d2));
  const shapes = tensors.map((t) => t.shape);
  const usePackedOp = env2().getBool("WEBGL_PACK");
  const program = usePackedOp ? new AddNPackedProgram(tensors[0].shape, shapes) : new AddNProgram(tensors[0].shape, shapes);
  return backend3.runWebGLProgram(program, tensors, dtype);
}
var addNConfig2 = {
  kernelName: AddN2,
  backendName: "webgl",
  kernelFunc: addN4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/All.ts
function all4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("all", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const a2D = reshape5({ inputs: { x: permutedX }, backend: backend3, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "all", backend3);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: newShape } });
  } else {
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: outShape } });
  }
  backend3.disposeIntermediateTensorInfo(a2D);
  backend3.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var allConfig2 = {
  kernelName: All2,
  backendName: "webgl",
  kernelFunc: all4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Any.ts
function any4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("any", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const a2D = reshape5({ inputs: { x: permutedX }, backend: backend3, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "any", backend3);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: newShape } });
  } else {
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: outShape } });
  }
  backend3.disposeIntermediateTensorInfo(a2D);
  backend3.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var anyConfig2 = {
  kernelName: Any2,
  backendName: "webgl",
  kernelFunc: any4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/argminmax_gpu.ts
var ArgMinMaxProgram = class {
  constructor(reduceInfo, op3, firstPass) {
    this.variableNames = ["A"];
    const { windowSize, batchSize, outSize } = reduceInfo;
    if (!firstPass) {
      this.variableNames.push("bestIndicesA");
    }
    this.outputShape = [batchSize, outSize];
    const compOp = op3 === "max" ? ">" : "<";
    const indexSnippet = firstPass ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${windowSize}; i++) {
          int inIdx = ${indexSnippet};
          float candidate = getA(batch, inIdx);
          if (candidate ${compOp} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/argminmax_packed_gpu.ts
var ArgMinMaxPackedProgram = class {
  constructor(shape, windowSize, op3, firstPass) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    util_exports2.assert(shape.length > 2, () => `Packed arg${op3.charAt(0).toUpperCase() + op3.slice(1)} supports only inputs with rank above 2.`);
    const inSize = shape[shape.length - 1];
    const outSize = Math.ceil(inSize / windowSize);
    this.outputShape = shape.slice(0, -1);
    if (outSize > 1) {
      this.outputShape.push(outSize);
    }
    if (!firstPass) {
      this.variableNames.push("bestIndicesA");
    }
    const outShape = this.outputShape;
    const rank = outShape.length;
    const dtype = getCoordsDataType(rank);
    const coords2 = getChannels("coords", rank);
    let sourceLocSetup;
    let sourceRank;
    if (outSize === 1) {
      sourceRank = rank + 1;
      const sourceLocDType = getCoordsDataType(sourceRank);
      sourceLocSetup = `
        ${sourceLocDType} sourceLocR = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 1]};
        ${sourceLocDType} sourceLocG = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 2]};
        ${sourceLocDType} sourceLocA = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 1]};
        ${sourceLocDType} sourceLocB = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 2]};`;
    } else {
      sourceRank = rank;
      sourceLocSetup = `
        ${dtype} sourceLocR = coords;
        ++${coords2[rank - 1]};
        ${dtype} sourceLocG = coords;
        ++${coords2[rank - 2]};
        ${dtype} sourceLocA = coords;
        --${coords2[rank - 1]};
        ${dtype} sourceLocB = coords;
        --${coords2[rank - 2]};`;
    }
    const channels = ["x", "y", "z", "w", "u", "v"].slice(0, sourceRank);
    const inChannel = "." + channels[sourceRank - 1];
    const intChannels = channels.map((x) => "int " + x);
    const srcRCoords = getChannels("sourceLocR", sourceRank - 1).concat("inIdx.r");
    const srcGCoords = getChannels("sourceLocG", sourceRank - 1).concat("inIdx.g");
    const srcBCoords = getChannels("sourceLocB", sourceRank - 1).concat("inIdx.b");
    const srcACoords = getChannels("sourceLocA", sourceRank - 1).concat("inIdx.a");
    const compOp = op3 === "max" ? "greaterThan" : "lessThan";
    const fetchCandidateIdx = firstPass ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${srcRCoords.join()}),
                             getBestIndicesAChannel(${srcGCoords.join()}),
                             getBestIndicesAChannel(${srcBCoords.join()}),
                             getBestIndicesAChannel(${srcACoords.join()})));`;
    const fetchValue = `vec4(
            getAChannel(${srcRCoords.join()}),
            hasNextCol ? getAChannel(${srcGCoords.join()}) : 0.,
            hasNextRow ? getAChannel(${srcBCoords.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${srcACoords.join()}) : 0.)`;
    const getBestIndicesAChannelSnippet = firstPass ? "" : `
      float getBestIndicesAChannel(${intChannels.join()}) {
        return getChannel(getBestIndicesA(${channels.join()}),
                                          vec2(${channels.slice(-2).join()}));
      }`;
    this.userCode = `
      float getAChannel(${intChannels.join()}) {
        return getChannel(getA(${channels.join()}),
                               vec2(${channels.slice(-2).join()}));
      }
      ${getBestIndicesAChannelSnippet}
      void main() {
        ${dtype} coords = getOutputCoords();
        bool hasNextCol = ${coords2[rank - 1]} < ${outShape[rank - 1] - 1};
        bool hasNextRow = ${coords2[rank - 2]} < ${outShape[rank - 2] - 1};
        ${sourceLocSetup}
        ivec4 srcIdx = ivec4(sourceLocR${inChannel}, sourceLocG${inChannel},
          sourceLocB${inChannel}, sourceLocA${inChannel}) * ${windowSize};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${fetchValue};

        for (int i = 0; i < ${windowSize}; i++) {
          inIdx = srcIdx;
          ${fetchCandidateIdx}
          vec4 candidate = ${fetchValue};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${compOp}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/arg_min_max.ts
function argReduce(backend3, x, reduceType, bestIndicesA = null) {
  let batchSize = x.shape[0];
  let inSize = x.shape[1];
  if (bestIndicesA != null) {
    batchSize = bestIndicesA.shape[0];
    inSize = bestIndicesA.shape[1];
  }
  const windowSize = backend_util_exports2.computeOptimalWindowSize(inSize);
  const reduceInfo = { windowSize, inSize, batchSize, outSize: Math.ceil(inSize / windowSize) };
  const program = new ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);
  const inputs = [x];
  if (bestIndicesA != null) {
    inputs.push(bestIndicesA);
  }
  const output = backend3.runWebGLProgram(program, inputs, "int32");
  if (output.shape[1] === 1) {
    return output;
  }
  const result = argReduce(backend3, x, reduceType, output);
  backend3.disposeIntermediateTensorInfo(output);
  return result;
}
function argReducePacked(backend3, x, reduceType, bestIndicesA = null) {
  const inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;
  const inSize = inShape[inShape.length - 1];
  const windowSize = backend_util_exports2.computeOptimalWindowSize(inSize);
  const program = new ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);
  const inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];
  const output = backend3.runWebGLProgram(program, inputs, "int32");
  if (output.shape.length === x.shape.length) {
    const result = argReducePacked(backend3, x, reduceType, output);
    backend3.disposeIntermediateTensorInfo(output);
    return result;
  }
  return output;
}
function argMinMaxReduce(backend3, x, axis, reduceType) {
  const axes = [axis];
  backend_util_exports2.assertAxesAreInnerMostDims("arg" + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.shape.length);
  if (!env2().getBool("WEBGL_PACK_REDUCE") || x.shape.length <= 2) {
    const intermediateTensorInfos = [];
    const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(x.shape, axes);
    const inSize = util_exports2.sizeFromShape(reduceShape);
    const a2D = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: [-1, inSize] } });
    intermediateTensorInfos.push(a2D);
    const reduced = argReduce(backend3, a2D, reduceType);
    intermediateTensorInfos.push(reduced);
    const reshaped = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: outShape } });
    intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
    return reshaped;
  }
  return argReducePacked(backend3, x, reduceType);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ArgMax.ts
function argMax4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports2.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("argMax", [axes[0]], $x.shape.length);
  const out = argMinMaxReduce(backend3, $x, axes[0], "max");
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return out;
}
var argMaxConfig2 = {
  kernelName: ArgMax2,
  backendName: "webgl",
  kernelFunc: argMax4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ArgMin.ts
function argMin4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports2.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports2.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("argMin", [axes[0]], $x.shape.length);
  const out = argMinMaxReduce(backend3, $x, axes[0], "min");
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return out;
}
var argMinConfig2 = {
  kernelName: ArgMin2,
  backendName: "webgl",
  kernelFunc: argMin4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Asin.ts
var ASIN = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
var asin4 = unaryKernelFunc2({ opSnippet: ASIN });
var asinConfig2 = {
  kernelName: Asin2,
  backendName: "webgl",
  kernelFunc: asin4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Asinh.ts
var ASINH = CHECK_NAN_SNIPPET + `return log(x + sqrt(x * x + 1.0));`;
var asinh4 = unaryKernelFunc2({ opSnippet: ASINH });
var asinhConfig2 = {
  kernelName: Asinh2,
  backendName: "webgl",
  kernelFunc: asinh4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Atan.ts
var ATAN = CHECK_NAN_SNIPPET + `
  return atan(x);
`;
var atan5 = unaryKernelFunc2({ opSnippet: ATAN });
var atanConfig2 = {
  kernelName: Atan3,
  backendName: "webgl",
  kernelFunc: atan5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Atan2.ts
var ATAN2 = CHECK_NAN_SNIPPET_BINARY + `
  return atan(a, b);
`;
var ATAN2_PACKED = `
  vec4 result = atan(a, b);
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET_BINARY_PACKED + `
  return result;
`;
var atan24 = binaryKernelFunc3({ opSnippet: ATAN2, packedOpSnippet: ATAN2_PACKED });
var atan2Config2 = {
  kernelName: Atan22,
  backendName: "webgl",
  kernelFunc: atan24
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Atanh.ts
var ATANH = CHECK_NAN_SNIPPET + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
var atanh4 = unaryKernelFunc2({ opSnippet: ATANH });
var atanhConfig2 = {
  kernelName: Atanh2,
  backendName: "webgl",
  kernelFunc: atanh4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/pool_gpu.ts
var Pool2DProgram = class {
  constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
    this.variableNames = ["x"];
    if (poolType === "avg" && computePositions) {
      throw new Error("Cannot compute positions for average pool.");
    }
    const filterWidth = convInfo.filterWidth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    this.outputShape = convInfo.outShape;
    const isAvgPool = poolType === "avg";
    const batchFlattenPositionStr = `((batch  * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
    const flattenPositionStr = `(xR * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
    let initializationValue = "0.0";
    if (!isAvgPool) {
      initializationValue = "-1.0 / 1e-20";
    }
    if (computePositions) {
      const compareOp2 = ">=";
      this.userCode = `
        const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
        const ivec2 pads = ivec2(${padTop}, ${padLeft});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${compareOp2} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${flattenPositions ? includeBatchInIndex ? batchFlattenPositionStr : flattenPositionStr : `wR * ${effectiveFilterWidth} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const compareOp = "max";
    let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    if (poolType === "avg") {
      returnValue = `avgValue / count`;
    }
    const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
    const filterWidthVec4Remainder = filterWidth % 4;
    const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
            int xC = xCCorner + wC * ${dilationWidth};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              getValue(batch, xR, xC + 3 * ${dilationWidth}, d)
            );

            ${updateSnippet}
          }

          int xC = xCCorner + ${filterWidthNearestVec4};
          if (${filterWidthVec4Remainder === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              initializationValue
            );

            ${updateSnippet}
          }
        }
        setOutput(${returnValue});
      }
    `;
  }
};
var Pool3DProgram = class {
  constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
    this.variableNames = ["x"];
    if (poolType === "avg" && computePositions) {
      throw new Error("Cannot compute positions for average pool.");
    }
    const filterWidth = convInfo.filterWidth;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    this.outputShape = convInfo.outShape;
    const isAvgPool = poolType === "avg";
    let initializationValue = "0.0";
    if (!isAvgPool) {
      initializationValue = "-1.0 / 1e-20";
    }
    if (computePositions) {
      const compareOp2 = ">=";
      this.userCode = `
        const ivec3 strides =
            ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
        const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${effectiveFilterDepth};
              wD += ${dilationDepth}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${convInfo.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${effectiveFilterHeight};
                wR += ${dilationHeight}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${effectiveFilterWidth};
                  wC += ${dilationWidth}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${compareOp2} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${flattenPositions ? includeBatchInIndex ? `(((batch * ${convInfo.inDepth} + xD) * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `((xD * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                      wR * ${effectiveFilterWidth} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const compareOp = "max";
    let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    if (poolType === "avg") {
      returnValue = `avgValue / count`;
    }
    const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
    const filterWidthVec4Remainder = filterWidth % 4;
    const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec3 strides =
        ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
              int xC = xCCorner + wC * ${dilationWidth};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 3 * ${dilationWidth}, ch)
              );

              ${updateSnippet}
            }

            int xC = xCCorner + ${filterWidthNearestVec4};
            if (${filterWidthVec4Remainder === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                initializationValue
              );

              ${updateSnippet}
            }
          }
          setOutput(${returnValue});
        }
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/AvgPool.ts
function avgPool4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  assertNotComplex2(x, "avgPool");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports2.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    return identity4({ inputs: { x }, backend: backend3 });
  }
  const avgPoolProgram = new Pool2DProgram(convInfo, "avg", false);
  return backend3.runWebGLProgram(avgPoolProgram, [x], "float32");
}
var avgPoolConfig2 = {
  kernelName: AvgPool2,
  backendName: "webgl",
  kernelFunc: avgPool4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/AvgPool3D.ts
function avgPool3D2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad4, dimRoundingMode, dataFormat } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode, dataFormat);
  const avgPoolProgram = new Pool3DProgram(convInfo, "avg", false);
  return backend3.runWebGLProgram(avgPoolProgram, [x], "float32");
}
var avgPool3DConfig2 = {
  kernelName: AvgPool3D2,
  backendName: "webgl",
  kernelFunc: avgPool3D2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/avg_pool_backprop_gpu.ts
var AvgPool2DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy"];
    this.outputShape = convInfo.inShape;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const avgMultiplier = 1 / (filterHeight * filterWidth);
    this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth};
            wC+= ${dilationWidth}) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var AvgPool3DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy"];
    this.outputShape = convInfo.inShape;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
    this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/AvgPool3DGrad.ts
function avgPool3DGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  const avgPoolBackpropProgram = new AvgPool3DBackpropProgram(convInfo);
  return backend3.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
}
var avgPoolGrad3DConfig = {
  kernelName: AvgPool3DGrad2,
  backendName: "webgl",
  kernelFunc: avgPool3DGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/AvgPoolGrad.ts
function avgPoolGrad3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  assertNotComplex2([dy, input2], "avgPoolGrad");
  const { filterSize, strides, pad: pad4 } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4);
  const avgPoolBackpropProgram = new AvgPool2DBackpropProgram(convInfo);
  return backend3.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
}
var avgPoolGradConfig3 = {
  kernelName: AvgPoolGrad2,
  backendName: "webgl",
  kernelFunc: avgPoolGrad3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/BatchMatMul.ts
function batchMatMul2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  return batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend3 });
}
var batchMatMulConfig2 = {
  kernelName: BatchMatMul2,
  backendName: "webgl",
  kernelFunc: batchMatMul2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/batchnorm_gpu.ts
var BatchNormProgram = class {
  constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
    this.outputShape = [];
    this.variableNames = ["x", "mean", "variance"];
    backend_util_exports2.assertAndGetBroadcastShape(xShape, meanShape);
    backend_util_exports2.assertAndGetBroadcastShape(xShape, varianceShape);
    let offsetSnippet = "0.0";
    if (offsetShape != null) {
      backend_util_exports2.assertAndGetBroadcastShape(xShape, offsetShape);
      this.variableNames.push("offset");
      offsetSnippet = "getOffsetAtOutCoords()";
    }
    let scaleSnippet = "1.0";
    if (scaleShape != null) {
      backend_util_exports2.assertAndGetBroadcastShape(xShape, scaleShape);
      this.variableNames.push("scale");
      scaleSnippet = "getScaleAtOutCoords()";
    }
    this.outputShape = xShape;
    this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${offsetSnippet};
        float scale = ${scaleSnippet};
        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/batchnorm_packed_gpu.ts
var BatchNormPackedProgram = class {
  constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
    this.packedInputs = true;
    this.packedOutput = true;
    this.variableNames = ["x", "mean", "variance"];
    backend_util_exports2.assertAndGetBroadcastShape(xShape, meanShape);
    backend_util_exports2.assertAndGetBroadcastShape(xShape, varianceShape);
    let offsetSnippet = "vec4(0.0)";
    if (offsetShape != null) {
      backend_util_exports2.assertAndGetBroadcastShape(xShape, offsetShape);
      this.variableNames.push("offset");
      offsetSnippet = "getOffsetAtOutCoords()";
    }
    let scaleSnippet = "vec4(1.0)";
    if (scaleShape != null) {
      backend_util_exports2.assertAndGetBroadcastShape(xShape, scaleShape);
      this.variableNames.push("scale");
      scaleSnippet = "getScaleAtOutCoords()";
    }
    this.outputShape = xShape;
    this.userCode = `
      void main() {
        vec4 offset = ${offsetSnippet};
        vec4 scale = ${scaleSnippet};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${varianceEpsilon}));

        setOutput((x - mean) * inv + offset);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/BatchNorm.ts
var batchNorm4 = ({ inputs, backend: backend3, attrs }) => {
  const { x, mean: mean5, variance, offset, scale: scale2 } = inputs;
  util_exports2.assert(mean5.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  util_exports2.assert(offset == null || mean5.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  util_exports2.assert(scale2 == null || mean5.shape.length === scale2.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  let { varianceEpsilon } = attrs;
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const finalInputs = [x, mean5, variance];
  let offsetShape = null;
  if (offset != null) {
    offsetShape = offset.shape;
    finalInputs.push(offset);
  }
  let scaleShape = null;
  if (scale2 != null) {
    scaleShape = scale2.shape;
    finalInputs.push(scale2);
  }
  const program = env2().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram(x.shape, mean5.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) : new BatchNormProgram(x.shape, mean5.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);
  const output = backend3.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);
  return output;
};
var batchNormConfig2 = {
  kernelName: FusedBatchNorm2,
  backendName: "webgl",
  kernelFunc: batchNorm4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/slice_gpu.ts
var SliceProgram = class {
  constructor(destSize) {
    this.variableNames = ["source"];
    this.outputShape = destSize;
    this.rank = destSize.length;
    const dtype = getCoordsDataType(this.rank);
    const uniformPart = `uniform int start[${this.rank}];`;
    const sourceCoords = getCoords(this.rank);
    let body;
    const coordSum = destSize.map((_, i) => {
      return `sourceLoc.${coords[i]} = start[${i}] + coords.${coords[i]};`;
    });
    body = `
        ${dtype} sourceLoc;
        ${dtype} coords = getOutputCoords();
        ${coordSum.join("\n")}
      `;
    this.userCode = `
      ${uniformPart}
      void main() {
        ${body}
        setOutput(getSource(${sourceCoords}));
      }
    `;
  }
  getCustomSetupFunc(start) {
    if (start.length !== this.rank) {
      throw Error(`The rank (${this.rank}) of the program must match the length of start (${start.length})`);
    }
    return (gpgpu, webGLProgram) => {
      if (this.startLoc == null) {
        this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "start");
        if (this.startLoc == null) {
          return;
        }
      }
      gpgpu.gl.uniform1iv(this.startLoc, start);
    };
  }
};
var coords = ["x", "y", "z", "w", "u", "v"];
function getCoords(rank) {
  if (rank === 1) {
    return "sourceLoc";
  } else if (rank <= 6) {
    return coords.slice(0, rank).map((x) => "sourceLoc." + x).join(",");
  } else {
    throw Error(`Slicing for rank ${rank} is not yet supported`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/slice_packed_gpu.ts
var SlicePackedProgram = class {
  constructor(destSize) {
    this.variableNames = ["source"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = destSize;
    this.rank = destSize.length;
    const dtype = getCoordsDataType(this.rank);
    const coords2 = getChannels("coords", this.rank);
    const sourceLoc = getChannels("sourceLoc", this.rank);
    const innerDims = this.rank === 1 ? "sourceLoc" : `vec2(${sourceLoc.slice(-2).join()})`;
    const getChannel = `getChannel(getSource(${sourceLoc.join()}), ${innerDims})`;
    const upperRow = `
      result.x = ${getChannel};
      if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
        ++${sourceLoc[this.rank - 1]};
        result.y = ${getChannel};
        --${sourceLoc[this.rank - 1]};
      }
    `;
    const lowerRow = this.rank === 1 ? "" : `
      --${coords2[this.rank - 1]};
      if (++${coords2[this.rank - 2]} < ${destSize[this.rank - 2]}) {
        ++${sourceLoc[this.rank - 2]};
        result.z = ${getChannel};
        if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
          ++${sourceLoc[this.rank - 1]};
          result.w = ${getChannel};
        }
      }
    `;
    const sourceLocSetup = this.rank <= 4 ? `sourceLoc = coords +
            ${dtype}(${destSize.map((_, i) => `start[${i}]`).join()});` : destSize.map((_, i) => `${sourceLoc[i]} = ${coords2[i]} + start[${i}];`).join("\n");
    this.userCode = `
      uniform int start[${this.rank}];
      void main() {
        ${dtype} coords = getOutputCoords();
        ${dtype} sourceLoc;
        ${sourceLocSetup}
        vec4 result = vec4(0.);
        ${upperRow}
        ${lowerRow}
        setOutput(result);
      }
    `;
  }
  getCustomSetupFunc(start) {
    if (start.length !== this.rank) {
      throw Error(`The rank (${this.rank}) of the program must match the length of start (${start.length})`);
    }
    return (gpgpu, webGLProgram) => {
      if (this.startLoc == null) {
        this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "start");
        if (this.startLoc == null) {
          return;
        }
      }
      gpgpu.gl.uniform1iv(this.startLoc, start);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Slice.ts
function shallowSlice(x, begin, size, backend3) {
  const xTexData = backend3.texData.get(x.dataId);
  const t = backend3.makeTensorInfo(size, x.dtype);
  const newTexData = backend3.texData.get(t.dataId);
  Object.assign(newTexData, xTexData);
  newTexData.refCount = 1;
  newTexData.shape = size;
  newTexData.dtype = x.dtype;
  let flatOffset = slice_util_exports2.computeFlatOffset(begin, util_exports2.computeStrides(x.shape));
  if (xTexData.slice) {
    flatOffset += xTexData.slice.flatOffset;
  }
  newTexData.slice = {
    flatOffset,
    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId
  };
  const refCount = backend3.dataRefCount.get(newTexData.slice.origDataId) || 1;
  backend3.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);
  return t;
}
function slice4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { begin, size } = attrs;
  const [$begin, $size] = slice_util_exports2.parseSliceParams(x, begin, size);
  slice_util_exports2.assertParamsValid(x, $begin, $size);
  if (util_exports2.sizeFromShape($size) === 0) {
    return backend3.makeTensorInfo($size, x.dtype, []);
  }
  if (backend3.shouldExecuteOnCPU([x]) || x.dtype === "string") {
    const xTexData = backend3.texData.get(x.dataId);
    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);
    return backend3.makeTensorInfo($size, x.dtype, outValues);
  }
  const { isPacked } = backend3.texData.get(x.dataId);
  const isContinous = slice_util_exports2.isSliceContinous(x.shape, $begin, $size);
  if (isPacked || !isContinous) {
    const program = env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram($size) : new SliceProgram($size);
    const customSetup = program.getCustomSetupFunc($begin);
    return backend3.runWebGLProgram(program, [x], x.dtype, customSetup);
  }
  backend3.uploadToGPU(x.dataId);
  return shallowSlice(x, $begin, $size, backend3);
}
var sliceConfig2 = {
  kernelName: Slice2,
  backendName: "webgl",
  kernelFunc: slice4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/BatchToSpaceND.ts
var batchToSpaceND4 = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockShape, crops } = attrs;
  util_exports2.assert(x.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  const prod6 = blockShape.reduce((a, b) => a * b);
  const reshaped = backend_util_exports2.getReshaped(x.shape, blockShape, prod6);
  const permuted = backend_util_exports2.getPermuted(reshaped.length, blockShape.length);
  const reshapedPermuted = backend_util_exports2.getReshapedPermuted(x.shape, blockShape, prod6);
  const sliceBeginCoords = backend_util_exports2.getSliceBeginCoords(crops, blockShape.length);
  const sliceSize = backend_util_exports2.getSliceSize(reshapedPermuted, crops, blockShape.length);
  const toDispose = [];
  const reshapedIntermediate = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: reshaped } });
  const transposedIntermediate = transpose5({ inputs: { x: reshapedIntermediate }, backend: backend3, attrs: { perm: permuted } });
  const reshapedIntermediate2 = reshape5({
    inputs: { x: transposedIntermediate },
    backend: backend3,
    attrs: { shape: reshapedPermuted }
  });
  const sliced = slice4({
    inputs: { x: reshapedIntermediate2 },
    backend: backend3,
    attrs: { begin: sliceBeginCoords, size: sliceSize }
  });
  toDispose.push(reshapedIntermediate);
  toDispose.push(transposedIntermediate);
  toDispose.push(reshapedIntermediate2);
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return sliced;
};
var batchToSpaceNDConfig2 = {
  kernelName: BatchToSpaceND2,
  backendName: "webgl",
  kernelFunc: batchToSpaceND4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Bincount.ts
function bincount4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, weights } = inputs;
  const { size } = attrs;
  const xVals = backend3.readSync(x.dataId);
  const weightsVals = backend3.readSync(weights.dataId);
  const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
  return backend3.makeTensorInfo([size], weights.dtype, outVals);
}
var bincountConfig2 = {
  kernelName: Bincount2,
  backendName: "webgl",
  kernelFunc: bincount4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/NotEqual.ts
var NOT_EQUAL = `return float(a != b);`;
var notEqual5 = binaryKernelFunc3({ opSnippet: NOT_EQUAL, cpuKernelImpl: notEqualImplCPU, dtype: "bool" });
var notEqualConfig2 = {
  kernelName: NotEqual2,
  backendName: "webgl",
  kernelFunc: notEqual5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Real.ts
function real5(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const inputData = backend3.texData.get(input2.dataId);
  return identity4({ inputs: { x: inputData.complexTensorInfos.real }, backend: backend3 });
}
var realConfig2 = {
  kernelName: Real2,
  backendName: "webgl",
  kernelFunc: real5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernel_utils/int.ts
var TO_INT = `return float(int(x));`;
function int(input2, backend3) {
  const program = new UnaryOpProgram(input2.shape, TO_INT);
  const output = backend3.runWebGLProgram(program, [input2], "int32");
  return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Cast.ts
function cast6(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity4({ inputs: { x }, backend: backend3 });
    }
    const zerosTensor = zeros2(x.shape);
    const floatX = cast6({ inputs: { x }, backend: backend3, attrs: { dtype: "float32" } });
    const result = complex5({ inputs: { real: floatX, imag: zerosTensor }, backend: backend3 });
    zerosTensor.dispose();
    backend3.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real5({ inputs: { input: x }, backend: backend3 });
    const result = cast6({ inputs: { x: realPart }, backend: backend3, attrs: { dtype } });
    backend3.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports2.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity4({ inputs: { x }, backend: backend3 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  if (dtype === "int32") {
    return int(x, backend3);
  }
  if (dtype === "bool") {
    const zerosTensorInfo = backend3.makeTensorInfo([], "bool", util_exports2.getTypedArrayFromDType("bool", 1));
    const binaryInputs = { a: x, b: zerosTensorInfo };
    const result = notEqual5({ inputs: binaryInputs, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(zerosTensorInfo);
    return result;
  }
  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
}
var castConfig2 = {
  kernelName: Cast2,
  backendName: "webgl",
  kernelFunc: cast6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Ceil.ts
var CEIL = `return ceil(x);`;
var ceil5 = unaryKernelFunc2({ opSnippet: CEIL, packedOpSnippet: CEIL, cpuKernelImpl: ceilImplCPU });
var ceilConfig2 = {
  kernelName: Ceil2,
  backendName: "webgl",
  kernelFunc: ceil5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/clip_gpu.ts
var ClipProgram = class {
  constructor(aShape) {
    this.variableNames = ["A"];
    this.outputShape = aShape;
    this.userCode = `
      uniform float minVal;
      uniform float maxVal;

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
  }
  getCustomSetupFunc(min7, max7) {
    return (gpgpu, webGLProgram) => {
      if (this.minLoc == null) {
        this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "minVal");
        this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "maxVal");
      }
      gpgpu.gl.uniform1f(this.minLoc, min7);
      gpgpu.gl.uniform1f(this.maxLoc, max7);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/clip_packed_gpu.ts
var ClipPackedProgram = class {
  constructor(aShape) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = aShape;
    this.userCode = `
      uniform float minVal;
      uniform float maxVal;

      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
  }
  getCustomSetupFunc(min7, max7) {
    return (gpgpu, webGLProgram) => {
      if (this.minLoc == null) {
        this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "minVal");
        this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "maxVal");
      }
      gpgpu.gl.uniform1f(this.minLoc, min7);
      gpgpu.gl.uniform1f(this.maxLoc, max7);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ClipByValue.ts
function clipByValue3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { clipValueMin, clipValueMax } = attrs;
  let program;
  if (env2().getBool("WEBGL_PACK_CLIP")) {
    program = new ClipPackedProgram(x.shape);
  } else {
    program = new ClipProgram(x.shape);
  }
  const customSetup = program.getCustomSetupFunc(clipValueMin, clipValueMax);
  return backend3.runWebGLProgram(program, [x], x.dtype, customSetup);
}
var clipByValueConfig = {
  kernelName: ClipByValue2,
  backendName: "webgl",
  kernelFunc: clipByValue3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/complex_abs_gpu.ts
var ComplexAbsProgram = class {
  constructor(shape) {
    this.variableNames = ["real", "imag"];
    this.outputShape = shape;
    this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ComplexAbs.ts
function makeComplexComponentTensorInfo(complexTensor, complexPart) {
  return {
    dataId: complexPart.dataId,
    dtype: complexPart.dtype,
    shape: complexTensor.shape
  };
}
function complexAbs2(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  const xData = backend3.texData.get(x.dataId);
  const program = new ComplexAbsProgram(x.shape);
  const programInputs = [
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)
  ];
  return backend3.runWebGLProgram(program, programInputs, programInputs[0].dtype);
}
var complexAbsConfig2 = {
  kernelName: ComplexAbs2,
  backendName: "webgl",
  kernelFunc: complexAbs2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/concat_gpu.ts
var ConcatProgram = class {
  constructor(shapes) {
    this.outputShape = [];
    this.outputShape = backend_util_exports2.computeOutShape(shapes, 1);
    this.variableNames = shapes.map((_, i) => `T${i}`);
    const offsets = new Array(shapes.length - 1);
    offsets[0] = shapes[0][1];
    for (let i = 1; i < offsets.length; i++) {
      offsets[i] = offsets[i - 1] + shapes[i][1];
    }
    const snippets = [`if (yC < ${offsets[0]}) setOutput(getT0(yR, yC));`];
    for (let i = 1; i < offsets.length; i++) {
      const shift = offsets[i - 1];
      snippets.push(`else if (yC < ${offsets[i]}) setOutput(getT${i}(yR, yC-${shift}));`);
    }
    const lastIndex = offsets.length;
    const lastShift = offsets[offsets.length - 1];
    snippets.push(`else setOutput(getT${lastIndex}(yR, yC-${lastShift}));`);
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${snippets.join("\n        ")}
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/concat_packed_gpu.ts
var ConcatPackedProgram = class {
  constructor(shapes, axis) {
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = [];
    this.outputShape = backend_util_exports2.computeOutShape(shapes, axis);
    const shape = this.outputShape;
    const rank = shape.length;
    const dtype = getCoordsDataType(rank);
    const coords2 = getChannels("coords", rank);
    const channels = ["x", "y", "z", "w", "u", "v"].slice(0, rank);
    this.variableNames = shapes.map((_, i) => `T${i}`);
    const offsets = new Array(shapes.length - 1);
    offsets[0] = shapes[0][axis];
    for (let i = 1; i < offsets.length; i++) {
      offsets[i] = offsets[i - 1] + shapes[i][axis];
    }
    const channel = channels[axis];
    const lastChannels = channels.slice(-2);
    const allChannels = channels.join();
    let getValueSnippet = `if (${channel} < ${offsets[0]}) {
        return getChannel(
            getT0(${allChannels}), vec2(${lastChannels.join()}));
        }`;
    for (let i = 1; i < offsets.length; i++) {
      const shift2 = offsets[i - 1];
      getValueSnippet += `
        if (${channel} < ${offsets[i]}  && ${channel} >= ${offsets[i - 1]}) {
          return getChannel(
            getT${i}(${shiftedChannels(channels, channel, shift2)}),
            vec2(${shiftedChannels(lastChannels, channel, shift2)}));
        }`;
    }
    const lastIndex = offsets.length;
    const shift = offsets[offsets.length - 1];
    getValueSnippet += `
        return getChannel(
          getT${lastIndex}(${shiftedChannels(channels, channel, shift)}),
          vec2(${shiftedChannels(lastChannels, channel, shift)}));`;
    this.userCode = `
      float getValue(${channels.map((x) => "int " + x)}) {
        ${getValueSnippet}
      }

      void main() {
        ${dtype} coords = getOutputCoords();
        vec4 result = vec4(getValue(${coords2}), 0., 0., 0.);

        ${coords2[rank - 1]} = ${coords2[rank - 1]} + 1;
        if (${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.g = getValue(${coords2});
        }

        ${coords2[rank - 2]} = ${coords2[rank - 2]} + 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]}) {
          result.a = getValue(${coords2});
        }

        ${coords2[rank - 1]} = ${coords2[rank - 1]} - 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]} &&
            ${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.b = getValue(${coords2});
        }
        setOutput(result);
      }
    `;
  }
};
function shiftedChannels(channels, channel, shift) {
  const channelIdx = channels.indexOf(channel);
  const res = channels.map((c, idx) => {
    if (idx === channelIdx) {
      return `${c} - ${shift}`;
    } else {
      return c;
    }
  });
  return res.join();
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Imag.ts
function imag4(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const inputData = backend3.texData.get(input2.dataId);
  return identity4({ inputs: { x: inputData.complexTensorInfos.imag }, backend: backend3 });
}
var imagConfig2 = {
  kernelName: Imag2,
  backendName: "webgl",
  kernelFunc: imag4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Concat_impl.ts
function concatImpl3(inputs, axis, backend3) {
  const dtype = inputs[0].dtype;
  if (dtype === "complex64") {
    const reals = inputs.map((t) => real5({ inputs: { input: t }, backend: backend3 }));
    const imags = inputs.map((t) => imag4({ inputs: { input: t }, backend: backend3 }));
    const realConcated = concatImpl3(reals, axis, backend3);
    const imagConcated = concatImpl3(imags, axis, backend3);
    const result2 = complex5({ inputs: { real: realConcated, imag: imagConcated }, backend: backend3 });
    reals.forEach((r) => backend3.disposeIntermediateTensorInfo(r));
    imags.forEach((i) => backend3.disposeIntermediateTensorInfo(i));
    backend3.disposeIntermediateTensorInfo(realConcated);
    backend3.disposeIntermediateTensorInfo(imagConcated);
    return result2;
  }
  let runOnCpu = backend3.shouldExecuteOnCPU(inputs);
  if (dtype === "string") {
    runOnCpu = true;
  }
  if (runOnCpu) {
    const tensors2D2 = inputs.map((t) => {
      const innerSize = util_exports2.sizeFromShape(t.shape.slice(axis));
      const shape = [-1, innerSize];
      return reshape5({ inputs: { x: t }, backend: backend3, attrs: { shape } });
    });
    const inputsValShapes = tensors2D2.map((t) => {
      return { vals: backend3.readSync(t.dataId), shape: t.shape };
    });
    const outShape2 = backend_util_exports2.computeOutShape(tensors2D2.map((t) => t.shape), 1);
    const simplyConcat = tensors2D2[0].shape[0] === 1;
    const outVals = concatImplCPU(inputsValShapes, outShape2, dtype, simplyConcat);
    const finalOutShape = backend_util_exports2.computeOutShape(inputs.map((t) => t.shape), axis);
    const outInfo = backend3.makeTensorInfo(finalOutShape, dtype, outVals);
    tensors2D2.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
    return outInfo;
  }
  if (inputs.length > env2().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    const midIndex = Math.floor(inputs.length / 2);
    const leftSide = concatImpl3(inputs.slice(0, midIndex), axis, backend3);
    const rightSide = concatImpl3(inputs.slice(midIndex), axis, backend3);
    const result2 = concatImpl3([leftSide, rightSide], axis, backend3);
    backend3.disposeIntermediateTensorInfo(leftSide);
    backend3.disposeIntermediateTensorInfo(rightSide);
    return result2;
  }
  if (env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && inputs[0].shape.length > 1) {
    const program2 = new ConcatPackedProgram(inputs.map((t) => t.shape), axis);
    return backend3.runWebGLProgram(program2, inputs, dtype);
  }
  const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend3);
  const program = new ConcatProgram(tensors2D.map((t) => t.shape));
  const result = backend3.runWebGLProgram(program, tensors2D, dtype);
  tensors2D.forEach((r) => backend3.disposeIntermediateTensorInfo(r));
  const reshapedResult = reshape5({ inputs: { x: result }, attrs: { shape: outShape }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(result);
  return reshapedResult;
}
function computeTensors2D(inputs, axis, backend3) {
  const outShape = backend_util_exports2.computeOutShape(inputs.map((t) => t.shape), axis);
  const tensors2D = inputs.map((x) => reshape5({
    inputs: { x },
    attrs: { shape: [-1, util_exports2.sizeFromShape(x.shape.slice(axis))] },
    backend: backend3
  }));
  return { tensors2D, outShape };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Concat.ts
function concat4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { axis } = attrs;
  const $axis = util_exports2.parseAxisParam(axis, inputs[0].shape)[0];
  const outShape = backend_util_exports2.computeOutShape(inputs.map((t) => t.shape), $axis);
  if (util_exports2.sizeFromShape(outShape) === 0) {
    return backend3.makeTensorInfo(outShape, inputs[0].dtype, []);
  }
  const $inputs = inputs.filter((t) => util_exports2.sizeFromShape(t.shape) > 0);
  if ($inputs.length === 1) {
    return identity4({ inputs: { x: $inputs[0] }, backend: backend3 });
  }
  const shapes = $inputs.map((t) => t.shape);
  backend_util_exports2.assertParamsConsistent(shapes, $axis);
  return concatImpl3($inputs, $axis, backend3);
}
var concatConfig2 = {
  kernelName: Concat2,
  backendName: "webgl",
  kernelFunc: concat4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/conv_gpu.ts
var Conv2DProgram = class {
  constructor(convInfo, addBias = false, activation2 = null, hasPreluActivationWeights = false, hasLeakyreluAlpha = false) {
    this.variableNames = ["x", "W"];
    this.outputShape = convInfo.outShape;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
    const inputDepthVec4Remainder = convInfo.inChannels % 4;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const rowDim = isChannelsLast ? 1 : 2;
    const colDim = isChannelsLast ? 2 : 3;
    const channelDim = isChannelsLast ? 3 : 1;
    let activationSnippet = "", applyActivationSnippet = "";
    if (activation2) {
      if (hasPreluActivationWeights) {
        activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation2}
        }`;
      } else if (hasLeakyreluAlpha) {
        activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation2}
        }`;
      } else {
        activationSnippet = `
          float activation(float x) {
            ${activation2}
          }
        `;
      }
      applyActivationSnippet = `result = activation(result);`;
    }
    const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivationWeights) {
      this.variableNames.push("preluActivationWeights");
    }
    if (hasLeakyreluAlpha) {
      this.variableNames.push("leakyreluAlpha");
    }
    this.userCode = `
      ${activationSnippet}

      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${channelDim}];

        ivec2 xRCCorner =
            ivec2(coords[${rowDim}], coords[${colDim}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * ${dilationHeight};

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * ${dilationWidth};

            if (xC < 0 || xC >= ${convInfo.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${isChannelsLast}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${inputDepthVec4Remainder === 1}) {

              if (${isChannelsLast}) {
                dotProd +=
                    getX(batch, xR, xC, ${inputDepthNearestVec4}) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              } else {
                dotProd +=
                    getX(batch, ${inputDepthNearestVec4}, xR, xC) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              }

            } else if (${inputDepthVec4Remainder === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2)
              );

              if (${isChannelsLast}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${inputDepthVec4Remainder === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 2, d2)
              );

              if (${isChannelsLast}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
  }
};
var Conv3DProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "W"];
    this.outputShape = convInfo.outShape;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
    const inputDepthVec4Remainder = convInfo.inChannels % 4;
    this.userCode = `
      const ivec3 strides = ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          int xF = xFCorner + wF * ${dilationDepth};

          if (xF < 0 || xF >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            int xR = xRCorner + wR * ${dilationHeight};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              int xC = xCCorner + wC * ${dilationWidth};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${inputDepthVec4Remainder === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}) *
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2);
              } else if (${inputDepthVec4Remainder === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${inputDepthVec4Remainder === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/im2col_packed_gpu.ts
var Im2ColPackedProgram = class {
  constructor(outputShape, inputShape, convInfo) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = outputShape;
    const {
      filterWidth,
      inChannels,
      strideWidth,
      strideHeight,
      padInfo,
      outWidth,
      dilationWidth,
      dilationHeight,
      dataFormat
    } = convInfo;
    const { left, top } = padInfo;
    const itemsPerBlockRow = inChannels * filterWidth;
    const glsl = getGlslDifferences();
    const isChannelsLast = dataFormat === "channelsLast";
    const rowDim = isChannelsLast ? 0 : 1;
    const colDim = isChannelsLast ? 1 : 2;
    let unrolled = ``;
    for (let row = 0; row <= 1; row++) {
      for (let col = 0; col <= 1; col++) {
        unrolled += `
          blockIndex = rc.y + ${col};
          pos = rc.x + ${row};

          if(blockIndex < ${outputShape[1]} && pos < ${outputShape[0]}) {
            offsetY = int(blockIndex / (${outWidth})) * ${strideHeight} - ${top};
            d0 = offsetY + ${dilationHeight} * (pos / ${itemsPerBlockRow});

            if(d0 < ${inputShape[rowDim]} && d0 >= 0) {

              offsetX = int(mod(float(blockIndex), ${outWidth}.) * ${strideWidth}. - ${left}.);
              d1 = offsetX + ${dilationWidth} * (int(mod(float(pos), ${itemsPerBlockRow}.) / ${inChannels}.));

              if(d1 < ${inputShape[colDim]} && d1 >= 0) {

                ch = int(mod(float(pos), ${inChannels}.));

                if (${isChannelsLast}) {
                  innerDims = vec2(d1, ch);
                  result[${row * 2 + col}] = getChannel(
                    getA(d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${row * 2 + col}] = getChannel(
                    getA(ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
      }
    }
    this.userCode = `
      void main() {
        ivec2 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${unrolled}

        ${glsl.output} = result;
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv2D_impl.ts
function conv2dByMatMul({
  x,
  filter,
  convInfo,
  backend: backend3,
  bias = null,
  preluActivationWeights = null,
  leakyreluAlpha = 0,
  activation: activation2 = null
}) {
  const xShape = x.shape;
  const xTexData = backend3.texData.get(x.dataId);
  const sharedMatMulDim = convInfo.inChannels;
  const outerShapeX = xShape[0] * xShape[1] * xShape[2];
  const outerShapeFilter = convInfo.outChannels;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const transposeA = false;
  const transposeB = false;
  let out;
  const intermediates = [];
  const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;
  const reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;
  if (batchMatMulWillBeUnpacked || !env2().getBool("WEBGL_LAZILY_UNPACK") || !env2().getBool("WEBGL_PACK_BINARY_OPERATIONS") || !reshapeWillBeExpensive) {
    const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] : xShape[0] * xShape[2] * xShape[3];
    const xReshaped = reshape5({
      inputs: { x },
      backend: backend3,
      attrs: { shape: [1, targetShape, convInfo.inChannels] }
    });
    const filterReshaped = reshape5({
      inputs: { x: filter },
      backend: backend3,
      attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
    });
    const result = batchMatMulImpl({
      a: xReshaped,
      b: filterReshaped,
      transposeA,
      transposeB,
      backend: backend3,
      bias,
      activation: activation2,
      preluActivationWeights,
      leakyreluAlpha
    });
    out = reshape5({ inputs: { x: result }, backend: backend3, attrs: { shape: convInfo.outShape } });
    intermediates.push(xReshaped);
    intermediates.push(filterReshaped);
    intermediates.push(result);
  } else {
    const targetShape = isChannelsLast ? xShape[0] * xShape[1] * (xShape[2] + 1) : xShape[0] * xShape[2] * (xShape[3] + 1);
    const xReshaped = {
      dataId: x.dataId,
      shape: [1, targetShape, convInfo.inChannels],
      dtype: x.dtype
    };
    const originalXTexDataShape = xTexData.shape;
    xTexData.shape = xTexData.shape.slice();
    xTexData.shape[xTexData.shape.length - 2]++;
    util_exports2.assert(isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);
    const filterReshaped = reshape5({
      inputs: { x: filter },
      backend: backend3,
      attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
    });
    intermediates.push(filterReshaped);
    const pointwiseConv = batchMatMulImpl({
      a: xReshaped,
      b: filterReshaped,
      backend: backend3,
      transposeA,
      transposeB,
      bias,
      activation: activation2,
      preluActivationWeights,
      leakyreluAlpha
    });
    const pointwiseConvTexData = backend3.texData.get(pointwiseConv.dataId);
    util_exports2.assert(pointwiseConvTexData.isPacked, () => "batchMatMul result is expected to be packed");
    xTexData.shape = originalXTexDataShape;
    pointwiseConvTexData.shape = convInfo.outShape;
    out = identity4({ inputs: { x: pointwiseConv }, backend: backend3 });
    out.shape = convInfo.outShape;
    intermediates.push(pointwiseConv);
  }
  for (const i of intermediates) {
    backend3.disposeIntermediateTensorInfo(i);
  }
  return out;
}
function conv2dWithIm2Row({
  x,
  filter,
  convInfo,
  backend: backend3,
  bias = null,
  preluActivationWeights = null,
  leakyreluAlpha = 0,
  activation: activation2 = null
}) {
  const {
    filterWidth,
    filterHeight,
    inChannels,
    outWidth,
    outHeight,
    dataFormat
  } = convInfo;
  const isChannelsLast = dataFormat === "channelsLast";
  const sharedDim = filterWidth * filterHeight * inChannels;
  const numCols = outHeight * outWidth;
  const x2ColShape = [sharedDim, numCols];
  const transposeA = true;
  const transposeB = false;
  const intermediates = [];
  const xSqueezed = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: x.shape.slice(1) } });
  const w2Row = reshape5({
    inputs: { x: filter },
    backend: backend3,
    attrs: { shape: [1, sharedDim, util_exports2.sizeFromShape(filter.shape) / sharedDim] }
  });
  intermediates.push(xSqueezed);
  intermediates.push(w2Row);
  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);
  const im2Col = backend3.runWebGLProgram(im2ColProgram, [xSqueezed], "float32");
  const im2ColReshaped = reshape5({
    inputs: { x: im2Col },
    backend: backend3,
    attrs: { shape: [1, x2ColShape[0], x2ColShape[1]] }
  });
  intermediates.push(im2Col);
  intermediates.push(im2ColReshaped);
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation2 === "leakyrelu";
  const fusedActivation = activation2 ? mapActivationToShaderProgram(activation2, true) : null;
  const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  const inputs = [im2ColReshaped, w2Row];
  if (bias) {
    inputs.push(bias);
  }
  if (hasPreluActivationWeights) {
    inputs.push(preluActivationWeights);
  }
  if (hasLeakyreluAlpha) {
    const $leakyreluAlpha = backend3.makeTensorInfo([], "float32", util_exports2.createScalarValue(leakyreluAlpha, "float32"));
    inputs.push($leakyreluAlpha);
    intermediates.push($leakyreluAlpha);
  }
  const product = backend3.runWebGLProgram(matmulProgram, inputs, "float32");
  const outShape = isChannelsLast ? [1, outHeight, outWidth, convInfo.outChannels] : [1, convInfo.outChannels, outHeight, outWidth];
  const out = reshape5({ inputs: { x: product }, backend: backend3, attrs: { shape: outShape } });
  intermediates.push(product);
  for (const i of intermediates) {
    backend3.disposeIntermediateTensorInfo(i);
  }
  return out;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv2D.ts
function conv2d6(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dataFormat, dilations, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode, false, $dataFormat);
  let out;
  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
    out = conv2dByMatMul({ x, filter, convInfo, backend: backend3 });
  } else if (env2().getBool("WEBGL_CONV_IM2COL") && x.shape[0] === 1) {
    out = conv2dWithIm2Row({ x, filter, convInfo, backend: backend3 });
  } else {
    const program = new Conv2DProgram(convInfo);
    out = backend3.runWebGLProgram(program, [x, filter], "float32");
  }
  const outReshaped = reshape5({ inputs: { x: out }, backend: backend3, attrs: { shape: convInfo.outShape } });
  backend3.disposeIntermediateTensorInfo(out);
  return outReshaped;
}
var conv2DConfig2 = {
  kernelName: Conv2D2,
  backendName: "webgl",
  kernelFunc: conv2d6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/conv_backprop_gpu.ts
var Conv2DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.outputShape = convInfo.filterShape;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              if (${isChannelsLast}) {
                float dyValue = getDy(b, yR, yC, d2);
                float xValue = getX(b, xR, xC, d1);
                dotProd += (xValue * dyValue);
              } else {
                float dyValue = getDy(b, d2, yR, yC);
                float xValue = getX(b, d1, xR, xC);
                dotProd += (xValue * dyValue);
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var Conv2DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.outputShape = convInfo.inShape;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const isChannelsLast = convInfo.dataFormat === "channelsLast";
    const padTop = filterHeight - 1 - convInfo.padInfo.top;
    const padLeft = filterWidth - 1 - convInfo.padInfo.left;
    const rowDim = isChannelsLast ? 1 : 2;
    const colDim = isChannelsLast ? 2 : 3;
    const channelDim = isChannelsLast ? 3 : 1;
    this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${channelDim}];

        ivec2 dyCorner = ivec2(coords[${rowDim}], coords[${colDim}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {

              if (${isChannelsLast}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var Conv3DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.outputShape = convInfo.filterShape;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const padFront = convInfo.padInfo.front;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yF = 0; yF < ${convInfo.outDepth}; yF++) {
            int xF = wF + yF * ${strideDepth} - ${padFront};

            if (xF < 0 || xF >= ${convInfo.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
              int xR = wR + yR * ${strideHeight} - ${padTop};

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
                int xC = wC + yC * ${strideWidth} - ${padLeft};

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var Conv3DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.outputShape = convInfo.inShape;
    const filterDepth = convInfo.filterDepth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const padFront = filterDepth - 1 - convInfo.padInfo.front;
    const padTop = filterHeight - 1 - convInfo.padInfo.top;
    const padLeft = filterWidth - 1 - convInfo.padInfo.left;
    this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          float dyF = float(dyFCorner + wF) / ${strideDepth}.0;

          if (dyF < 0.0 || dyF >= ${convInfo.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${filterDepth} - 1 - wF;

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${filterHeight} - 1 - wR;

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${filterWidth} - 1 - wC;

              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv2DBackpropFilter.ts
function conv2DBackpropFilter4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad4, dataFormat, dimRoundingMode, filterShape } = attrs;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filterShape, strides, 1, pad4, dimRoundingMode, false, $dataFormat);
  const program = new Conv2DDerFilterProgram(convInfo);
  return backend3.runWebGLProgram(program, [x, dy], "float32");
}
var conv2DBackpropFilterConfig2 = {
  kernelName: Conv2DBackpropFilter2,
  backendName: "webgl",
  kernelFunc: conv2DBackpropFilter4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv2DBackpropInput.ts
function conv2DBackpropInput4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { inputShape, strides, pad: pad4, dataFormat, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad4, dimRoundingMode, false, $dataFormat);
  const program = new Conv2DDerInputProgram(convInfo);
  return backend3.runWebGLProgram(program, [dy, filter], "float32");
}
var conv2DBackpropInputConfig2 = {
  kernelName: Conv2DBackpropInput2,
  backendName: "webgl",
  kernelFunc: conv2DBackpropInput4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv3D.ts
function conv3D2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dilations } = attrs;
  const convInfo = backend_util_exports2.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad4);
  const program = new Conv3DProgram(convInfo);
  return backend3.runWebGLProgram(program, [x, filter], "float32");
}
var conv3DConfig2 = {
  kernelName: Conv3D2,
  backendName: "webgl",
  kernelFunc: conv3D2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv3DBackpropFilterV2.ts
function conv3DBackpropFilterV22(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad4, filterShape } = attrs;
  const convInfo = backend_util_exports2.computeConv3DInfo(x.shape, filterShape, strides, 1, pad4);
  const program = new Conv3DDerFilterProgram(convInfo);
  return backend3.runWebGLProgram(program, [x, dy], "float32");
}
var conv3DBackpropFilterV2Config2 = {
  kernelName: Conv3DBackpropFilterV22,
  backendName: "webgl",
  kernelFunc: conv3DBackpropFilterV22
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Conv3DBackpropInputV2.ts
function conv3DBackpropInput3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { pad: pad4, strides, inputShape } = attrs;
  const convInfo = backend_util_exports2.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad4);
  const program = new Conv3DDerInputProgram(convInfo);
  return backend3.runWebGLProgram(program, [dy, filter], "float32");
}
var conv3DBackpropInputConfig = {
  kernelName: Conv3DBackpropInputV22,
  backendName: "webgl",
  kernelFunc: conv3DBackpropInput3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Cos.ts
var COS = CHECK_NAN_SNIPPET_UNARY + `
  return cos(x);
`;
var cos4 = unaryKernelFunc2({ opSnippet: COS });
var cosConfig2 = {
  kernelName: Cos2,
  backendName: "webgl",
  kernelFunc: cos4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Cosh.ts
var COSH = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
var cosh4 = unaryKernelFunc2({ opSnippet: COSH });
var coshConfig2 = {
  kernelName: Cosh2,
  backendName: "webgl",
  kernelFunc: cosh4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/crop_and_resize_gpu.ts
var CropAndResizeProgram = class {
  constructor(imageShape, boxShape, cropSize, method, extrapolationValue) {
    this.variableNames = ["Image", "Boxes", "BoxInd"];
    this.outputShape = [];
    const [batch, imageHeight, imageWidth, depth] = imageShape;
    const [numBoxes] = boxShape;
    const [cropHeight, cropWidth] = cropSize;
    this.outputShape = [numBoxes, cropHeight, cropWidth, depth];
    const methodId = method === "bilinear" ? 1 : 0;
    const [inputHeightFloat, inputWidthFloat] = [`${imageHeight - 1}.0`, `${imageWidth - 1}.0`];
    const [heightRatio, heightScale, inY] = cropHeight > 1 ? [
      `${(imageHeight - 1) / (cropHeight - 1)}`,
      "(y2-y1) * height_ratio",
      `y1*${inputHeightFloat} + float(y)*(height_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (y1+y2) * ${inputHeightFloat}`
    ];
    const [widthRatio, widthScale, inX] = cropWidth > 1 ? [
      `${(imageWidth - 1) / (cropWidth - 1)}`,
      "(x2-x1) * width_ratio",
      `x1*${inputWidthFloat} + float(x)*(width_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (x1+x2) * ${inputWidthFloat}`
    ];
    this.userCode = `
      const float height_ratio = float(${heightRatio});
      const float width_ratio = float(${widthRatio});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${batch}) {
          return;
        }

        float height_scale = ${heightScale};
        float width_scale = ${widthScale};

        float in_y = ${inY};
        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }
        float in_x = ${inX};
        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${methodId} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/CropAndResize.ts
var cropAndResize4 = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { image: image4, boxes, boxInd } = inputs;
  const { cropSize, method, extrapolationValue } = attrs;
  const program = new CropAndResizeProgram(image4.shape, boxes.shape, cropSize, method, extrapolationValue);
  return backend3.runWebGLProgram(program, [image4, boxes, boxInd], "float32");
};
var cropAndResizeConfig2 = {
  kernelName: CropAndResize2,
  backendName: "webgl",
  kernelFunc: cropAndResize4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/cumsum_gpu.ts
var CumSumProgram = class {
  constructor(shape, exclusive, reverse6) {
    this.variableNames = ["x"];
    this.outputShape = shape;
    const rank = shape.length;
    const val = exclusive ? "0.0" : `getX(${getCoords2(rank, "coords")})`;
    const length = shape[shape.length - 1];
    let condition = "";
    let idxString = "";
    if (exclusive) {
      condition = reverse6 ? `end != ${length - 1}` : "end != 0";
      idxString = reverse6 ? "end + 1" : "end - 1";
    } else {
      condition = reverse6 ? `end + pow2 < ${length}` : "end >= pow2";
      idxString = reverse6 ? "end + pow2" : "end - pow2";
    }
    this.userCode = `
      uniform float index;
      void main() {
        ${getCoordsDataType(rank)} coords = getOutputCoords();
        int end = ${getFinalCoord(rank, "coords")};
        float val = ${val};
        int pow2 = int(pow(2.0, index));
        if (${condition}) {
          int idx = ${idxString};
          ${getFinalCoord(rank, "coords")} = idx;
          val += getX(${getCoords2(rank, "coords")});
        }
        setOutput(val);
      }
    `;
  }
  getCustomSetupFunc(index) {
    return (gpgpu, webGLProgram) => {
      if (this.index == null) {
        this.index = gpgpu.getUniformLocation(webGLProgram, "index");
      }
      gpgpu.gl.uniform1f(this.index, index);
    };
  }
};
function getCoords2(rank, name) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.x, ${name}.y`;
  } else if (rank === 3) {
    return `${name}.x, ${name}.y, ${name}.z`;
  } else if (rank === 4) {
    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;
  } else {
    throw Error(`Cumulative sum for rank ${rank} is not yet supported`);
  }
}
function getFinalCoord(rank, name) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.y`;
  } else if (rank === 3) {
    return `${name}.z`;
  } else if (rank === 4) {
    return `${name}.w`;
  } else {
    throw Error(`Cumulative sum for rank ${rank} is not yet supported`);
  }
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Cumsum.ts
function cumsum4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse6 } = attrs;
  const xRank = x.shape.length;
  const permutation = backend_util_exports2.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports2.getInnerMostAxes(1, xRank)[0];
  if (permutedAxis !== xRank - 1) {
    throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length - 1} but got axis=${axis}`);
  }
  const size = permutedX.shape[permutedAxis];
  let result = identity4({ inputs: { x: permutedX }, backend: backend3 });
  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {
    const program = new CumSumProgram(permutedX.shape, false, reverse6);
    const customSetup = program.getCustomSetupFunc(i);
    const prevResult = result;
    result = backend3.runWebGLProgram(program, [result], result.dtype, customSetup);
    backend3.disposeIntermediateTensorInfo(prevResult);
  }
  if (exclusive) {
    const program = new CumSumProgram(permutedX.shape, exclusive, reverse6);
    const prevResult = result;
    result = backend3.runWebGLProgram(program, [result], result.dtype);
    backend3.disposeIntermediateTensorInfo(prevResult);
  }
  if (permutation != null) {
    const reversePermutation = backend_util_exports2.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose5({ inputs: { x: result }, backend: backend3, attrs: { perm: reversePermutation } });
    backend3.disposeIntermediateTensorInfo(result);
    backend3.disposeIntermediateTensorInfo(permutedX);
    return reverseTransposedResult;
  }
  return result;
}
var cumsumConfig2 = {
  kernelName: Cumsum2,
  backendName: "webgl",
  kernelFunc: cumsum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/DenseBincount.ts
function denseBincount4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, weights } = inputs;
  const { size, binaryOutput } = attrs;
  if (x.shape.length === 1) {
    const xVals = backend3.readSync(x.dataId);
    const weightsVals = backend3.readSync(weights.dataId);
    const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
    return backend3.makeTensorInfo([size], weights.dtype, outVals);
  } else if (x.shape.length === 2) {
    const xBuf = backend3.bufferSync(x);
    const weightsBuf = backend3.bufferSync(weights);
    const outBuf = bincountReduceImplCPU(xBuf, weightsBuf, size, binaryOutput);
    return backend3.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
}
var denseBincountConfig2 = {
  kernelName: DenseBincount2,
  backendName: "webgl",
  kernelFunc: denseBincount4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/depth_to_space_gpu.ts
var DepthToSpaceProgram = class {
  constructor(outputShape, blockSize, dataFormat) {
    this.variableNames = ["x"];
    this.outputShape = [];
    this.outputShape = outputShape;
    this.blockSize = blockSize;
    this.dataFormat = dataFormat;
    this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${blockSize};
      int offset_h = imod(h, ${blockSize});
      int in_w = w / ${blockSize};
      int offset_w = imod(w, ${blockSize});
      int offset_d = (offset_h * ${blockSize} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
  }
  getHeightCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[1]`;
    } else {
      return `coords[2]`;
    }
  }
  getWidthCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[2]`;
    } else {
      return `coords[3]`;
    }
  }
  getDepthCoordString() {
    if (this.dataFormat === "NHWC") {
      return `coords[3]`;
    } else {
      return `coords[1]`;
    }
  }
  getOutputDepthSize() {
    if (this.dataFormat === "NHWC") {
      return this.outputShape[3];
    } else {
      return this.outputShape[1];
    }
  }
  getInputSamplingString() {
    if (this.dataFormat === "NHWC") {
      return `getX(b, in_h, in_w, in_d)`;
    } else {
      return `getX(b, in_d, in_h, in_w)`;
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/DepthToSpace.ts
function depthToSpace4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  util_exports2.assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
  const batchSize = x.shape[0];
  const inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
  const program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);
  return backend3.runWebGLProgram(program, [x], x.dtype);
}
var depthToSpaceConfig2 = {
  kernelName: DepthToSpace2,
  backendName: "webgl",
  kernelFunc: depthToSpace4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/conv_gpu_depthwise.ts
var DepthwiseConv2DProgram = class {
  constructor(convInfo, addBias = false, activation2 = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
    this.variableNames = ["x", "W"];
    this.outputShape = convInfo.outShape;
    const xNumRows = convInfo.inHeight;
    const xNumCols = convInfo.inWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const channelMul = convInfo.outChannels / convInfo.inChannels;
    let activationSnippet = "", applyActivationSnippet = "";
    if (activation2) {
      if (hasPreluActivation) {
        activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation2}
        }`;
      } else if (hasLeakyReluAlpha) {
        activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation2}
        }`;
      } else {
        activationSnippet = `
          float activation(float x) {
            ${activation2}
          }
        `;
      }
      applyActivationSnippet = `result = activation(result);`;
    }
    const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    if (hasLeakyReluAlpha) {
      this.variableNames.push("leakyreluAlpha");
    }
    this.userCode = `
      ${activationSnippet}

      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * ${dilationHeight};

          if (xR < 0 || xR >= ${xNumRows}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * ${dilationWidth};

            if (xC < 0 || xC >= ${xNumCols}) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/conv_packed_gpu_depthwise.ts
var DepthwiseConvPacked2DProgram = class {
  constructor(convInfo, addBias = false, activation2 = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
    this.variableNames = ["x", "W"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = convInfo.outShape;
    const channelMul = convInfo.outChannels / convInfo.inChannels;
    const xNumRows = convInfo.inHeight;
    const xNumCols = convInfo.inWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const texelsAcross = filterWidth;
    let mainLoop = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
    for (let c = 0; c < filterWidth; c++) {
      mainLoop += `
          vec4 xTexelC${c * 2};
          int xTexelC${c * 2}Ready;
          vec4 xC${c};`;
    }
    for (let r = 0; r < filterHeight; r++) {
      for (let c = 0; c < filterWidth; c++) {
        mainLoop += `
          xTexelC${c * 2} = vec4(0.0);
          xTexelC${c * 2}Ready = 0;
          xC${c} = vec4(0.0);`;
      }
      mainLoop += `
        xR = xRCorner + ${r * dilationHeight};
        if (xR >=0 && xR < ${xNumRows}) {
      `;
      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
        const colIndex = texelC * 2;
        const c = colIndex * dilationWidth;
        mainLoop += `
          xC = xCCorner + ${c};
          `;
        if (strideWidth === 1) {
          if (colIndex < filterWidth) {
            if (padLeft % 2 === 1) {
              mainLoop += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {
                  xTexelC${c} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= ${xNumCols}) {
                    xTexelC${c}.zw = vec2(0.0);
                  }
                  xTexelC${c}Ready = 1;
                }
              `;
              if (dilationWidth === 1 && c > 0) {
                mainLoop += `
                xC${colIndex} = vec4(xTexelC${c - 2}.zw, xTexelC${c}.xy);
                `;
              } else {
                mainLoop += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < ${xNumCols}) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= ${xNumCols}) {
                      previous.zw = vec2(0.0);
                    }

                    xC${colIndex} = vec4(previous.zw, xTexelC${c}.xy);
                  } else {
                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${c}.xy);
                  }
                  `;
              }
            } else {
              mainLoop += `
                if (xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {
                  xTexelC${c} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= ${xNumCols}) {
                    xTexelC${c}.zw = vec2(0.0);
                  }
                  xTexelC${c}Ready = 1;
                }

                xC${colIndex} = xTexelC${c};
                `;
            }
            if (c + 1 < filterWidth) {
              const nextTexelOffset = padLeft % 2 === 0 ? util_exports2.nearestLargerEven(dilationWidth) : dilationWidth;
              if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                mainLoop += `
                  xCOffset = xC + ${padLeft % 2} + ${nextTexelOffset};

                  if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c + 2}Ready == 0) {
                    xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= ${xNumCols}) {
                      xTexelC${c + 2}.zw = vec2(0.0);
                    }
                    xTexelC${c + 2}Ready = 1;
                  }
                  `;
                if (dilationWidth > 1) {
                  mainLoop += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {
                      xTexelC${c} = getX(batch, xR, xCOffset, d1);
                      xTexelC${c}Ready = 1;
                    }
                    `;
                }
                mainLoop += `
                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.xy);
                  `;
              } else {
                if (nextTexelOffset === 1) {
                  mainLoop += `
                    xC${colIndex + 1} = xTexelC${c};
                    `;
                } else {
                  mainLoop += `
                    xCOffset = xC + ${nextTexelOffset};

                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c + 2}Ready == 0) {
                      xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= ${xNumCols}) {
                        xTexelC${c + 2}.zw = vec2(0.0);
                      }
                      xTexelC${c + 2}Ready = 1;
                    }

                    xC${colIndex + 1} = xTexelC${c + 2};
                    `;
                }
              }
            }
          }
        } else {
          if (c < filterWidth) {
            if (padLeft % 2 === 1) {
              mainLoop += `
                xCOffset = xC + 1 - ${strideWidth};
                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {
                  xTexelC${c} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= ${xNumCols}) {
                    xTexelC${c}.zw = vec2(0.0);
                  }
                  xTexelC${c}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < ${xNumCols} && xTexelC${c + 2}Ready == 0) {
                  xTexelC${c + 2} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= ${xNumCols}) {
                    xTexelC${c + 2}.zw = vec2(0.0);
                  }
                  xTexelC${c + 2}Ready = 1;
                }

                xC${colIndex} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);
              `;
              if (c + 1 < filterWidth) {
                mainLoop += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + ${strideWidth};
                  if(xCOffset >= 0 && xCOffset < ${xNumCols}) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${colIndex + 1} = vec4(xTexelC${c + 2}.xy, final.xy);
                `;
              }
            } else {
              mainLoop += `
                if(xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {
                  xTexelC${c} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= ${xNumCols}) {
                    xTexelC${c}.zw = vec2(0.0);
                  }
                  xTexelC${c}Ready = 1;
                }

                xCOffset = xC + ${strideWidth};
                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c + 2}Ready == 0) {
                  xTexelC${c + 2} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= ${xNumCols}) {
                    xTexelC${c + 2}.zw = vec2(0.);
                  }
                  xTexelC${c + 2}Ready = 1;
                }

                xC${colIndex} = vec4(
                  xTexelC${c}.xy, xTexelC${c + 2}.xy);
              `;
              if (c + 1 < filterWidth) {
                mainLoop += `
                  xC${colIndex + 1} = vec4(xTexelC${c}.zw, xTexelC${c + 2}.zw);
                `;
              }
            }
          }
        }
        if (colIndex < filterWidth) {
          mainLoop += `
            wTexel = getW(${r}, ${c}, d1, q);
            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);
          `;
          if (c + 1 < filterWidth) {
            mainLoop += `
              wTexel = getW(${r}, ${c + 1}, d1, q);
              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);
            `;
          }
        }
      }
      mainLoop += `
        }
      `;
    }
    let activationSnippet = "", applyActivationSnippet = "";
    if (activation2) {
      if (hasPreluActivation) {
        activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation2}
        }`;
      } else if (hasLeakyReluAlpha) {
        activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation2}
        }`;
      } else {
        activationSnippet = `vec4 activation(vec4 x) {
          ${activation2}
        }`;
      }
      applyActivationSnippet = `result = activation(result);`;
    }
    const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
    if (addBias) {
      this.variableNames.push("bias");
    }
    if (hasPreluActivation) {
      this.variableNames.push("preluActivationWeights");
    }
    if (hasLeakyReluAlpha) {
      this.variableNames.push("leakyreluAlpha");
    }
    this.userCode = `
      ${activationSnippet}

      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {

        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${mainLoop}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/DepthwiseConv2dNative.ts
function depthwiseConv2dNative2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dilations, dimRoundingMode } = attrs;
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad4, dimRoundingMode, true);
  let program;
  if (env2().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1) {
    program = new DepthwiseConvPacked2DProgram(convInfo);
  } else {
    program = new DepthwiseConv2DProgram(convInfo);
  }
  return backend3.runWebGLProgram(program, [x, filter], "float32");
}
var depthwiseConv2dNativeConfig2 = {
  kernelName: DepthwiseConv2dNative2,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNative2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/conv_backprop_gpu_depthwise.ts
var DepthwiseConv2DDerFilterProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "dy"];
    this.outputShape = convInfo.filterShape;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const padTop = convInfo.padInfo.top;
    const padLeft = convInfo.padInfo.left;
    const channelMul = convInfo.outChannels / convInfo.inChannels;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${channelMul} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var DepthwiseConv2DDerInputProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "W"];
    this.outputShape = convInfo.inShape;
    const filterHeight = convInfo.filterHeight;
    const filterWidth = convInfo.filterWidth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const padTop = filterHeight - 1 - convInfo.padInfo.top;
    const padLeft = filterWidth - 1 - convInfo.padInfo.left;
    const channelMul = convInfo.outChannels / convInfo.inChannels;
    this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${channelMul}; dm++) {
              int d2 = d1 * ${channelMul} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts
function depthwiseConv2dNativeBackpropFilter4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, dy } = inputs;
  const { strides, dilations, pad: pad4, dimRoundingMode, filterShape } = attrs;
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad4, dimRoundingMode, true);
  const program = new DepthwiseConv2DDerFilterProgram(convInfo);
  return backend3.runWebGLProgram(program, [x, dy], "float32");
}
var depthwiseConv2dNativeBackpropFilterConfig2 = {
  kernelName: DepthwiseConv2dNativeBackpropFilter2,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropFilter4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/DepthwiseConv2dNativeBackpropInput.ts
function depthwiseConv2dNativeBackpropInput4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, dilations, pad: pad4, dimRoundingMode, inputShape } = attrs;
  const convInfo = backend_util_exports2.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad4, dimRoundingMode, true);
  const program = new DepthwiseConv2DDerInputProgram(convInfo);
  return backend3.runWebGLProgram(program, [dy, filter], "float32");
}
var depthwiseConv2dNativeBackpropInputConfig2 = {
  kernelName: DepthwiseConv2dNativeBackpropInput2,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropInput4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/diag_gpu.ts
var DiagProgram = class {
  constructor(size) {
    this.variableNames = ["X"];
    this.outputShape = [size, size];
    this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Diag.ts
function diag4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  const outShape = [...x.shape, ...x.shape];
  const xSize = util_exports2.sizeFromShape(x.shape);
  const flat = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: [xSize] } });
  const program = new DiagProgram(xSize);
  const res = backend3.runWebGLProgram(program, [flat], flat.dtype);
  const out = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape: outShape } });
  backend3.disposeIntermediateTensorInfo(flat);
  backend3.disposeIntermediateTensorInfo(res);
  return out;
}
var diagConfig2 = {
  kernelName: Diag2,
  backendName: "webgl",
  kernelFunc: diag4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/dilation_gpu.ts
var Dilation2DProgram = class {
  constructor(convInfo) {
    this.variableNames = ["x", "W"];
    this.outputShape = convInfo.outShape;
    const {
      inHeight,
      inWidth,
      padInfo,
      strideHeight,
      strideWidth,
      filterHeight,
      filterWidth,
      dilationHeight,
      dilationWidth
    } = convInfo;
    const { top: padTop, left: padLeft } = padInfo;
    this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${filterHeight}; h++) {
          int hIn = hBeg + h * ${dilationHeight};

          if (hIn >= 0 && hIn < ${inHeight}) {
            for (int w = 0; w < ${filterWidth}; w++) {
              int wIn = wBeg + w * ${dilationWidth};

              if (wIn >= 0 && wIn < ${inWidth}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Dilation2D.ts
function dilation2D(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad4, dilations } = attrs;
  const convInfo = backend_util_exports2.computeDilation2DInfo(x.shape, filter.shape, strides, pad4, "NHWC", dilations);
  let out;
  const program = new Dilation2DProgram(convInfo);
  out = backend3.runWebGLProgram(program, [x, filter], "float32");
  const outReshaped = reshape5({ inputs: { x: out }, backend: backend3, attrs: { shape: convInfo.outShape } });
  backend3.disposeIntermediateTensorInfo(out);
  return outReshaped;
}
var dilation2DConfig = {
  kernelName: Dilation2D2,
  backendName: "webgl",
  kernelFunc: dilation2D
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Einsum.ts
function einsum4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { equation } = attrs;
  const tensors = inputs;
  const { allDims, summedDims, idDims } = backend_util_exports2.decodeEinsumEquation(equation, tensors.length);
  backend_util_exports2.checkEinsumDimSizes(allDims.length, idDims, tensors);
  const { path, steps } = backend_util_exports2.getEinsumComputePath(summedDims, idDims);
  const nSteps = steps.length;
  let out = null;
  let numDimsRemaining = allDims.length;
  const tensorsToDispose = [];
  for (let i = 0; i < nSteps; ++i) {
    for (const idTerm of steps[i]) {
      const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports2.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
      let x;
      if (backend_util_exports2.isIdentityPermutation(perm)) {
        x = tensors[idTerm];
      } else {
        x = transpose5({ inputs: { x: tensors[idTerm] }, backend: backend3, attrs: { perm } });
        tensorsToDispose.push(x);
      }
      const targetShape = x.shape.slice();
      for (let k = 0; k < dimsToExpand.length; ++k) {
        targetShape.splice(dimsToExpand[k], 0, 1);
      }
      if (!util_exports2.arraysEqual(x.shape, targetShape)) {
        x = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: targetShape } });
        tensorsToDispose.push(x);
      }
      if (out === null) {
        out = x;
      } else {
        out = multiply4({ inputs: { a: x, b: out }, backend: backend3 });
        tensorsToDispose.push(out);
      }
    }
    if (i < nSteps - 1) {
      if (path[i] >= 0) {
        out = sum6({
          inputs: { x: out },
          backend: backend3,
          attrs: {
            axis: path[i] - (allDims.length - numDimsRemaining),
            keepDims: false
          }
        });
        tensorsToDispose.push(out);
      }
      numDimsRemaining--;
    }
  }
  for (const tensorInfo of tensorsToDispose) {
    if (tensorInfo === out) {
      continue;
    }
    backend3.disposeIntermediateTensorInfo(tensorInfo);
  }
  return out;
}
var einsumConfig2 = {
  kernelName: Einsum2,
  backendName: "webgl",
  kernelFunc: einsum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Elu.ts
var ELU4 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
var ELU_PACKED = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var elu6 = unaryKernelFunc2({ opSnippet: ELU4, packedOpSnippet: ELU_PACKED });
var eluConfig2 = {
  kernelName: Elu2,
  backendName: "webgl",
  kernelFunc: elu6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/EluGrad.ts
var ELU_DER = `return (b >= 1.0) ? a : a * (b + 1.0);`;
var ELU_DER_PACKED = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
var eluGrad2 = (args) => {
  const { inputs, backend: backend3 } = args;
  const { dy, y } = inputs;
  const program = env2().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(ELU_DER_PACKED, dy.shape, y.shape) : new BinaryOpProgram(ELU_DER, dy.shape, y.shape);
  return backend3.runWebGLProgram(program, [dy, y], dy.dtype);
};
var eluGradConfig3 = {
  kernelName: EluGrad2,
  backendName: "webgl",
  kernelFunc: eluGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Equal.ts
var PACKED_EQUAL = `
  return vec4(equal(a, b));
`;
var EQUAL = `return float(a == b);`;
var equal5 = binaryKernelFunc3({
  opSnippet: EQUAL,
  packedOpSnippet: PACKED_EQUAL,
  dtype: "bool",
  cpuKernelImpl: equalImplCPU
});
var equalConfig2 = {
  kernelName: Equal2,
  backendName: "webgl",
  kernelFunc: equal5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Erf.ts
var ERF = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${backend_util_exports2.ERF_P};
  float a1 = ${backend_util_exports2.ERF_A1};
  float a2 = ${backend_util_exports2.ERF_A2};
  float a3 = ${backend_util_exports2.ERF_A3};
  float a4 = ${backend_util_exports2.ERF_A4};
  float a5 = ${backend_util_exports2.ERF_A5};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
var erf4 = unaryKernelFunc2({ opSnippet: ERF });
var erfConfig2 = {
  kernelName: Erf2,
  backendName: "webgl",
  kernelFunc: erf4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Exp.ts
var EXP = `return exp(x);`;
var exp5 = unaryKernelFunc2({ opSnippet: EXP, packedOpSnippet: EXP, cpuKernelImpl: expImplCPU });
var expConfig2 = {
  kernelName: Exp2,
  backendName: "webgl",
  kernelFunc: exp5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ExpandDims.ts
function expandDims5(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { dim } = attrs;
  const { input: input2 } = inputs;
  const inputRank = input2.shape.length;
  const newShape = input2.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports2.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape5({ inputs: { x: input2 }, backend: backend3, attrs: { shape: newShape } });
}
var expandDimsConfig2 = {
  kernelName: ExpandDims2,
  backendName: "webgl",
  kernelFunc: expandDims5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Expm1.ts
var EXPM1 = `return exp(x) - 1.0;`;
var expm15 = unaryKernelFunc2({ opSnippet: EXPM1, packedOpSnippet: EXPM1, cpuKernelImpl: expm1ImplCPU });
var expm1Config2 = {
  kernelName: Expm12,
  backendName: "webgl",
  kernelFunc: expm15
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/fft_gpu.ts
var FFTProgram = class {
  constructor(component, inputShape, inverse) {
    this.variableNames = ["real", "imag"];
    const innerDim = inputShape[1];
    this.outputShape = inputShape;
    const exponentMultiplierSnippet = inverse ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`;
    const resultDenominator = inverse ? `${innerDim}.0` : "1.0";
    let opString;
    if (component === "real") {
      opString = "return real * expR - imag * expI;";
    } else if (component === "imag") {
      opString = "return real * expI + imag * expR;";
    } else {
      throw new Error(`FFT component must be either "real" or "imag", got ${component}.`);
    }
    this.userCode = `
      const float exponentMultiplier = ${exponentMultiplierSnippet};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${opString}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${innerDim});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${innerDim}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${resultDenominator};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FFT_impl.ts
function fftImpl2(x, inverse, backend3) {
  const xData = backend3.texData.get(x.dataId);
  const inputSize = util_exports2.sizeFromShape(x.shape);
  const innerDimensionSize = x.shape[x.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: [batch, innerDimensionSize] } });
  const xShape = input2D.shape;
  const realProgram = new FFTProgram("real", xShape, inverse);
  const imagProgram = new FFTProgram("imag", xShape, inverse);
  const inputs = [
    {
      dataId: xData.complexTensorInfos.real.dataId,
      dtype: xData.complexTensorInfos.real.dtype,
      shape: xShape
    },
    {
      dataId: xData.complexTensorInfos.imag.dataId,
      dtype: xData.complexTensorInfos.imag.dtype,
      shape: xShape
    }
  ];
  const realPart = backend3.runWebGLProgram(realProgram, inputs, "float32");
  const imagPart = backend3.runWebGLProgram(imagProgram, inputs, "float32");
  const complexOutput = complex5({ inputs: { real: realPart, imag: imagPart }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(realPart);
  backend3.disposeIntermediateTensorInfo(imagPart);
  const complexOutputReshaped = reshape5({ inputs: { x: complexOutput }, backend: backend3, attrs: { shape: x.shape } });
  backend3.disposeIntermediateTensorInfo(input2D);
  backend3.disposeIntermediateTensorInfo(complexOutput);
  return complexOutputReshaped;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FFT.ts
function fft4(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  return fftImpl2(input2, false, backend3);
}
var fftConfig2 = {
  kernelName: FFT2,
  backendName: "webgl",
  kernelFunc: fft4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/fill_gpu.ts
var FillProgram = class {
  constructor(shape, value) {
    this.outputShape = [];
    this.variableNames = ["x"];
    this.outputShape = shape;
    this.userCode = `
      uniform float value;
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
  }
  getCustomSetupFunc(value) {
    return (gpgpu, webGLProgram) => {
      if (this.valueLoc == null) {
        this.valueLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "value");
      }
      gpgpu.gl.uniform1f(this.valueLoc, value);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Fill.ts
function fill4(args) {
  const { backend: backend3, attrs } = args;
  const { shape, value } = attrs;
  let { dtype } = attrs;
  dtype = dtype || util_exports2.inferDtype(value);
  if (dtype === "string") {
    const values = util_exports2.getArrayFromDType(dtype, util_exports2.sizeFromShape(shape));
    values.fill(value);
    return backend3.makeTensorInfo(shape, dtype, values);
  } else {
    const program = new FillProgram(shape, value);
    const customSetup = program.getCustomSetupFunc(value);
    return backend3.runWebGLProgram(program, [], dtype, customSetup);
  }
}
var fillConfig2 = {
  kernelName: Fill2,
  backendName: "webgl",
  kernelFunc: fill4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/flip_left_right_gpu.ts
var FlipLeftRightProgram = class {
  constructor(imageShape) {
    this.variableNames = ["Image"];
    this.outputShape = [];
    const imageWidth = imageShape[2];
    this.outputShape = imageShape;
    this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${imageWidth} - x;
          float outputValue;
          if(coordX >= 0 && coordX < ${imageWidth}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FlipLeftRight.ts
var flipLeftRightConfig2 = {
  kernelName: FlipLeftRight2,
  backendName: "webgl",
  kernelFunc: ({ inputs, backend: backend3 }) => {
    const { image: image4 } = inputs;
    const webglBackend = backend3;
    const program = new FlipLeftRightProgram(image4.shape);
    const output = webglBackend.runWebGLProgram(program, [image4], image4.dtype);
    return output;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Floor.ts
var FLOOR = `return floor(x);`;
var floor5 = unaryKernelFunc2({ opSnippet: FLOOR, packedOpSnippet: FLOOR, cpuKernelImpl: floorImplCPU });
var floorConfig2 = {
  kernelName: Floor2,
  backendName: "webgl",
  kernelFunc: floor5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FloorDiv.ts
var INT_DIV = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
var INT_DIV_PACKED = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
var floorDiv4 = binaryKernelFunc3({ opSnippet: INT_DIV, packedOpSnippet: INT_DIV_PACKED, dtype: "int32" });
var floorDivConfig2 = {
  kernelName: FloorDiv2,
  backendName: "webgl",
  kernelFunc: floorDiv4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FromPixels_utils/from_pixels_gpu.ts
var FromPixelsProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    const glsl = getGlslDifferences();
    const [height, width] = outputShape;
    this.outputShape = outputShape;
    this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);

        vec4 values = ${glsl.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FromPixels_utils/from_pixels_packed_gpu.ts
var FromPixelsPackedProgram = class {
  constructor(outputShape) {
    this.variableNames = ["A"];
    this.packedInputs = false;
    this.packedOutput = true;
    const glsl = getGlslDifferences();
    const [height, width] = outputShape;
    this.outputShape = outputShape;
    this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${width}.0, ${height}.0);
            vec4 values = ${glsl.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${glsl.output} = result;
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FromPixels.ts
var fromPixelsConfig = {
  kernelName: FromPixels2,
  backendName: "webgl",
  kernelFunc: fromPixels3
};
var fromPixels2DContext3;
function fromPixels3(args) {
  const { inputs, backend: backend3, attrs } = args;
  let { pixels } = inputs;
  const { numChannels } = attrs;
  const isVideo = typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement;
  const isImage = typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement;
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  const texShape = [height, width];
  const outShape = [height, width, numChannels];
  if (isImage || isVideo) {
    if (fromPixels2DContext3 == null) {
      fromPixels2DContext3 = document.createElement("canvas").getContext("2d");
    }
    fromPixels2DContext3.canvas.width = width;
    fromPixels2DContext3.canvas.height = height;
    fromPixels2DContext3.drawImage(pixels, 0, 0, width, height);
    pixels = fromPixels2DContext3.canvas;
  }
  const tempPixelHandle = backend3.makeTensorInfo(texShape, "int32");
  backend3.texData.get(tempPixelHandle.dataId).usage = TextureUsage.PIXELS;
  backend3.gpgpu.uploadPixelDataToTexture(backend3.getTexture(tempPixelHandle.dataId), pixels);
  const program = env2().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram(outShape) : new FromPixelsProgram(outShape);
  const res = backend3.runWebGLProgram(program, [tempPixelHandle], "int32");
  backend3.disposeData(tempPixelHandle.dataId);
  return res;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FusedConv2D.ts
function fusedConv2d(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const {
    strides,
    pad: pad4,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  } = attrs;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode, false, $dataFormat);
  let out;
  const intermediates = [];
  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
    out = conv2dByMatMul({
      x,
      filter,
      convInfo,
      backend: backend3,
      bias,
      activation: activation2,
      preluActivationWeights,
      leakyreluAlpha
    });
  } else if (env2().getBool("WEBGL_CONV_IM2COL") && x.shape[0] === 1) {
    out = conv2dWithIm2Row({
      x,
      filter,
      convInfo,
      backend: backend3,
      bias,
      activation: activation2,
      preluActivationWeights,
      leakyreluAlpha
    });
  } else {
    const hasBias = bias != null;
    const hasPreluActivationWeights = preluActivationWeights != null;
    const hasLeakyreluAlpha = activation2 === "leakyrelu";
    const fusedActivation = activation2 ? mapActivationToShaderProgram(activation2, false) : null;
    const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const inputs2 = [x, filter];
    if (bias) {
      inputs2.push(bias);
    }
    if (preluActivationWeights) {
      inputs2.push(preluActivationWeights);
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend3.makeTensorInfo([], "float32", util_exports2.createScalarValue(leakyreluAlpha, "float32"));
      inputs2.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    out = backend3.runWebGLProgram(program, inputs2, "float32");
  }
  const outReshaped = reshape5({ inputs: { x: out }, backend: backend3, attrs: { shape: convInfo.outShape } });
  intermediates.push(out);
  intermediates.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return outReshaped;
}
var fusedConv2DConfig2 = {
  kernelName: FusedConv2D2,
  backendName: "webgl",
  kernelFunc: fusedConv2d
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/FusedDepthwiseConv2D.ts
function fusedDepthwiseConv2D2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad4, dilations, dimRoundingMode, activation: activation2, leakyreluAlpha } = attrs;
  const intermediates = [];
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad4, dimRoundingMode, true);
  const shouldPackDepthwiseConv = env2().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;
  const fusedActivation = activation2 ? mapActivationToShaderProgram(activation2, shouldPackDepthwiseConv) : null;
  const programInputs = [x, filter];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation2 === "leakyrelu";
  if (hasBias) {
    programInputs.push(bias);
  }
  if (hasPreluActivationWeights) {
    programInputs.push(preluActivationWeights);
  }
  if (hasLeakyreluAlpha) {
    const $leakyreluAlpha = backend3.makeTensorInfo([], "float32", util_exports2.createScalarValue(leakyreluAlpha, "float32"));
    programInputs.push($leakyreluAlpha);
    intermediates.push($leakyreluAlpha);
  }
  let program;
  if (shouldPackDepthwiseConv) {
    program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  } else {
    program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  }
  const result = backend3.runWebGLProgram(program, programInputs, "float32");
  intermediates.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var fusedDepthwiseConv2DConfig2 = {
  kernelName: FusedDepthwiseConv2D2,
  backendName: "webgl",
  kernelFunc: fusedDepthwiseConv2D2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/gather_nd_gpu.ts
var GatherNDProgram = class {
  constructor(sliceDim, strides, shape) {
    this.sliceDim = sliceDim;
    this.strides = strides;
    this.variableNames = ["x", "indices"];
    this.outputShape = shape;
    const stridesType = getCoordsDataType(strides.length);
    const dtype = getCoordsDataType(shape.length);
    const strideString = this.sliceDim > 1 ? "strides[j]" : "strides";
    this.userCode = `
        ${stridesType} strides = ${stridesType}(${this.strides});
         void main() {
          ${dtype} coords = getOutputCoords();
          int flattenIndex = 0;
          for (int j = 0; j < ${this.sliceDim}; j++) {
            int index = round(getIndices(coords[0], j));
            flattenIndex += index * ${strideString};
          }
          setOutput(getX(flattenIndex, coords[1]));
        }
      `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/GatherNd.ts
function gatherNd2(args) {
  const { inputs, backend: backend3 } = args;
  const { params, indices } = inputs;
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const paramsSize = util_exports2.sizeFromShape(params.shape);
  const [resultShape, numSlices, sliceSize, strides] = backend_util_exports2.prepareAndValidate(params, indices);
  const flattenIndices = reshape5({ inputs: { x: indices }, backend: backend3, attrs: { shape: [numSlices, sliceRank] } });
  const flattenX = reshape5({
    inputs: { x: params },
    backend: backend3,
    attrs: { shape: [util_exports2.sizeFromShape(params.shape) / sliceSize, sliceSize] }
  });
  if (backend3.shouldExecuteOnCPU([params, indices]) || params.dtype === "string") {
    const indicesData = backend3.readSync(indices.dataId);
    const paramsBuf = backend3.bufferSync(params);
    const outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
    return backend3.makeTensorInfo(resultShape, params.dtype, outValue.values);
  }
  const program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);
  const res = backend3.runWebGLProgram(program, [flattenX, flattenIndices], flattenX.dtype);
  const reshaped = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape: resultShape } });
  backend3.disposeIntermediateTensorInfo(flattenIndices);
  backend3.disposeIntermediateTensorInfo(flattenX);
  backend3.disposeIntermediateTensorInfo(res);
  return reshaped;
}
var gatherNdConfig2 = {
  kernelName: GatherNd2,
  backendName: "webgl",
  kernelFunc: gatherNd2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/gather_gpu.ts
var GatherProgram = class {
  constructor(aShape, outputShape) {
    this.variableNames = ["A", "indices"];
    this.outputShape = outputShape;
    this.rank = outputShape.length;
    const dtype = getCoordsDataType(this.rank);
    const sourceCoords = getSourceCoords2(aShape, 2);
    this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        setOutput(getA(${sourceCoords}));
      }
    `;
  }
};
function getSourceCoords2(aShape, axis) {
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
  const sourceCoords = [];
  for (let i = 0; i < aShape.length; i++) {
    if (i === 2) {
      sourceCoords.push("int(getIndices(resRC.x, resRC.z))");
    } else {
      sourceCoords.push(`${currentCoords[i]}`);
    }
  }
  return sourceCoords.join();
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/GatherV2.ts
function gatherV22(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  const parsedAxis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const shapeInfo = backend_util_exports2.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
  const indicesSize = util_exports2.sizeFromShape(indices.shape);
  const toDispose = [];
  const flattenX = reshape5({
    inputs: { x },
    backend: backend3,
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    }
  });
  const flattenIndex = reshape5({
    inputs: { x: indices },
    backend: backend3,
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
  });
  toDispose.push(flattenX);
  toDispose.push(flattenIndex);
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  if (backend3.shouldExecuteOnCPU([x, indices]) || x.dtype === "string") {
    const indicesBuf = backend3.bufferSync(flattenIndex);
    const xBuf = backend3.bufferSync(flattenX);
    const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);
    toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
    return backend3.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
  }
  const program = new GatherProgram(flattenX.shape, flattenOutputShape);
  const res = backend3.runWebGLProgram(program, [flattenX, flattenIndex], flattenX.dtype);
  toDispose.push(res);
  const reshaped = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape: shapeInfo.outputShape } });
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return reshaped;
}
var gatherV2Config2 = {
  kernelName: GatherV22,
  backendName: "webgl",
  kernelFunc: gatherV22
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Greater.ts
var GREATER = `return float(a > b);`;
var GREATER_PACKED = `
  return vec4(greaterThan(a, b));
`;
var greater6 = binaryKernelFunc3({
  opSnippet: GREATER,
  packedOpSnippet: GREATER_PACKED,
  cpuKernelImpl: greaterImplCPU,
  dtype: "bool"
});
var greaterConfig2 = {
  kernelName: Greater2,
  backendName: "webgl",
  kernelFunc: greater6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/GreaterEqual.ts
var GREATER_EQUAL = `return float(a >= b);`;
var GREATER_EQUAL_PACKED = `
  return vec4(greaterThanEqual(a, b));
`;
var greaterEqual5 = binaryKernelFunc3({
  opSnippet: GREATER_EQUAL,
  packedOpSnippet: GREATER_EQUAL_PACKED,
  dtype: "bool",
  cpuKernelImpl: greaterEqualImplCPU
});
var greaterEqualConfig2 = {
  kernelName: GreaterEqual2,
  backendName: "webgl",
  kernelFunc: greaterEqual5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/IFFT.ts
function ifft4(args) {
  const { inputs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  return fftImpl2(input2, true, backend3);
}
var ifftConfig2 = {
  kernelName: IFFT2,
  backendName: "webgl",
  kernelFunc: ifft4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/IsFinite.ts
var IS_FINITE = `return float(!isnan(x) && !isinf(x));`;
var isFinite5 = unaryKernelFunc2({ opSnippet: IS_FINITE, dtype: "bool" });
var isFiniteConfig2 = {
  kernelName: IsFinite2,
  backendName: "webgl",
  kernelFunc: isFinite5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/IsInf.ts
var IS_INF = `return float(isinf(x));`;
var isInf4 = unaryKernelFunc2({ opSnippet: IS_INF, dtype: "bool" });
var isInfConfig2 = {
  kernelName: IsInf2,
  backendName: "webgl",
  kernelFunc: isInf4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/IsNaN.ts
var IS_NAN = `return float(isnan(x));`;
var isNaN5 = unaryKernelFunc2({ opSnippet: IS_NAN, dtype: "bool" });
var isNaNConfig2 = {
  kernelName: IsNan2,
  backendName: "webgl",
  kernelFunc: isNaN5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Less.ts
var LESS = `return float(a < b);`;
var LESS_PACKED = `
  return vec4(lessThan(a, b));
`;
var less6 = binaryKernelFunc3({
  opSnippet: LESS,
  packedOpSnippet: LESS_PACKED,
  cpuKernelImpl: lessImplCPU,
  dtype: "bool"
});
var lessConfig2 = {
  kernelName: Less2,
  backendName: "webgl",
  kernelFunc: less6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LessEqual.ts
var LESS_EQUAL = `return float(a <= b);`;
var LESS_EQUAL_PACKED = `
  return vec4(lessThanEqual(a, b));
`;
var lessEqual5 = binaryKernelFunc3({
  opSnippet: LESS_EQUAL,
  packedOpSnippet: LESS_EQUAL_PACKED,
  cpuKernelImpl: lessEqualImplCPU,
  dtype: "bool"
});
var lessEqualConfig2 = {
  kernelName: LessEqual2,
  backendName: "webgl",
  kernelFunc: lessEqual5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LinSpace.ts
function linSpace2(args) {
  const { backend: backend3, attrs } = args;
  const { start, stop, num } = attrs;
  const outVals = linSpaceImplCPU(start, stop, num);
  return backend3.makeTensorInfo([outVals.length], "float32", outVals);
}
var linSpaceConfig2 = {
  kernelName: LinSpace2,
  backendName: "webgl",
  kernelFunc: linSpace2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Log.ts
var LOG = `if (x < 0.0) return NAN;
  return log(x);`;
var LOG_PACKED = `
  vec4 result = log(x);
  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));
  result.r = isNaN.r == 1.0 ? NAN : result.r;
  result.g = isNaN.g == 1.0 ? NAN : result.g;
  result.b = isNaN.b == 1.0 ? NAN : result.b;
  result.a = isNaN.a == 1.0 ? NAN : result.a;

  return result;
`;
var log7 = unaryKernelFunc2({ opSnippet: LOG, packedOpSnippet: LOG_PACKED, cpuKernelImpl: logImplCPU });
var logConfig2 = {
  kernelName: Log2,
  backendName: "webgl",
  kernelFunc: log7
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Log1p.ts
var LOG1P = `return log(1.0 + x);`;
var log1p4 = unaryKernelFunc2({ opSnippet: LOG1P });
var log1pConfig2 = {
  kernelName: Log1p2,
  backendName: "webgl",
  kernelFunc: log1p4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LogicalAnd.ts
var LOGICAL_AND = `return float(a >= 1.0 && b >= 1.0);`;
var LOGICAL_AND_PACKED = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
var logicalAnd4 = binaryKernelFunc3({
  opSnippet: LOGICAL_AND,
  packedOpSnippet: LOGICAL_AND_PACKED,
  dtype: "bool"
});
var logicalAndConfig2 = {
  kernelName: LogicalAnd2,
  backendName: "webgl",
  kernelFunc: logicalAnd4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LogicalNot.ts
var LOGICAL_NOT = `return float(!(x >= 1.0));`;
var logicalNot4 = unaryKernelFunc2({ opSnippet: LOGICAL_NOT });
var logicalNotConfig2 = {
  kernelName: LogicalNot2,
  backendName: "webgl",
  kernelFunc: logicalNot4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LogicalOr.ts
var LOGICAL_OR = `return float(a >= 1.0 || b >= 1.0);`;
var LOGICAL_OR_PACKED = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
var logicalOr4 = binaryKernelFunc3({ opSnippet: LOGICAL_OR, packedOpSnippet: LOGICAL_OR_PACKED, dtype: "bool" });
var logicalOrConfig2 = {
  kernelName: LogicalOr2,
  backendName: "webgl",
  kernelFunc: logicalOr4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/lrn_gpu.ts
var LRNProgram = class {
  constructor(xShape, radius, bias, alpha, beta) {
    this.variableNames = ["x"];
    this.outputShape = [];
    const rad = radius;
    const maxD = xShape[3] - 1;
    this.outputShape = xShape;
    let powOperator;
    const basis = `float(${bias}) + float(${alpha}) * sum`;
    if (beta === 0.5) {
      powOperator = `inversesqrt(${basis})`;
    } else if (beta === 1) {
      powOperator = `1.0/(${basis})`;
    } else {
      powOperator = `exp(log(${basis}) * float(-${beta}));`;
    }
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${rad}; j <= ${rad}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${maxD}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${powOperator};
        setOutput(val);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/lrn_packed_gpu.ts
var LRNPackedProgram = class {
  constructor(xShape, radius, bias, alpha, beta) {
    this.variableNames = ["x"];
    this.outputShape = [];
    this.packedInputs = true;
    this.packedOutput = true;
    const rad = radius;
    const maxD = xShape[3] - 1;
    this.outputShape = xShape;
    let powOperator;
    const basis = `float(${bias}) + float(${alpha}) * sum`;
    if (beta === 0.5) {
      powOperator = `inversesqrt(${basis})`;
    } else if (beta === 1) {
      powOperator = `1.0/(${basis})`;
    } else {
      powOperator = `exp(log(${basis}) * float(-${beta}));`;
    }
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${rad};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${rad}; j <= ${rad}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${maxD}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${powOperator};
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LRN.ts
var lrn = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  const program = env2().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram(x.shape, depthRadius, bias, alpha, beta) : new LRNProgram(x.shape, depthRadius, bias, alpha, beta);
  return backend3.runWebGLProgram(program, [x], x.dtype);
};
var LRNConfig = {
  kernelName: LRN2,
  backendName: "webgl",
  kernelFunc: lrn
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/lrn_grad_gpu.ts
var LRNGradProgram = class {
  constructor(inputShape, depthRadius, bias, alpha, beta) {
    this.variableNames = ["inputImage", "outputImage", "dy"];
    this.outputShape = [];
    this.outputShape = inputShape;
    this.depth = inputShape[3];
    this.depthRadius = depthRadius;
    this.bias = bias;
    this.alpha = alpha;
    this.beta = beta;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${depthRadius})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${depthRadius} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${alpha}) * norm + float(${bias});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${alpha})
                * float(${beta})
                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${beta});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/LRNGrad.ts
var lrnGrad = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { x, y, dy } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  const program = new LRNGradProgram(x.shape, depthRadius, bias, alpha, beta);
  return backend3.runWebGLProgram(program, [x, y, dy], x.dtype);
};
var LRNGradConfig = {
  kernelName: LRNGrad2,
  backendName: "webgl",
  kernelFunc: lrnGrad
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Max_impl.ts
function maxImpl3(x, reduceShape, outShape, backend3) {
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const xSize = util_exports2.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape5({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend3 });
  const reduced = reduce(reshapedInput, x.dtype, "max", backend3);
  const reshapedOutput = reshape5({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(reshapedInput);
  backend3.disposeIntermediateTensorInfo(reduced);
  return reshapedOutput;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Max.ts
function max5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { reductionIndices, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports2.parseAxisParam(reductionIndices, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  const maxInputIsTransposed = permutedAxes != null;
  const shouldExecuteOnCPU = backend3.shouldExecuteOnCPU([x]);
  let maxInput = x;
  if (maxInputIsTransposed) {
    if (shouldExecuteOnCPU) {
      const xTexData = backend3.texData.get(maxInput.dataId);
      const values = xTexData.values;
      const newShape = new Array(xRank);
      for (let i = 0; i < newShape.length; i++) {
        newShape[i] = x.shape[permutedAxes[i]];
      }
      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
      maxInput = backend3.makeTensorInfo(newShape, x.dtype);
      const maxInputData = backend3.texData.get(maxInput.dataId);
      maxInputData.values = maxInputValues;
    } else {
      maxInput = transposeImpl3(x, permutedAxes, backend3);
    }
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("max", axes, xRank);
  const [maxOutShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(maxInput.shape, axes);
  let outShape = maxOutShape;
  if (keepDims) {
    outShape = backend_util_exports2.expandShapeToKeepDim(maxOutShape, origAxes);
  }
  let out;
  if (shouldExecuteOnCPU) {
    const xTexData = backend3.texData.get(maxInput.dataId);
    const values = xTexData.values;
    const outValues = maxImplCPU(values, util_exports2.sizeFromShape(reduceShape), outShape, x.dtype);
    out = backend3.makeTensorInfo(outShape, x.dtype);
    const outData = backend3.texData.get(out.dataId);
    outData.values = outValues;
  } else {
    out = maxImpl3(maxInput, reduceShape, outShape, backend3);
  }
  if (maxInputIsTransposed) {
    backend3.disposeIntermediateTensorInfo(maxInput);
  }
  return out;
}
var maxConfig2 = {
  kernelName: Max2,
  backendName: "webgl",
  kernelFunc: max5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Maximum.ts
var MAXIMUM = CHECK_NAN_SNIPPET2 + `
  return max(a, b);
`;
var MAXIMUM_PACKED = `
  vec4 result = vec4(max(a, b));
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
var maximum6 = binaryKernelFunc3({
  opSnippet: MAXIMUM,
  packedOpSnippet: MAXIMUM_PACKED,
  cpuKernelImpl: maximumImplCPU
});
var maximumConfig2 = {
  kernelName: Maximum2,
  backendName: "webgl",
  kernelFunc: maximum6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPool.ts
function maxPool4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  assertNotComplex2(x, "maxPool");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports2.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    return identity4({ inputs: { x }, backend: backend3 });
  }
  const maxPoolProgram = new Pool2DProgram(convInfo, "max", false);
  return backend3.runWebGLProgram(maxPoolProgram, [x], x.dtype);
}
var maxPoolConfig2 = {
  kernelName: MaxPool2,
  backendName: "webgl",
  kernelFunc: maxPool4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPool3D.ts
function maxPool3d3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad4, dataFormat, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode, dataFormat);
  const maxPoolProgram = new Pool3DProgram(convInfo, "max", false);
  return backend3.runWebGLProgram(maxPoolProgram, [x], x.dtype);
}
var maxPool3DConfig2 = {
  kernelName: MaxPool3D2,
  backendName: "webgl",
  kernelFunc: maxPool3d3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/max_pool_backprop_gpu.ts
var MaxPool2DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "maxPos"];
    this.outputShape = convInfo.inShape;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationHeight = convInfo.dilationHeight;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;
    this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
          wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${lastIndex} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${effectiveFilterWidth} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var MaxPool3DBackpropProgram = class {
  constructor(convInfo) {
    this.variableNames = ["dy", "maxPos"];
    this.outputShape = convInfo.inShape;
    const strideDepth = convInfo.strideDepth;
    const strideHeight = convInfo.strideHeight;
    const strideWidth = convInfo.strideWidth;
    const dilationDepth = convInfo.dilationDepth;
    const dilationHeight = convInfo.dilationHeight;
    const dilationWidth = convInfo.dilationWidth;
    const effectiveFilterDepth = convInfo.effectiveFilterDepth;
    const effectiveFilterHeight = convInfo.effectiveFilterHeight;
    const effectiveFilterWidth = convInfo.effectiveFilterWidth;
    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
    const lastIndex = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1;
    this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
           wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${lastIndex} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                  wR * ${effectiveFilterWidth} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPool3DGrad.ts
function maxPool3DGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports2.computePool3DInfo(x.shape, filterSize, strides, dilations, pad4, dimRoundingMode);
  const maxPool3dPositionsProgram = new Pool3DProgram(convInfo, "max", true);
  const maxPool3dPositions2 = backend3.runWebGLProgram(maxPool3dPositionsProgram, [x], x.dtype);
  const maxPoolBackpropProgram = new MaxPool3DBackpropProgram(convInfo);
  const result = backend3.runWebGLProgram(maxPoolBackpropProgram, [dy, maxPool3dPositions2], x.dtype);
  backend3.disposeIntermediateTensorInfo(maxPool3dPositions2);
  return result;
}
var maxPoolGrad3DConfig = {
  kernelName: MaxPool3DGrad2,
  backendName: "webgl",
  kernelFunc: maxPool3DGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPoolGrad.ts
function maxPoolGrad3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { dy, input: input2, output } = inputs;
  const x = input2;
  assertNotComplex2([input2, output], "maxPoolGrad");
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const getPositions = true;
  const maxPoolPositionsProgram = new Pool2DProgram(convInfo, "max", getPositions);
  const maxPoolPositions2 = backend3.runWebGLProgram(maxPoolPositionsProgram, [x], x.dtype);
  const maxPoolBackPropProgram = new MaxPool2DBackpropProgram(convInfo);
  const result = backend3.runWebGLProgram(maxPoolBackPropProgram, [dy, maxPoolPositions2], x.dtype);
  backend3.disposeIntermediateTensorInfo(maxPoolPositions2);
  return result;
}
var maxPoolGradConfig3 = {
  kernelName: MaxPoolGrad2,
  backendName: "webgl",
  kernelFunc: maxPoolGrad3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPoolWithArgmax_impl.ts
function maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, backend3) {
  let program = new Pool2DProgram(convInfo, "max", false);
  const poolOutput = backend3.runWebGLProgram(program, [x], "float32");
  program = new Pool2DProgram(convInfo, "max", true, true, includeBatchInIndex);
  const indexOutput = backend3.runWebGLProgram(program, [x], "float32");
  return [poolOutput, indexOutput];
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MaxPoolWithArgmax.ts
var maxPoolWithArgmaxConfig2 = {
  kernelName: MaxPoolWithArgmax2,
  backendName: "webgl",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    const { filterSize, strides, pad: pad4, includeBatchInIndex } = attrs;
    const webglBackend = backend3;
    util_exports2.assert(x.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);
    const dilations = [1, 1];
    util_exports2.assert(backend_util_exports2.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
    const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, dilations, pad4);
    const [result, indexes] = maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, webglBackend);
    return [result, indexes];
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Mean_impl.ts
function meanImpl(x, reduceShape, outShape, backend3) {
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const xSize = util_exports2.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape5({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend3 });
  const reduced = reduce(reshapedInput, "float32", "mean", backend3);
  const reshapedOutput = reshape5({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(reshapedInput);
  backend3.disposeIntermediateTensorInfo(reduced);
  return reshapedOutput;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Mean.ts
var meanConfig2 = {
  kernelName: Mean2,
  backendName: "webgl",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { x } = inputs;
    const { keepDims, axis } = attrs;
    const webglBackend = backend3;
    const xRank = x.shape.length;
    const origAxes = util_exports2.parseAxisParam(axis, x.shape);
    let axes = origAxes;
    const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
    const meanInputIsTransposed = permutedAxes != null;
    const shouldExecuteOnCPU = webglBackend.shouldExecuteOnCPU([x]);
    const intermediates = [];
    let meanInput = x;
    if (meanInputIsTransposed) {
      if (shouldExecuteOnCPU) {
        const xTexData = webglBackend.texData.get(meanInput.dataId);
        const values = xTexData.values;
        const newShape = new Array(xRank);
        for (let i = 0; i < newShape.length; i++) {
          newShape[i] = x.shape[permutedAxes[i]];
        }
        const meanInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
        meanInput = webglBackend.makeTensorInfo(newShape, x.dtype);
        const meanInputData = webglBackend.texData.get(meanInput.dataId);
        meanInputData.values = meanInputValues;
      } else {
        meanInput = transposeImpl3(x, permutedAxes, webglBackend);
      }
      intermediates.push(meanInput);
      axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
    }
    backend_util_exports2.assertAxesAreInnerMostDims("sum", axes, xRank);
    const [meanOutShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(meanInput.shape, axes);
    let outShape = meanOutShape;
    if (keepDims) {
      outShape = backend_util_exports2.expandShapeToKeepDim(meanOutShape, origAxes);
    }
    const out = meanImpl(meanInput, reduceShape, outShape, webglBackend);
    for (const i of intermediates) {
      webglBackend.disposeIntermediateTensorInfo(i);
    }
    return out;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Min.ts
function min5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("min", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports2.sizeFromShape(reduceShape);
  const a2D = reshape5({ inputs: { x: permutedX }, backend: backend3, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "min", backend3);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(outShape, origAxes);
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: newShape } });
  } else {
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: outShape } });
  }
  backend3.disposeIntermediateTensorInfo(a2D);
  backend3.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend3.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var minConfig2 = {
  kernelName: Min2,
  backendName: "webgl",
  kernelFunc: min5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Minimum.ts
var MINIMUM = CHECK_NAN_SNIPPET2 + `
  return min(a, b);
`;
var MINIMUM_PACKED = `
  vec4 result = vec4(min(a, b));
  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
var minimum6 = binaryKernelFunc3({
  opSnippet: MINIMUM,
  packedOpSnippet: MINIMUM_PACKED,
  cpuKernelImpl: minimumImplCPU
});
var minimumConfig2 = {
  kernelName: Minimum2,
  backendName: "webgl",
  kernelFunc: minimum6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/mirror_pad_gpu.ts
var MirrorPadProgram = class {
  constructor(xShape, paddings, mode) {
    this.variableNames = ["x"];
    this.outputShape = paddings.map((p2, i) => p2[0] + xShape[i] + p2[1]);
    const rank = xShape.length;
    const dtype = getCoordsDataType(rank);
    const start = paddings.map((p2) => p2[0]).join(",");
    const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
    const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
    const offset = mode === "reflect" ? 0 : 1;
    if (rank === 1) {
      this.userCode = `
        int start = ${start};
        int end = ${end};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${offset};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${offset};
          }
          setOutput(getX(outC - start));
        }
      `;
      return;
    }
    this.userCode = `
      ${dtype} start = ${dtype}(${start});
      ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outC = getOutputCoords();
        for (int i = 0; i < ${rank}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${offset};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${offset};
          }
        }
        ${dtype} coords = outC - start;
        setOutput(getX(${unpackedCoords}));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/mirror_pad_packed_gpu.ts
var MirrorPadPackedProgram = class {
  constructor(xShape, paddings, mode) {
    this.variableNames = ["x"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = paddings.map((p2, i) => p2[0] + xShape[i] + p2[1]);
    const rank = xShape.length;
    const dtype = getCoordsDataType(rank);
    const start = paddings.map((p2) => p2[0]).join(",");
    const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
    const coords2 = getChannels("rc", rank);
    const source = getChannels("source", rank);
    const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
    const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
    const offset = mode === "reflect" ? 0 : 1;
    let mainLoop = "";
    if (rank === 1) {
      const padSetup = `
        ${dtype} source = rc;
        if (source < start) {
          source = start * 2 - source - ${offset};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${offset};
        }
        source -= start;
      `;
      mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
    } else {
      const padSetup = `
        ${dtype} source = rc;
        ${dtype} lt = ${dtype}(lessThan(source, start));
        ${dtype} gte = ${dtype}(greaterThanEqual(source, end));
        ${dtype} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${offset}) +
                gte * ((end - 1) * 2 - source + ${offset});
        source -= start;
      `;
      mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
        rc = outputLoc;
        ${coords2[rank - 2]} += 1;
        if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {
          ${padSetup}
          result[2] = getChannel(getX(${source.join()}), ${innerDims});
          ${coords2[rank - 1]} += 1;
          if(${cLimit}) {
            ${padSetup}
            result[3] = getChannel(getX(${source.join()}), ${innerDims});
          }
        }
      `;
    }
    this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/MirrorPad.ts
var mirrorPadKernelFunc = ({ inputs, backend: backend3, attrs }) => {
  const { x } = inputs;
  const { paddings, mode } = attrs;
  const program = env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram(x.shape, paddings, mode) : new MirrorPadProgram(x.shape, paddings, mode);
  const output = backend3.runWebGLProgram(program, [x], x.dtype);
  return output;
};
var mirrorPadConfig2 = {
  kernelName: MirrorPad2,
  backendName: "webgl",
  kernelFunc: mirrorPadKernelFunc
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Mod.ts
var MOD = `if (b == 0.0) return NAN;
  return mod(a, b);`;
var MOD_PACKED = `
  vec4 result = mod(a, b);
  vec4 isNaN = vec4(equal(b, vec4(0.0)));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
var mod4 = binaryKernelFunc3({
  opSnippet: MOD,
  packedOpSnippet: MOD_PACKED
});
var modConfig2 = {
  kernelName: Mod2,
  backendName: "webgl",
  kernelFunc: mod4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/multinomial_gpu.ts
var MultinomialProgram = class {
  constructor(batchSize, numOutcomes, numSamples) {
    this.variableNames = ["probs"];
    this.outputShape = [batchSize, numSamples];
    this.userCode = `
      uniform float seed;

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${numOutcomes - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${numOutcomes - 1}));
      }
    `;
  }
  getCustomSetupFunc(seed) {
    return (gpgpu, webGLProgram) => {
      if (this.seedLoc == null) {
        this.seedLoc = gpgpu.getUniformLocation(webGLProgram, "seed");
      }
      gpgpu.gl.uniform1f(this.seedLoc, seed);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/RealDiv.ts
var DIV = `
if (a == b) {
  return 1.0;
};
return a / b;`;
var DIV_PACKED = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
var realDiv = binaryKernelFunc3({ opSnippet: DIV, packedOpSnippet: DIV_PACKED, checkOutOfBounds: true });
var realDivConfig2 = {
  kernelName: RealDiv2,
  backendName: "webgl",
  kernelFunc: realDiv
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sub.ts
var SUB = "return a - b;";
var sub5 = binaryKernelFunc3({
  opSnippet: SUB,
  packedOpSnippet: SUB,
  supportsComplex: true,
  cpuKernelImpl: subImplCPU
});
var subConfig2 = {
  kernelName: Sub2,
  backendName: "webgl",
  kernelFunc: sub5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Softmax.ts
function softmax5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { logits } = inputs;
  const { dim } = attrs;
  const axes = util_exports2.parseAxisParam([dim], logits.shape);
  const maxLogit = max5({
    inputs: { x: logits },
    backend: backend3,
    attrs: { reductionIndices: axes, keepDims: false }
  });
  const expandedShape = backend_util_exports2.expandShapeToKeepDim(maxLogit.shape, axes);
  const maxLogitsReshaped = reshape5({ inputs: { x: maxLogit }, backend: backend3, attrs: { shape: expandedShape } });
  const a = sub5({ inputs: { a: logits, b: maxLogitsReshaped }, backend: backend3 });
  const b = exp5({ inputs: { x: a }, backend: backend3 });
  const sumExp = sum6({ inputs: { x: b }, backend: backend3, attrs: { axis: axes, keepDims: false } });
  const sumExpReshaped = reshape5({ inputs: { x: sumExp }, backend: backend3, attrs: { shape: expandedShape } });
  const res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend: backend3 });
  backend3.disposeIntermediateTensorInfo(maxLogit);
  backend3.disposeIntermediateTensorInfo(maxLogitsReshaped);
  backend3.disposeIntermediateTensorInfo(a);
  backend3.disposeIntermediateTensorInfo(b);
  backend3.disposeIntermediateTensorInfo(sumExp);
  backend3.disposeIntermediateTensorInfo(sumExpReshaped);
  return res;
}
var softmaxConfig2 = {
  kernelName: Softmax2,
  backendName: "webgl",
  kernelFunc: softmax5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Multinomial.ts
function multinomial4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { logits } = inputs;
  const { numSamples, seed, normalized } = attrs;
  const probs = normalized ? logits : softmax5({ inputs: { logits }, backend: backend3, attrs: { dim: logits.shape.length - 1 } });
  const batchSize = probs.shape[0];
  const numOutcomes = probs.shape[1];
  const program = new MultinomialProgram(batchSize, numOutcomes, numSamples);
  const customSetup = program.getCustomSetupFunc(seed);
  const res = backend3.runWebGLProgram(program, [probs], "int32", customSetup);
  if (!normalized) {
    backend3.disposeIntermediateTensorInfo(probs);
  }
  return res;
}
var multinomialConfig2 = {
  kernelName: Multinomial2,
  backendName: "webgl",
  kernelFunc: multinomial4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Neg.ts
var NEG = `return -x;`;
function neg4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (backend3.shouldExecuteOnCPU([x])) {
    const xData = backend3.texData.get(x.dataId);
    const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);
    return backend3.makeTensorInfo(newShape, x.dtype, outValues);
  }
  let program;
  if (env2().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
    program = new UnaryOpPackedProgram(x.shape, NEG);
  } else {
    program = new UnaryOpProgram(x.shape, NEG);
  }
  return backend3.runWebGLProgram(program, [x], x.dtype);
}
var negConfig2 = {
  kernelName: Neg2,
  backendName: "webgl",
  kernelFunc: neg4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/NonMaxSuppressionV3.ts
var nonMaxSuppressionV3Impl4 = kernel_impls_exports2.nonMaxSuppressionV3Impl;
function nonMaxSuppressionV32(args) {
  backend_util_exports2.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
  const boxesVals = backend3.readSync(boxes.dataId);
  const scoresVals = backend3.readSync(scores.dataId);
  const { selectedIndices } = nonMaxSuppressionV3Impl4(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  return backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
}
var nonMaxSuppressionV3Config2 = {
  kernelName: NonMaxSuppressionV32,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV32
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/NonMaxSuppressionV4.ts
var nonMaxSuppressionV4Impl4 = kernel_impls_exports2.nonMaxSuppressionV4Impl;
function nonMaxSuppressionV42(args) {
  backend_util_exports2.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
  const boxesVals = backend3.readSync(boxes.dataId);
  const scoresVals = backend3.readSync(scores.dataId);
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl4(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
  return [
    backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend3.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
  ];
}
var nonMaxSuppressionV4Config2 = {
  kernelName: NonMaxSuppressionV42,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV42
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/NonMaxSuppressionV5.ts
var nonMaxSuppressionV5Impl4 = kernel_impls_exports2.nonMaxSuppressionV5Impl;
function nonMaxSuppressionV52(args) {
  backend_util_exports2.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend3, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
  const boxesVals = backend3.readSync(boxes.dataId);
  const scoresVals = backend3.readSync(scores.dataId);
  const maxOutputSizeVal = maxOutputSize;
  const iouThresholdVal = iouThreshold;
  const scoreThresholdVal = scoreThreshold;
  const softNmsSigmaVal = softNmsSigma;
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl4(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
  return [
    backend3.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend3.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
  ];
}
var nonMaxSuppressionV5Config2 = {
  kernelName: NonMaxSuppressionV52,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV52
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/onehot_gpu.ts
var OneHotProgram = class {
  constructor(numIndices, depth, onValue, offValue) {
    this.variableNames = ["indices"];
    this.outputShape = [numIndices, depth];
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${offValue}), float(${onValue}),
                      float(index == coords.y)));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/OneHot.ts
var oneHot4 = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { indices } = inputs;
  const { depth, onValue, offValue } = attrs;
  const indicesSize = util_exports2.sizeFromShape(indices.shape);
  const program = new OneHotProgram(indicesSize, depth, onValue, offValue);
  const reshaped = reshape5({ inputs: { x: indices }, backend: backend3, attrs: { shape: [indicesSize] } });
  const result = backend3.runWebGLProgram(program, [reshaped], indices.dtype);
  backend3.disposeIntermediateTensorInfo(reshaped);
  const outShape = [...indices.shape, depth];
  const out = reshape5({ inputs: { x: result }, backend: backend3, attrs: { shape: outShape } });
  backend3.disposeIntermediateTensorInfo(result);
  return out;
};
var oneHotConfig2 = {
  kernelName: OneHot2,
  backendName: "webgl",
  kernelFunc: oneHot4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ZerosLike.ts
function zerosLike4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (x.dtype === "complex64") {
    const realPart = real5({ inputs: { input: x }, backend: backend3 });
    const r = zerosLike4({ inputs: { x: realPart }, backend: backend3 });
    const imagPart = imag4({ inputs: { input: x }, backend: backend3 });
    const i = zerosLike4({ inputs: { x: imagPart }, backend: backend3 });
    const result = complex5({ inputs: { real: r, imag: i }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(realPart);
    backend3.disposeIntermediateTensorInfo(r);
    backend3.disposeIntermediateTensorInfo(imagPart);
    backend3.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill4({
      attrs: {
        shape: x.shape,
        dtype: x.dtype,
        value: x.dtype === "string" ? "" : 0
      },
      backend: backend3
    });
  }
}
var zerosLikeConfig2 = {
  kernelName: ZerosLike2,
  backendName: "webgl",
  kernelFunc: zerosLike4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/OnesLike.ts
function onesLike4(args) {
  const { inputs, backend: backend3 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("onesLike is not supported under string dtype");
  } else if (x.dtype === "complex64") {
    const realPart = real5({ inputs: { input: x }, backend: backend3 });
    const r = onesLike4({ inputs: { x: realPart }, backend: backend3 });
    const imagPart = imag4({ inputs: { input: x }, backend: backend3 });
    const i = zerosLike4({ inputs: { x: imagPart }, backend: backend3 });
    const result = complex5({ inputs: { real: r, imag: i }, backend: backend3 });
    backend3.disposeIntermediateTensorInfo(realPart);
    backend3.disposeIntermediateTensorInfo(r);
    backend3.disposeIntermediateTensorInfo(imagPart);
    backend3.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill4({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend: backend3 });
  }
}
var onesLikeConfig2 = {
  kernelName: OnesLike2,
  backendName: "webgl",
  kernelFunc: onesLike4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Pack.ts
function pack2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims5({ inputs: { input: inputs[0] }, backend: backend3, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t) => {
    util_exports2.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
    util_exports2.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t) => {
    const expandedT = expandDims5({ inputs: { input: t }, backend: backend3, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat4({ inputs: expandedTensors, backend: backend3, attrs: { axis } });
  intermediateTensorInfos.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var packConfig2 = {
  kernelName: Pack2,
  backendName: "webgl",
  kernelFunc: pack2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/pad_gpu.ts
var PadProgram = class {
  constructor(xShape, paddings, constantValue) {
    this.variableNames = ["x"];
    this.outputShape = paddings.map((p2, i) => p2[0] + xShape[i] + p2[1]);
    const rank = xShape.length;
    const type = getCoordsDataType(rank);
    const start = paddings.map((p2) => p2[0]).join(",");
    const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
    const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
    if (rank === 1) {
      this.userCode = `
        int start = ${start};
        int end = ${end};
        uniform float value;

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
      return;
    }
    this.userCode = `
      ${type} start = ${type}(${start});
      ${type} end = ${type}(${end});
      uniform float value;

      void main() {
        ${type} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${type} coords = outC - start;
          setOutput(getX(${unpackedCoords}));
        }
      }
    `;
  }
  getCustomSetupFunc(value) {
    return (gpgpu, webGLProgram) => {
      if (this.valueLoc == null) {
        this.valueLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "value");
      }
      gpgpu.gl.uniform1f(this.valueLoc, value);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/pad_packed_gpu.ts
var PadPackedProgram = class {
  constructor(xShape, paddings, constantValue) {
    this.variableNames = ["x"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = paddings.map((p2, i) => p2[0] + xShape[i] + p2[1]);
    const rank = xShape.length;
    const dtype = getCoordsDataType(rank);
    const start = paddings.map((p2) => p2[0]).join(",");
    const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
    const coords2 = getChannels("rc", rank);
    const source = getChannels("source", rank);
    const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
    const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
    const componentSetup = [
      `${dtype} rc = outputLoc;`,
      `${coords2[rank - 1]} += 1;
       if(${cLimit}) {
      `,
      rank === 1 ? "" : `}
       rc = outputLoc;
       ${coords2[rank - 2]} += 1;
       if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {`,
      rank === 1 ? "" : `  ${coords2[rank - 1]} += 1;
         if(${cLimit}) {`
    ];
    const paddingArea = rank === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
    let mainLoop = "";
    for (let i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {
      mainLoop += `
        ${componentSetup[i]}
        if (${paddingArea}) {
          result[${i}] = float(value);
        } else {
          ${dtype} source = rc - start;
          result[${i}] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
    }
    mainLoop += rank === 1 ? `} ` : `}}`;
    this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});
      uniform float value;

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
  }
  getCustomSetupFunc(value) {
    return (gpgpu, webGLProgram) => {
      if (this.valueLoc == null) {
        this.valueLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "value");
      }
      gpgpu.gl.uniform1f(this.valueLoc, value);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/PadV2.ts
var padV22 = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { paddings, constantValue } = attrs;
  const program = env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram(x.shape, paddings, constantValue) : new PadProgram(x.shape, paddings, constantValue);
  const customSetup = program.getCustomSetupFunc(constantValue);
  return backend3.runWebGLProgram(program, [x], x.dtype, customSetup);
};
var padV2Config2 = {
  kernelName: PadV22,
  backendName: "webgl",
  kernelFunc: padV22
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Pow.ts
var POW = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
var POW_PACKED = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));
  ` + CHECK_NAN_SNIPPET3 + `
  return result;
`;
var pow4 = binaryKernelFunc3({ opSnippet: POW, packedOpSnippet: POW_PACKED });
var powConfig2 = {
  kernelName: Pow2,
  backendName: "webgl",
  kernelFunc: pow4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Prod.ts
function prod4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const toDispose = [];
  const origAxes = util_exports2.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutedAxes } });
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
    toDispose.push(permutedX);
  }
  backend_util_exports2.assertAxesAreInnerMostDims("prod", axes, xRank);
  let res;
  if (backend3.shouldExecuteOnCPU([permutedX])) {
    const xVals = backend3.texData.get(permutedX.dataId).values;
    const { outVals, outShape, outDtype } = prodImplCPU(permutedX.shape, permutedX.dtype, xVals, axes);
    res = backend3.makeTensorInfo(outShape, outDtype, outVals);
  } else {
    const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(permutedX.shape, axes);
    const inSize = util_exports2.sizeFromShape(reduceShape);
    const a2D = reshape5({ inputs: { x: permutedX }, backend: backend3, attrs: { shape: [-1, inSize] } });
    const outputDType = sumOutType2(x.dtype);
    const reduced = reduce(a2D, outputDType, "prod", backend3);
    res = reshape5({ inputs: { x: reduced }, backend: backend3, attrs: { shape: outShape } });
    toDispose.push(a2D);
    toDispose.push(reduced);
  }
  if (keepDims) {
    toDispose.push(res);
    const newShape = backend_util_exports2.expandShapeToKeepDim(res.shape, origAxes);
    res = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape: newShape } });
  }
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return res;
}
var prodConfig2 = {
  kernelName: Prod2,
  backendName: "webgl",
  kernelFunc: prod4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Range.ts
var range5 = (args) => {
  const { backend: backend3, attrs } = args;
  const { start, stop, step: step6, dtype } = attrs;
  const values = rangeImplCPU(start, stop, step6, dtype);
  return backend3.makeTensorInfo([values.length], dtype, values);
};
var rangeConfig2 = {
  kernelName: Range2,
  backendName: "webgl",
  kernelFunc: range5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Reciprocal.ts
var RECIPROCAL = `return 1.0 / x;`;
var reciprocal4 = unaryKernelFunc2({ opSnippet: RECIPROCAL });
var reciprocalConfig2 = {
  kernelName: Reciprocal2,
  backendName: "webgl",
  kernelFunc: reciprocal4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Relu.ts
var RELU3 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
var RELU_PACKED = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var relu4 = unaryKernelFunc2({ opSnippet: RELU3, packedOpSnippet: RELU_PACKED });
var reluConfig2 = {
  kernelName: Relu2,
  backendName: "webgl",
  kernelFunc: relu4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Relu6.ts
var RELU63 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var RELU6_PACKED = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var relu64 = unaryKernelFunc2({ opSnippet: RELU63, packedOpSnippet: RELU6_PACKED });
var relu6Config2 = {
  kernelName: Relu62,
  backendName: "webgl",
  kernelFunc: relu64
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_bilinear_gpu.ts
var ResizeBilinearProgram = class {
  constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
    this.variableNames = ["A"];
    this.outputShape = [];
    const [batch, oldHeight, oldWidth, depth] = inputShape;
    this.outputShape = [batch, newHeight, newWidth, depth];
    const effectiveInSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    let sourceFracIndexRC;
    if (halfPixelCenters) {
      sourceFracIndexRC = `(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)`;
    } else {
      sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
    }
    this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_bilinear_packed_gpu.ts
var ResizeBilinearPackedProgram = class {
  constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = [];
    const [batch, oldHeight, oldWidth, depth] = inputShape;
    this.outputShape = [batch, newHeight, newWidth, depth];
    const effectiveInSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    let sourceFracIndexRC;
    if (halfPixelCenters) {
      sourceFracIndexRC = `(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)`;
    } else {
      sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
    }
    this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ResizeBilinear.ts
function resizeBilinear4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const program = env2().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeBilinearProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
  return backend3.runWebGLProgram(program, [images], "float32");
}
var resizeBilinearConfig2 = {
  kernelName: ResizeBilinear2,
  backendName: "webgl",
  kernelFunc: resizeBilinear4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_bilinear_backprop_gpu.ts
var ResizeBilinearBackpropProgram = class {
  constructor(dyShape, inputShape, alignCorners) {
    this.variableNames = ["dy"];
    this.outputShape = [];
    this.outputShape = inputShape;
    const [, xHeight, xWidth] = inputShape;
    const [, yHeight, yWidth] = dyShape;
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const invHeightScale = 1 / heightScale;
    const invWidthScale = 1 / widthScale;
    const winHeight = Math.ceil(invHeightScale) * 2 + 2;
    const winWidth = Math.ceil(invWidthScale) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${xHeight - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${xWidth - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ResizeBilinearGrad.ts
function resizeBilinearGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const program = new ResizeBilinearBackpropProgram(dy.shape, images.shape, alignCorners);
  return backend3.runWebGLProgram(program, [dy], dy.dtype);
}
var resizeBilinearGradConfig3 = {
  kernelName: ResizeBilinearGrad2,
  backendName: "webgl",
  kernelFunc: resizeBilinearGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_nearest_neighbor_gpu.ts
var ResizeNearestNeighborProgram = class {
  constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
    this.variableNames = ["A"];
    this.outputShape = [];
    const [batch, oldHeight, oldWidth, depth] = inputShape;
    this.outputShape = [batch, newHeight, newWidth, depth];
    const effectiveInSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    const roundBase = alignCorners ? "0.5" : "0.0";
    let sourceFracIndexRC;
    if (halfPixelCenters) {
      sourceFracIndexRC = `max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))`;
    } else {
      sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
    }
    this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_nearest_neighbor_packed_gpu.ts
var ResizeNearestNeighborPackedProgram = class {
  constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
    this.variableNames = ["A"];
    this.packedInputs = true;
    this.packedOutput = true;
    this.outputShape = [];
    const [batch, oldHeight, oldWidth, depth] = inputShape;
    this.outputShape = [batch, newHeight, newWidth, depth];
    const effectiveInSize = [
      alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
      alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
    ];
    const effectiveOutSize = [
      alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
      alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
    ];
    const roundBase = alignCorners ? "0.5" : "0.0";
    let sourceFracIndexRC;
    if (halfPixelCenters) {
      sourceFracIndexRC = `max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))`;
    } else {
      sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
    }
    this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ResizeNearestNeighbor.ts
function resizeNearestNeighbor4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const program = env2().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
  return backend3.runWebGLProgram(program, [images], images.dtype);
}
var resizeNearestNeighborConfig2 = {
  kernelName: ResizeNearestNeighbor2,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighbor4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/resize_nearest_neighbor_backprop_gpu.ts
var ResizeNearestNeigborBackpropProgram = class {
  constructor(dyShape, inputShape, alignCorners) {
    this.variableNames = ["dy"];
    this.outputShape = [];
    this.outputShape = inputShape;
    const [, xHeight, xWidth] = inputShape;
    const [, yHeight, yWidth] = dyShape;
    const effectiveXSize = [
      alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
      alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
    ];
    const effectiveYSize = [
      alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
      alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
    ];
    const heightScale = effectiveXSize[0] / effectiveYSize[0];
    const widthScale = effectiveXSize[1] / effectiveYSize[1];
    const invHeightScale = 1 / heightScale;
    const invWidthScale = 1 / widthScale;
    const winHeight = Math.ceil(invHeightScale) * 2 + 2;
    const winWidth = Math.ceil(invWidthScale) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float sourceFracRow =
              float(${effectiveXSize[0]}) *
                (float(dyR) / float(${effectiveYSize[0]}));

            float sourceFracCol =
                float(${effectiveXSize[1]}) *
                  (float(dyC) / float(${effectiveYSize[1]}));

            int sourceNearestRow = int(min(
                float(int(${xHeight}) - 1),
                ${alignCorners} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${xWidth}) - 1),
                ${alignCorners} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ResizeNearestNeighborGrad.ts
function resizeNearestNeighborGrad2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const program = new ResizeNearestNeigborBackpropProgram(dy.shape, images.shape, alignCorners);
  return backend3.runWebGLProgram(program, [dy], dy.dtype);
}
var resizeNearestNeighborGradConfig3 = {
  kernelName: ResizeNearestNeighborGrad2,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighborGrad2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/reverse_gpu.ts
var ReverseProgram = class {
  constructor(xShape, axis) {
    this.variableNames = ["x"];
    const rank = xShape.length;
    if (rank > 4) {
      throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
    }
    this.outputShape = xShape;
    if (rank === 1) {
      this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${xShape[0]} - coord - 1));
        }
      `;
      return;
    }
    const getInCoord = (i) => {
      if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
        return `${xShape[i]} - coords[${i}] - 1`;
      }
      return `coords[${i}]`;
    };
    const inCoords = xShape.map((_, i) => getInCoord(i)).join(",");
    const type = getCoordsDataType(rank);
    this.userCode = `
      void main() {
        ${type} coords = getOutputCoords();
        setOutput(getX(${inCoords}));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/reverse_packed_gpu.ts
var ReversePackedProgram = class {
  constructor(xShape, axis) {
    this.variableNames = ["x"];
    this.packedInputs = true;
    this.packedOutput = true;
    const rank = xShape.length;
    if (rank > 4) {
      throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
    }
    this.outputShape = xShape;
    const channels = getChannels("rc", rank);
    const nextColumn = `${channels[rank - 1]} + 1 < ${this.outputShape[rank - 1]}`;
    const nextRow = `${channels[rank - 2]} + 1 < ${this.outputShape[rank - 2]}`;
    const type = getCoordsDataType(rank);
    if (rank === 1) {
      this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${xShape[0]} - rc - 1),
            ${xShape[0]} - rc - 1);
          if(${nextColumn}){
              result.g = getChannel(getX(${xShape[0]} - (rc  + 1) - 1),
                ${xShape[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      `;
    } else {
      this.userCode = `
        void main() {
          ${type} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${getR(channels.slice())};
          if(${nextColumn}){
            result.g = ${getG(channels.slice())};
          }
          if(${nextRow}) {
            result.b = ${getB(channels.slice())};
            if(${nextColumn}) {
              result.a = ${getA(channels.slice())};
            }
          }
          setOutput(result);
        }
    `;
    }
    function getR(channels2) {
      return getChannel(channels2);
    }
    function getG(channels2) {
      channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
      return getChannel(channels2);
    }
    function getB(channels2) {
      channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
      return getChannel(channels2);
    }
    function getA(channels2) {
      channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
      channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
      return getChannel(channels2);
    }
    function getChannel(channels2) {
      const inCoordsArray = xShape.map((_, i) => getInCoord(i, channels2));
      const inCoords = inCoordsArray.join(",");
      const innerDims = inCoordsArray.slice(-2).join(",");
      return `getChannel(getX(${inCoords}), vec2(${innerDims}))`;
    }
    function getInCoord(i, channels1) {
      if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
        return `${xShape[i]} - ${channels1[i]} - 1`;
      } else {
        return `${channels1[i]}`;
      }
    }
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Reverse.ts
function reverse4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  const xRank = x.shape.length;
  const $dims = util_exports2.parseAxisParam(dims, x.shape);
  if (xRank === 0) {
    return identity4({ inputs: { x }, backend: backend3 });
  }
  const program = env2().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram(x.shape, $dims) : new ReverseProgram(x.shape, $dims);
  return backend3.runWebGLProgram(program, [x], x.dtype);
}
var reverseConfig2 = {
  kernelName: Reverse2,
  backendName: "webgl",
  kernelFunc: reverse4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/rotate_gpu.ts
var RotateProgram = class {
  constructor(imageShape, fillValue) {
    this.variableNames = ["Image"];
    this.outputShape = [];
    const imageHeight = imageShape[1];
    const imageWidth = imageShape[2];
    this.outputShape = imageShape;
    let fillSnippet = "";
    if (typeof fillValue === "number") {
      fillSnippet = `float outputValue = ${fillValue.toFixed(2)};`;
    } else {
      fillSnippet = `
        vec3 fill = vec3(${fillValue.join(",")});
        float outputValue = fill[coords[3]];`;
    }
    this.userCode = `
        uniform vec4 params;
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${fillSnippet}
          if(coordX >= 0 && coordX < ${imageWidth} && coordY >= 0 && coordY < ${imageHeight}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
  getCustomSetupFunc(centerX, centerY, sinFactor, cosFactor) {
    return (gpgpu, webGLProgram) => {
      if (this.paramsLoc == null) {
        this.paramsLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, "params");
      }
      gpgpu.gl.uniform4f(this.paramsLoc, centerX, centerY, sinFactor, cosFactor);
    };
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/RotateWithOffset.ts
var rotateWithOffsetConfig2 = {
  kernelName: RotateWithOffset2,
  backendName: "webgl",
  kernelFunc: ({ inputs, attrs, backend: backend3 }) => {
    const { image: image4 } = inputs;
    const { radians, fillValue, center } = attrs;
    const webglBackend = backend3;
    const program = new RotateProgram(image4.shape, fillValue);
    const [centerX, centerY] = backend_util_exports2.getImageCenter(center, image4.shape[1], image4.shape[2]);
    const customSetup = program.getCustomSetupFunc(centerX, centerY, Math.sin(radians), Math.cos(radians));
    const output = webglBackend.runWebGLProgram(program, [image4], image4.dtype, customSetup);
    return output;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Round.ts
var ROUND = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
var round6 = unaryKernelFunc2({ opSnippet: ROUND });
var roundConfig2 = {
  kernelName: Round2,
  backendName: "webgl",
  kernelFunc: round6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Rsqrt.ts
var RSQRT = `return inversesqrt(x);`;
var rsqrt5 = unaryKernelFunc2({ opSnippet: RSQRT, cpuKernelImpl: rsqrtImplCPU });
var rsqrtConfig2 = {
  kernelName: Rsqrt2,
  backendName: "webgl",
  kernelFunc: rsqrt5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/scatter_gpu.ts
var ScatterProgram = class {
  constructor(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex = true) {
    this.variableNames = ["updates", "indices", "defaultValue"];
    this.outputShape = shape;
    const stridesType = getCoordsDataType(strides.length);
    const dtype = getCoordsDataType(shape.length);
    let indicesString = "";
    if (indicesRank === 1) {
      indicesString = "i";
    } else if (indicesRank === 2) {
      indicesString = "i, j";
    }
    const indicesSnippet = `getIndices(${indicesString})`;
    let updatesString = "";
    if (updatesRank === 1) {
      updatesString = "i";
    } else if (updatesRank === 2) {
      updatesString = "i, coords[1]";
    }
    const updatesSnippet = `getUpdates(${updatesString})`;
    const strideString = sliceDim > 1 ? "strides[j]" : "strides";
    this.userCode = `
        ${stridesType} strides = ${stridesType}(${strides});

        void main() {
          ${dtype} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${updateSize}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${sliceDim}; j++) {
              int index = round(${indicesSnippet});
              flattenedIndex += index * ${strideString};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${updatesSnippet};
              found = true;
            }
          }
          setOutput(mix(getDefaultValue(), sum, float(found)));
        }
      `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/ScatterNd.ts
function scatterNd2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports2.calculateShapes(updates, indices, shape);
  const flattenShape = [outputSize / sliceSize, sliceSize];
  if (outputSize === 0) {
    return backend3.makeTensorInfo(shape, indices.dtype);
  }
  const flattenIndices = reshape5({ inputs: { x: indices }, backend: backend3, attrs: { shape: [numUpdates, sliceRank] } });
  const flattenX = reshape5({ inputs: { x: updates }, backend: backend3, attrs: { shape: [numUpdates, sliceSize] } });
  const defaultValue = backend3.makeTensorInfo([], "float32", new Float32Array([0]));
  const program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape);
  const res = backend3.runWebGLProgram(program, [flattenX, flattenIndices, defaultValue], flattenX.dtype);
  const reshaped = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape } });
  backend3.disposeIntermediateTensorInfo(flattenIndices);
  backend3.disposeIntermediateTensorInfo(flattenX);
  backend3.disposeIntermediateTensorInfo(res);
  backend3.disposeIntermediateTensorInfo(defaultValue);
  return reshaped;
}
var scatterNdConfig2 = {
  kernelName: ScatterNd2,
  backendName: "webgl",
  kernelFunc: scatterNd2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/select_gpu.ts
var SelectProgram = class {
  constructor(cRank, shape, rank) {
    this.variableNames = ["c", "a", "b"];
    this.outputShape = shape;
    let cCoords;
    let abCoords;
    if (rank > 4) {
      throw Error(`Where for rank ${rank} is not yet supported`);
    }
    if (rank === 1) {
      abCoords = `resRC`;
      cCoords = `resRC`;
    } else {
      const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
      const cCoordVars = [];
      const abCoordVars = [];
      for (let i = 0; i < shape.length; i++) {
        abCoordVars.push(`${currentCoords[i]}`);
        if (i < cRank) {
          cCoordVars.push(`${currentCoords[i]}`);
        }
      }
      cCoords = cCoordVars.join();
      abCoords = abCoordVars.join();
    }
    const dtype = getCoordsDataType(rank);
    this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        float cVal = getC(${cCoords});
        if (cVal >= 1.0) {
          setOutput(getA(${abCoords}));
        } else {
          setOutput(getB(${abCoords}));
        }
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Select.ts
function select2(args) {
  const { inputs, backend: backend3 } = args;
  const { condition, t, e } = inputs;
  const program = new SelectProgram(condition.shape.length, t.shape, t.shape.length);
  return backend3.runWebGLProgram(program, [condition, t, e], upcastType2(t.dtype, e.dtype));
}
var selectConfig2 = {
  kernelName: Select2,
  backendName: "webgl",
  kernelFunc: select2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Selu.ts
var SELU = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${backend_util_exports2.SELU_SCALEALPHA};
  float scale = ${backend_util_exports2.SELU_SCALE};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
var selu4 = unaryKernelFunc2({ opSnippet: SELU });
var seluConfig2 = {
  kernelName: Selu2,
  backendName: "webgl",
  kernelFunc: selu4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sigmoid.ts
var SIGMOID3 = `return 1.0 / (1.0 + exp(-1.0 * x));`;
var sigmoid4 = unaryKernelFunc2({ opSnippet: SIGMOID3 });
var sigmoidConfig2 = {
  kernelName: Sigmoid2,
  backendName: "webgl",
  kernelFunc: sigmoid4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sign.ts
var SIGN = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
var sign4 = unaryKernelFunc2({ opSnippet: SIGN });
var signConfig2 = {
  kernelName: Sign2,
  backendName: "webgl",
  kernelFunc: sign4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sin.ts
var SIN = CHECK_NAN_SNIPPET_UNARY + `
  return sin(x);
`;
var sin4 = unaryKernelFunc2({ opSnippet: SIN });
var sinConfig2 = {
  kernelName: Sin2,
  backendName: "webgl",
  kernelFunc: sin4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sinh.ts
var SINH = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
var sinh4 = unaryKernelFunc2({ opSnippet: SINH });
var sinhConfig2 = {
  kernelName: Sinh2,
  backendName: "webgl",
  kernelFunc: sinh4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Softplus.ts
var SOFTPLUS = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
var softplus4 = unaryKernelFunc2({ opSnippet: SOFTPLUS });
var softplusConfig2 = {
  kernelName: Softplus2,
  backendName: "webgl",
  kernelFunc: softplus4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SpaceToBatchND.ts
var spaceToBatchND4 = (args) => {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { blockShape, paddings } = attrs;
  util_exports2.assert(x.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  const prod6 = blockShape.reduce((a, b) => a * b);
  const completePaddings = [[0, 0]];
  completePaddings.push(...paddings);
  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
    completePaddings.push([0, 0]);
  }
  const toDispose = [];
  const paddedX = padV22({
    inputs: { x },
    backend: backend3,
    attrs: { paddings: completePaddings, constantValue: 0 }
  });
  const reshapedPaddedShape = backend_util_exports2.getReshaped(paddedX.shape, blockShape, prod6, false);
  const permutedReshapedPaddedPermutation = backend_util_exports2.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
  const flattenShape = backend_util_exports2.getReshapedPermuted(paddedX.shape, blockShape, prod6, false);
  const reshapedPaddedX = reshape5({ inputs: { x: paddedX }, backend: backend3, attrs: { shape: reshapedPaddedShape } });
  const paddedXT = transpose5({
    inputs: { x: reshapedPaddedX },
    backend: backend3,
    attrs: { perm: permutedReshapedPaddedPermutation }
  });
  const result = reshape5({ inputs: { x: paddedXT }, backend: backend3, attrs: { shape: flattenShape } });
  toDispose.push(paddedX);
  toDispose.push(reshapedPaddedX);
  toDispose.push(paddedXT);
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
};
var spaceToBatchNDConfig2 = {
  kernelName: SpaceToBatchND2,
  backendName: "webgl",
  kernelFunc: spaceToBatchND4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SparseFillEmptyRows.ts
function sparseFillEmptyRows4(args) {
  const { inputs, backend: backend3 } = args;
  const { indices, values, denseShape, defaultValue } = inputs;
  if (denseShape.shape.length !== 1) {
    throw new Error(`Dense shape must be a vector, saw:
         ${denseShape.shape}`);
  }
  if (indices.shape.length !== 2) {
    throw new Error(`Indices must be a matrix, saw:
         ${indices.shape}`);
  }
  if (values.shape.length !== 1) {
    throw new Error(`Values must be a vector, saw:
         ${values.shape}`);
  }
  if (defaultValue.shape.length !== 0) {
    throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
  }
  const $indices = backend3.readSync(indices.dataId);
  const $values = backend3.readSync(values.dataId);
  const $denseShape = backend3.readSync(denseShape.dataId);
  const $defaultValue = backend3.readSync(defaultValue.dataId)[0];
  const [
    outputIndices,
    outputIndicesShape,
    outputValues,
    emptyRowIndicator,
    reverseIndexMap
  ] = sparseFillEmptyRowsImplCPU($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
  return [
    backend3.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
    backend3.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
    backend3.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
    backend3.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
  ];
}
var sparseFillEmptyRowsConfig2 = {
  kernelName: SparseFillEmptyRows2,
  backendName: "webgl",
  kernelFunc: sparseFillEmptyRows4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SparseReshape.ts
function sparseReshape4(args) {
  const { inputs, backend: backend3 } = args;
  const { inputIndices, inputShape, newShape } = inputs;
  if (inputIndices.shape.length !== 2) {
    throw new Error(`Input indices should be a matrix but received shape ${inputIndices.shape}`);
  }
  if (inputShape.shape.length !== 1) {
    throw new Error(`Input shape should be a vector but received shape ${inputShape.shape}`);
  }
  if (newShape.shape.length !== 1) {
    throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
  }
  const $inputShape = Array.from(backend3.readSync(inputShape.dataId));
  const $inputIndices = backend3.readSync(inputIndices.dataId);
  const targetShape = Array.from(backend3.readSync(newShape.dataId));
  const [newIndices, indicesShape, outputShape] = sparseReshapeImplCPU($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
  return [
    backend3.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
    backend3.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
  ];
}
var sparseReshapeConfig2 = {
  kernelName: SparseReshape2,
  backendName: "webgl",
  kernelFunc: sparseReshape4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SparseSegmentMean.ts
function sparseSegmentMean4(args) {
  const { inputs, backend: backend3 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
              ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
              ${segmentIds.shape}`);
  }
  const $data = backend3.readSync(data.dataId);
  const $indices = backend3.readSync(indices.dataId);
  const $segmentIds = backend3.readSync(segmentIds.dataId);
  const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds, true);
  return backend3.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentMeanConfig2 = {
  kernelName: SparseSegmentMean2,
  backendName: "webgl",
  kernelFunc: sparseSegmentMean4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SparseSegmentSum.ts
function sparseSegmentSum4(args) {
  const { inputs, backend: backend3 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
             ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
             ${segmentIds.shape}`);
  }
  const $data = backend3.readSync(data.dataId);
  const $indices = backend3.readSync(indices.dataId);
  const $segmentIds = backend3.readSync(segmentIds.dataId);
  const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds);
  return backend3.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentSumConfig2 = {
  kernelName: SparseSegmentSum2,
  backendName: "webgl",
  kernelFunc: sparseSegmentSum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SparseToDense.ts
function sparseToDense4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { sparseIndices, sparseValues, defaultValue } = inputs;
  const { outputShape } = attrs;
  const { sliceRank, numUpdates, strides, outputSize } = backend_util_exports2.calculateShapes(sparseValues, sparseIndices, outputShape);
  const sumDupeIndices = false;
  const program = new ScatterProgram(numUpdates, sliceRank, sparseIndices.shape.length, sparseValues.shape.length, strides, [outputSize, 1], sumDupeIndices);
  const res = backend3.runWebGLProgram(program, [sparseValues, sparseIndices, defaultValue], sparseValues.dtype);
  const reshaped = reshape5({ inputs: { x: res }, backend: backend3, attrs: { shape: outputShape } });
  backend3.disposeIntermediateTensorInfo(res);
  return reshaped;
}
var sparseToDenseConfig2 = {
  kernelName: SparseToDense2,
  backendName: "webgl",
  kernelFunc: sparseToDense4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SplitV.ts
function splitV2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports2.prepareSplitSize(x, numOrSizeSplits, $axis);
  const xRank = x.shape.length;
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const sliceSize = [...size];
    sliceSize[$axis] = s;
    const sliceT = slice4({ inputs: { x }, backend: backend3, attrs: { begin, size: sliceSize } });
    begin[$axis] += s;
    return sliceT;
  });
}
var splitVConfig2 = {
  kernelName: SplitV2,
  backendName: "webgl",
  kernelFunc: splitV2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Sqrt.ts
var SQRT = `return sqrt(x);`;
var sqrt4 = unaryKernelFunc2({ opSnippet: SQRT });
var sqrtConfig2 = {
  kernelName: Sqrt2,
  backendName: "webgl",
  kernelFunc: sqrt4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Square.ts
var SQUARE = `return x * x;`;
var square4 = unaryKernelFunc2({ opSnippet: SQUARE });
var squareConfig2 = {
  kernelName: Square2,
  backendName: "webgl",
  kernelFunc: square4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/SquaredDifference.ts
var SQUARED_DIFFERENCE = "return (a - b) * (a - b);";
var squaredDifference5 = binaryKernelFunc3({ opSnippet: SQUARED_DIFFERENCE, packedOpSnippet: SQUARED_DIFFERENCE });
var squaredDifferenceConfig2 = {
  kernelName: SquaredDifference2,
  backendName: "webgl",
  kernelFunc: squaredDifference5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Step.ts
function step4({ inputs, attrs, backend: backend3 }) {
  const { x } = inputs;
  const opSnippet = CHECK_NAN_SNIPPET + `
    return x > 0.0 ? 1.0 : float(${attrs.alpha});
  `;
  const program = new UnaryOpProgram(x.shape, opSnippet);
  return backend3.runWebGLProgram(program, [x], x.dtype);
}
var stepConfig2 = {
  kernelName: Step2,
  backendName: "webgl",
  kernelFunc: step4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/strided_slice_gpu.ts
var StridedSliceProgram = class {
  constructor(begin, strides, size) {
    this.variableNames = ["x"];
    this.outputShape = size;
    const rank = size.length;
    const inputDtype = getCoordsDataType(size.length);
    const dtype = getCoordsDataType(size.length);
    let newCoords = "";
    if (rank === 1) {
      newCoords = "coords * strides + begin";
    } else {
      let outputAxis = 0;
      newCoords = size.map((_, i) => {
        outputAxis++;
        return size.length === 1 ? `coords * strides[${i}] + begin[${i}]` : `coords[${outputAxis - 1}] * strides[${i}] + begin[${i}]`;
      }).join(",");
    }
    this.userCode = `
      ${inputDtype} begin = ${inputDtype}(${begin});
      ${inputDtype} strides = ${inputDtype}(${strides});

      void main() {
        ${dtype} coords = getOutputCoords();
        setOutput(getX(${newCoords}));
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/StridedSlice.ts
function stridedSlice4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  } = attrs;
  const { nonStrided, $begin, $strides, size, newShape, outShape } = slice_util_exports2.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  const $x = reshape5({ inputs: { x }, backend: backend3, attrs: { shape: newShape } });
  let result;
  if (nonStrided) {
    const sliced = slice4({ inputs: { x: $x }, backend: backend3, attrs: { begin: $begin, size } });
    result = reshape5({ inputs: { x: sliced }, backend: backend3, attrs: { shape: outShape } });
    backend3.disposeIntermediateTensorInfo(sliced);
  } else if (outShape.some((axis) => axis === 0)) {
    result = backend3.makeTensorInfo(outShape, x.dtype, []);
  } else {
    const shouldExecuteOnCPU = backend3.shouldExecuteOnCPU([$x]);
    if (shouldExecuteOnCPU) {
      const xTexData = backend3.texData.get($x.dataId);
      const values = xTexData.values;
      const xBuf = buffer2($x.shape, $x.dtype, values);
      const resultValues = stridedSliceImplCPU(outShape, xBuf, $strides, $begin);
      result = backend3.makeTensorInfo(outShape, $x.dtype, resultValues.values);
    } else {
      const program = new StridedSliceProgram($begin, $strides, outShape);
      result = backend3.runWebGLProgram(program, [$x], $x.dtype);
    }
  }
  const resultReshaped = reshape5({ inputs: { x: result }, backend: backend3, attrs: { shape: outShape } });
  backend3.disposeIntermediateTensorInfo($x);
  backend3.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var stridedSliceConfig2 = {
  kernelName: StridedSlice2,
  backendName: "webgl",
  kernelFunc: stridedSlice4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/StringNGrams.ts
function stringNGrams4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const {
    separator,
    nGramWidths,
    leftPad,
    rightPad: rightPad3,
    padWidth,
    preserveShortSequences
  } = attrs;
  const { data, dataSplits } = inputs;
  const $data = backend3.readSync(data.dataId);
  const $dataSplits = backend3.readSync(dataSplits.dataId);
  const [nGrams, nGramsSplits] = stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad3, padWidth, preserveShortSequences);
  return [
    backend3.makeTensorInfo([nGrams.length], "string", nGrams),
    backend3.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
  ];
}
var stringNGramsConfig2 = {
  kernelName: StringNGrams2,
  backendName: "webgl",
  kernelFunc: stringNGrams4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/StringSplit.ts
function stringSplit4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { skipEmpty } = attrs;
  const { input: input2, delimiter } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (input2.shape.length !== 1) {
    throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
  }
  if (delimiter.shape.length !== 0) {
    throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
  }
  const $input = backend3.readSync(input2.dataId);
  const $delimiter = backend3.readSync(delimiter.dataId)[0];
  const [indices, values, shape] = stringSplitImplCPU($input, $delimiter, skipEmpty);
  const outputSize = values.length;
  return [
    backend3.makeTensorInfo([outputSize, 2], "int32", indices),
    backend3.makeTensorInfo([outputSize], "string", values),
    backend3.makeTensorInfo([2], "int32", new Int32Array(shape))
  ];
}
var stringSplitConfig2 = {
  kernelName: StringSplit2,
  backendName: "webgl",
  kernelFunc: stringSplit4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/StringToHashBucketFast.ts
function stringToHashBucketFast4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { numBuckets } = attrs;
  const { input: input2 } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const $input = backend3.readSync(input2.dataId);
  const output = stringToHashBucketFastImplCPU($input, numBuckets);
  return backend3.makeTensorInfo(input2.shape, "int32", output);
}
var stringToHashBucketFastConfig2 = {
  kernelName: StringToHashBucketFast2,
  backendName: "webgl",
  kernelFunc: stringToHashBucketFast4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Tan.ts
var TAN = `return tan(x);`;
var tan4 = unaryKernelFunc2({ opSnippet: TAN });
var tanConfig2 = {
  kernelName: Tan2,
  backendName: "webgl",
  kernelFunc: tan4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Tanh.ts
var TANH = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
var tanh6 = unaryKernelFunc2({ opSnippet: TANH });
var tanhConfig2 = {
  kernelName: Tanh2,
  backendName: "webgl",
  kernelFunc: tanh6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/tile_gpu.ts
var TileProgram = class {
  constructor(aShape, reps) {
    this.variableNames = ["A"];
    const outputShape = new Array(aShape.length);
    for (let i = 0; i < outputShape.length; i++) {
      outputShape[i] = aShape[i] * reps[i];
    }
    this.outputShape = outputShape;
    this.rank = outputShape.length;
    const dtype = getCoordsDataType(this.rank);
    const sourceCoords = getSourceCoords3(aShape);
    this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        setOutput(getA(${sourceCoords}));
      }
    `;
  }
};
function getSourceCoords3(aShape) {
  const rank = aShape.length;
  if (rank > 5) {
    throw Error(`Tile for rank ${rank} is not yet supported`);
  }
  if (rank === 1) {
    return `imod(resRC, ${aShape[0]})`;
  }
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"];
  const sourceCoords = [];
  for (let i = 0; i < aShape.length; i++) {
    sourceCoords.push(`imod(${currentCoords[i]}, ${aShape[i]})`);
  }
  return sourceCoords.join();
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Tile.ts
function tile5(params) {
  const { inputs, backend: backend3, attrs } = params;
  const { x } = inputs;
  const { reps } = attrs;
  if (x.dtype === "string" || x.shape.length > 5) {
    const data = backend3.readSync(x.dataId);
    const value = x.dtype === "string" ? data.map((d) => util_exports2.decodeString(d)) : data;
    const buf = buffer2(x.shape, x.dtype, value);
    const outBuf = tileImplCPU(buf, reps);
    return backend3.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  const program = new TileProgram(x.shape, reps);
  const output = backend3.runWebGLProgram(program, [x], x.dtype);
  return output;
}
var tileConfig2 = {
  kernelName: Tile2,
  backendName: "webgl",
  kernelFunc: tile5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/TopK.ts
function topK2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { k, sorted } = attrs;
  const xVals = backend3.readSync(x.dataId);
  const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, x.shape, x.dtype, k, sorted);
  return [
    backend3.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
    backend3.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
  ];
}
var topKConfig2 = {
  kernelName: TopK2,
  backendName: "webgl",
  kernelFunc: topK2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/transform_gpu.ts
var TransformProgram = class {
  constructor(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape) {
    this.variableNames = ["Image", "Transforms"];
    this.outputShape = outShape;
    const interpolationModeId = interpolation === "nearest" ? 1 : 2;
    let fillModeId;
    switch (fillMode) {
      case "constant":
        fillModeId = 1;
        break;
      case "reflect":
        fillModeId = 2;
        break;
      case "wrap":
        fillModeId = 3;
        break;
      case "nearest":
        fillModeId = 4;
        break;
      default:
        fillModeId = 1;
        break;
    }
    this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${fillModeId} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${imageHeight} && 0 <= coordX && coordX < ${imageWidth}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${fillValue});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${fillValue});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${imageWidth}));
                float mapY = mapCoord(inY, float(${imageHeight}));

                if (${interpolationModeId} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Transform.ts
function transform4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { image: image4, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [
    batch,
    outHeight,
    outWidth,
    numChannels
  ];
  const program = new TransformProgram(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape);
  return backend3.runWebGLProgram(program, [image4, transforms], "float32");
}
var transformConfig2 = {
  kernelName: Transform2,
  backendName: "webgl",
  kernelFunc: transform4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Unique.ts
function unique5(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { axis } = attrs;
  const { x } = inputs;
  assertNotComplex2(x, "unique");
  console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  const values = backend3.readSync(x.dataId);
  const { outputValues, outputShape, indices } = uniqueImplCPU(values, axis, x.shape, x.dtype);
  return [
    backend3.makeTensorInfo(outputShape, x.dtype, outputValues),
    backend3.makeTensorInfo([indices.length], "int32", indices)
  ];
}
var uniqueConfig2 = {
  kernelName: Unique2,
  backendName: "webgl",
  kernelFunc: unique5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/Unpack.ts
function unpack2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const x = value;
  const xRank = x.shape.length;
  const num = value.shape[axis];
  const outShape = new Array(xRank - 1);
  let outIndex = 0;
  for (let i = 0; i < xRank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = x.shape[i];
    }
  }
  const toDispose = [];
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  size[axis] = 1;
  const res = new Array(num);
  for (let i = 0; i < res.length; i++) {
    begin[axis] = i;
    const sliced = slice4({ inputs: { x }, backend: backend3, attrs: { begin, size } });
    const reshaped = reshape5({ inputs: { x: sliced }, backend: backend3, attrs: { shape: outShape } });
    res[i] = reshaped;
    toDispose.push(sliced);
  }
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return res;
}
var unpackConfig2 = {
  kernelName: Unpack2,
  backendName: "webgl",
  kernelFunc: unpack2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/segment_gpu.ts
var SegmentOpProgram = class {
  constructor(segOpInfo, segOpType) {
    this.variableNames = ["x", "segmentIds"];
    const windowSize = segOpInfo.windowSize;
    const batchSize = segOpInfo.batchSize;
    const inSize = segOpInfo.inSize;
    const numSegments = segOpInfo.numSegments;
    const outSize = numSegments * Math.ceil(inSize / windowSize);
    this.outputShape = [batchSize, outSize];
    const initializationValue = "0.0";
    const returnValue = `sumValue`;
    const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
    const windowSizeVec4Remainder = windowSize % 4;
    const updateSnippet = `
        sumValue += dot(values, segFilter);
    `;
    let checkValueOutOfBounds = "";
    if (inSize % windowSize > 0) {
      checkValueOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
    }
    let checkSegmentIdOutOfBounds = "";
    if (inSize % windowSize > 0) {
      checkSegmentIdOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return -1.0;
        }
      `;
    }
    this.userCode = `
      const float initializationValue = ${initializationValue};

      float getValue(int batch, int inIdx) {
        ${checkValueOutOfBounds}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${checkSegmentIdOutOfBounds}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${numSegments})) * float(${windowSize}));
        int currentSeg = int(mod(float(outIdx), float(${numSegments})));

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
  }
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/kernels/UnsortedSegmentSum.ts
function unsortedSegmentSum4(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x, segmentIds } = inputs;
  const { numSegments } = attrs;
  const xRank = x.shape.length;
  const toDispose = [];
  let axis = 0;
  const permutation = backend_util_exports2.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose5({ inputs: { x }, backend: backend3, attrs: { perm: permutation } });
    toDispose.push(permutedX);
    axis = backend_util_exports2.getInnerMostAxes(1, xRank)[0];
  }
  const outShape = backend_util_exports2.segment_util.computeOutShape(permutedX.shape, axis, numSegments);
  const inSize = util_exports2.sizeFromShape([permutedX.shape[axis]]);
  const a2D = reshape5({ inputs: { x: permutedX }, backend: backend3, attrs: { shape: [-1, inSize] } });
  toDispose.push(a2D);
  const outputDType = sumOutType2(x.dtype);
  const segOpCompute = (x2, segOpType, segmentIds2, dtype, numSegments2) => {
    const batchSize = x2.shape[0];
    const inSize2 = x2.shape[1];
    const windowSize = backend_util_exports2.segment_util.segOpComputeOptimalWindowSize(inSize2, numSegments2);
    const segOpInfo = { windowSize, inSize: inSize2, batchSize, numSegments: numSegments2 };
    const program = new SegmentOpProgram(segOpInfo, segOpType);
    const output = backend3.compileAndRun(program, [x2, segmentIds2], dtype);
    toDispose.push(output);
    if (output.shape[1] === numSegments2) {
      return output;
    }
    const rangeInfo = range5({
      backend: backend3,
      attrs: { start: 0, stop: numSegments2, step: 1, dtype: "float32" }
    });
    const tileInfo = tile5({
      inputs: { x: rangeInfo },
      backend: backend3,
      attrs: { reps: [inSize2 / windowSize] }
    });
    toDispose.push(rangeInfo);
    toDispose.push(tileInfo);
    const result2 = segOpCompute(output, segOpType, tileInfo, dtype, numSegments2);
    return result2;
  };
  const segOpResult = segOpCompute(a2D, "unsortedSegmentSum", segmentIds, outputDType, numSegments);
  const reshaped = reshape5({ inputs: { x: segOpResult }, backend: backend3, attrs: { shape: outShape } });
  let result = reshaped;
  if (permutation != null) {
    toDispose.push(reshaped);
    const perm = backend_util_exports2.getUndoAxesPermutation(permutation);
    result = transpose5({ inputs: { x: result }, backend: backend3, attrs: { perm } });
  }
  toDispose.forEach((t) => backend3.disposeIntermediateTensorInfo(t));
  return result;
}
var unsortedSegmentSumConfig2 = {
  kernelName: UnsortedSegmentSum2,
  backendName: "webgl",
  kernelFunc: unsortedSegmentSum4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-webgl@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-webgl/src/register_all_kernels.ts
var kernelConfigs2 = [
  LRNConfig,
  LRNGradConfig,
  _fusedMatMulConfig2,
  absConfig2,
  acosConfig2,
  acoshConfig2,
  addConfig2,
  addNConfig2,
  allConfig2,
  anyConfig2,
  argMaxConfig2,
  argMinConfig2,
  asinConfig2,
  asinhConfig2,
  atan2Config2,
  atanConfig2,
  atanhConfig2,
  avgPool3DConfig2,
  avgPoolConfig2,
  avgPoolGrad3DConfig,
  avgPoolGradConfig3,
  batchMatMulConfig2,
  batchNormConfig2,
  batchToSpaceNDConfig2,
  bincountConfig2,
  castConfig2,
  ceilConfig2,
  clipByValueConfig,
  complexAbsConfig2,
  complexConfig2,
  concatConfig2,
  conv2DBackpropFilterConfig2,
  conv2DBackpropInputConfig2,
  conv2DConfig2,
  conv3DBackpropFilterV2Config2,
  conv3DBackpropInputConfig,
  conv3DConfig2,
  cosConfig2,
  coshConfig2,
  cropAndResizeConfig2,
  cumsumConfig2,
  denseBincountConfig2,
  depthToSpaceConfig2,
  depthwiseConv2dNativeBackpropFilterConfig2,
  depthwiseConv2dNativeBackpropInputConfig2,
  depthwiseConv2dNativeConfig2,
  diagConfig2,
  dilation2DConfig,
  einsumConfig2,
  eluConfig2,
  eluGradConfig3,
  equalConfig2,
  erfConfig2,
  expConfig2,
  expandDimsConfig2,
  expm1Config2,
  fftConfig2,
  fillConfig2,
  flipLeftRightConfig2,
  floorConfig2,
  floorDivConfig2,
  fromPixelsConfig,
  fusedConv2DConfig2,
  fusedDepthwiseConv2DConfig2,
  gatherNdConfig2,
  gatherV2Config2,
  greaterConfig2,
  greaterEqualConfig2,
  identityConfig2,
  ifftConfig2,
  imagConfig2,
  isFiniteConfig2,
  isInfConfig2,
  isNaNConfig2,
  leakyReluConfig2,
  lessConfig2,
  lessEqualConfig2,
  linSpaceConfig2,
  log1pConfig2,
  logConfig2,
  logicalAndConfig2,
  logicalNotConfig2,
  logicalOrConfig2,
  maxConfig2,
  maxPool3DConfig2,
  maxPoolConfig2,
  maxPoolGrad3DConfig,
  maxPoolGradConfig3,
  maxPoolWithArgmaxConfig2,
  maximumConfig2,
  meanConfig2,
  minConfig2,
  minimumConfig2,
  mirrorPadConfig2,
  modConfig2,
  multinomialConfig2,
  multiplyConfig2,
  negConfig2,
  nonMaxSuppressionV3Config2,
  nonMaxSuppressionV4Config2,
  nonMaxSuppressionV5Config2,
  notEqualConfig2,
  oneHotConfig2,
  onesLikeConfig2,
  packConfig2,
  padV2Config2,
  powConfig2,
  preluConfig2,
  prodConfig2,
  rangeConfig2,
  realConfig2,
  realDivConfig2,
  reciprocalConfig2,
  relu6Config2,
  reluConfig2,
  reshapeConfig2,
  resizeBilinearConfig2,
  resizeBilinearGradConfig3,
  resizeNearestNeighborConfig2,
  resizeNearestNeighborGradConfig3,
  reverseConfig2,
  rotateWithOffsetConfig2,
  roundConfig2,
  rsqrtConfig2,
  scatterNdConfig2,
  selectConfig2,
  seluConfig2,
  sigmoidConfig2,
  signConfig2,
  sinConfig2,
  sinhConfig2,
  sliceConfig2,
  softmaxConfig2,
  softplusConfig2,
  spaceToBatchNDConfig2,
  sparseFillEmptyRowsConfig2,
  sparseReshapeConfig2,
  sparseSegmentMeanConfig2,
  sparseSegmentSumConfig2,
  sparseToDenseConfig2,
  splitVConfig2,
  sqrtConfig2,
  squareConfig2,
  squaredDifferenceConfig2,
  stepConfig2,
  stridedSliceConfig2,
  stringNGramsConfig2,
  stringSplitConfig2,
  stringToHashBucketFastConfig2,
  subConfig2,
  sumConfig2,
  tanConfig2,
  tanhConfig2,
  tileConfig2,
  topKConfig2,
  transformConfig2,
  transposeConfig2,
  uniqueConfig2,
  unpackConfig2,
  unsortedSegmentSumConfig2,
  zerosLikeConfig2
];
for (const kernelConfig of kernelConfigs2) {
  registerKernel2(kernelConfig);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/types.ts
var CppDType;
(function(CppDType2) {
  CppDType2[CppDType2["float32"] = 0] = "float32";
  CppDType2[CppDType2["int32"] = 1] = "int32";
  CppDType2[CppDType2["bool"] = 2] = "bool";
  CppDType2[CppDType2["string"] = 3] = "string";
  CppDType2[CppDType2["complex64"] = 4] = "complex64";
})(CppDType || (CppDType = {}));
var FusableActivation;
(function(FusableActivation2) {
  FusableActivation2[FusableActivation2["linear"] = 0] = "linear";
  FusableActivation2[FusableActivation2["relu"] = 1] = "relu";
  FusableActivation2[FusableActivation2["relu6"] = 2] = "relu6";
  FusableActivation2[FusableActivation2["prelu"] = 3] = "prelu";
  FusableActivation2[FusableActivation2["leakyrelu"] = 4] = "leakyrelu";
  FusableActivation2[FusableActivation2["sigmoid"] = 5] = "sigmoid";
})(FusableActivation || (FusableActivation = {}));

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/_FusedMatMul.ts
var wasmFusedMatMul;
function setup(backend3) {
  wasmFusedMatMul = backend3.wasm.cwrap(_FusedMatMul2, null, [
    "number",
    "array",
    "number",
    "number",
    "array",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function fusedBatchMatMul(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  if (a.dtype !== "float32" || b.dtype !== "float32") {
    throw new Error(`_FusedMatMul for non non-float32 tensors not yet supported.`);
  }
  const { transposeA, transposeB, activation: activation2, leakyreluAlpha } = attrs;
  const aId = backend3.dataIdMap.get(a.dataId).id;
  const bId = backend3.dataIdMap.get(b.dataId).id;
  let biasId = 0;
  if (bias != null) {
    const biasData = backend3.dataIdMap.get(bias.dataId);
    if (biasData.shape.length !== 1) {
      throw new Error(`_FusedMatMul only supports rank-1 bias but got rank ${biasData.shape.length}.`);
    }
    biasId = biasData.id;
  }
  const preluActivationWeightsId = preluActivationWeights == null ? 0 : backend3.dataIdMap.get(preluActivationWeights.dataId).id;
  const fusedActivation = FusableActivation[activation2];
  if (fusedActivation == null) {
    throw new Error(`${activation2} activation not yet supported for FusedConv2D in the wasm backend.`);
  }
  const leftDim = transposeA ? a.shape[2] : a.shape[1];
  const rightDim = transposeB ? b.shape[1] : b.shape[2];
  const batchDim = a.shape[0];
  const out = backend3.makeOutput([batchDim, leftDim, rightDim], a.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);
  const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);
  wasmFusedMatMul(aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length, transposeA, transposeB, fusedActivation, biasId, preluActivationWeightsId, leakyreluAlpha || 0, outId);
  return out;
}
var fusedMatMulConfig = {
  kernelName: _FusedMatMul2,
  backendName: "wasm",
  setupFunc: setup,
  kernelFunc: fusedBatchMatMul
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/unary_kernel.ts
function createUnaryKernelConfig(kernelName) {
  let wasmFunc9;
  function setupFunc3(backend3) {
    wasmFunc9 = backend3.wasm.cwrap(kernelName, null, ["number", "number"]);
  }
  function kernelFunc3(args) {
    const { backend: backend3, inputs: { x } } = args;
    const xId = backend3.dataIdMap.get(x.dataId).id;
    const out = backend3.makeOutput(x.shape, x.dtype);
    const outId = backend3.dataIdMap.get(out.dataId).id;
    if (util_exports2.sizeFromShape(out.shape) === 0) {
      return out;
    }
    wasmFunc9(xId, outId);
    return out;
  }
  return { kernelName, backendName: "wasm", setupFunc: setupFunc3, kernelFunc: kernelFunc3 };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Abs.ts
var absConfig3 = createUnaryKernelConfig(Abs2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/binary_kernel.ts
function createBinaryKernelConfig(kernelName, supportsFullBroadcast17, dtype) {
  let wasmFunc9;
  function setupFunc3(backend3) {
    wasmFunc9 = backend3.wasm.cwrap(kernelName, null, [
      "number",
      "array",
      "number",
      "number",
      "array",
      "number",
      "number",
      "number"
    ]);
  }
  function kernelFunc3(args) {
    const { backend: backend3, inputs } = args;
    const { a, b } = inputs;
    const aId = backend3.dataIdMap.get(a.dataId).id;
    const bId = backend3.dataIdMap.get(b.dataId).id;
    const outputType = dtype != null ? dtype : a.dtype;
    const newShape = backend_util_exports2.assertAndGetBroadcastShape(a.shape, b.shape);
    const out = backend3.makeOutput(newShape, outputType);
    if (util_exports2.sizeFromShape(newShape) === 0) {
      return out;
    }
    const aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);
    const bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);
    const outId = backend3.dataIdMap.get(out.dataId).id;
    const kernelFunc4 = () => wasmFunc9(aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length, CppDType[a.dtype], outId);
    if (supportsFullBroadcast17 && a.dtype === "float32") {
      kernelFunc4();
      return out;
    }
    const aBroadcastDims = backend_util_exports2.getBroadcastDims(a.shape, newShape);
    const bBroadcastDims = backend_util_exports2.getBroadcastDims(b.shape, newShape);
    const loopsOverAllOfA = aBroadcastDims.every((v, i) => v === i);
    const loopsOverAllOfB = bBroadcastDims.every((v, i) => v === i);
    if (loopsOverAllOfA && loopsOverAllOfB) {
      kernelFunc4();
      return out;
    } else {
      throw new Error(`Broadcasting along outer dims is not yet supported for ${a.dtype} ${kernelName}.`);
    }
  }
  return { kernelName, backendName: "wasm", setupFunc: setupFunc3, kernelFunc: kernelFunc3 };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Add.ts
var supportsFullBroadcast = true;
var addConfig3 = createBinaryKernelConfig(Add2, supportsFullBroadcast);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/AddN.ts
var wasmFunc;
function setupFunc(backend3) {
  wasmFunc = backend3.wasm.cwrap(AddN2, null, [
    "array",
    "number",
    "number",
    "number"
  ]);
}
function addn(args) {
  const { inputs, backend: backend3 } = args;
  const out = backend3.makeOutput(inputs[0].shape, inputs[0].dtype);
  if (util_exports2.sizeFromShape(out.shape) === 0) {
    return out;
  }
  const inputIds = inputs.map((x) => backend3.dataIdMap.get(x.dataId).id);
  const inputIdsBytes = new Uint8Array(new Int32Array(inputIds).buffer);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmFunc(inputIdsBytes, inputIds.length, CppDType[out.dtype], outId);
  return out;
}
var addNConfig3 = {
  kernelName: AddN2,
  backendName: "wasm",
  setupFunc,
  kernelFunc: addn
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Identity.ts
function identity5(args) {
  const { inputs: { x }, backend: backend3 } = args;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const inVals = backend3.typedArrayFromHeap(x);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.set(inVals);
  return out;
}
var identityConfig3 = {
  kernelName: Identity2,
  backendName: "wasm",
  kernelFunc: identity5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Transpose.ts
var wasmTranspose;
function setup2(backend3) {
  wasmTranspose = backend3.wasm.cwrap(Transpose2, null, [
    "number",
    "array",
    "number",
    "number",
    "number",
    "array",
    "number"
  ]);
}
function transpose6(args) {
  const { inputs, backend: backend3, attrs } = args;
  const [reducedShape, perm] = removeOneSizeDims(inputs.x.shape, attrs.perm);
  let permIsNoOp = true;
  for (let i = 0; i < perm.length; i++) {
    if (perm[i] !== i) {
      permIsNoOp = false;
    }
  }
  const outShape = computeOutShape7(inputs.x.shape, attrs.perm);
  const x = {
    dataId: inputs.x.dataId,
    shape: reducedShape,
    dtype: inputs.x.dtype
  };
  if (permIsNoOp) {
    const cloned = identity5({ inputs, backend: backend3 });
    cloned.shape = outShape;
    return cloned;
  }
  const out = backend3.makeOutput(outShape, x.dtype);
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const permBytes = new Uint8Array(new Int32Array(perm).buffer);
  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  wasmTranspose(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], outId, permBytes, perm.length);
  return out;
}
function computeOutShape7(inShape, perm) {
  const outShape = new Array(inShape.length);
  for (let i = 0; i < outShape.length; i++) {
    outShape[i] = inShape[perm[i]];
  }
  return outShape;
}
function removeOneSizeDims(shape, perm) {
  const newShape = [];
  const newPerm = [];
  for (let i = 0; i < shape.length; ++i) {
    if (shape[i] !== 1) {
      newShape.push(shape[i]);
    }
    if (shape[perm[i]] !== 1) {
      newPerm.push(perm[i]);
    }
  }
  for (let i = 0; i < newPerm.length; ++i) {
    let minValIdx = -1;
    for (let j = 0; j < newPerm.length; ++j) {
      if (newPerm[j] >= i && (minValIdx === -1 || newPerm[minValIdx] > newPerm[j])) {
        minValIdx = j;
      }
    }
    newPerm[minValIdx] = i;
  }
  return [newShape, newPerm];
}
var transposeConfig3 = {
  kernelName: Transpose2,
  backendName: "wasm",
  kernelFunc: transpose6,
  setupFunc: setup2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/kernel_utils.ts
function permuteAxesAndTranspose(x, axis, backend3) {
  const xShape = x.shape;
  const xRank = x.shape.length;
  const originalAxes = util_exports2.parseAxisParam(axis, xShape);
  let axes = originalAxes;
  const permutedAxes = backend_util_exports2.getAxesPermutation(axes, xRank);
  let xTransposed = null;
  let inputWasTransposed = false;
  if (permutedAxes != null) {
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = xShape[permutedAxes[i]];
    }
    axes = backend_util_exports2.getInnerMostAxes(axes.length, xRank);
    xTransposed = transpose6({ inputs: { x }, attrs: { perm: permutedAxes }, backend: backend3 });
    const xId = backend3.dataIdMap.get(x.dataId).id;
    const transposedId = backend3.dataIdMap.get(xTransposed.dataId).id;
    if (transposedId !== xId) {
      inputWasTransposed = true;
    }
  }
  return { transposed: xTransposed, originalAxes, axes, inputWasTransposed };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/All.ts
var wasmAll;
function setup3(backend3) {
  wasmAll = backend3.wasm.cwrap(All2, null, ["number, number, number"]);
}
function all5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    input2 = transposed;
    inputId = transposedId;
  }
  const inputRank = input2.shape.length;
  backend_util_exports2.assertAxesAreInnerMostDims("all", axes, inputRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, x.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmAll(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var allConfig3 = {
  kernelName: All2,
  backendName: "wasm",
  setupFunc: setup3,
  kernelFunc: all5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Any.ts
var wasmAny;
function setup4(backend3) {
  wasmAny = backend3.wasm.cwrap(Any2, null, ["number, number, number"]);
}
function any5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    input2 = transposed;
    inputId = transposedId;
  }
  const inputRank = input2.shape.length;
  backend_util_exports2.assertAxesAreInnerMostDims("any", axes, inputRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, x.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmAny(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var anyConfig3 = {
  kernelName: Any2,
  backendName: "wasm",
  setupFunc: setup4,
  kernelFunc: any5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ArgMax.ts
var wasmFunc2;
function setup5(backend3) {
  wasmFunc2 = backend3.wasm.cwrap(ArgMax2, null, [
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function argmax(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    if (transposedId !== xId) {
      input2 = transposed;
      inputId = transposedId;
    }
  }
  const outShape = input2.shape.slice(0, -1);
  const out = backend3.makeOutput(outShape, "int32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const outerSize = util_exports2.sizeFromShape(out.shape);
  const innerSize = input2.shape[axes[0]];
  wasmFunc2(inputId, CppDType[input2.dtype], outerSize, innerSize, outId);
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  return out;
}
var argMaxConfig3 = {
  kernelName: ArgMax2,
  backendName: "wasm",
  kernelFunc: argmax,
  setupFunc: setup5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/AvgPool.ts
var wasmAvgPool;
function setup6(backend3) {
  wasmAvgPool = backend3.wasm.cwrap(AvgPool2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function avgPool5(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const x = inputs.x;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const channels = convInfo.inChannels;
  if (convInfo.dataFormat !== "channelsLast") {
    throw new Error(`wasm backend does not support dataFormat:'${convInfo.dataFormat}'. Please use 'channelsLast'.`);
  }
  if (convInfo.dilationWidth !== 1 || convInfo.dilationHeight !== 1) {
    throw new Error(`was backend only supports average pooling with dilation = [1, 1], got [${convInfo.dilationHeight}, ${convInfo.dilationWidth}].`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmAvgPool(xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, strideHeight, strideWidth, channels, outId);
  return out;
}
var avgPoolConfig3 = {
  kernelName: AvgPool2,
  backendName: "wasm",
  setupFunc: setup6,
  kernelFunc: avgPool5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Reshape.ts
function reshape6(args) {
  const { inputs, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const xSize = util_exports2.sizeFromShape(x.shape);
  const $shape = util_exports2.inferFromImplicitShape(shape, xSize);
  util_exports2.assert(xSize === util_exports2.sizeFromShape($shape), () => `new shape: ${$shape}, old shape: ${x.shape}. New shape and old shape must have the same number of elements.`);
  args.backend.incRef(x.dataId);
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig3 = {
  kernelName: Reshape2,
  backendName: "wasm",
  kernelFunc: reshape6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/BatchMatMul.ts
var wasmBatchMatMul;
function setup7(backend3) {
  wasmBatchMatMul = backend3.wasm.cwrap(BatchMatMul2, null, [
    "number",
    "array",
    "number",
    "number",
    "array",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function batchMatMul3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  if (a.dtype !== "float32" || b.dtype !== "float32") {
    throw new Error(`BatchMatMul for non non-float32 tensors not yet supported.`);
  }
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports2.sizeFromShape(outerDimsA);
  const batchDimB = util_exports2.sizeFromShape(outerDimsB);
  const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;
  util_exports2.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);
  const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports2.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape6({ inputs: { x: a }, backend: backend3, attrs: { shape: a3dShape } });
  const b3d = reshape6({ inputs: { x: b }, backend: backend3, attrs: { shape: b3dShape } });
  const a3dId = backend3.dataIdMap.get(a3d.dataId).id;
  const b3dId = backend3.dataIdMap.get(b3d.dataId).id;
  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
  const batchDim = Math.max(batchDimA, batchDimB);
  const out = backend3.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);
  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);
  wasmBatchMatMul(a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes, b3d.shape.length, transposeA, transposeB, outId);
  backend3.disposeData(a3d.dataId);
  backend3.disposeData(b3d.dataId);
  out.shape = outShape;
  return out;
}
var batchMatMulConfig3 = {
  kernelName: BatchMatMul2,
  backendName: "wasm",
  setupFunc: setup7,
  kernelFunc: batchMatMul3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Cast.ts
function cast7(args) {
  const { inputs: { x }, attrs: { dtype }, backend: backend3 } = args;
  const out = backend3.makeOutput(x.shape, dtype);
  const inVals = backend3.typedArrayFromHeap(x);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.set(inVals);
  return out;
}
var castConfig3 = {
  kernelName: Cast2,
  backendName: "wasm",
  kernelFunc: cast7
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Ceil.ts
var ceilConfig3 = createUnaryKernelConfig(Ceil2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ClipByValue.ts
var wasmClip;
function setup8(backend3) {
  wasmClip = backend3.wasm.cwrap(ClipByValue2, null, [
    "number",
    "number",
    "number",
    "number"
  ]);
}
function clip2(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { clipValueMin, clipValueMax } = attrs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmClip(xId, clipValueMin, clipValueMax, outId);
  return out;
}
var clipByValueConfig2 = {
  kernelName: ClipByValue2,
  backendName: "wasm",
  setupFunc: setup8,
  kernelFunc: clip2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Concat.ts
function concat5(args) {
  const { inputs, backend: backend3 } = args;
  const axis = util_exports2.parseAxisParam(args.attrs.axis, inputs[0].shape)[0];
  let outShape = backend_util_exports2.computeOutShape(inputs.map((t) => t.shape), axis);
  const $inputs = inputs.filter((t) => util_exports2.sizeFromShape(t.shape) > 0);
  if ($inputs.length === 1) {
    return identity5({ inputs: { x: $inputs[0] }, backend: backend3 });
  }
  const out = backend3.makeOutput(outShape, inputs[0].dtype);
  if (util_exports2.sizeFromShape(outShape) === 0) {
    return out;
  }
  const shapes = $inputs.map((t) => t.shape);
  backend_util_exports2.assertParamsConsistent(shapes, axis);
  if ($inputs[0].dtype === "string") {
    const inputs2D = $inputs.map((t) => {
      const innerSize = util_exports2.sizeFromShape(t.shape.slice(axis));
      const shape = [-1, innerSize];
      return reshape6({ inputs: { x: t }, backend: backend3, attrs: { shape } });
    });
    const inputsValShapes = inputs2D.map((t) => {
      return { vals: backend3.readSync(t.dataId), shape: t.shape };
    });
    outShape = backend_util_exports2.computeOutShape(inputs2D.map((t) => t.shape), 1);
    const simplyConcat = inputs2D[0].shape[0] === 1;
    const outVals2 = concatImpl2(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
    const finalOutShape = backend_util_exports2.computeOutShape($inputs.map((t) => t.shape), axis);
    out.shape = finalOutShape;
    const outData = backend3.dataIdMap.get(out.dataId);
    outData.stringBytes = backend_util_exports2.fromStringArrayToUint8(outVals2);
    inputs2D.forEach((t) => backend3.disposeData(t.dataId));
    return out;
  }
  const batchDim = util_exports2.sizeFromShape($inputs[0].shape.slice(0, axis));
  let sumInnerDims = 0;
  const innerDims = $inputs.map((input2) => {
    const innerDim = util_exports2.sizeFromShape(input2.shape.slice(axis));
    sumInnerDims += innerDim;
    return innerDim;
  });
  const inVals = $inputs.map((input2) => backend3.typedArrayFromHeap(input2));
  const outVals = backend3.typedArrayFromHeap(out);
  for (let b = 0; b < batchDim; b++) {
    let outOffset = b * sumInnerDims;
    for (let i = 0; i < inVals.length; i++) {
      const innerDim = innerDims[i];
      const inOffset = b * innerDim;
      const vals = inVals[i].subarray(inOffset, inOffset + innerDim);
      outVals.set(vals, outOffset);
      outOffset += innerDim;
    }
  }
  return out;
}
var concatConfig3 = {
  kernelName: Concat2,
  backendName: "wasm",
  kernelFunc: concat5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Conv2D.ts
var wasmConv2d;
function setup9(backend3) {
  wasmConv2d = backend3.wasm.cwrap(Conv2D2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function conv2d7(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x, filter } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const filterId = backend3.dataIdMap.get(filter.dataId).id;
  const { strides, dilations, pad: pad4, dimRoundingMode, dataFormat } = attrs;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode, false, $dataFormat);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const inputChannels = convInfo.inChannels;
  const outputChannels = convInfo.outChannels;
  const isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
  if (convInfo.dataFormat !== "channelsLast") {
    throw new Error(`wasm backend Conv2D does not support dataFormat:'${convInfo.dataFormat}'. Please use 'channelsLast'.`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmConv2d(xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
  return out;
}
var conv2DConfig3 = {
  kernelName: Conv2D2,
  backendName: "wasm",
  setupFunc: setup9,
  kernelFunc: conv2d7
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Conv2DBackpropInput.ts
var wasmConv2DBackpropInput;
function setup10(backend3) {
  wasmConv2DBackpropInput = backend3.wasm.cwrap(Conv2DBackpropInput2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function conv2DBackpropInput5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, pad: pad4, dataFormat, dimRoundingMode, inputShape } = attrs;
  const dilations = 1;
  const $dataFormat = backend_util_exports2.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports2.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad4, dimRoundingMode, false, $dataFormat);
  const {
    batchSize,
    filterHeight,
    filterWidth,
    inChannels,
    inHeight,
    inWidth,
    outChannels,
    outHeight,
    outWidth,
    strideHeight,
    strideWidth
  } = convInfo;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const dxStrides = util_exports2.computeStrides(convInfo.inShape);
  const dyStrides = util_exports2.computeStrides(dy.shape);
  const [fltS0, fltS1, fltS2] = util_exports2.computeStrides(filter.shape);
  const xBatchStride = dxStrides[0];
  const xRowStride = isChannelsLast ? dxStrides[1] : dxStrides[2];
  const xColStride = isChannelsLast ? dxStrides[2] : 1;
  const xChannelStride = isChannelsLast ? 1 : dxStrides[1];
  const yBatchStride = dyStrides[0];
  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
  const yColStride = isChannelsLast ? dyStrides[2] : 1;
  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];
  const out = backend3.makeOutput(convInfo.inShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const dyId = backend3.dataIdMap.get(dy.dataId).id;
  const filterId = backend3.dataIdMap.get(filter.dataId).id;
  wasmConv2DBackpropInput(dyId, filterId, batchSize, filterHeight, filterWidth, inHeight, inWidth, inChannels, outHeight, outWidth, outChannels, strideHeight, strideWidth, topPad, leftPad, fltS0, fltS1, fltS2, xBatchStride, xRowStride, xColStride, xChannelStride, yBatchStride, yRowStride, yColStride, yChannelStride, outId);
  return out;
}
var conv2DBackpropInputConfig3 = {
  kernelName: Conv2DBackpropInput2,
  backendName: "wasm",
  setupFunc: setup10,
  kernelFunc: conv2DBackpropInput5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Cos.ts
var cosConfig3 = createUnaryKernelConfig(Cos2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/CropAndResize.ts
var InterpolationMethod;
(function(InterpolationMethod2) {
  InterpolationMethod2[InterpolationMethod2["bilinear"] = 0] = "bilinear";
  InterpolationMethod2[InterpolationMethod2["nearest"] = 1] = "nearest";
})(InterpolationMethod || (InterpolationMethod = {}));
var wasmCropAndResize;
function setup11(backend3) {
  wasmCropAndResize = backend3.wasm.cwrap(CropAndResize2, null, [
    "number",
    "number",
    "number",
    "number",
    "array",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function cropAndResize5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { method, extrapolationValue, cropSize } = attrs;
  const { image: image4, boxes, boxInd } = inputs;
  const numBoxes = boxes.shape[0];
  const [cropHeight, cropWidth] = cropSize;
  const outShape = [numBoxes, cropHeight, cropWidth, image4.shape[3]];
  let imagesData = backend3.dataIdMap.get(image4.dataId);
  let castedData;
  if (image4.dtype !== "float32") {
    castedData = cast7({ backend: backend3, inputs: { x: image4 }, attrs: { dtype: "float32" } });
    imagesData = backend3.dataIdMap.get(castedData.dataId);
  }
  const imagesId = imagesData.id;
  const boxesId = backend3.dataIdMap.get(boxes.dataId).id;
  const boxIndId = backend3.dataIdMap.get(boxInd.dataId).id;
  const out = backend3.makeOutput(outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const imagesShapeBytes = new Uint8Array(new Int32Array(image4.shape).buffer);
  wasmCropAndResize(imagesId, boxesId, boxIndId, numBoxes, imagesShapeBytes, cropHeight, cropWidth, InterpolationMethod[method], extrapolationValue, outId);
  if (castedData != null) {
    backend3.disposeData(castedData.dataId);
  }
  return out;
}
var cropAndResizeConfig3 = {
  kernelName: CropAndResize2,
  backendName: "wasm",
  setupFunc: setup11,
  kernelFunc: cropAndResize5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Cumsum.ts
var wasmCumsum;
function setup12(backend3) {
  wasmCumsum = backend3.wasm.cwrap(Cumsum2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function cumsum5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse6 } = attrs;
  const xRank = x.shape.length;
  util_exports2.assert(x.dtype === "float32" || x.dtype === "int32", () => `cumsum does not support ${x.dtype} tensors in the WASM backend`);
  const permutation = backend_util_exports2.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation !== null) {
    permutedX = transpose6({ inputs: { x }, attrs: { perm: permutation }, backend: backend3 });
  }
  const permutedAxis = backend_util_exports2.getInnerMostAxes(1, xRank)[0];
  backend_util_exports2.assertAxesAreInnerMostDims("cumsum", [permutedAxis], xRank);
  const permutedOut = backend3.makeOutput(permutedX.shape, permutedX.dtype);
  const finalDim = permutedX.shape[permutedAxis];
  const permutedXId = backend3.dataIdMap.get(permutedX.dataId).id;
  const permutedOutId = backend3.dataIdMap.get(permutedOut.dataId).id;
  wasmCumsum(permutedXId, exclusive ? 1 : 0, reverse6 ? 1 : 0, finalDim, permutedOutId, CppDType[x.dtype]);
  let out = permutedOut;
  if (permutation !== null) {
    const undoPermutation = backend_util_exports2.getUndoAxesPermutation(permutation);
    out = transpose6({ inputs: { x: permutedOut }, attrs: { perm: undoPermutation }, backend: backend3 });
    backend3.disposeData(permutedX.dataId);
    backend3.disposeData(permutedOut.dataId);
  }
  return out;
}
var cumsumConfig3 = {
  kernelName: Cumsum2,
  backendName: "wasm",
  setupFunc: setup12,
  kernelFunc: cumsum5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/DepthToSpace.ts
var wasmDepthToSpace;
function setup13(backend3) {
  wasmDepthToSpace = backend3.wasm.cwrap(DepthToSpace2, null, [
    "number",
    "number",
    "number",
    "array",
    "number",
    "array",
    "array",
    "number",
    "number"
  ]);
}
function depthToSpace5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  util_exports2.assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
  const batchSize = x.shape[0];
  const inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
  const out = backend3.makeOutput(outputShape, "float32");
  const xData = backend3.dataIdMap.get(x.dataId);
  const xId = xData.id;
  const xStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(x.shape)).buffer);
  const outputShapeBytes = new Uint8Array(new Int32Array(outputShape).buffer);
  const outStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(outputShape)).buffer);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const channelsLast = dataFormat === "NHWC" ? 1 : 0;
  wasmDepthToSpace(xId, blockSize, channelsLast, xStridesBytes, x.shape.length - 1, outputShapeBytes, outStridesBytes, outputShape.length, outId);
  return out;
}
var depthToSpaceConfig3 = {
  kernelName: DepthToSpace2,
  backendName: "wasm",
  setupFunc: setup13,
  kernelFunc: depthToSpace5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/DepthwiseConv2dNative.ts
var wasmDepthwiseConv2d;
function setup14(backend3) {
  wasmDepthwiseConv2d = backend3.wasm.cwrap(DepthwiseConv2dNative2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function depthwiseConv2d7(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x, filter } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const filterId = backend3.dataIdMap.get(filter.dataId).id;
  const { strides, dilations, pad: pad4, dimRoundingMode } = attrs;
  const $dilations = dilations == null ? [1, 1] : dilations;
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad4, dimRoundingMode, true);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const inputChannels = convInfo.inChannels;
  const outputChannels = convInfo.outChannels;
  const isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
  if (convInfo.dataFormat !== "channelsLast") {
    throw new Error(`wasm backend DepthwiseConv2dNative does not support dataFormat:'${convInfo.dataFormat}'. Please use 'channelsLast'.`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmDepthwiseConv2d(xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
  return out;
}
var depthwiseConv2dNativeConfig3 = {
  kernelName: DepthwiseConv2dNative2,
  backendName: "wasm",
  setupFunc: setup14,
  kernelFunc: depthwiseConv2d7
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Equal.ts
var supportsFullBroadcast2 = false;
var equalConfig3 = createBinaryKernelConfig(Equal2, supportsFullBroadcast2, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Exp.ts
var expConfig3 = createUnaryKernelConfig(Exp2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ExpandDims.ts
function expandDims6(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { input: input2 } = inputs;
  const { dim } = attrs;
  const inputRank = input2.shape.length;
  const newShape = input2.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports2.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape6({ inputs: { x: input2 }, backend: backend3, attrs: { shape: newShape } });
}
var expandDimsConfig3 = {
  kernelName: ExpandDims2,
  backendName: "wasm",
  kernelFunc: expandDims6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Fill.ts
function fill5(args) {
  const { attrs: { shape, value, dtype }, backend: backend3 } = args;
  const out = backend3.makeOutput(shape, dtype);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.fill(value);
  return out;
}
var fillConfig3 = {
  kernelName: Fill2,
  backendName: "wasm",
  kernelFunc: fill5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/FlipLeftRight.ts
var wasmFlipLeftRight;
function setup15(backend3) {
  wasmFlipLeftRight = backend3.wasm.cwrap(FlipLeftRight2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function flipLeftRight3(args) {
  const { inputs, backend: backend3 } = args;
  const { image: image4 } = inputs;
  const out = backend3.makeOutput(image4.shape, image4.dtype);
  const imageId = backend3.dataIdMap.get(image4.dataId).id;
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  wasmFlipLeftRight(imageId, batch, imageHeight, imageWidth, numChannels, outId);
  return out;
}
var flipLeftRightConfig3 = {
  kernelName: FlipLeftRight2,
  backendName: "wasm",
  kernelFunc: flipLeftRight3,
  setupFunc: setup15
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Floor.ts
var floorConfig3 = createUnaryKernelConfig(Floor2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/FloorDiv.ts
var supportsFullBroadcast3 = false;
var floorDivConfig3 = createBinaryKernelConfig(FloorDiv2, supportsFullBroadcast3);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/FusedBatchNorm.ts
var wasmBatchNorm;
function setup16(backend3) {
  wasmBatchNorm = backend3.wasm.cwrap(FusedBatchNorm2, null, ["number", "number", "number", "number", "number", "number", "number"]);
}
function fusedBatchNorm(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { varianceEpsilon } = attrs;
  const { x, mean: mean5, variance, offset, scale: scale2 } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const meanId = backend3.dataIdMap.get(mean5.dataId).id;
  const varianceId = backend3.dataIdMap.get(variance.dataId).id;
  const offsetId = offset != null ? backend3.dataIdMap.get(offset.dataId).id : 0;
  const scaleId = scale2 != null ? backend3.dataIdMap.get(scale2.dataId).id : 0;
  const out = backend3.makeOutput(x.shape, x.dtype);
  if (util_exports2.sizeFromShape(x.shape) === 0) {
    return out;
  }
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmBatchNorm(xId, meanId, varianceId, offsetId, scaleId, varianceEpsilon, outId);
  return out;
}
var fusedBatchNormConfig = {
  kernelName: FusedBatchNorm2,
  backendName: "wasm",
  setupFunc: setup16,
  kernelFunc: fusedBatchNorm
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/FusedConv2D.ts
var wasmFusedConv2d;
function setup17(backend3) {
  wasmFusedConv2d = backend3.wasm.cwrap(FusedConv2D2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function fusedConv2d2(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const {
    strides,
    pad: pad4,
    dilations,
    dataFormat,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  } = attrs;
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode);
  const fusedActivation = FusableActivation[activation2];
  if (fusedActivation == null) {
    throw new Error(`${activation2} activation not yet supported for FusedConv2D in the wasm backend.`);
  }
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const filterId = backend3.dataIdMap.get(filter.dataId).id;
  const outputChannels = convInfo.outChannels;
  let biasId = 0;
  if (bias != null) {
    const biasData = backend3.dataIdMap.get(bias.dataId);
    if (biasData.shape.length !== 1) {
      throw new Error(`FusedConv2D only supports rank-1 bias but got rank ${biasData.shape.length}.`);
    }
    if (biasData.shape[0] !== outputChannels) {
      throw new Error(`FusedConv2D bias shape (${biasData.shape}) does not match the number of output channels (${outputChannels})`);
    }
    biasId = biasData.id;
  }
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const inputChannels = convInfo.inChannels;
  const isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
  const batchSize = convInfo.batchSize;
  const inHeight = convInfo.inHeight;
  const inWidth = convInfo.inWidth;
  if (dataFormat !== "NHWC") {
    throw new Error(`wasm backend FusedConv2D does not support dataFormat:'${dataFormat}'. Please use 'NHWC'.`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const preluActivationWeightsId = preluActivationWeights == null ? 0 : backend3.dataIdMap.get(preluActivationWeights.dataId).id;
  wasmFusedConv2d(xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth, biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);
  return out;
}
var fusedConv2DConfig3 = {
  kernelName: FusedConv2D2,
  backendName: "wasm",
  setupFunc: setup17,
  kernelFunc: fusedConv2d2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/FusedDepthwiseConv2D.ts
var wasmFusedDepthwiseConv2d;
function setup18(backend3) {
  wasmFusedDepthwiseConv2d = backend3.wasm.cwrap(FusedDepthwiseConv2D2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function fusedDepthwiseConv2d(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const {
    strides,
    pad: pad4,
    dilations,
    dataFormat,
    dimRoundingMode,
    activation: activation2,
    leakyreluAlpha
  } = attrs;
  const convInfo = backend_util_exports2.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad4, dimRoundingMode, true);
  const fusedActivation = FusableActivation[activation2];
  if (fusedActivation == null) {
    throw new Error(`${activation2} activation not yet supported for FusedDepthwiseConv2D in the wasm backend.`);
  }
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const filterId = backend3.dataIdMap.get(filter.dataId).id;
  const outputChannels = convInfo.outChannels;
  let biasId = 0;
  if (bias != null) {
    const biasData = backend3.dataIdMap.get(bias.dataId);
    if (biasData.shape.length !== 1) {
      throw new Error(`FusedDepthwiseConv2D only supports rank-1 bias but got rank ${biasData.shape.length}.`);
    }
    if (biasData.shape[0] !== outputChannels) {
      throw new Error(`FusedDepthwiseConv2D bias shape (${biasData.shape}) does not match the number of output channels (${outputChannels})`);
    }
    biasId = biasData.id;
  }
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const inputChannels = convInfo.inChannels;
  const isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
  const batchSize = convInfo.batchSize;
  const inHeight = convInfo.inHeight;
  const inWidth = convInfo.inWidth;
  if (dataFormat !== "NHWC") {
    throw new Error(`wasm backend FusedDepthwiseConv2D does not support dataFormat:'${dataFormat}'. Please use 'NHWC'.`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const preluActivationWeightsId = preluActivationWeights == null ? 0 : backend3.dataIdMap.get(preluActivationWeights.dataId).id;
  wasmFusedDepthwiseConv2d(xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth, biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);
  return out;
}
var fusedDepthwiseConv2DConfig3 = {
  kernelName: FusedDepthwiseConv2D2,
  backendName: "wasm",
  setupFunc: setup18,
  kernelFunc: fusedDepthwiseConv2d
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/GatherNd.ts
var wasmGatherNd;
function setup19(backend3) {
  wasmGatherNd = backend3.wasm.cwrap(GatherNd2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "array",
    "number"
  ]);
}
function gatherNd3(args) {
  const { backend: backend3, inputs } = args;
  const { params, indices } = inputs;
  const [resultShape, numSlices, sliceSize, strides] = gather_nd_util_exports2.prepareAndValidate(params, indices);
  const out = backend3.makeOutput(resultShape, params.dtype);
  if (numSlices === 0) {
    return out;
  }
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const xData = backend3.dataIdMap.get(params.dataId);
  const xId = xData.id;
  const indicesData = backend3.dataIdMap.get(indices.dataId);
  const indicesId = indicesData.id;
  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmGatherNd(xId, CppDType[params.dtype], indicesId, numSlices, sliceRank, sliceSize, stridesBytes, outId);
  return out;
}
var gatherNdConfig3 = {
  kernelName: GatherNd2,
  backendName: "wasm",
  setupFunc: setup19,
  kernelFunc: gatherNd3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/GatherV2.ts
var wasmGather;
function setup20(backend3) {
  wasmGather = backend3.wasm.cwrap("Gather", null, [
    "number",
    "number",
    "array",
    "number",
    "number",
    "number",
    "array",
    "number"
  ]);
}
function gatherV23(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  const parsedAxis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const shapeInfo = backend_util_exports2.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
  const flattenX = reshape6({
    inputs: { x },
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    },
    backend: backend3
  });
  const indicesSize = util_exports2.sizeFromShape(indices.shape);
  const flattenIndex = reshape6({
    inputs: { x: indices },
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] },
    backend: backend3
  });
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  const out = backend3.makeOutput(flattenOutputShape, x.dtype);
  if (util_exports2.sizeFromShape(x.shape) === 0) {
    return out;
  }
  const stridesSize = flattenX.shape.length - 1;
  const xData = backend3.dataIdMap.get(flattenX.dataId);
  const xId = xData.id;
  const indicesData = backend3.dataIdMap.get(flattenIndex.dataId);
  const indicesId = indicesData.id;
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const xStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(flattenX.shape)).buffer);
  const outStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(flattenOutputShape)).buffer);
  wasmGather(xId, CppDType[x.dtype], xStridesBytes, stridesSize, indicesId, shapeInfo.batchSize, outStridesBytes, outId);
  backend3.disposeData(flattenX.dataId);
  backend3.disposeData(flattenIndex.dataId);
  out.shape = shapeInfo.outputShape;
  return out;
}
var gatherV2Config3 = {
  kernelName: GatherV22,
  backendName: "wasm",
  setupFunc: setup20,
  kernelFunc: gatherV23
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Greater.ts
var supportsFullBroadcast4 = false;
var greaterConfig3 = createBinaryKernelConfig(Greater2, supportsFullBroadcast4, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/GreaterEqual.ts
var supportsFullBroadcast5 = false;
var greaterEqualConfig3 = createBinaryKernelConfig(GreaterEqual2, supportsFullBroadcast5, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/LeakyRelu.ts
var wasmFunc3;
function setupFunc2(backend3) {
  wasmFunc3 = backend3.wasm.cwrap(LeakyRelu2, null, [
    "number",
    "number",
    "number"
  ]);
}
function leakyRelu5(args) {
  const { inputs: { x }, attrs: { alpha }, backend: backend3 } = args;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(x.shape, x.dtype);
  if (util_exports2.sizeFromShape(x.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmFunc3(xId, alpha, outId);
  }
  return out;
}
var leakyReluConfig3 = {
  kernelName: LeakyRelu2,
  backendName: "wasm",
  setupFunc: setupFunc2,
  kernelFunc: leakyRelu5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Less.ts
var supportsFullBroadcast6 = false;
var lessConfig3 = createBinaryKernelConfig(Less2, supportsFullBroadcast6, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/LessEqual.ts
var supportsFullBroadcast7 = false;
var lessEqualConfig3 = createBinaryKernelConfig(LessEqual2, supportsFullBroadcast7, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Log.ts
var logConfig3 = createUnaryKernelConfig(Log2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/LogicalAnd.ts
var supportsFullBroadcast8 = false;
var logicalAndConfig3 = createBinaryKernelConfig(LogicalAnd2, supportsFullBroadcast8, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Max.ts
var wasmMax;
function setup21(backend3) {
  wasmMax = backend3.wasm.cwrap(Max2, null, ["number, number, number"]);
}
function max6(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { reductionIndices: axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    input2 = transposed;
    inputId = transposedId;
  }
  const inputRank = input2.shape.length;
  backend_util_exports2.assertAxesAreInnerMostDims("max", axes, inputRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, x.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmMax(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var maxConfig3 = {
  kernelName: Max2,
  backendName: "wasm",
  setupFunc: setup21,
  kernelFunc: max6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Maximum.ts
var supportsFullBroadcast9 = false;
var maximumConfig3 = createBinaryKernelConfig(Maximum2, supportsFullBroadcast9);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/MaxPool.ts
var wasmMaxPool;
function setup22(backend3) {
  wasmMaxPool = backend3.wasm.cwrap(MaxPool2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function maxPool5(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const x = inputs.x;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const { filterSize, strides, pad: pad4, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports2.computePool2DInfo(x.shape, filterSize, strides, 1, pad4, dimRoundingMode);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const padTop = convInfo.padInfo.top;
  const padRight = convInfo.padInfo.right;
  const padBottom = convInfo.padInfo.bottom;
  const padLeft = convInfo.padInfo.left;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const inputChannels = convInfo.inChannels;
  const outputChannels = convInfo.outChannels;
  if (convInfo.dataFormat !== "channelsLast") {
    throw new Error(`wasm backend does not support dataFormat:'${convInfo.dataFormat}'. Please use 'channelsLast'.`);
  }
  const out = backend3.makeOutput(convInfo.outShape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmMaxPool(xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
  return out;
}
var maxPoolConfig3 = {
  kernelName: MaxPool2,
  backendName: "wasm",
  setupFunc: setup22,
  kernelFunc: maxPool5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Mean.ts
var wasmMean;
function setup23(backend3) {
  wasmMean = backend3.wasm.cwrap(Mean2, null, ["number, number, number"]);
}
function mean4(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  let reductionAxes = axes;
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    if (transposedId !== xId) {
      input2 = transposed;
      inputId = transposedId;
      reductionAxes = backend_util_exports2.getInnerMostAxes(reductionAxes.length, input2.shape.length);
    }
  }
  backend_util_exports2.assertAxesAreInnerMostDims("mean", reductionAxes, input2.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, reductionAxes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  let castedInput = input2;
  if (input2.dtype !== "float32") {
    castedInput = cast7({ backend: backend3, inputs: { x: input2 }, attrs: { dtype: "float32" } });
    inputId = backend3.dataIdMap.get(castedInput.dataId).id;
  }
  const out = backend3.makeOutput(outShape, "float32");
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmMean(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  if (input2.dtype !== "float32") {
    backend3.disposeData(castedInput.dataId);
  }
  return out;
}
var meanConfig3 = {
  kernelName: Mean2,
  backendName: "wasm",
  setupFunc: setup23,
  kernelFunc: mean4
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Min.ts
var wasmMin;
function setup24(backend3) {
  wasmMin = backend3.wasm.cwrap(Min2, null, ["number, number, number"]);
}
function min6(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    if (transposedId !== xId) {
      input2 = transposed;
      inputId = transposedId;
    }
  }
  const inputRank = input2.shape.length;
  backend_util_exports2.assertAxesAreInnerMostDims("min", axes, inputRank);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, axes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, input2.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmMin(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var minConfig3 = {
  kernelName: Min2,
  backendName: "wasm",
  setupFunc: setup24,
  kernelFunc: min6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Minimum.ts
var supportsFullBroadcast10 = false;
var minimumConfig3 = createBinaryKernelConfig(Minimum2, supportsFullBroadcast10);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/MirrorPad.ts
var MirrorPaddingMode;
(function(MirrorPaddingMode2) {
  MirrorPaddingMode2[MirrorPaddingMode2["reflect"] = 0] = "reflect";
  MirrorPaddingMode2[MirrorPaddingMode2["symmetric"] = 1] = "symmetric";
})(MirrorPaddingMode || (MirrorPaddingMode = {}));
var wasmMirrorPad;
function setup25(backend3) {
  wasmMirrorPad = backend3.wasm.cwrap(MirrorPad2, null, [
    "number",
    "array",
    "number",
    "number",
    "array",
    "array",
    "number",
    "number"
  ]);
}
function mirrorPad4(args) {
  const { inputs: { x }, backend: backend3, attrs: { paddings, mode } } = args;
  const outShape = paddings.map((p2, i) => p2[0] + x.shape[i] + p2[1]);
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(outShape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  const prePaddingsFlat = paddings.map((padTuple) => padTuple[0]);
  const postPaddingsFlat = paddings.map((padTuple) => padTuple[1]);
  const prePaddingsBytes = new Uint8Array(new Int32Array(prePaddingsFlat).buffer);
  const postPaddingsBytes = new Uint8Array(new Int32Array(postPaddingsFlat).buffer);
  wasmMirrorPad(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes, postPaddingsBytes, MirrorPaddingMode[mode], outId);
  return out;
}
var mirrorPadConfig3 = {
  kernelName: MirrorPad2,
  backendName: "wasm",
  kernelFunc: mirrorPad4,
  setupFunc: setup25
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Multiply.ts
var supportsFullBroadcast11 = true;
var multiplyConfig3 = createBinaryKernelConfig(Multiply2, supportsFullBroadcast11);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Neg.ts
var negConfig3 = createUnaryKernelConfig(Neg2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/NonMaxSuppression_util.ts
function parseResultStruct(backend3, resOffset) {
  const result = new Int32Array(backend3.wasm.HEAPU8.buffer, resOffset, 4);
  const pSelectedIndices = result[0];
  const selectedSize = result[1];
  const pSelectedScores = result[2];
  const pValidOutputs = result[3];
  backend3.wasm._free(resOffset);
  return { pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs };
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/NonMaxSuppressionV3.ts
var wasmFunc4;
function setup26(backend3) {
  wasmFunc4 = backend3.wasm.cwrap(NonMaxSuppressionV32, "number", [
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function kernelFunc(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { iouThreshold, maxOutputSize, scoreThreshold } = attrs;
  const { boxes, scores } = inputs;
  const boxesId = backend3.dataIdMap.get(boxes.dataId).id;
  const scoresId = backend3.dataIdMap.get(scores.dataId).id;
  const resOffset = wasmFunc4(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold);
  const { pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs } = parseResultStruct(backend3, resOffset);
  backend3.wasm._free(pSelectedScores);
  backend3.wasm._free(pValidOutputs);
  const selectedIndicesTensor = backend3.makeOutput([selectedSize], "int32", pSelectedIndices);
  return selectedIndicesTensor;
}
var nonMaxSuppressionV3Config3 = {
  kernelName: NonMaxSuppressionV32,
  backendName: "wasm",
  setupFunc: setup26,
  kernelFunc
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/NonMaxSuppressionV4.ts
var wasmFunc5;
function setup27(backend3) {
  wasmFunc5 = backend3.wasm.cwrap(NonMaxSuppressionV42, "number", [
    "number",
    "number",
    "number",
    "number",
    "number",
    "bool"
  ]);
}
function nonMaxSuppressionV43(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { iouThreshold, maxOutputSize, scoreThreshold, padToMaxOutputSize } = attrs;
  const { boxes, scores } = inputs;
  const boxesId = backend3.dataIdMap.get(boxes.dataId).id;
  const scoresId = backend3.dataIdMap.get(scores.dataId).id;
  const resOffset = wasmFunc5(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
  const { pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs } = parseResultStruct(backend3, resOffset);
  backend3.wasm._free(pSelectedScores);
  const selectedIndicesTensor = backend3.makeOutput([selectedSize], "int32", pSelectedIndices);
  const validOutputsTensor = backend3.makeOutput([], "int32", pValidOutputs);
  return [selectedIndicesTensor, validOutputsTensor];
}
var nonMaxSuppressionV4Config3 = {
  kernelName: NonMaxSuppressionV42,
  backendName: "wasm",
  setupFunc: setup27,
  kernelFunc: nonMaxSuppressionV43
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/NonMaxSuppressionV5.ts
var wasmFunc6;
function setup28(backend3) {
  wasmFunc6 = backend3.wasm.cwrap(NonMaxSuppressionV52, "number", [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function kernelFunc2(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { iouThreshold, maxOutputSize, scoreThreshold, softNmsSigma } = attrs;
  const { boxes, scores } = inputs;
  const boxesId = backend3.dataIdMap.get(boxes.dataId).id;
  const scoresId = backend3.dataIdMap.get(scores.dataId).id;
  const resOffset = wasmFunc6(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  const { pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs } = parseResultStruct(backend3, resOffset);
  backend3.wasm._free(pValidOutputs);
  const selectedIndicesTensor = backend3.makeOutput([selectedSize], "int32", pSelectedIndices);
  const selectedScoresTensor = backend3.makeOutput([selectedSize], "float32", pSelectedScores);
  return [selectedIndicesTensor, selectedScoresTensor];
}
var nonMaxSuppressionV5Config3 = {
  kernelName: NonMaxSuppressionV52,
  backendName: "wasm",
  setupFunc: setup28,
  kernelFunc: kernelFunc2
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/NotEqual.ts
var supportsFullBroadcast12 = false;
var notEqualConfig3 = createBinaryKernelConfig(NotEqual2, supportsFullBroadcast12, "bool");

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/OneHot.ts
var wasmOneHot;
function setup29(backend3) {
  wasmOneHot = backend3.wasm.cwrap(OneHot2, null, [
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function oneHot5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { indices } = inputs;
  const { depth, onValue, offValue } = attrs;
  const out = backend3.makeOutput([...indices.shape, depth], "int32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const indicesData = backend3.dataIdMap.get(indices.dataId);
  const indicesId = indicesData.id;
  wasmOneHot(indicesId, depth, onValue, offValue, outId);
  return out;
}
var oneHotConfig3 = {
  kernelName: OneHot2,
  backendName: "wasm",
  setupFunc: setup29,
  kernelFunc: oneHot5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/OnesLike.ts
function onesLike5(args) {
  const { inputs: { x }, backend: backend3 } = args;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.fill(1);
  return out;
}
var onesLikeConfig3 = {
  kernelName: OnesLike2,
  backendName: "wasm",
  kernelFunc: onesLike5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Pack.ts
function pack3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims6({ inputs: { input: inputs[0] }, backend: backend3, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t) => {
    util_exports2.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
    util_exports2.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t) => {
    const expandedT = expandDims6({ inputs: { input: t }, backend: backend3, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat5({ inputs: expandedTensors, backend: backend3, attrs: { axis } });
  intermediateTensorInfos.forEach((t) => backend3.disposeData(t.dataId));
  return result;
}
var packConfig3 = {
  kernelName: Pack2,
  backendName: "wasm",
  kernelFunc: pack3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/PadV2.ts
var wasmPadV2;
function setup30(backend3) {
  wasmPadV2 = backend3.wasm.cwrap(PadV22, null, [
    "number",
    "array",
    "number",
    "number",
    "array",
    "array",
    "number",
    "number"
  ]);
}
function pad3(args) {
  const { inputs: { x }, backend: backend3, attrs: { paddings, constantValue } } = args;
  const outShape = paddings.map((p2, i) => p2[0] + x.shape[i] + p2[1]);
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(outShape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  const prePaddingsFlat = paddings.map((padTuple) => padTuple[0]);
  const postPaddingsFlat = paddings.map((padTuple) => padTuple[1]);
  const prePaddingsBytes = new Uint8Array(new Int32Array(prePaddingsFlat).buffer);
  const postPaddingsBytes = new Uint8Array(new Int32Array(postPaddingsFlat).buffer);
  wasmPadV2(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes, postPaddingsBytes, constantValue, outId);
  return out;
}
var padV2Config3 = {
  kernelName: PadV22,
  backendName: "wasm",
  kernelFunc: pad3,
  setupFunc: setup30
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Pow.ts
var supportsFullBroadcast13 = false;
var powConfig3 = createBinaryKernelConfig(Pow2, supportsFullBroadcast13);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Prelu.ts
var wasmPrelu;
function setup31(backend3) {
  wasmPrelu = backend3.wasm.cwrap(Prelu2, null, [
    "number",
    "number",
    "number"
  ]);
}
function prelu6(args) {
  const { inputs, backend: backend3 } = args;
  const { x, alpha } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const weightsId = backend3.dataIdMap.get(alpha.dataId).id;
  const out = backend3.makeOutput(x.shape, "float32");
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmPrelu(xId, weightsId, outId);
  return out;
}
var preluConfig3 = {
  kernelName: Prelu2,
  backendName: "wasm",
  setupFunc: setup31,
  kernelFunc: prelu6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Prod.ts
var wasmProd;
function setup32(backend3) {
  wasmProd = backend3.wasm.cwrap(Prod2, null, [
    "number",
    "number",
    "number",
    "number"
  ]);
}
function prod5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  let reductionAxes = axes;
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    if (transposedId !== xId) {
      input2 = transposed;
      inputId = transposedId;
      reductionAxes = backend_util_exports2.getInnerMostAxes(reductionAxes.length, input2.shape.length);
    }
  }
  backend_util_exports2.assertAxesAreInnerMostDims("prod", reductionAxes, input2.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, reductionAxes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, input2.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmProd(inputId, reduceSize, CppDType[out.dtype], outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var prodConfig3 = {
  kernelName: Prod2,
  backendName: "wasm",
  setupFunc: setup32,
  kernelFunc: prod5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Range.ts
var range6 = (args) => {
  const { backend: backend3, attrs } = args;
  const { start, stop, step: step6, dtype } = attrs;
  const values = rangeImpl2(start, stop, step6, dtype);
  const out = backend3.makeOutput([values.length], dtype);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.set(values);
  return out;
};
var rangeConfig3 = {
  kernelName: Range2,
  backendName: "wasm",
  kernelFunc: range6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/RealDiv.ts
var supportsFullBroadcast14 = true;
var realDivConfig3 = createBinaryKernelConfig(RealDiv2, supportsFullBroadcast14);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Relu.ts
var reluConfig3 = createUnaryKernelConfig(Relu2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Relu6.ts
var relu6Config3 = createUnaryKernelConfig(Relu62);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ResizeBilinear.ts
var wasmResizeBilinear;
function setup33(backend3) {
  wasmResizeBilinear = backend3.wasm.cwrap(ResizeBilinear2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function resizeBilinear5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const [batch, oldHeight, oldWidth, numChannels] = images.shape;
  const outShape = [batch, newHeight, newWidth, numChannels];
  let xData = backend3.dataIdMap.get(images.dataId);
  let castedData;
  if (xData.dtype !== "float32") {
    castedData = cast7({ backend: backend3, inputs: { x: images }, attrs: { dtype: "float32" } });
    xData = backend3.dataIdMap.get(castedData.dataId);
  }
  const xId = xData.id;
  const out = backend3.makeOutput(outShape, "float32");
  if (util_exports2.sizeFromShape(images.shape) === 0) {
    return out;
  }
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmResizeBilinear(xId, batch, oldHeight, oldWidth, numChannels, newHeight, newWidth, alignCorners ? 1 : 0, halfPixelCenters ? 1 : 0, outId);
  if (castedData != null) {
    backend3.disposeData(castedData.dataId);
  }
  return out;
}
var resizeBilinearConfig3 = {
  kernelName: ResizeBilinear2,
  backendName: "wasm",
  setupFunc: setup33,
  kernelFunc: resizeBilinear5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Reverse.ts
var wasmReverse;
function setup34(backend3) {
  wasmReverse = backend3.wasm.cwrap(Reverse2, null, [
    "number",
    "array",
    "number",
    "array",
    "number",
    "number"
  ]);
}
function reverse5(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  const axes = util_exports2.parseAxisParam(dims, x.shape);
  if (x.shape.length === 0) {
    return identity5({ inputs: { x }, backend: backend3 });
  }
  const out = backend3.makeOutput(x.shape, x.dtype);
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const axesBytes = new Uint8Array(new Int32Array(axes).buffer);
  const outShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  wasmReverse(xId, axesBytes, axes.length, outShapeBytes, x.shape.length, outId);
  const reshaped = reshape6({ inputs: { x: out }, attrs: { shape: x.shape }, backend: backend3 });
  backend3.disposeData(out.dataId);
  return reshaped;
}
var reverseConfig3 = {
  kernelName: Reverse2,
  backendName: "wasm",
  kernelFunc: reverse5,
  setupFunc: setup34
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/RotateWithOffset.ts
var wasmRotate;
function setup35(backend3) {
  wasmRotate = backend3.wasm.cwrap(RotateWithOffset2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "array",
    "number",
    "number"
  ]);
}
function rotateWithOffset3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { image: image4 } = inputs;
  const { radians, fillValue, center } = attrs;
  const out = backend3.makeOutput(image4.shape, image4.dtype);
  const imageId = backend3.dataIdMap.get(image4.dataId).id;
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  const [centerX, centerY] = backend_util_exports2.getImageCenter(center, imageHeight, imageWidth);
  const fillIsBlack = fillValue === 0;
  const fullOpacityValue = 255;
  const fillValues2 = typeof fillValue === "number" ? [fillValue, fillValue, fillValue, fillIsBlack ? 0 : fullOpacityValue] : [...fillValue, fullOpacityValue];
  const fillBytes = new Uint8Array(new Int32Array(fillValues2).buffer);
  wasmRotate(imageId, batch, imageHeight, imageWidth, numChannels, radians, centerX, centerY, fillBytes, fillValues2.length, outId);
  return out;
}
var rotateWithOffsetConfig3 = {
  kernelName: RotateWithOffset2,
  backendName: "wasm",
  kernelFunc: rotateWithOffset3,
  setupFunc: setup35
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Round.ts
var roundConfig3 = createUnaryKernelConfig(Round2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Rsqrt.ts
var rsqrtConfig3 = createUnaryKernelConfig(Rsqrt2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ScatterNd.ts
var wasmScatterNd;
function setup36(backend3) {
  wasmScatterNd = backend3.wasm.cwrap(ScatterNd2, null, [
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "array",
    "number",
    "number"
  ]);
}
function scatterNd3(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const out = backend3.makeOutput(shape, updates.dtype);
  if (util_exports2.sizeFromShape(shape) === 0) {
    return out;
  }
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = scatter_nd_util_exports2.calculateShapes(updates, indices, shape);
  const indicesData = backend3.dataIdMap.get(indices.dataId);
  const indicesId = indicesData.id;
  const updatesData = backend3.dataIdMap.get(updates.dataId);
  const updatesId = updatesData.id;
  const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmScatterNd(indicesId, updatesId, CppDType[updates.dtype], sliceRank, numUpdates, sliceSize, stridesBytes, outputSize, outId);
  return out;
}
var scatterNdConfig3 = {
  kernelName: ScatterNd2,
  backendName: "wasm",
  setupFunc: setup36,
  kernelFunc: scatterNd3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Select.ts
var wasmSelect;
function setup37(backend3) {
  wasmSelect = backend3.wasm.cwrap("SelectV2", null, [
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function select3(args) {
  const { inputs, backend: backend3 } = args;
  const { condition, t, e } = inputs;
  const conditionId = backend3.dataIdMap.get(condition.dataId).id;
  const tId = backend3.dataIdMap.get(t.dataId).id;
  const eId = backend3.dataIdMap.get(e.dataId).id;
  const out = backend3.makeOutput(t.shape, t.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const cRank = condition.shape.length;
  const tRank = t.shape.length;
  const offset = cRank === 0 || cRank > 1 || tRank === 1 ? 1 : util_exports2.sizeFromShape(t.shape.slice(1));
  wasmSelect(conditionId, tId, eId, offset, outId);
  return out;
}
var selectConfig3 = {
  kernelName: Select2,
  backendName: "wasm",
  kernelFunc: select3,
  setupFunc: setup37
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Sigmoid.ts
var wasmFunc7;
function setup38(backend3) {
  wasmFunc7 = backend3.wasm.cwrap(Sigmoid2, null, ["number", "number"]);
}
function sigmoid5(args) {
  const { backend: backend3, inputs: { x } } = args;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  if (util_exports2.sizeFromShape(out.shape) === 0) {
    return out;
  }
  wasmFunc7(xId, outId);
  return out;
}
var sigmoidConfig3 = {
  kernelName: "Sigmoid",
  backendName: "wasm",
  setupFunc: setup38,
  kernelFunc: sigmoid5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Sin.ts
var sinConfig3 = createUnaryKernelConfig(Sin2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Slice.ts
function slice5(args) {
  const { inputs: { x }, attrs: { begin, size }, backend: backend3 } = args;
  const [begin_, size_] = slice_util_exports2.parseSliceParams(x, begin, size);
  const isContinous = slice_util_exports2.isSliceContinous(x.shape, begin_, size_);
  const xVals = backend3.readSync(x.dataId);
  const out = backend3.makeOutput(size_, x.dtype);
  const xStrides = util_exports2.computeStrides(x.shape);
  const outData = backend3.dataIdMap.get(out.dataId);
  if (isContinous) {
    const flatOffset = slice_util_exports2.computeFlatOffset(begin_, xStrides);
    if (x.dtype === "string") {
      outData.stringBytes = xVals.slice(flatOffset, flatOffset + util_exports2.sizeFromShape(size_));
    } else {
      const outVals2 = backend3.typedArrayFromHeap(out);
      outVals2.set(xVals.subarray(flatOffset, flatOffset + util_exports2.sizeFromShape(size_)));
    }
    return out;
  }
  if (x.dtype === "string") {
    const res = sliceImpl2(xVals, begin_, size_, x.shape, x.dtype);
    outData.stringBytes = res;
    return out;
  }
  const outVals = backend3.typedArrayFromHeap(out);
  const rank = x.shape.length;
  if (rank === 2) {
    slice2d3(xVals, xStrides[0], outVals, begin_, size_);
  } else if (rank === 3) {
    slice3d3(xVals, xStrides[0], xStrides[1], outVals, begin_, size_);
  } else if (rank === 4) {
    slice4d3(xVals, xStrides[0], xStrides[1], xStrides[2], outVals, begin_, size_);
  } else {
    const res = sliceImpl2(xVals, begin_, size_, x.shape, x.dtype);
    outVals.set(res);
  }
  return out;
}
function slice2d3(xVals, xStride, outVals, begin, size) {
  let outOffset = 0;
  const beginI = begin[0];
  const beginJ = begin[1];
  const endI = beginI + size[0];
  for (let i = beginI; i < endI; i++) {
    const xOffset = i * xStride + beginJ;
    outVals.set(xVals.subarray(xOffset, xOffset + size[1]), outOffset);
    outOffset += size[1];
  }
}
function slice3d3(xVals, xStride1, xStride2, outVals, begin, size) {
  let outOffset = 0;
  const beginI = begin[0];
  const beginJ = begin[1];
  const beginK = begin[2];
  const endI = beginI + size[0];
  const endJ = beginJ + size[1];
  for (let i = beginI; i < endI; i++) {
    for (let j = beginJ; j < endJ; j++) {
      const xOffset = i * xStride1 + j * xStride2 + beginK;
      outVals.set(xVals.subarray(xOffset, xOffset + size[2]), outOffset);
      outOffset += size[2];
    }
  }
}
function slice4d3(xVals, xStride1, xStride2, xStride3, outVals, begin, size) {
  let outOffset = 0;
  const beginI = begin[0];
  const beginJ = begin[1];
  const beginK = begin[2];
  const endI = beginI + size[0];
  const endJ = beginJ + size[1];
  const endK = beginK + size[2];
  const beginL = begin[3];
  for (let i = beginI; i < endI; i++) {
    for (let j = beginJ; j < endJ; j++) {
      for (let k = beginK; k < endK; k++) {
        const xOffset = i * xStride1 + j * xStride2 + k * xStride3 + beginL;
        outVals.set(xVals.subarray(xOffset, xOffset + size[3]), outOffset);
        outOffset += size[3];
      }
    }
  }
}
var sliceConfig3 = {
  kernelName: Slice2,
  backendName: "wasm",
  kernelFunc: slice5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Softmax.ts
var wasmFunc8;
function setup39(backend3) {
  wasmFunc8 = backend3.wasm.cwrap(Softmax2, null, [
    "number",
    "number",
    "number",
    "number"
  ]);
}
function softmax6(args) {
  const { backend: backend3, inputs: { logits }, attrs: { dim } } = args;
  const xId = backend3.dataIdMap.get(logits.dataId).id;
  const out = backend3.makeOutput(logits.shape, logits.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const channels = logits.shape[dim];
  const batch = util_exports2.sizeFromShape(logits.shape) / channels;
  if (util_exports2.sizeFromShape(out.shape) === 0) {
    return out;
  }
  wasmFunc8(xId, outId, channels, batch);
  return out;
}
var softmaxConfig3 = {
  kernelName: Softmax2,
  backendName: "wasm",
  setupFunc: setup39,
  kernelFunc: softmax6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/SplitV.ts
function splitV3(args) {
  const { inputs, attrs, backend: backend3 } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports2.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports2.prepareSplitSize(x, numOrSizeSplits, $axis);
  const begin = new Array(x.shape.length).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const xSliceSize = [...size];
    xSliceSize[$axis] = s;
    const xSlice = slice5({ inputs: { x }, attrs: { begin, size: xSliceSize }, backend: backend3 });
    begin[$axis] += s;
    return xSlice;
  });
}
var splitVConfig3 = {
  kernelName: SplitV2,
  backendName: "wasm",
  kernelFunc: splitV3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Sqrt.ts
var sqrtConfig3 = createUnaryKernelConfig(Sqrt2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Square.ts
var squareConfig3 = createUnaryKernelConfig(Square2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/SquaredDifference.ts
var supportsFullBroadcast15 = true;
var squaredDifferenceConfig3 = createBinaryKernelConfig(SquaredDifference2, supportsFullBroadcast15);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Step.ts
var wasmStep;
function setup40(backend3) {
  wasmStep = backend3.wasm.cwrap(Step2, null, [
    "number",
    "number",
    "number"
  ]);
}
function step5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { alpha } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmStep(xId, alpha, outId);
  return out;
}
var stepConfig3 = {
  kernelName: Step2,
  backendName: "wasm",
  setupFunc: setup40,
  kernelFunc: step5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/StridedSlice.ts
var wasmStridedSlice;
function setup41(backend3) {
  wasmStridedSlice = backend3.wasm.cwrap(StridedSlice2, null, [
    "number",
    "array",
    "number",
    "array",
    "array",
    "array",
    "array",
    "array",
    "number",
    "number"
  ]);
}
function stridedSlice5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { x } = inputs;
  let { begin, end, strides } = attrs;
  if (strides == null) {
    strides = new Array(begin.length);
  }
  const { beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
  const ellipsisAxes = backend_util_exports2.slice_util.maskToAxes(ellipsisMask);
  if (ellipsisAxes.length > 1) {
    throw new Error("Multiple ellipses in slice is not allowed.");
  }
  if (ellipsisMask !== 0 && newAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");
  }
  if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {
    throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");
  }
  const numInterpolatedAxes = x.shape.length - begin.length;
  const expandAxes = backend_util_exports2.slice_util.maskToAxes(newAxisMask);
  const newShape = x.shape.slice();
  expandAxes.forEach((axis) => {
    begin[axis] = 0;
    end[axis] = 1;
    newShape.splice(axis, 0, 1);
  });
  const xReshaped = reshape6({ inputs: { x }, attrs: { shape: newShape }, backend: backend3 });
  const {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  } = backend_util_exports2.slice_util.getNormalizedAxes(xReshaped.shape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask);
  begin = normalizedBegin;
  end = normalizedEnd;
  strides = normalizedStrides;
  const shrinkAxes = backend_util_exports2.slice_util.maskToAxes(shrinkAxisMask);
  shrinkAxes.forEach((axis) => {
    end[axis] = begin[axis] + 1;
    strides[axis] = 1;
  });
  const size = backend_util_exports2.slice_util.computeOutShape(begin, end, strides);
  const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);
  const nonStrided = strides.every((v) => v === 1);
  if (nonStrided) {
    const xSliced = slice5({ inputs: { x: xReshaped }, attrs: { begin, size }, backend: backend3 });
    backend3.disposeData(xReshaped.dataId);
    const reshaped2 = reshape6({ inputs: { x: xSliced }, attrs: { shape: outShape }, backend: backend3 });
    backend3.disposeData(xSliced.dataId);
    return reshaped2;
  }
  const out = backend3.makeOutput(outShape, "float32");
  if (!outShape.some((axis) => axis === 0)) {
    const xId = backend3.dataIdMap.get(xReshaped.dataId).id;
    const xStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(xReshaped.shape)).buffer);
    const beginBytes = new Uint8Array(new Int32Array(begin).buffer);
    const endBytes = new Uint8Array(new Int32Array(end).buffer);
    const stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
    const outputShapeBytes = new Uint8Array(new Int32Array(outShape).buffer);
    const outStridesBytes = new Uint8Array(new Int32Array(util_exports2.computeStrides(outShape)).buffer);
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmStridedSlice(xId, xStridesBytes, xReshaped.shape.length, beginBytes, endBytes, stridesBytes, outputShapeBytes, outStridesBytes, outShape.length, outId);
  }
  backend3.disposeData(xReshaped.dataId);
  const reshaped = reshape6({ inputs: { x: out }, attrs: { shape: outShape }, backend: backend3 });
  backend3.disposeData(out.dataId);
  return reshaped;
}
var stridedSliceConfig3 = {
  kernelName: StridedSlice2,
  backendName: "wasm",
  setupFunc: setup41,
  kernelFunc: stridedSlice5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Sub.ts
var supportsFullBroadcast16 = true;
var subConfig3 = createBinaryKernelConfig(Sub2, supportsFullBroadcast16);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Sum.ts
var wasmSum;
function setup42(backend3) {
  wasmSum = backend3.wasm.cwrap(Sum2, null, ["number, number, number"]);
}
function sum7(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { axis, keepDims } = attrs;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  let inputId = xId;
  let input2 = x;
  const { transposed, axes, originalAxes, inputWasTransposed } = permuteAxesAndTranspose(x, axis, backend3);
  let reductionAxes = axes;
  if (inputWasTransposed) {
    const transposedId = backend3.dataIdMap.get(transposed.dataId).id;
    if (transposedId !== xId) {
      input2 = transposed;
      inputId = transposedId;
      reductionAxes = backend_util_exports2.getInnerMostAxes(reductionAxes.length, input2.shape.length);
    }
  }
  backend_util_exports2.assertAxesAreInnerMostDims("sum", reductionAxes, input2.shape.length);
  const [outShape, reduceShape] = backend_util_exports2.computeOutAndReduceShapes(input2.shape, reductionAxes);
  const reduceSize = util_exports2.sizeFromShape(reduceShape);
  const out = backend3.makeOutput(outShape, input2.dtype);
  if (util_exports2.sizeFromShape(input2.shape) !== 0) {
    const outId = backend3.dataIdMap.get(out.dataId).id;
    wasmSum(inputId, reduceSize, outId);
  }
  if (inputWasTransposed) {
    backend3.disposeData(transposed.dataId);
  }
  if (keepDims) {
    const newShape = backend_util_exports2.expandShapeToKeepDim(out.shape, originalAxes);
    out.shape = newShape;
  }
  return out;
}
var sumConfig3 = {
  kernelName: Sum2,
  backendName: "wasm",
  setupFunc: setup42,
  kernelFunc: sum7
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Tan.ts
var tanConfig3 = createUnaryKernelConfig(Tan2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Tanh.ts
var tanhConfig3 = createUnaryKernelConfig(Tanh2);

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Tile.ts
var wasmTile;
function setup43(backend3) {
  wasmTile = backend3.wasm.cwrap(Tile2, null, [
    "number",
    "array",
    "number",
    "array",
    "number",
    "number"
  ]);
}
function tile6(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { x } = inputs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const { reps } = attrs;
  const newShape = new Array(x.shape.length);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[i] * reps[i];
  }
  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  const newShapeBytes = new Uint8Array(new Int32Array(newShape).buffer);
  const out = backend3.makeOutput(newShape, x.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  wasmTile(xId, xShapeBytes, x.shape.length, newShapeBytes, newShape.length, CppDType[out.dtype], outId);
  return out;
}
var tileConfig3 = {
  kernelName: Tile2,
  backendName: "wasm",
  setupFunc: setup43,
  kernelFunc: tile6
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/TopK.ts
var wasmTopK;
function setup44(backend3) {
  wasmTopK = backend3.wasm.cwrap(TopK2, null, [
    "number",
    "array",
    "number",
    "number",
    "number",
    "bool",
    "number",
    "number"
  ]);
}
var topk3 = ({ inputs, backend: backend3, attrs }) => {
  const { x } = inputs;
  const { k, sorted } = attrs;
  const xId = backend3.dataIdMap.get(x.dataId).id;
  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
  const outputShape = x.shape.slice();
  outputShape[outputShape.length - 1] = k;
  const outValues = backend3.makeOutput(outputShape, x.dtype);
  const outValuesId = backend3.dataIdMap.get(outValues.dataId).id;
  const outIndices = backend3.makeOutput(outputShape, "int32");
  const outIndicesId = backend3.dataIdMap.get(outIndices.dataId).id;
  wasmTopK(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], k, sorted, outValuesId, outIndicesId);
  return [outValues, outIndices];
};
var topKConfig3 = {
  kernelName: TopK2,
  backendName: "wasm",
  setupFunc: setup44,
  kernelFunc: topk3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Transform.ts
var wasmTransform;
function setup45(backend3) {
  wasmTransform = backend3.wasm.cwrap(Transform2, null, [
    "number",
    "number",
    "bool",
    "number",
    "number",
    "number",
    "number",
    "number",
    "number",
    "array",
    "number",
    "number",
    "number",
    "number",
    "number"
  ]);
}
function transform5(args) {
  const { backend: backend3, inputs, attrs } = args;
  const { image: image4, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image4.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [
    batch,
    outHeight,
    outWidth,
    numChannels
  ];
  const strides = new Uint8Array(new Int32Array(util_exports2.computeStrides(image4.shape)).buffer);
  const out = backend3.makeOutput(outShape, image4.dtype);
  const outId = backend3.dataIdMap.get(out.dataId).id;
  const imageData = backend3.dataIdMap.get(image4.dataId);
  const imageId = imageData.id;
  const transformsData = backend3.dataIdMap.get(transforms.dataId);
  const transformsId = transformsData.id;
  const interpolationModeId = interpolation === "nearest" ? 1 : 2;
  let fillModeId;
  switch (fillMode) {
    case "constant":
      fillModeId = 1;
      break;
    case "reflect":
      fillModeId = 2;
      break;
    case "wrap":
      fillModeId = 3;
      break;
    case "nearest":
      fillModeId = 4;
      break;
    default:
      fillModeId = 1;
      break;
  }
  wasmTransform(imageId, transformsId, transforms.shape[0] > 1, batch, outHeight, outWidth, numChannels, imageWidth, imageHeight, strides, image4.shape.length - 1, interpolationModeId, fillModeId, fillValue, outId);
  return out;
}
var transformConfig3 = {
  kernelName: Transform2,
  backendName: "wasm",
  setupFunc: setup45,
  kernelFunc: transform5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/Unpack.ts
function unpack3(args) {
  const { inputs, backend: backend3, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const numOutputs = value.shape[axis];
  const rank = value.shape.length;
  const outShape = new Array(rank - 1);
  let outIndex = 0;
  for (let i = 0; i < rank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = value.shape[i];
    }
  }
  const outs = new Array(numOutputs);
  const begin = new Array(rank).fill(0);
  const size = value.shape.slice();
  size[axis] = 1;
  for (let i = 0; i < outs.length; i++) {
    begin[axis] = i;
    outs[i] = slice5({ inputs: { x: value }, attrs: { begin, size }, backend: backend3 });
  }
  return outs.map(({ dataId, dtype }) => ({ dataId, dtype, shape: outShape }));
}
var unpackConfig3 = {
  kernelName: Unpack2,
  backendName: "wasm",
  kernelFunc: unpack3
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/kernels/ZerosLike.ts
function zerosLike5(args) {
  const { inputs: { x }, backend: backend3 } = args;
  const out = backend3.makeOutput(x.shape, x.dtype);
  const outVals = backend3.typedArrayFromHeap(out);
  outVals.fill(0);
  return out;
}
var zerosLikeConfig3 = {
  kernelName: ZerosLike2,
  backendName: "wasm",
  kernelFunc: zerosLike5
};

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/register_all_kernels.ts
var kernelConfigs3 = [
  absConfig3,
  addConfig3,
  addNConfig3,
  allConfig3,
  anyConfig3,
  argMaxConfig3,
  avgPoolConfig3,
  batchMatMulConfig3,
  castConfig3,
  ceilConfig3,
  clipByValueConfig2,
  concatConfig3,
  conv2DConfig3,
  conv2DBackpropInputConfig3,
  cosConfig3,
  cropAndResizeConfig3,
  cumsumConfig3,
  depthToSpaceConfig3,
  depthwiseConv2dNativeConfig3,
  equalConfig3,
  expConfig3,
  expandDimsConfig3,
  fillConfig3,
  flipLeftRightConfig3,
  floorConfig3,
  floorDivConfig3,
  fusedMatMulConfig,
  fusedBatchNormConfig,
  fusedConv2DConfig3,
  fusedDepthwiseConv2DConfig3,
  gatherNdConfig3,
  gatherV2Config3,
  greaterConfig3,
  greaterEqualConfig3,
  identityConfig3,
  leakyReluConfig3,
  lessConfig3,
  lessEqualConfig3,
  logConfig3,
  logicalAndConfig3,
  maxConfig3,
  maximumConfig3,
  maxPoolConfig3,
  meanConfig3,
  minConfig3,
  minimumConfig3,
  mirrorPadConfig3,
  multiplyConfig3,
  negConfig3,
  nonMaxSuppressionV3Config3,
  nonMaxSuppressionV4Config3,
  nonMaxSuppressionV5Config3,
  notEqualConfig3,
  oneHotConfig3,
  onesLikeConfig3,
  packConfig3,
  padV2Config3,
  powConfig3,
  preluConfig3,
  prodConfig3,
  rangeConfig3,
  realDivConfig3,
  reluConfig3,
  relu6Config3,
  reshapeConfig3,
  resizeBilinearConfig3,
  reverseConfig3,
  rotateWithOffsetConfig3,
  rsqrtConfig3,
  roundConfig3,
  scatterNdConfig3,
  selectConfig3,
  sigmoidConfig3,
  sinConfig3,
  sliceConfig3,
  softmaxConfig3,
  splitVConfig3,
  sqrtConfig3,
  squareConfig3,
  squaredDifferenceConfig3,
  stepConfig3,
  stridedSliceConfig3,
  subConfig3,
  sumConfig3,
  tanConfig3,
  tanhConfig3,
  tileConfig3,
  topKConfig3,
  transformConfig3,
  transposeConfig3,
  unpackConfig3,
  zerosLikeConfig3
];
for (const kernelConfig of kernelConfigs3) {
  registerKernel2(kernelConfig);
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/flags_wasm.ts
var ENV6 = env2();
ENV6.registerFlag("WASM_HAS_SIMD_SUPPORT", async () => WebAssembly.validate(new Uint8Array([
  0,
  97,
  115,
  109,
  1,
  0,
  0,
  0,
  1,
  4,
  1,
  96,
  0,
  0,
  3,
  2,
  1,
  0,
  10,
  9,
  1,
  7,
  0,
  65,
  0,
  253,
  15,
  26,
  11
])));
ENV6.registerFlag("WASM_HAS_MULTITHREAD_SUPPORT", async () => {
  if (ENV6.get("IS_NODE")) {
    return false;
  }
  try {
    new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));
    return WebAssembly.validate(new Uint8Array([
      0,
      97,
      115,
      109,
      1,
      0,
      0,
      0,
      1,
      4,
      1,
      96,
      0,
      0,
      3,
      2,
      1,
      0,
      5,
      4,
      1,
      3,
      1,
      1,
      10,
      11,
      1,
      9,
      0,
      65,
      0,
      254,
      16,
      2,
      0,
      26,
      11
    ]));
  } catch (e) {
    return false;
  }
});

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/backend_wasm.ts
var import_tfjs_backend_wasm_threaded_simd = __toModule(require_tfjs_backend_wasm_threaded_simd());

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/wasm-out/tfjs-backend-wasm-threaded-simd.worker.js
var wasmWorkerContents = 'var Module={};function threadPrintErr(){var text=Array.prototype.slice.call(arguments).join(" ");console.error(text)}function threadAlert(){var text=Array.prototype.slice.call(arguments).join(" ");postMessage({cmd:"alert",text:text,threadId:Module["_pthread_self"]()})}var err=threadPrintErr;this.alert=threadAlert;Module["instantiateWasm"]=function(info,receiveInstance){var instance=new WebAssembly.Instance(Module["wasmModule"],info);Module["wasmModule"]=null;receiveInstance(instance);return instance.exports};function moduleLoaded(){}this.onmessage=function(e){try{if(e.data.cmd==="load"){Module["wasmModule"]=e.data.wasmModule;Module["wasmMemory"]=e.data.wasmMemory;Module["buffer"]=Module["wasmMemory"].buffer;Module["ENVIRONMENT_IS_PTHREAD"]=true;if(typeof e.data.urlOrBlob==="string"){importScripts(e.data.urlOrBlob)}else{var objectUrl=URL.createObjectURL(e.data.urlOrBlob);importScripts(objectUrl);URL.revokeObjectURL(objectUrl)}WasmBackendModuleThreadedSimd(Module).then(function(instance){Module=instance;moduleLoaded()})}else if(e.data.cmd==="objectTransfer"){Module["PThread"].receiveObjectTransfer(e.data)}else if(e.data.cmd==="run"){Module["__performance_now_clock_drift"]=performance.now()-e.data.time;Module["__emscripten_thread_init"](e.data.threadInfoStruct,0,0);var max=e.data.stackBase;var top=e.data.stackBase+e.data.stackSize;Module["establishStackSpace"](top,max);Module["_emscripten_tls_init"]();Module["PThread"].receiveObjectTransfer(e.data);Module["PThread"].setThreadStatus(Module["_pthread_self"](),1);try{var result=Module["invokeEntryPoint"](e.data.start_routine,e.data.arg);if(!Module["getNoExitRuntime"]())Module["PThread"].threadExit(result)}catch(ex){if(ex==="Canceled!"){Module["PThread"].threadCancel()}else if(ex!="unwind"){if(ex instanceof Module["ExitStatus"]){if(Module["getNoExitRuntime"]()){}else{Module["PThread"].threadExit(ex.status)}}else{Module["PThread"].threadExit(-2);throw ex}}}}else if(e.data.cmd==="cancel"){if(Module["_pthread_self"]()){Module["PThread"].threadCancel()}}else if(e.data.target==="setimmediate"){}else if(e.data.cmd==="processThreadQueue"){if(Module["_pthread_self"]()){Module["_emscripten_current_thread_process_queued_calls"]()}}else{err("worker.js received unknown command "+e.data.cmd);err(e.data)}}catch(ex){err("worker.js onmessage() captured an uncaught exception: "+ex);if(ex&&ex.stack)err(ex.stack);throw ex}};if(typeof process==="object"&&typeof process.versions==="object"&&typeof process.versions.node==="string"){self={location:{href:__filename}};var onmessage=this.onmessage;var nodeWorkerThreads=require("worker_threads");global.Worker=nodeWorkerThreads.Worker;var parentPort=nodeWorkerThreads.parentPort;parentPort.on("message",function(data){onmessage({data:data})});var nodeFS=require("fs");var nodeRead=function(filename){return nodeFS.readFileSync(filename,"utf8")};function globalEval(x){global.require=require;global.Module=Module;eval.call(null,x)}importScripts=function(f){globalEval(nodeRead(f))};postMessage=function(msg){parentPort.postMessage(msg)};if(typeof performance==="undefined"){performance={now:function(){return Date.now()}}}}';

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/backend_wasm.ts
var import_tfjs_backend_wasm = __toModule(require_tfjs_backend_wasm());
var BackendWasm = class extends KernelBackend2 {
  constructor(wasm) {
    super();
    this.wasm = wasm;
    this.dataIdNextNumber = 1;
    this.wasm.tfjs.init();
    this.dataIdMap = new DataStorage2(this, engine2());
  }
  write(values, shape, dtype) {
    const dataId = { id: this.dataIdNextNumber++ };
    this.move(dataId, values, shape, dtype, 1);
    return dataId;
  }
  numDataIds() {
    return this.dataIdMap.numDataIds();
  }
  async time(f) {
    const start = util_exports2.now();
    f();
    const kernelMs = util_exports2.now() - start;
    return { kernelMs };
  }
  move(dataId, values, shape, dtype, refCount) {
    const id = this.dataIdNextNumber++;
    if (dtype === "string") {
      const stringBytes = values;
      this.dataIdMap.set(dataId, { id, stringBytes, shape, dtype, memoryOffset: null, refCount });
      return;
    }
    const size = util_exports2.sizeFromShape(shape);
    const numBytes = size * util_exports2.bytesPerElement(dtype);
    const memoryOffset = this.wasm._malloc(numBytes);
    this.dataIdMap.set(dataId, { id, memoryOffset, shape, dtype, refCount });
    this.wasm.tfjs.registerTensor(id, size, memoryOffset);
    if (values != null) {
      this.wasm.HEAPU8.set(new Uint8Array(values.buffer, values.byteOffset, numBytes), memoryOffset);
    }
  }
  async read(dataId) {
    return this.readSync(dataId);
  }
  readSync(dataId) {
    const { memoryOffset, dtype, shape, stringBytes } = this.dataIdMap.get(dataId);
    if (dtype === "string") {
      return stringBytes;
    }
    const bytes = this.wasm.HEAPU8.slice(memoryOffset, memoryOffset + util_exports2.sizeFromShape(shape) * util_exports2.bytesPerElement(dtype));
    return typedArrayFromBuffer(bytes.buffer, dtype);
  }
  disposeData(dataId, force = false) {
    if (this.dataIdMap.has(dataId)) {
      const data = this.dataIdMap.get(dataId);
      data.refCount--;
      if (!force && data.refCount > 0) {
        return false;
      }
      this.wasm._free(data.memoryOffset);
      this.wasm.tfjs.disposeData(data.id);
      this.dataIdMap.delete(dataId);
    }
    return true;
  }
  refCount(dataId) {
    if (this.dataIdMap.has(dataId)) {
      const tensorData = this.dataIdMap.get(dataId);
      return tensorData.refCount;
    }
    return 0;
  }
  incRef(dataId) {
    const data = this.dataIdMap.get(dataId);
    if (data != null) {
      data.refCount++;
    }
  }
  floatPrecision() {
    return 32;
  }
  getMemoryOffset(dataId) {
    return this.dataIdMap.get(dataId).memoryOffset;
  }
  dispose() {
    this.wasm.tfjs.dispose();
    if ("PThread" in this.wasm) {
      this.wasm.PThread.terminateAllThreads();
    }
    this.wasm = null;
  }
  memory() {
    return { unreliable: false };
  }
  makeOutput(shape, dtype, memoryOffset) {
    let dataId;
    if (memoryOffset == null) {
      dataId = this.write(null, shape, dtype);
    } else {
      const id = this.dataIdNextNumber++;
      dataId = { id };
      this.dataIdMap.set(dataId, { id, memoryOffset, shape, dtype, refCount: 1 });
      const size = util_exports2.sizeFromShape(shape);
      this.wasm.tfjs.registerTensor(id, size, memoryOffset);
    }
    return { dataId, shape, dtype };
  }
  typedArrayFromHeap({ shape, dtype, dataId }) {
    const buffer3 = this.wasm.HEAPU8.buffer;
    const { memoryOffset } = this.dataIdMap.get(dataId);
    const size = util_exports2.sizeFromShape(shape);
    switch (dtype) {
      case "float32":
        return new Float32Array(buffer3, memoryOffset, size);
      case "int32":
        return new Int32Array(buffer3, memoryOffset, size);
      case "bool":
        return new Uint8Array(buffer3, memoryOffset, size);
      default:
        throw new Error(`Unknown dtype ${dtype}`);
    }
  }
};
function createInstantiateWasmFunc(path) {
  return (imports, callback) => {
    util_exports2.fetch(path, { credentials: "same-origin" }).then((response) => {
      if (!response["ok"]) {
        imports.env.a(`failed to load wasm binary file at '${path}'`);
      }
      response.arrayBuffer().then((binary) => {
        WebAssembly.instantiate(binary, imports).then((output) => {
          callback(output.instance, output.module);
        });
      });
    });
    return {};
  };
}
function getPathToWasmBinary(simdSupported, threadsSupported, wasmModuleFolder) {
  if (wasmPath != null) {
    return wasmPath;
  }
  let path = "tfjs-backend-wasm.wasm";
  if (simdSupported && threadsSupported) {
    path = "tfjs-backend-wasm-threaded-simd.wasm";
  } else if (simdSupported) {
    path = "tfjs-backend-wasm-simd.wasm";
  }
  if (wasmFileMap != null) {
    if (wasmFileMap[path] != null) {
      return wasmFileMap[path];
    }
  }
  return wasmModuleFolder + path;
}
async function init() {
  const [simdSupported, threadsSupported] = await Promise.all([
    env2().getAsync("WASM_HAS_SIMD_SUPPORT"),
    env2().getAsync("WASM_HAS_MULTITHREAD_SUPPORT")
  ]);
  return new Promise((resolve, reject) => {
    const factoryConfig = {};
    factoryConfig.locateFile = (path, prefix) => {
      if (path.endsWith(".worker.js")) {
        const response = wasmWorkerContents;
        const blob = new Blob([response], { type: "application/javascript" });
        return URL.createObjectURL(blob);
      }
      if (path.endsWith(".wasm")) {
        return getPathToWasmBinary(simdSupported, threadsSupported, wasmPathPrefix != null ? wasmPathPrefix : prefix);
      }
      return prefix + path;
    };
    if (customFetch) {
      factoryConfig.instantiateWasm = createInstantiateWasmFunc(getPathToWasmBinary(simdSupported, threadsSupported, wasmPathPrefix != null ? wasmPathPrefix : ""));
    }
    let initialized = false;
    factoryConfig.onAbort = () => {
      if (initialized) {
        return;
      }
      if (initAborted) {
        return;
      }
      initAborted = true;
      const rejectMsg = "Make sure the server can serve the `.wasm` file relative to the bundled js file. For more details see https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-wasm/README.md#using-bundlers";
      reject({ message: rejectMsg });
    };
    let wasm;
    if (threadsSupported && simdSupported && wasmPath == null) {
      factoryConfig.mainScriptUrlOrBlob = new Blob([`var WasmBackendModuleThreadedSimd = ` + import_tfjs_backend_wasm_threaded_simd.default.toString()], { type: "text/javascript" });
      wasm = (0, import_tfjs_backend_wasm_threaded_simd.default)(factoryConfig);
    } else {
      wasm = (0, import_tfjs_backend_wasm.default)(factoryConfig);
    }
    wasm.then((module) => {
      initialized = true;
      initAborted = false;
      const voidReturnType = null;
      module.tfjs = {
        init: module.cwrap("init", null, []),
        registerTensor: module.cwrap("register_tensor", null, [
          "number",
          "number",
          "number"
        ]),
        disposeData: module.cwrap("dispose_data", voidReturnType, ["number"]),
        dispose: module.cwrap("dispose", voidReturnType, [])
      };
      resolve({ wasm: module });
    });
  });
}
function typedArrayFromBuffer(buffer3, dtype) {
  switch (dtype) {
    case "float32":
      return new Float32Array(buffer3);
    case "int32":
      return new Int32Array(buffer3);
    case "bool":
      return new Uint8Array(buffer3);
    default:
      throw new Error(`Unknown dtype ${dtype}`);
  }
}
var wasmBinaryNames = [
  "tfjs-backend-wasm.wasm",
  "tfjs-backend-wasm-simd.wasm",
  "tfjs-backend-wasm-threaded-simd.wasm"
];
var wasmPath = null;
var wasmPathPrefix = null;
var wasmFileMap = {};
var initAborted = false;
var customFetch = false;
function setWasmPath(path, usePlatformFetch = false) {
  deprecationWarn2("setWasmPath has been deprecated in favor of setWasmPaths and will be removed in a future release.");
  if (initAborted) {
    throw new Error("The WASM backend was already initialized. Make sure you call `setWasmPath()` before you call `tf.setBackend()` or `tf.ready()`");
  }
  wasmPath = path;
  customFetch = usePlatformFetch;
}
function setWasmPaths(prefixOrFileMap, usePlatformFetch = false) {
  if (initAborted) {
    throw new Error("The WASM backend was already initialized. Make sure you call `setWasmPaths()` before you call `tf.setBackend()` or `tf.ready()`");
  }
  if (typeof prefixOrFileMap === "string") {
    wasmPathPrefix = prefixOrFileMap;
  } else {
    wasmFileMap = prefixOrFileMap;
    const missingPaths = wasmBinaryNames.filter((name) => wasmFileMap[name] == null);
    if (missingPaths.length > 0) {
      throw new Error(`There were no entries found for the following binaries: ${missingPaths.join(",")}. Please either call setWasmPaths with a map providing a path for each binary, or with a string indicating the directory where all the binaries can be found.`);
    }
  }
  customFetch = usePlatformFetch;
}

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/version.ts
var version16 = "3.7.0";

// node_modules/.pnpm/@tensorflow+tfjs-backend-wasm@3.7.0_@tensorflow+tfjs-core@3.7.0/node_modules/@tensorflow/tfjs-backend-wasm/src/base.ts
var WASM_PRIORITY = 2;
registerBackend2("wasm", async () => {
  const { wasm } = await init();
  return new BackendWasm(wasm);
}, WASM_PRIORITY);

// tfjs/tf-browser.ts
var version17 = {
  tfjs: version,
  "tfjs-core": version2,
  "tfjs-data": version3,
  "tfjs-layers": version4,
  "tfjs-converter": version5,
  "tfjs-backend-cpu": version6,
  "tfjs-backend-webgl": version7,
  "tfjs-backend-wasm": version8
};
export {
  Abs,
  Acos,
  Acosh,
  AdadeltaOptimizer,
  AdagradOptimizer,
  AdamOptimizer,
  AdamaxOptimizer,
  Add,
  AddN,
  All,
  Any,
  ArgMax,
  ArgMin,
  Asin,
  Asinh,
  Atan,
  Atan2,
  Atanh,
  AvgPool,
  AvgPool3D,
  AvgPool3DGrad,
  AvgPoolGrad,
  BackendWasm,
  BatchMatMul,
  BatchToSpaceND,
  Bincount,
  BroadcastTo,
  Callback,
  CallbackList,
  Cast,
  Ceil,
  ClipByValue,
  Complex,
  ComplexAbs,
  Concat,
  Conv2D,
  Conv2DBackpropFilter,
  Conv2DBackpropInput,
  Conv3D,
  Conv3DBackpropFilterV2,
  Conv3DBackpropInputV2,
  Cos,
  Cosh,
  CropAndResize,
  Cumsum,
  CustomCallback,
  DataStorage,
  DenseBincount,
  DepthToSpace,
  DepthwiseConv2dNative,
  DepthwiseConv2dNativeBackpropFilter,
  DepthwiseConv2dNativeBackpropInput,
  Diag,
  Dilation2D,
  Dilation2DBackpropFilter,
  Dilation2DBackpropInput,
  ENV,
  EarlyStopping,
  Einsum,
  Elu,
  EluGrad,
  Environment,
  Equal,
  Erf,
  Exp,
  ExpandDims,
  Expm1,
  FFT,
  Fill,
  FlipLeftRight,
  Floor,
  FloorDiv,
  FromPixels,
  FusedBatchNorm,
  FusedConv2D,
  FusedDepthwiseConv2D,
  GPGPUContext,
  GatherNd,
  GatherV2,
  GraphModel,
  Greater,
  GreaterEqual,
  History,
  IFFT,
  Identity,
  Imag,
  InputSpec,
  IsFinite,
  IsInf,
  IsNan,
  KernelBackend,
  LRN,
  LRNGrad,
  LayerVariable,
  LayersModel,
  LeakyRelu,
  Less,
  LessEqual,
  LinSpace,
  Log,
  Log1p,
  LogSoftmax,
  LogicalAnd,
  LogicalNot,
  LogicalOr,
  MathBackendCPU,
  MathBackendWebGL,
  Max,
  MaxPool,
  MaxPool3D,
  MaxPool3DGrad,
  MaxPoolGrad,
  MaxPoolWithArgmax,
  Maximum,
  Mean,
  Min,
  Minimum,
  MirrorPad,
  Mod,
  MomentumOptimizer,
  Multinomial,
  Multiply,
  Neg,
  NonMaxSuppressionV3,
  NonMaxSuppressionV4,
  NonMaxSuppressionV5,
  NotEqual,
  OP_SCOPE_SUFFIX,
  OneHot,
  OnesLike,
  Optimizer,
  Pack,
  PadV2,
  Pool,
  Pow,
  Prelu,
  Prod,
  RMSPropOptimizer,
  RNN,
  Range,
  Rank,
  Real,
  RealDiv,
  Reciprocal,
  Reduction,
  Relu,
  Relu6,
  Reshape,
  ResizeBilinear,
  ResizeBilinearGrad,
  ResizeNearestNeighbor,
  ResizeNearestNeighborGrad,
  Reverse,
  RotateWithOffset,
  Round,
  Rsqrt,
  SGDOptimizer,
  ScatterNd,
  Select,
  Selu,
  Sequential,
  Sigmoid,
  Sign,
  Sin,
  Sinh,
  Slice,
  Softmax,
  Softplus,
  SpaceToBatchND,
  SparseFillEmptyRows,
  SparseReshape,
  SparseSegmentMean,
  SparseSegmentSum,
  SparseToDense,
  SplitV,
  Sqrt,
  Square,
  SquaredDifference,
  Step,
  StridedSlice,
  StringNGrams,
  StringSplit,
  StringToHashBucketFast,
  Sub,
  Sum,
  SymbolicTensor,
  Tan,
  Tanh,
  Tensor,
  TensorBuffer,
  Tile,
  TopK,
  Transform,
  Transpose,
  Unique,
  Unpack,
  UnsortedSegmentSum,
  Variable,
  ZerosLike,
  _FusedMatMul,
  abs,
  acos,
  acosh,
  add2 as add,
  addN,
  all,
  any,
  argMax,
  argMin,
  asin,
  asinh,
  atan,
  atan2,
  atanh,
  avgPool,
  avgPool3d,
  backend,
  backend_util_exports as backend_util,
  basicLSTMCell,
  batchNorm,
  batchNorm2d,
  batchNorm3d,
  batchNorm4d,
  batchToSpaceND,
  bincount,
  booleanMaskAsync,
  broadcastTo,
  browser_exports as browser,
  buffer,
  callbacks,
  cast,
  ceil,
  clipByValue,
  clone,
  complex,
  concat,
  concat1d,
  concat2d,
  concat3d,
  concat4d,
  exports_constraints_exports as constraints,
  conv1d,
  conv2d,
  conv2dTranspose,
  conv3d,
  conv3dTranspose,
  copyRegisteredKernels,
  cos,
  cosh,
  cosineWindow,
  cumsum,
  customGrad,
  src_exports as data,
  denseBincount,
  deprecationWarn,
  depthToSpace,
  depthwiseConv2d,
  deregisterOp,
  device_util_exports as device_util,
  diag,
  dilation2d,
  disableDeprecationWarnings,
  dispose,
  disposeVariables,
  div,
  divNoNan,
  dot,
  dropout,
  einsum,
  elu,
  enableDebugMode,
  enableProdMode,
  enclosingPowerOfTwo,
  engine,
  env,
  equal,
  erf,
  exp,
  expandDims,
  expm1,
  eye,
  fft,
  fill,
  findBackend,
  findBackendFactory,
  floor,
  floorDiv,
  forceHalfFloat,
  fused_ops_exports as fused,
  gather,
  gatherND,
  gather_nd_util_exports as gather_util,
  getBackend,
  getGradient,
  getKernel,
  getKernelsForBackend,
  gpgpu_util_exports as gpgpu_util,
  grad,
  grads,
  greater,
  greaterEqual,
  ifft,
  imag,
  image,
  inTopKAsync,
  exports_initializers_exports as initializers,
  input,
  io_exports as io,
  irfft,
  isFinite2 as isFinite,
  isInf,
  isNaN2 as isNaN,
  keep,
  kernel_impls_exports as kernel_impls,
  exports_layers_exports as layers,
  leakyRelu,
  less,
  lessEqual,
  linalg,
  linspace,
  loadGraphModel,
  loadLayersModel,
  localResponseNormalization,
  log,
  log1p,
  logSigmoid,
  logSoftmax,
  logSumExp,
  logicalAnd,
  logicalNot,
  logicalOr,
  logicalXor,
  losses,
  matMul,
  math_exports as math,
  max,
  maxPool,
  maxPool3d,
  maxPoolWithArgmax,
  maximum,
  mean,
  memory,
  meshgrid,
  exports_metrics_exports as metrics,
  min,
  minimum,
  mirrorPad,
  mod,
  model,
  exports_models_exports as models,
  moments,
  movingAverage,
  mul,
  multiRNNCell,
  multinomial,
  neg,
  nextFrame,
  norm,
  notEqual,
  oneHot,
  ones2 as ones,
  onesLike,
  op,
  outerProduct,
  pad,
  pad1d,
  pad2d,
  pad3d,
  pad4d,
  pool,
  pow,
  prelu,
  print2 as print,
  prod,
  profile,
  rand,
  randomGamma,
  randomNormal,
  randomUniform,
  range,
  ready,
  real,
  reciprocal,
  registerBackend,
  registerCallbackConstructor,
  registerGradient,
  registerKernel,
  registerOp,
  exports_regularizers_exports as regularizers,
  relu,
  relu6,
  removeBackend,
  reshape,
  reverse,
  reverse1d,
  reverse2d,
  reverse3d,
  reverse4d,
  rfft,
  round2 as round,
  rsqrt,
  scalar,
  scatterND,
  scatter_nd_util_exports as scatter_util,
  selu,
  separableConv2d,
  sequential,
  serialization_exports as serialization,
  setBackend,
  setPlatform,
  setWasmPath,
  setWasmPaths,
  setWebGLContext,
  setdiff1dAsync,
  shared_exports as shared,
  sigmoid,
  sign,
  signal,
  sin,
  sinh,
  slice,
  slice1d,
  slice2d,
  slice3d,
  slice4d,
  slice_util_exports as slice_util,
  softmax,
  softplus,
  spaceToBatchND,
  sparse,
  sparseToDense,
  spectral,
  split,
  sqrt,
  square,
  squaredDifference,
  squeeze,
  stack,
  step,
  stridedSlice,
  string,
  sub,
  sum2 as sum,
  sumOutType,
  tan,
  tanh2 as tanh,
  tensor,
  tensor1d,
  tensor2d,
  tensor3d,
  tensor4d,
  tensor5d,
  tensor6d,
  tensor_util_exports as tensor_util,
  test_util_exports as test_util,
  tidy,
  tile,
  time,
  topk,
  train,
  transpose,
  truncatedNormal,
  unique,
  unregisterGradient,
  unregisterKernel,
  unsortedSegmentSum,
  unstack,
  upcastType,
  util_exports as util,
  valueAndGrad,
  valueAndGrads,
  variable,
  variableGrads,
  version17 as version,
  version12 as version_converter,
  version9 as version_core,
  version14 as version_cpu,
  version11 as version_layers,
  version16 as version_wasm,
  version15 as version_webgl,
  webgl,
  webgl_util_exports as webgl_util,
  where,
  whereAsync,
  zeros,
  zerosLike
};
/**
 * @license
 * Copyright 2017 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * =============================================================================
 */
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * =============================================================================
 */
/**
 * @license
 * Copyright 2019 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2020 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the License);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an AS IS BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2021 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
 * @license
 * Copyright 2021 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/**
* @license
* Copyright 2018 Google LLC. All Rights Reserved.
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
* http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
* =============================================================================
*/
/** @license See the LICENSE file. */
//# sourceMappingURL=tfjs.esm.js.map
